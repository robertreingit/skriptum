# ANCOVA 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```
```{r defs, echo = FALSE, message = FALSE, warning=FALSE}
require(emmeans)
my_tbl <- function(df, header, caption='', ...) {
  knitr::kable(df,
               booktabs = TRUE,
               digits = 2,
               col.names = header,
               caption = caption,
               linesep = '',
               ...)
}
```

In den vorhergehenden Kapiteln zu CRD bzw. CRFD haben wir uns angeschaut, wie wir den Einfluss einer oder mehrerer nominaler, unabhängiger Variablen auf eine abhängige Variable modellieren können. In diesem Zusammenhang haben wir uns auch mit der Varianzzerlegung auseinandergesetzt und immer wieder gesehen, dass diese Zerlegung auch als der Vergleich von verschiedenen Modellen miteinander betrachtet werden kann. Im Rahmen der ANCOVA führen wir jetzt wieder eine kontinuierliche Variable in unser Modell ein, wie wir das schon im Rahmen der multiplen linearen Regression getan haben. Diese zusätzliche, kontinuierliche Variable spielt dabei die Rolle einer Kontrollvariablen. Mit Hilfe dieser Kontrollvariable soll ebenfalls Varianz von $Y$ erklärt werden. Der Effekt der Kontrollvariablen auf $Y$ ist allerdings nicht das Primärinteresse der Untersuchung sondern dient nur die Präzision des Modells zu erhöhen. Letztendlich führt dies dazu, dass auch die Power der Untersuchung erhöht wird.

Ein Beispiel könnte eine Untersuchung zu Trainingseffekten sein. Aus der Literatur wissen wir bereits, das das Alter der Teilnehmerinnen und Teilnehmer eine Rolle auf den Trainingseffekt hat. Daher macht es Sinn für den Effekt des Alters im Rahmen der Modells zu kontrollieren. Das primäre Interessiere der Untersuchung liegt auf dem Effekt des Trainings. Die Variable Alter wird in diesem Fall als Kovariate bezeichnet, wodurch sich auch die Namensgebung ANCOVA als Abkürzung für Analysis of Covariance herleitet. Welche Variablen die Rolle der primären Variablen und der Kovariaten spielen ist dabei von der konkreten Untersuchung abhängig. Es kann genauso vorkommen, dass eine nominale Variable die Rolle der Kovariaten spielt und eine kontinuierliche Variable die Primärvariable der Untersuchung ist.

Konzeptionell wird durch die Integration einer Kovariaten Information über Unterschiede zwischen den beiden Gruppen die vor der Beobachtungsphase bestehen in das Modell mit einbezogen. D.h. trotzdem wir die Beobachtungseinheiten randomisiert in beispielsweise zwei Gruppen unterteilt haben, wissen wir, das das Alter einen Effekt auf die abhängige Variable hat. Bei einer perfekten, randomisierten Zuweisung sollte das Alter eigentlich keinen mehr Einfluss haben, da beide Gruppen die gleiche Altersstruktur haben sollten. Trotzdem sind wir in der Lage die Einbeziehung zusätzliche Varianz aufzuklären und können so den Effekt der Primärvariablen hoffentlich besser isolieren. Oft kann zum Beispiel der Startwert der abhängigen Variable als Kovariate verwendet werden. Die Kovariate ist dann auf der gleichen Skala wie die Zielvariable.

::: {#exm-ancova-01}
In @fien2019 wurde unter anderem der Einfluss einer Trainingsintervention auf die Gehgeschwindigkeit in einem zweiarmigen Untersuchungsdesign untersucht. Als Zielvariable wurde die Gehgeschwindigkeit nach der Interventionsphase verwendet. Um die bestehenden Unterschiede zwischen den Teilnehmerinnen und Teilnehmer vor der Untersuchung mit einzubeziehen, wurde die Gehgeschwindigkeit vor der Intervention als Kovariate verwendet.
:::

::: {#def-covariate}
## Kovariate

Eine Kovariate\index{Kovariate} ist eine Variable, die verwendet wird, um den Einfluss auf die abhängige Variable zu kontrollieren um genauere Schätzungen der Beziehungen zwischen den primären unabhängigen Variablen und der abhängigen Variable zu erhalten. 

Alternativ werden in der Literatur auch die Begriffe Störvariable (engl. nuisance factor) oder concomitant variable (engl.) verwendet. Wenn die Kovariate auf der gleichen Skala wie die Primärvariable ist, wird sie auch als commensurate (engl.) bezeichnet.
:::

Beginnen wir mit einem einfachen konzeptionellen Modell (siehe @fig-ed-ancova-01).

```{r}
#| fig-cap: "Zusammenhang einer abhängigen Variable mit einer Kovariate und einer nominalen Variable (treatment)"
#| label: fig-ed-ancova-01

dat_0 <- tibble(
  x = c(-1,1),
  A = 3*x,
  B = 3*x + 1
) |> tidyr::pivot_longer(-x, values_to='y')
ggplot(dat_0, aes(x, y, color=name)) +
  geom_line(linewidth=2) +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL) +
  scale_color_discrete("Treatment") 
```

@fig-ed-ancova-01 zeigt den Zusammenhang zwischen zwei Gruppen $A$ und $B$ und einer abhängigen Variablen DV sowie den Zusammenhang einer Kovariate ($x$-Achse) mit DV. Zwischen der Kovariaten und der DV besteht ein positiver Zusammenhang und der Effekt von Treatment $A$ ist kleiner als derjenige von Treatment $B$. Der Effekt der Kovariaten ist dabei in beiden Gruppen gleich und es besteht keine Interaktion zwischen der Kovariaten und den Gruppen. Dies führt dazu, dass die beiden Geraden parallel zueinander sind. Letztendlich haben wir dieses Modell schon bei der Besprechung der Intergration von nominalen Variablen in das multiple Regressionsmodell behandelt.

Wenn wir die beiden Gruppen miteinander vergleichen sind mehrere unterschiedliche Vergleiche möglich. Nehmen wir zum Beispiel einen Datenpunkt $P1$ aus Gruppe $A$. Dann können wir den $P1$ mit mehreren verschiedenen Datenpunkten aus Gruppe $B$ vergleichen. In @fig-ed-ancova-02 sind drei mögliche Vergleiche eingezeichnet.

```{r}
#| fig-cap: "Verschiedene Vergleiche der beiden Gruppen miteinander"
#| label: fig-ed-ancova-02

df_pts <- tibble(x = rep(0,3), xend = c(-.5,0,.5),
                 y = rep(0,3), yend = c(-.5,1,2.5))
ggplot(dat_0, aes(x, y, color=name)) +
  geom_line(linewidth=2) +
  geom_point(data = df_pts, aes(x=xend, y=yend), color = 'red', size=3) +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL) +
  scale_color_discrete("Treatment") +
  annotate("segment", x = rep(0,3),
            y = rep(0,3), 
            xend = c(-.5,0,.5),
            yend = c(-.5,1,2.5),
            arrow = arrow(length=unit(.08, 'inch'), ends = 'both',
                          type='closed')) +
  annotate("label", x = 0, y = 0, label = 'P1')

```

Letztendlich erscheint aber nur einer der Vergleiche sinnvoll, nämlich der Vergleich wenn die beiden Gruppenwerte den gleichen Wert in der Kovariate haben. Wäre zum Beispiel die Kovariate das Alter, dann würde ein Vergleich von zwei Personen die sich im Alter unterscheiden wenig sinnvoll da nicht klar ist ob ein beobachteter Unterschied zwischen den beiden Personen in der abhängigen Variable auf den Unterschied im Alter oder auf den Unterschied im Treatment zurück zu führen ist. Genau dieses Problem wird mit Hilfe der ANCOVA gelöst. Die ANCOVA liefert daher eine Antwort auf die Frage:

*Wie unterschieden sich die Gruppen voneinander, wenn sie die gleichen Werte in der Kovariate hätten?*

Schauen wir uns ein weiteres Beispiel an. In @fig-ed-ancova-03 sind diesmal Datenpunkte eingezeichnet und scheinbar ist bei der Zuweisung der Teilnehmerinnen und Teilnehmer etwas grundsätzlich schief gelaufen.

```{r}
#| fig-cap: "Probleme durch die Kovariate"
#| label: fig-ed-ancova-03

set.seed(1)
slope <- 0.2
trt <- 8
dat_1 <- tibble(
  x = rep(seq(10, 80, 10), each=2),
  trt = rep(c(trt,0), each=8),
  trt_f = factor(trt, labels=c('A','B')),
  y = slope * x + trt + rnorm(16, 0, sd=1),
)
p1 <- ggplot(dat_1, aes(x, y, color=trt_f)) +
  geom_point(size=3) +
  geom_abline(slope = slope, linetype='dashed') +
  geom_abline(slope = slope, intercept = trt, linetype='dashed') +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL) +
  scale_color_discrete("Treatment") 
p1
```

Die Personen in Gruppe $B$ haben alle einen kleineren Wert in der Kovariate als die Personen in Gruppe $A$. Gleichzeitig hat die Kovariate aber einen positiven Einfluss auf die DV. Hätte wir keine Information über die Kovariate und würden die beiden Gruppenmittelwerte miteinander vergleichen, dann würden wir wahrscheinlich keinen Unterschied zwischen den beiden Gruppen finden (siehe @fig-ed-ancova-04). 

```{r}
#| fig-cap: "Mittelwerte der Gruppen (schwarze Punkte) mit unterschiedlichen Kovariaten"
#| label: fig-ed-ancova-04

dat_1_bar <- dat_1 |> group_by(trt_f) |>
    summarize(y = mean(y), x = mean(x))
p1 + 
  geom_point(data = dat_1_bar, color='black', size=4)
```

Um die beiden Gruppen miteinander vergleichen zu können, müssen wir die Unterschiede in den Mittelwerten der Kovariaten korrigieren um die Gruppen miteinander vergleichbar zu machen. D.h. wie würden die Unterschied aussehen, wenn beide Gruppen die gleiche Verteilung in der Kovariaten hätten.

```{r}
#| fig-cap: "Vergleich der Gruppen bei koorigierten Kovariaten"
#| label: fig-ed-ancova-05

ggplot(dat_1, aes(x, y, color=trt_f)) +
  geom_point(size=3) +
  geom_abline(slope = slope, linetype='dashed') +
  geom_abline(slope = slope, intercept = trt, linetype='dashed') +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL, limits = c(0,25)) +
  scale_color_discrete("Treatment") +
  geom_point(data = dat_1 |> group_by(trt_f) |>
    summarize(y = mean(y), x = mean(x)), color='black', size=4) +
  annotate(geom = 'segment', x = dat_1_bar$x[1], xend = dat_1_bar$x[1],
          y = dat_1_bar$y[1], yend = dat_1_bar$y[1]+7,
          arrow = arrow(type = 'closed', length=unit(.15,'inch'))) +
  annotate(geom = 'segment', x = dat_1_bar$x[2], xend = dat_1_bar$x[2],
          y = dat_1_bar$y[2], yend = dat_1_bar$y[2]-7,
          arrow = arrow(type = 'closed', length=unit(.15,'inch')))
```

In @fig-ed-ancova-05 sind die eigentlich sinnvollen Vergleiche angezeigt. Dabei wird auch noch einmal klar, dass in diesem Modell sobald wir für die Werte der Kovariaten kontrolliert haben, die Position des Vergleichs unerheblich ist, da wir von einem Modell ausgehen, bei dem der Effekt der Kovariaten in beiden Gruppen gleich ist. Dies führt zu den parallelen Linien.

## Das Modell

Übertragen wir die Beispiele nun wieder in eine Modellformulierung. Letztendlich können wir, wie bereits angemerkt, das uns schon bekannte Modell aus der multiple linearen Regression anwenden.

\begin{equation}
Y_{it} = \mu + \tau_i + \beta x_{it} + \epsilon_{it} \quad \epsilon_{it} \sim \mathcal{N}(0,\sigma^2), i = 1,\ldots,K
\label{eq-ed-ancova-model}
\end{equation}

In Model \eqref{eq-ed-ancova-model} kommt dementsprechend nichts Neues dazu, sondern unser bekanntes lineares Modell. Der einzige Unterschied besteht in der Terminologie, während wir vorher $\alpha_i$ für die nominale Variable verwendet haben, wird der nominale Faktor im ANCOVA-Modell $\tau_i$ bezeichnet. Das sind aber nur Unterschiede in den Buchstaben die leider auch in der Literatur unterschiedlich verwendet werden.

Um die spätere Interpretation der Koeffizienten zu vereinfachen, wird auch oft ein in der Kovariaten zentriertes Modell verwendet. Dies hat jedoch keine Auswirkung auf das Ergebnis. Von den Werten der Kovariate wird dazu der Gesamtmittelwert $\bar{x}_{..}$ der Kovariatenwerten abgezogen.

\begin{equation}
Y_{it} = \mu + \tau_i + \beta (x_{it} - \bar{x}_{..}) + \epsilon_{it}
\label{eq-ed-ancova-model-c}
\end{equation}

Ein interessante Interpretation der ANCOVA erhalten wir, wenn wir in Formel \eqref{eq-ed-ancova-model-c} auf beiden Seiten $\mu + \tau_i$ abziehen (siehe [@casella2008, p.65]).

\begin{equation*}
Y_{it} - \beta (x_{it} - \bar{x}_{..}) = \mu + \tau_i + \epsilon_{it}
\end{equation*}

Auf der linken Seite stehen die Residuen einer einfachen Regression, die Differenz der beobachteten Werte $Y_{it}$ von denen mittels der Regression auf die Kovariate vorhergesagten Werten $\beta (x_{it} - \bar{x}_{..}$. Auf der rechten Seite haben wir das Modell der CRD. D.h. durch die ANCOVA werden die beobachteten Werte $Y_{it}$ korrigiert und dadurch deren Varianz reduziert. 

Da es sich bei der ANCOVA aber insgesamt wieder nur um eine Variante des linearen Modell handelt, ergeben sich entsprechend auch keine unbekannten Voraussetzungen:

- Experimental units sind randomisiert den $K$ Gruppen zugewiesen worden
- Varianz $\sigma^2$ ist konstant über Gruppen und Werte der Kovariate
- Die Kovariate und das Treatment sind statistisch unabhängig voneinander

Der letzte Punkte, die Unabhängigkeit zwischen dem Treatment und der Kovariate ist wichtig. Dies bedeutet, dass der Einfluss der Kovariaten sind nicht im Zusammenhang mit dem Treatment verändert. Der der ANCOVA zugrundeliegende Test beruht dann wie immer auf einen  Modellvergleich eines vollen Modell (Model \eqref{eq-ed-ancova-model}) mit einem reduzierten Modell. Das reduzierte Modell beinhaltet dann nur die Kovariate, da wir den Unterschied in Bezug auf den Effekt der Primärvariable überprüfen wollen.

\begin{align*}
y_{ij} &= \mu + \tau_{j} + \beta X_{ij} + \epsilon_{ij} \quad \text{full} \\
y_{ij} &= \mu + \beta X_{ij} + \epsilon_{ij} \quad \text{reduced}
\end{align*}

Die $H_0$ für den Treatmenteffekt ist:

\begin{equation*}
H_0: \tau_1 = \tau_2 = \cdots = tau_K = 0
\end{equation*}

Der Unterschied zwischen den Treatmentstufen wird dabei für den Wert $\bar{x}_{..}$, als den Mittelwert der Kovariate über alle Gruppenhinweg bestimmt.

Die $H_0$ für die Kovariate ist:

\begin{equation*}
H_0: \beta = 0
\end{equation*}

Das Ergebnis der Analyse wird oft auch in Form einer Varianz-Tabelle dargestellt (siehe @tbl-ed-ancova-ssq).

| Term | $df$ | $SSQ$ | $MSQ$ | F |
| --- | --- | --- | --- | --- |
| $T|\beta$ | $K-1$ | $ss(T|\beta)$ | $\frac{ss(T|\beta)}{K-1}$ | $\frac{ms(T|\beta)}{msE}$ |
| $\beta|T$ | $1$ | $ss(\beta|T)$ | $\frac{ss(\beta|T)}{1}$ | $\frac{ms(\beta|T)}{msE}$ |
| Error | $N-K-1$ | $ssE$ | $msE$ |  |

: Varianztabelle der ANCOVA {#tbl-ed-ancova-ssq} 

Die Schreibweise $T|\beta$ bezeichnet den Effekt des Treatments nachdem für die Kovariate kontrolliert wurde während $\beta|T$ den Effekt der Kovariate nachdem für das Treatment kontrolliert wurde beschreibt. Hier tritt eine Besonderheit auf, die Summe der Quadratsummen addiert sich nicht zur totalen Varianz von $Y$. Dies kommt dadurch zustande das die Quadratsummen nicht der Hierarchie folgend vom einfachsten zum vollen Modell gebildet werden, sondern Vergleiche zwischen dem vollen Modell und jeweils einem Modell bei dem die andere Variable bereits vorhanden ist durchgeführt werden. Diese Quadratsummen werden als korrigierte Quadratsummen (adjusted sums of squares) [@christensen2018, p.362] oder auch Type-II Quadratsummen bezeichnet. Dadurch verlieren die Quadratsummen ihre additive Eigenschaft. Im Spezialfall wenn beide Gruppen den gleichen Mittelwert in der Kovariaten $X$ haben, sind die Quadratsummen dann doch wieder additive. Die beiden Effekt Treatment und Kovariate sind dann orthogonal zueinander.

Schauen wir uns die Analyse in einem Spielzeugbeispiel an. In @tbl-ed-ancova-max-01 ist ein Beispieldatensatz aus @maxwell2004 abgebildet.

```{r}
#| tbl-cap: "Ein einfacher ANCOVA-Datensatz"
#| label: tbl-ed-ancova-max-01
bw <- tibble(
  id = paste0('S', 1:6),
  group = rep(c('TRT','CON'), each=3),
  x = c(1,2,3,3,4,5),
  y = c(4,9,8,12,11,16)
)
bw |> kable(
  col.names=c('ID','Gruppe','x','y'),
  caption="Beispieldaten",
  linesep = "",
  booktabs = TRUE
)
```

Wir haben zwei Gruppen (TRT und CON) mit jeweils $N = 3$ mit einer Kovariate $x$.

Ein Vergleich des vollen und des reduzierten Modells führt zu folgendem Ergebnis:

```{r}
#| tbl-cap: "Vergleich full vs. reduced model."
#| label: tbl-ed-ancova-toy-1

mod_0 <- lm(y ~ x, bw)
mod_1 <- lm(y ~ x + group, bw)
broom::tidy(anova(mod_0, mod_1)) |>
  knitr::kable(booktabs=T,
               digits=3)
```

Wie wir @tbl-ed-ancova-toy-1 sehen können finden wir keinen statistisch signifikanten Effekt für das Treatment nachdem wir für die Kovariate $X$ kontrolliert haben. Dargestellt als Varianztabelle erhalten wir die folgende Dokumentation (siehe @tbl-ed-ancova-ex-01):

```{r}
#| label: tbl-ed-ancova-ex-01
#| tbl-cap: "Varianztabelle"

car::Anova(mod_1) |> broom::tidy() |>
  dplyr::mutate(MSQ = sumsq/df, .before=4) |> 
  kable(booktabs = TRUE,
  digits = 3,
  col.names = c("Term", "SSQ","df","MSQ","F","p-Wert"))
```

Hier finden wir ebenfalls keinen statisch signifikaten Effekt für beide Variablen, die Wert für die Treatmentvariable sind in beiden Tabellen gleich. Schauen wir uns die Summe der Quadratsummen an.

```{r}
ssq <- car::Anova(mod_1) |> broom::tidy() |> dplyr::pull(sumsq)
```
$$
SSQ_x + SSQ_{\text{group}} + SSE = `r paste(ssq, collapse="+")` = `r sum(ssq)`
$$

Aber die totale Quadratsumme von $y$ ist $SST = `r var(bw$y)*5`$. D.h. die Summer der Quadratsummen addiert sich nicht zu $SST$.

Schauen wir aber rein interessehalber an, was passiert wenn wir den Treatmenteffekt gegen ein auf den $y$-Achsenabschnitt reduziertes Modell testen. Wir ignorieren die Information aus der Kovariate.

```{r}
#| label: tbl-ed-ancova-mod00
#| tbl-cap: "Modellvergleich von $y_i = \\beta_0 + \\epsilon_i$ gegen $y_i = \\beta_0 + \\tau_i + \\epsilon_i$" 

mod_0a <- lm(y ~ 1, bw)
mod_1a <- lm(y ~ group, bw)
anova(mod_0a, mod_1a) |> broom::tidy() |> 
  kable(
    booktabs = TRUE,
    digits = 4)
```

In @tbl-ed-ancova-mod00 haben wir nun einen statistisch signifikanten Effekt gefunden. Wie kann das denn sein? Schauen wir uns dazu eine graphische Darstellung der Daten an (siehe @fig-ed-ancova-mod01).

```{r}
#| fig-cap: "Streudiagramm der Rohdaten"
#| label: fig-ed-ancova-mod01

ggplot(bw, aes(x, y)) +
  geom_point(aes(pch=group), size=4) +
  scale_shape_discrete('Gruppe') +
  scale_x_continuous("Kovariate x")
```

In @fig-ed-ancova-mod01 können wir sehen, dass die beiden Gruppen sich deutlich in der Kovariate $x$ voneinander unterscheiden. Dies führt dazu, dass die Mittelwerte der beiden Gruppen auch entsprechend unterschiedlich voneinander sind. Dadurch führt ein Test für den Unterschied zwischen den beiden Gruppen dazu, dass es zu einem statistisch signifikanten Ergebnis für das Treatment kommt. Letztendlich wird dieser Unterschied nur durch die Kovariate verursacht. Wird für die Kovariate kontrolliert, dann verschwindet der Effekt (siehe @fig-ed-ancova-mod02).

```{r}
#| fig-cap: "Streudiagramm der Rohdaten mit den Geraden aus dem ANCOVA-Modell"
#| label: fig-ed-ancova-mod02

ggplot(bw, aes(x,y,color=group)) +
  geom_point(size=4) +
  geom_smooth(method='lm', se=F) +
  scale_color_discrete("Gruppe") +
  scale_x_continuous("Kovariate x")
```

In @fig-ed-ancova-mod02 sehen wir, dass wenn die beiden parallen Geraden für die Kovariate auf Basis des ANCOVA-Modells eingefügt werden, dann ist der Unterschied zwischen den beiden Gruppen deutlich geringer. Dies betont noch einmal, dass ein Vergleich nur sinnvoll ist, wenn das level der Kovariaten zwischen den beiden Gruppen gleich ist. Es wird in diesem Fall dann von adjusted means $\bar{Y}_l'$ \index{adjusted means} gesprochen. Dazu wird der Mittelwert $\bar{X}_{..}$ der Kovariaten $X$ über alle Gruppen gebildet und dann der Effekt der Gruppe berechnet.

\begin{equation*}
E[\bar{Y}_{i.}] = \mu + \tau_i + \beta\bar{x}_{..}
\label{eq-ed-ancova-adjusted-mean}
\end{equation*}

Im Beispiel werden die Gruppen daher wie folgt miteinander verglichen (siehe @fig-ed-ancova-adjusted-means)

```{r}
#| fig-cap: "Korrigierte Mittelwerte der Gruppen bei $\\bar{x}$."
#| label: fig-ed-ancova-adjusted-means

x_new <- tibble(x = mean(bw$x), group=c('TRT','CON'))
y_bar_j <- predict(mod_1, newdata = x_new)
mod_slopes <- tibble(
  x = rep(coef(mod_1)[2],2),
  y = c(coef(mod_1)[1] + c(0, coef(mod_1)[3])),
  group = c('CON','TRT'))
x_new <- x_new |> dplyr::mutate(y = y_bar_j)
ggplot(bw, aes(x,y,shape=group)) +
  geom_point(size=4) +
  geom_abline(data = mod_slopes, aes(slope=x, intercept=y),
              linetype='dashed') +
  geom_point(data = x_new, size=4, col='red') +
  annotate(geom = 'segment', x=x_new$x[1], y=x_new$y[1],
                             xend=x_new$x[2], yend=x_new$y[2],
            arrow=arrow(length=unit(0.1,"inch"), type='closed', ends='both')) +
  scale_shape_discrete("Gruppe") 
```

Wie wir an dem Beispiel sehen konnten, führt die Kombination von Mittelwerten in der Kovariaten $X$ dazu, dass der Effekt kleiner wird nachdem für die Kovariate kontrolliert wurde. Dies ist nicht immer der Fall sondern hängt davon ab, wie groß der Effekt ist und wie die Anordnung der Mittelwerte $\bar{X}_j$ in den Gruppen ist.

In @fig-ed-ancova-adjusted-means-2 ist der Fall noch mal etwas klarer dargestellt.

```{r}
#| fig-cap: "Zusammenhang zwischen der Kovariate und dem Gruppen Effekt, der sich verkleinert."
#| label: fig-ed-ancova-adjusted-means-2

gg_adjust <- function(y_1=1) {
df_g <- tibble(
  x = c(1,2,2,3),
  y = c(y_1,y_1+1,3,4),
  g = rep(letters[1:2],each=2),
  Typ = c('roh','korrigiert','korrigiert','roh'),
  xend = 1:4,
  yend = 1:4
)
df_g_2 <- tibble(
  x = 1:3, xend=1:3,
  y = rep(0,3), yend=c(y_1,max(y_1+1,3),4),
  g = letters[4:6]
)
df_g_3 <- tibble(
  x = c(0,0),
  xend = c(1,3),
  y = c(y_1,4),
  yend = c(y_1,4),
  g = letters[7:8]
)
ggplot(df_g, aes(x,y,groups=g,xend=xend,yend=yend)) +
  geom_segment(data = df_g_2, 
               linetype='dashed') +
  geom_segment(data = df_g_3) +
  geom_hline(yintercept=c(y_1+1,3), col='red', linetype='dashed') +
  geom_line(linewidth=2) +
  geom_point(mapping=aes(color = Typ), size=4) +
  scale_x_continuous("", breaks=1:3,
                     labels=c(expression(bar(X)[1]),
                              expression(bar(X)),
                              expression(bar(X)[2]))) +
  scale_y_continuous("", labels=NULL) 
}
gg_adjust()
```

Wir haben einerseits die einfachen, rohen Gruppenmittelwerte und die korrigierten Mittelwerte. In @fig-ed-ancova-adjusted-means-2 sind die einfachen Mittelwerte weiter auseinander entfernt als die korrigierten Mittelwerte. Daher wird der Effekt nach der Korrektur kleiner. Es kann aber auch der gegensätzliche Effekt eintreten. In @fig-ed-ancova-adjusted-means-3 ist dafür ein vereinfachtes Beispiel dargestellt.

```{r}
#| fig-cap: "Zusammenhang zwischen der Kovariate und dem Gruppen Effekt, der sich vergrößert."
#| label: fig-ed-ancova-adjusted-means-3

gg_adjust(3.5)
```

In @fig-ed-ancova-adjusted-means-3 sind die einfachen Gruppenmittelwerte näher zusammen als dies der Fall bei den korrigierten Mittelwerten der Fall. Darin können wir sehen, dass nicht immer direkt klar ist in welche Richtung sich die Effekte verändern, wenn für eine Kovariate kontrolliert wird. Die Veränderung des Effekts hängt mit dem Zusammenhang zwischen der Kovariate und der abhängigen Variable $\beta$, dem Abstand der Mittelwerte der Kovariate $\bar{X}_i$ in den Gruppen und natürlich dem tatsächlichen Effekt $\tau_i$ zusammen.

## Analyse einer ANCOVA in `R`

Für die Analyse in `R` können wir die üblichen Herangehensweise mittels `lm()` verwenden. Einzig, wenn wir die Varianztabelle nach dem Muster in @tbl-ed-ancova-ssq erzeugen wollen und nicht von Hand die Modellvergleiche durchführen wollen, müssen wir auf die Funktion `ANOVA()` aus dem package `car` zurückgreifen. Beispielweise für das Spielzeugbeispiel (Daten sind im `tibble` `bw`) ergibt sich der folgende Code:

```{r}
#| echo: true

mod <- lm(y ~ group + x, bw)
car::Anova(mod)
```

Über die Modellvergleiche:

```{r}
#| echo: true

mod_full <- lm(y ~ group + x, bw)
mod_r1 <- lm(y ~ group, bw)
mod_r2 <- lm(y ~ x, bw)
anova(mod_r1, mod_full)
anova(mod_r2, mod_full)
```

Wenn wir die Standard-`anova()`-Funktion auf das `lm`-Modell anwenden erhalten wir einen sequentiellen Modellvergleich bei dem es darauf ankommt in welcher Reihenfolge wir die unabhängigen Variablen in das Modell eingefügt haben.

```{r}
#| echo: true

mod_g_x <- lm(y ~ group + x , bw)
mod_x_g <- lm(y ~ x + group , bw)
anova(mod_g_x)
anova(mod_x_g)
```

## Effektstärke bei der ANCOVA

Für die ANCOVA können wir natürlich auch wieder eine Effektstärke berechnen. Wir verwenden wieder eine $\Omega^2$-Typ Effektstärke für den Gesamteffekt des Modells (siehe Formel \eqref{ed-ancova-omega_sqr}.

\begin{equation}
\hat{\omega}^2=\frac{df_{\text{effect}}(MS_{\text{effect}}-MS_{\text{error}})}{SS_{\text{total}}+MS_{\text{error}}}
\label{ed-ancova-omega_sqr}
\end{equation}

Für das Spielzeugbeispiel erhalten wir den folgenden Wert:

$$
\hat{\omega}^2 = \frac{1(2.4 - 4)}{82 + 4} = `r round(1*(2.4-4)/(82+4),2)`
$$

Per Konvention wird bei $\hat{\omega}^2 < 0$ der Wert auf $0$ gekappt. D.h. in diesem Fall ist die Effektstärke gleich $0$. Die Effektstärke wird dabei bei Vernachlässigung der Kovariaten bestimmt. Die Kovariate wird als intrinsische Variable betrachtet und daher gehört die durch die Kovariate verursachte Varianz zur Varianz der abhängigen Variablen. Daher wird bei der ANCOVA der Gesamteffekt unter Einbeziehung der Kovariatenvarianz berechnet. D.h. es wird nicht der partielle Effekt bestimmt.

Wenn wir die Effektstärke in `R` berechnen wollen, können wir wieder auf das package `effectsize` zurückgreifen und die `omega_squared()` Funktion anwenden. Hierbei sollte der Parameter `partial` wieder auf `FALSE` gesetzt werden um den globalen Effekt zu berechnen. 

```{r}
#| echo: true

effectsize::omega_squared(mod_1, partial=F)
```

## Mehrfachvergleiche bei der ANCOVA

Sollten wir einen statistisch signifikanten Effekt für die Treatmentvariable gefunden haben, dann können wir, wie üblich, auch Mehrfachvergleiche über Kontraste $\Psi_i$ berechnen. Dies macht nur Sinn wenn $K>2$ gilt, da ansonsten der einzelne $\tau_i$-Koeffizient im Modell direkt den Vergleich der beiden Gruppen gibt. Auf die Herleitung der Varianz der Kontraste verzichten wir hier, da sich außer umfangreicher Algebra nichts grundlegendes Neues ergibt. Die Varianz für einen Kontrast $\Psi_i$ besitzt einen zusätzlichen Term für den Einfluss der Kovariate $X$.

$$
Var\left(\sum_{i}c_i \hat{\tau_i}\right) = MSE\left(\sum_i\frac{c_i^2}{r_i} + \frac{(\sum_i c_i \bar{x}_{i.})^2}{\sum_{i=1}^K \sum_{t=1}^{r_i} (x_{it}-\bar{x}_{i.})^2} \right)
$$
Der interessante Punkte hier, das die Varianz mit dem Abstand der Mittelwerte der Kovariate in den Gruppen $\bar{x}_{i.}$ größer wird. Deshalb ist eine möglichst ähnliche Verteilung der Kovariaten in den Gruppen zu bevorzugen. Um das nominelle Signifikanzniveau dann wieder für Mehrfachtestung zu kontrollieren können entweder eine Bonferroni- (pre-planned) oder die die Scheffé-Methode verwendet werden. Für die Tukey-Methode gibt es keinen geschlossenen Beweis, obwohl wahrscheinlich auch die Tukey-Methode möglich ist [vgl. @dean1999, p.294].

## Mehrfachvergleiche in `R`

Um Mehrfachvergleiche in `R` durchzuführen, verwenden wir wieder das `emmeans`-package. Schauen wir uns dazu ein Beispiel hypothetisches Beispiel aus [@maxwell2004, p.429] mit drei Stufen für die Treatmentvariable an (siehe @fig-ed-ancova-max-01). Es wurde drei Patientengruppen mit Depression in drei Gruppen unterteilt. Eine Gruppe fungierte als Kontrollgruppe (`wait list`), eine Gruppe bekam ein Medikament (SSRI) und eine Gruppe bekam ein Placebo. Die Patienten wurde vor und nach dem Treatment auf einer Depressionskala (BDI depression score) getestet.

```{r}
#| fig-cap: "Depression Beispiel aus Maxwell et al. (2004, p.429)"
#| label: fig-ed-ancova-max-01

tbl_97 <- readr::read_delim('data/maxwell_tbl_9_7.csv',
                     delim = ',', trim_ws = TRUE) |> 
  mutate(Condition = factor(Condition,
                            levels = 1:3,
                            labels = c('SSRI','Placebo','Wait list'))) |> 
  mutate(id = paste0('P',1:n()), .before = 1) |> 
  pivot_longer(-c(id, Condition), names_to = 'time', values_to = 'bdi') |> 
  mutate(time = factor(time, levels = c('Pre','Post')))
ggplot(tbl_97, aes(Condition, bdi, fill=time)) + 
  geom_boxplot() +
  scale_fill_discrete('Zeit') +
  labs(x = 'Kondition', y = 'BDI depression score')
```

Da davon auszugehen ist, dass die Schwere der Depression vor Beginn der Untersuchung einen Einfluss auf das Ergebnis hat, wurde die Eingangsmessung als eine Kovariate behandelt (commensurate covariate). Die Analyse der Daten (in `tibble` `bdi_w`) führte zu folgendem Ergebnis:

```{r}
bdi_w <-tbl_97 |>
  pivot_wider(id_cols = c(id,Condition), names_from=time, values_from=bdi) 
```

```{r}
#| echo: true
#| lst-label: lst-ed-ancova-max-ex
#| lst-cap: "Ergebnis der ANCOVA-Analyse"

mod_bdi <- lm(Post ~ Pre + Condition, bdi_w)
car::Anova(mod_bdi)
```

Es wurde ein statistisch signifikanter Effekt für die Gruppenzugehörigkeit gefunden. Den nachfolgenden Mehrfachvergleich können wir für die paarweisen Vergleiche wie folgt wieder mittels `emmeans()` berechnen.

```{r}
#| echo: true

bdi_em <- emmeans(mod_bdi, ~Condition)
pairs(bdi_em, infer=T, adjust='scheffe')
```

D.h. wir finden nur für den Kontrast zwischen der medikamentös behandelten Gruppe und der Kontrollgruppe einen statistisch signifikanten Effekt. An dem Beispiel können wir auch schön sehen, wie das ANCOVA-Modell eine Alternative darstellt um Daten zu analysieren die traditionell eher unter Repeated measures Designs fallen. Tatsächlich lässt sich zeigen, dass unter relativ milden, realistischen Annahmen die ANCOVA eine hohe Power für diese Designs besitzt [siehe @wan2021; @wan2020].

### Effektstärken für paarweise Vergleiche

Oft möchten wir für paarweise Vergleiche eine Cohen's D-artige Effektstärke berechnen. Dazu werden die sogenannte standardized differences between means \index{standardized differences between means} verwendet. Der einzige Schritt der etwas problematischer ist, ist die Berechnung der Standardabweichung. Hier wird auch wieder die Restvarianz $MS_W$ ohne die Reduktion durch die Kovariate $X$ verwendet.

\begin{equation}
\hat{d} = \frac{\bar{Y}_l' - \bar{Y}_m'}{\sqrt{MS_W}}
\label{eq-ed-ancova-sdbw}
\end{equation}

Für die Berechnung von $MS_W$ muss ein lineares Modell ohne die Kovariate $X$ gefittet werden und der Term $MSE$ aus diesem Modell wird als $MS_W$ verwendet. Alternativ kann mit Hilfe der Werte aus dem ANCOVA Modell die folgende Formel verwendet werden: $MS_W = \sqrt{(SS_X + SS_{\text{error}})/(N-K)}$.

In `R` kann dies wie folgt mittels der Funktion `eff_size()` wieder aus dem package `emmeans` berechnet werden:

```{r}
#| echo: true

y_bars <- emmeans(mod_bdi, ~Condition)
mod_r <- lm(Post ~ Condition, bdi_w)
eff_size(y_bars, sigma = sigma(mod_r), edf = df.residual(mod_r))
```

Unter Verwendung der Varianztabelle (siehe @lst-ed-ancova-max-ex) aus der ANCOVA können die standardized differences between means äquivalent wie folgt berechnet werden.

```{r}
#| echo: true

df_W <- 30 - 3
MS_W <- sqrt((756.33 + 313.37)/df_W)
eff_size(y_bars, sigma = MS_W, edf = df_W)
```

## Bestimmung der Anzahl der Replikationen 

Der Vorteil der ANCOVA besteht nun darin, dass durch die Korrelation der Kovariate mit der abhängigen Variable zusätzliche Varianz aufgeklärt werden kann. Daher umso stärker der Zusammenhang ist zwischen $X$ und der abhängigen Variable umso mehr Varianz in $Y$ kann aufgeklärt werden und umso höher ist die Power des Modells. Dementsprechend kann im Prinzip die gleiche Berechnung wie beim CRD angewendet werden wobei die Residualvarianz um Korrelation $\rho_{xy}$ zwischen der Kovariate $X$ und $Y$ vermindert wird. Formal folgt:

\begin{align*}
\sigma_{\epsilon(\text{ANCOVA})}^2 &= \sigma_{\epsilon(\text{CRD})}^2(1-\rho_{xy}^2) \\
f_{\text{ANCOVA}} &= \frac{\sigma_{\text{btw}}}{\sigma_{\epsilon(\text{CRD})}}\frac{1}{\sqrt{1-\rho_{xy}^2}} = \frac{f_{\text{CRD}}}{\sqrt{1-\rho_{xy}^2}} 
\end{align*}

Um den gleichen Ansatz wie beim CRD zu verwenden müssen dann lediglich noch die Freiheitsgrade angepasst werden mittels $df_{\text{Residual}} = N - K - 1$ aus dem ANCOVA-Modell.

::: {#exm-ed-ancova-sample-size} 
Also beispielsweise in einer CRD-Studie wurde eine Effektstärke für den Unterschied zwischen drei Gruppen ($K = 3$) von $f = 0.41$ gefunden. Wie verändert sich die notwendige Stichprobengröße wenn eine Kovariate mit einer Korrelation von $\rho_{xy} = 0.5$ mit der abhängigen Variable hinzugenommen wird? Um eine power von $pow = 0.8$ zu erreichen wird im CRD zunächst die folgende Stichprobengröße benötigt:

```{r}
#| echo: true

pwr::pwr.anova.test(k=3, f=0.41, sig.level=0.05, power=0.8)$n
```

D.h. es ist eine Stichprobengröße von $N_i = 21$ pro Gruppe notwendig um im CRD eine Power von $pow = 0.8$ zu erreichen. Wenn nun die Kovariate $X$ in das Modell integriert wird, erhöht sich die Effektstärke von $f = 0.41$ auf $f = 0.41/\sqrt{1-0.5^2} = 0.47$. Daraus resultiert dann eine reduzierte Stichprobengröße von:

```{r}
#| echo: true

pwr::pwr.anova.test(k=2, f=0.47, sig.level=0.05, power=0.8)$n
```

D.h. im ANCOVA-Modell wird nur noch eine Stichprobengröße von $N_i = 19$ pro Gruppe benötigt. 
:::

Das Prinzip sollte daher eigentlich einleuchtend sein, durch die Modellierung der Kovariate $X$ vermindert sich Residualvarianz was dann bei einer gegebenen Effektstärke zu einer Vergrößerung der standardisierten Effektstärke führt.

::: {#exm-ed-ancova-fien-02}
Schließen wir die ANCOVA noch einmal mit einer Reproduktion der Ergebnisse aus @fien2019 ab und versuchen die Ergebnisse in Tabelle 4 zu replizieren. Die Daten aus der Publikation sind in der Datei `fien_2019_part.txt` gespeichert.

```{r}
#| echo: true

df_small <- readr::read_delim('data/fien_2019_parts.txt', delim = '\t')
mod <- lm(gaitspeed24week ~ gaitspeedbaseline + chronicdiseases + exercise,
          data = df_small)
summary(mod)
confint(mod) |> round(3)
```

Wenn wir die berechneten Werte mit denen aus Tabelle 4 aus @fien2019 vergleichen, sehen wir, dass wir zum gleichen Ergebnis kommen.
:::

## ANCOVA mit Interaktionseffekt 

Tatsächlich kann es auch vorkommen, dass der Einfluss der Kovariaten $X$ in den Gruppen nicht gleich ist. D.h. das Treatment und die Kovariate nicht unabhänngig voneinander sind. In diesem Fall könnte z.B. der folgende Effekt eintreten (siehe @fig-ed-ancova-inter-01).

```{r}
#| fig-cap: "Beispiel für einen Interaktionseffekt zwischen der Treatmentvariablen und der Kovariate"
#| label: fig-ed-ancova-inter-01 

n <- 60
set.seed(1)
foo <- function(x,g) 3 + 2*g + 3*x + g*x 
df_i <- tibble(
  x = runif(n, -3, 3),
  g = sample(-1:1, n, replace=T),
  y = foo(x,g) + rnorm(length(x)),
  gruppe = LETTERS[1:3][g+2]
)
p_1 <- ggplot(df_i, aes(x,y,color=gruppe)) + 
  geom_point(size=2) +
  geom_smooth(method='lm', se=F, formula=y~x) +
  scale_color_manual('Gruppe', values=c('dark red','green','blue')) +
  labs(x = 'X', y = 'Y') 
print(p_1)
```

Hier sehen wir, dass die Steigungen in den drei Gruppen unterschiedlich sind. Das Modell haben wir schon vorher bei der multiplen linearen Regression gesehen, wir haben ein Interaktionsmodell.

\begin{equation}
y_{it} = \beta_0 + \tau_i + \beta \cdot x_{it} + (\tau\beta)_{it}x_{it} + \epsilon_{it}
\label{eq-ed-ancova-inter}
\end{equation}

Im Prinzip bleibt bei der Analyse alles gleich. Es ergibt sich aber ein Problem wenn die Unterschied zwischen den drei Gruppen untersucht werden, da diese davon abhängigen für welchen Wert der Kovariate der Unterschied untersucht wird. In @fig-ed-ancova-inter-02 ist dieser Fall angezeigt.

```{r}
#| fig-cap: "Vergleiche der Gruppe A mit Gruppe C für verschiedene Werte der Kovariaten $X$"
#| label: fig-ed-ancova-inter-02

p_1 +
  annotate(geom = 'segment',
            x=c(-1,-1), xend=c(-1,-1),
            y=foo(c(-1,-1),-1), yend=foo(c(-1,-1),1),
            arrow = arrow(type = 'closed', length=unit(.1,'inch'),
                    ends='both')) +
  annotate(geom = 'segment',
            x=c(2,2), xend=c(2,2),
            y=foo(c(2,2),-1), yend=foo(c(2,2),1),
            arrow = arrow(type = 'closed', length=unit(.1,'inch'),
                    ends='both')) 
```

In @fig-ed-ancova-inter-02 ist klar zu erkennen, dass in Abhängigkeit vom Wert der Kovariaten $X$ der Unterschied zwischen den Gruppen sehr unterschiedlich ausfällt. Wollten wir zum Beispiel die Unterschiede zwischen den Gruppen für die Werte der Kovariaten $X$ für $X = [-2,0,2]$ berechnen dann könnten wir das in `R` mittels `emmeans()` wie folgt durchführen:

```{r}
#| echo: true
 
mod <- lm(y ~ x*gruppe, df_i)
mod_ems <- emmeans(mod, ~gruppe|x, at=list(x=c(-2,0,2)))
pairs(mod_ems, adjust='bonferroni')
```

Damit solche Vergleiche sinnvoll sind, müssten die jeweiligen Werte für die Kovariaten schon im voraus möglichst bekannt sein bzw. festgelegt worden sein.

## Zusammenfassung

In der Herleitung und den Beispielen haben wir ANCOVAs mit nur einer Kovariate $X$ und einem Treatmentfaktor $\tau_i$ uns angeschaut. Die ANCOVA ist aber nicht nur auf diesen Fall beschränkt sondern es können problemlos auch mehrere Kovariaten $X_i, \ldots, X_p$ in das Modell nach dem genau gleichen Prinzip intergriert werden. Genauso kann die ANCOVA auch mit einem CRFD kombiniert werden und es kann eine kompliziertere Treatmenstruktur mit mehreren Faktoren verwendet werden. Ein Beispiel ist in @duncan2017 zu finden wo mehrere ANCOVAs gerechnet wurden um Körperkomposition in Abhängigkeit von Gender und Bewegungsfertigkeiten (high, medium, low) zu modellieren mit Alter, Alter beim maximalen Wachstumsschub und körperliche Aktivität als Kovariaten. Diese flexiblen Möglichkeiten machen die ANCOVA zu einem sehr mächtigen Verfahren. Wie schon mehrfach betont, ist die ANCOVA dabei nichts anderes als ein allgemeines lineares Modell.

## Zum Nach- und Weiterlesen

Ein gute Quelle um noch einmal die Grundlagen zur ANCOVA zu verstehen ist @maxwell2004. Genauere Information zur ANCOVA für pre-post Untersuchungen sind in @wan2021 und @wan2020 zu finden.

