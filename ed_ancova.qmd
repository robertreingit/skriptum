# ANCOVA 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```
```{r defs, echo = FALSE, message = FALSE, warning=FALSE}
require(emmeans)
my_tbl <- function(df, header, caption='', ...) {
  knitr::kable(df,
               booktabs = TRUE,
               digits = 2,
               col.names = header,
               caption = caption,
               linesep = '',
               ...)
}
```

In den vorhergehenden Kapiteln zu CRD bzw. CRFD haben wir uns angeschaut, wie wir den Einfluss einer oder mehrerer nominaler, unabhängiger Variablen auf eine abhängige Variable modellieren können. In diesem Zusammenhang haben wir uns auch mit der Varianzzerlegung auseinandergesetzt und immer wieder gesehen, dass diese Zerlegung auch als der Vergleich von verschiedenen Modellen miteinander betrachtet werden kann. Im Rahmen der ANCOVA führen wir jetzt wieder eine kontinuierliche Variable in unser Modell ein, wie wir das schon im Rahmen der multiplen linearen Regression getan haben. Diese zusätzliche, kontinuierliche Variable spielt dabei die Rolle einer Kontrollvariablen. Mit Hilfe dieser Kontrollvariable soll ebenfalls Varianz von $Y$ erklärt werden. Der Effekt der Kontrollvariablen auf $Y$ ist allerdings nicht das Primärinteresse der Untersuchung sondern dient nur die Präzision des Modells zu erhöhen. Letztendlich führt dies dazu, dass auch die Power der Untersuchung erhöht wird.

Ein Beispiel könnte eine Untersuchung zu Trainingseffekten sein. Aus der Literatur wissen wir bereits, das das Alter der Teilnehmerinnen und Teilnehmer eine Rolle auf den Trainingseffekt hat. Daher macht es Sinn für den Effekt des Alters im Rahmen der Modells zu kontrollieren. Das primäre Interessiere der Untersuchung liegt auf dem Effekt des Trainings. Die Variable Alter wird in diesem Fall als Kovariate bezeichnet, wodurch sich auch die Namensgebung ANCOVA als Abkürzung für Analysis of Covariance herleitet. Welche Variablen die Rolle der primären Variablen und der Kovariaten spielen ist dabei von der konkreten Untersuchung abhängig. Es kann genauso vorkommen, dass eine nominale Variable die Rolle der Kovariaten spielt und eine kontinuierliche Variable die Primärvariable der Untersuchung ist.

Konzeptionell wird durch die Integration einer Kovariaten Information über Unterschiede zwischen den beiden Gruppen die vor der Beobachtungsphase bestehen in das Modell mit einbezogen. D.h. trotzdem wir die Beobachtungseinheiten randomisiert in beispielsweise zwei Gruppen unterteilt haben, wissen wir, das das Alter einen Effekt auf die abhängige Variable hat. Bei einer perfekten, randomisierten Zuweisung sollte das Alter eigentlich keinen mehr Einfluss haben, da beide Gruppen die gleiche Altersstruktur haben sollten. Trotzdem sind wir in der Lage die Einbeziehung zusätzliche Varianz aufzuklären und können so den Effekt der Primärvariablen hoffentlich besser isolieren. Oft kann zum Beispiel der Startwert der abhängigen Variable als Kovariate verwendet werden. Die Kovariate ist dann auf der gleichen Skala wie die Zielvariable.

::: {#exm-ancova-01}
In @fien2019 wurde unter anderem der Einfluss einer Trainingsintervention auf die Gehgeschwindigkeit in einem zweiarmigen Untersuchungsdesign untersucht. Als Zielvariable wurde die Gehgeschwindigkeit nach der Interventionsphase verwendet. Um die bestehenden Unterschiede zwischen den Teilnehmerinnen und Teilnehmer vor der Untersuchung mit einzubeziehen, wurde die Gehgeschwindigkeit vor der Intervention als Kovariate verwendet.
:::

::: {#def-covariate}
## Kovariate

Eine Kovariate\index{Kovariate} ist eine Variable, die verwendet wird, um den Einfluss auf die abhängige Variable zu kontrollieren um genauere Schätzungen der Beziehungen zwischen den primären unabhängigen Variablen und der abhängigen Variable zu erhalten. 

Alternativ werden in der Literatur auch die Begriffe Störvariable (engl. nuisance factor) oder concomitant variable (engl.) verwendet. Wenn die Kovariate auf der gleichen Skala wie die Primärvariable ist, wird sie auch als commensurate (engl.) bezeichnet.
:::

Beginnen wir mit einem einfachen konzeptionellen Modell (siehe @fig-ed-ancova-01).

```{r}
#| fig-cap: "Zusammenhang einer abhängigen Variable mit einer Kovariate und einer nominalen Variable (treatment)"
#| label: fig-ed-ancova-01

dat_0 <- tibble(
  x = c(-1,1),
  A = 3*x,
  B = 3*x + 1
) |> tidyr::pivot_longer(-x, values_to='y')
ggplot(dat_0, aes(x, y, color=name)) +
  geom_line(linewidth=2) +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL) +
  scale_color_discrete("Treatment") 
```

@fig-ed-ancova-01 zeigt den Zusammenhang zwischen zwei Gruppen $A$ und $B$ und einer abhängigen Variablen DV sowie den Zusammenhang einer Kovariate ($x$-Achse) mit DV. Zwischen der Kovariaten und der DV besteht ein positiver Zusammenhang und der Effekt von Treatment $A$ ist kleiner als derjenige von Treatment $B$. Der Effekt der Kovariaten ist dabei in beiden Gruppen gleich und es besteht keine Interaktion zwischen der Kovariaten und den Gruppen. Dies führt dazu, dass die beiden Geraden parallel zueinander sind. Letztendlich haben wir dieses Modell schon bei der Besprechung der Intergration von nominalen Variablen in das multiple Regressionsmodell behandelt.

Wenn wir die beiden Gruppen miteinander vergleich sind mehrer unterschiedliche Vergleiche möglich. Nehmen wir zum Beispiel einen Datenpunkt $P1$ aus Gruppe $A$. Dann können wir den $P1$ mit mehreren verschiedenen Datenpunkten aus Gruppe $B$ vergleichen. In @fig-ed-ancova-02 sind drei mögliche Vergleiche eingezeichnet.

```{r}
#| fig-cap: "Verschiedene Vergleiche der beiden Gruppen miteinander"
#| label: fig-ed-ancova-02

df_pts <- tibble(x = rep(0,3), xend = c(-.5,0,.5),
                 y = rep(0,3), yend = c(-.5,1,2.5))
ggplot(dat_0, aes(x, y, color=name)) +
  geom_line(linewidth=2) +
  geom_point(data = df_pts, aes(x=xend, y=yend), color = 'red', size=3) +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL) +
  scale_color_discrete("Treatment") +
  annotate("segment", x = rep(0,3),
            y = rep(0,3), 
            xend = c(-.5,0,.5),
            yend = c(-.5,1,2.5),
            arrow = arrow(length=unit(.08, 'inch'), ends = 'both',
                          type='closed')) +
  annotate("label", x = 0, y = 0, label = 'P1')

```

Letztendlich erscheint aber nur einer der Vergleiche sinnvoll, nämlich der Vergleich wenn die beiden Gruppenwerte den gleichen Wert in der Kovariate haben. Wäre zum Beispiel die Kovariate das Alter, dann würde ein Vergleich von zwei Personen die sich im Alter unterscheiden wenig sinnvoll da nicht klar ist ob der Unterschied in der abhängigen Variable auf den Unterschied im Alter oder auf den Unterschied im Treatment zurück zu führen ist. Genau dieses Problem wird mit Hilfe der ANCOVA gelöst und die ANCOVA liefert eine Antwort auf die Frage:

*Wie unterschieden sich die Gruppen voneinander, wenn sie die gleichen Werte in der Kovariate hätten?*

Schauen wir uns ein weiteres Beispiel an. In @fig-ed-ancova-03 sind diesmal Datenpunkte eingezeichnet und scheinbar ist bei der Zuweisung der Teilnehmerinnen und Teilnehmer etwas grundsätzlich schief gelaufen.

```{r}
#| fig-cap: "Probleme durch die Kovariate"
#| label: fig-ed-ancova-03

set.seed(1)
slope <- 0.2
trt <- 8
dat_1 <- tibble(
  x = rep(seq(10, 80, 10), each=2),
  trt = rep(c(trt,0), each=8),
  trt_f = factor(trt, labels=c('A','B')),
  y = slope * x + trt + rnorm(16, 0, sd=1),
)
p1 <- ggplot(dat_1, aes(x, y, color=trt_f)) +
  geom_point(size=3) +
  geom_abline(slope = slope, linetype='dashed') +
  geom_abline(slope = slope, intercept = trt, linetype='dashed') +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL) +
  scale_color_discrete("Treatment") 
p1
```

Die Personen in Gruppe $B$ haben alle einen kleineren Wert in der Kovariate als die Personen in Gruppe $A$. Gleichzeitig hat die Kovariate aber einen positiven Einfluss auf die DV. Hätte wir keine Information über die Kovariate und würden die beiden Gruppenmittelwerte miteinander vergleichen, dann würden wir wahrscheinlich keinen Unterschied zwischen den beiden Gruppen finden (siehe @fig-ed-ancova-04). 

```{r}
#| fig-cap: "Mittelwerte der Gruppen (schwarze Punkte) mit unterschiedlichen Kovariaten"
#| label: fig-ed-ancova-04

dat_1_bar <- dat_1 |> group_by(trt_f) |>
    summarize(y = mean(y), x = mean(x))
p1 + 
  geom_point(data = dat_1_bar, color='black', size=4)
```

Um die beiden Gruppen miteinander vergleichen zu können müssten wir die Unterschiede in den Mittelwerten der Kovariaten korrigieren um die Gruppen zu vergleichen wenn sie die gleiche Verteilung in der Kovariaten hätten.

```{r}
#| fig-cap: "Vergleich der Gruppen bei koorigierten Kovariaten"
#| label: fig-ed-ancova-05

ggplot(dat_1, aes(x, y, color=trt_f)) +
  geom_point(size=3) +
  geom_abline(slope = slope, linetype='dashed') +
  geom_abline(slope = slope, intercept = trt, linetype='dashed') +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL, limits = c(0,25)) +
  scale_color_discrete("Treatment") +
  geom_point(data = dat_1 |> group_by(trt_f) |>
    summarize(y = mean(y), x = mean(x)), color='black', size=4) +
  annotate(geom = 'segment', x = dat_1_bar$x[1], xend = dat_1_bar$x[1],
          y = dat_1_bar$y[1], yend = dat_1_bar$y[1]+7,
          arrow = arrow(type = 'closed', length=unit(.15,'inch'))) +
  annotate(geom = 'segment', x = dat_1_bar$x[2], xend = dat_1_bar$x[2],
          y = dat_1_bar$y[2], yend = dat_1_bar$y[2]-7,
          arrow = arrow(type = 'closed', length=unit(.15,'inch')))
```

In @fig-ed-ancova-05 sind die eigentlich sinnvollen Vergleiche angezeigt. Dabei wird auch noch einmal klar, dass in diesem Modell sobald wir für die Werte der Kovariaten kontrolliert haben, die Position des Vergleichs unerheblich ist, da wir von einem Modell ausgehen, bei dem der Effekt der Kovariaten in beiden Gruppen gleich ist. Dies führt zu den parallelen Linien.

## Modell der ANCOVA

Übertragen wir die Beispiele in eine Modellformulierung. Letztendlich können wir, wie schon angemerkt, das uns schon bekannte Modell aus der multiple linearen Regression anwenden.

\begin{equation}
Y_{it} = \mu + \tau_i + \beta x_{it} + \epsilon_{it} \quad \epsilon_{it} \sim \mathcal{N}(0,\sigma^2), i = 1,\ldots,K
\label{eq-ed-ancova-model}
\end{equation}

In Model \eqref{eq-ed-ancova-model} kommt dementsprechend nichts Neues dazu, sondern unser standard lineares Modell. Der einzige Unterschied besteht in der Terminologie, während wir vorher $\alpha_i$ für die nominale Variable verwendet haben, wird der nominale Faktor im ANCOVA-Modell $\tau_i$ bezeichnet. Das sind aber nur Unterschied in den Buchstaben die leider auch nicht konsequent in der Literatur verwendet werden.

Um die spätere Interpretation der Koeffizienten zu vereinfachen, wird auch oft ein in der Kovariaten zentriertes Modell verwendet. Dies hat jedoch keine Auswirkung auf das Ergebnis.

\begin{equation}
Y_{it} = \mu^* + \tau_i + \beta (x_{it} - \bar{x}_{..}) + \epsilon_{it}
\label{eq-ed-ancova-model-c}
\end{equation}

Entsprechend ergeben sich auch keine unbekannten Voraussetzungen:

- Experimental units sind randomisiert den $K$ Gruppen zugewiesen worden
- Varianz $\sigma^2$ ist konstant über Gruppen und Werte der Kovariate
- Die Kovariate und das Treatment sind statistisch unabhängig voneinander

Der der ANCOVA zugrundeliegende Test beruht dann wie immer auf einen  Modellvergleich eines vollen Modell (Model \eqref{eq-ed-ancova-model}) mit einem reduzierten Modell. Das reduzierte Modell beinhaltet dann nur die Kovariate, da wir den Unterschied in Bezug auf den Effekt der Primärvariable überprüfen wollen.

\begin{align*}
y_{ij} &= \mu + \tau_{j} + \beta X_{ij} + \epsilon_{ij} \quad \text{full} \\
y_{ij} &= \mu + \beta X_{ij} + \epsilon_{ij} \quad \text{reduced}
\end{align*}

Die $H_0$ für den Treatmenteffekt ist:

\begin{equation*}
H_0: \tau_1 = \tau_2 = \cdots = tau_K = 0
\end{equation*}

Der Unterschied zwischen den Treatmentstufen wird dabei für den Wert $\bar{x}_{..}$, als den Mittelwert der Kovariate über alle Gruppenhinweg bestimmt.

Die $H_0$ für die Kovariate ist:

\begin{equation*}
H_0: \beta = 0
\end{equation*}

Das Ergebnis der Analyse wird oft auch in Form einer Varianz-Tabelle dargestellt (siehe @tbl-ed-ancova-ssq).

| Term | $df$ | $SSQ$ | $MSQ$ | F |
| --- | --- | --- | --- | --- |
| $T|\beta$ | $K-1$ | $ss(T|\beta)$ | $\frac{ss(T|\beta)}{K-1}$ | $\frac{ms(T|\beta)}{msE}$ |
| $\beta|T$ | $1$ | $ss(\beta|T)$ | $\frac{ss(\beta|T)}{1}$ | $\frac{ms(\beta|T)}{msE}$ |
| Error | $N-K-1$ | $ssE$ | $msE$ |  |

: Varianztabelle der ANCOVA {#tbl-ed-ancova-ssq} 

Die Schreibweise $T|\beta$ bezeichnet den Effekt des Treatments nachdem für die Kovariate kontrolliert wurde während $\beta|T$ den Effekt der Kovariate nachdem für das Treatment kontrolliert wurde beschreibt. 

Schauen wir uns dies in einem Spielzeugbeispiel an. In @tbl-ed-ancova-max-01 ist ein Beispieldatensatz aus @maxwell2004 tabellelarisch abgebildet.

```{r}
#| tbl-cap: "Ein einfacher ANCOVA-Datensatz"
#| label: tbl-ed-ancova-max-01
bw <- tibble(
  id = paste0('S', 1:6),
  group = rep(c('TRT','CON'), each=3),
  x = c(1,2,3,3,4,5),
  y = c(4,9,8,12,11,16)
)
bw |> kable(
  col.names=c('ID','Gruppe','x','y'),
  caption="Beispieldaten",
  linesep = "",
  booktabs = TRUE
)
```

Wir haben zwei Gruppen (TRT und CON) mit jeweils $N = 3$ mit einer Kovariate $x$.

Ein Vergleich des vollen und des reduzierten Modells führt zu folgendem Ergebnis:

```{r}
mod_0 <- lm(y ~ x, bw)
mod_1 <- lm(y ~ x + group, bw)
broom::tidy(anova(mod_0, mod_1)) |>
  knitr::kable(booktabs=T,
               caption="Vergleich full vs. reduced model.",
               digits=3)
```

Oder die Varianztabelle (siehe @tbl-ed-ancova-ex-01):

```{r}
#| label: tbl-ed-ancova-ex-01
#| tbl-cap: "Varianztabelle"

car::Anova(mod_1) |> broom::tidy() |>
  dplyr::mutate(MSQ = sumsq/df, .before=4) |> 
  kable(booktabs = TRUE,
  digits = 3,
  col.names = c("Term", "SSQ","df","MSQ","F","p-Wert"))
```

D.h. im Beispiel ist kein statistisch signifikanter Effekt des Treatment zu finden. Aber was passiert wenn wir den Treatmenteffekt gegen ein auf den $y$-Achsenabschnitt reduziertes Modell testen?

```{r}
#| label: tbl-ed-ancova-mod00
#| tbl-cap: "Modellvergleich von $y_i = \\beta_0 + \\epsilon_i$ gegen $y_i = \\beta_0 + \\tau_i + \\epsilon_i$" 

mod_0a <- lm(y ~ 1, bw)
mod_1a <- lm(y ~ group, bw)
anova(mod_0a, mod_1a) |> broom::tidy() |> 
  kable(
    booktabs = TRUE,
    digits = 4)
```

Wie kann das denn sein? Schauen wir uns dazu eine graphische Darstellung der Daten an (siehe @fig-ed-ancova-mod01).

```{r}
#| fig-cap: "Streudiagramm der Rohdaten"
#| label: fig-ed-ancova-mod01

ggplot(bw, aes(x, y)) +
  geom_point(aes(pch=group), size=4) +
  scale_shape_discrete('Gruppe') +
  scale_x_continuous("Kovariate x")
```

In @fig-ed-ancova-mod01 können wir sehen, dass die beiden Gruppen sich deutlich in der Kovariate $x$ unterscheiden. Was dazu führt, dass die Mittelwerte der beiden Gruppen auch entsprechend unterschiedlich ist. Dadurch führt ein Test für den Unterschied zwischen den beiden Gruppen dazu, dass es zu einem statistisch signifikanten Ergebnis für das Treatment führt. Wird allerdings zunächst für die Kovariate kontrolliert (siehe @fig-ed-ancova-mod02).

```{r}
#| fig-cap: "Streudiagramm der Rohdaten mit den Geraden aus dem ANCOVA-Modell"
#| label: fig-ed-ancova-mod02

ggplot(bw, aes(x,y,color=group)) +
  geom_point(size=4) +
  geom_smooth(method='lm', se=F) +
  scale_color_discrete("Gruppe") +
  scale_x_continuous("Kovariate x")
```

In @fig-ed-ancova-mod02 sehen wir, dass wenn die beiden parallen Geraden für die Kovariate auf Basis des ANCOVA-Modells eingefügt werden, dann ist der Unterschied zwischen den beiden Gruppen deutlich geringer.

Adjusted means $\bar{Y}_l'$

$$
E[\bar{Y}_{i.}] = \mu + \tau_i + \beta\bar{x}_{..})
$$

```{r}
#| echo: true

x_new <- tibble(x = mean(bw$x), group=c('TRT','CON'))
y_bar_j <- predict(mod_1, newdata = x_new)
y_bar_j
```

Adjusted means im Beispiel

```{r}
#| fig-cap: "Korrigierte Mittelwerte der Gruppen bei $\\bar{x}$."

mod_slopes <- tibble(
  x = rep(coef(mod_1)[2],2),
  y = c(coef(mod_1)[1] + c(0, coef(mod_1)[3])),
  group = c('CON','TRT'))
x_new <- x_new |> dplyr::mutate(y = y_bar_j)
ggplot(bw, aes(x,y,shape=group)) +
  geom_point(size=4) +
  geom_abline(data = mod_slopes, aes(slope=x, intercept=y),
              linetype='dashed') +
  geom_point(data = x_new, size=4, col='red') +
  scale_shape_discrete("Gruppe") 
```

 ... oder Adjusted means mit `emmeans()`

```{r}
#| echo: true

y_bar_j2 <- emmeans::emmeans(mod_1, ~group)
y_bar_j2
```


## Beispiele für Effektrelationen 

:::: columns
::: column
```{r}
#| fig-height: 4
#| fig-cap: "Effekt verkleinert sich"
 
gg_adjust <- function(y_1=1) {
df_g <- tibble(
  x = c(1,2,2,3),
  y = c(y_1,y_1+1,3,4),
  g = rep(letters[1:2],each=2),
  Typ = c('raw','adj','adj','raw'),
  xend = 1:4,
  yend = 1:4
)
df_g_2 <- tibble(
  x = 1:3, xend=1:3,
  y = rep(0,3), yend=c(y_1,max(y_1+1,3),4),
  g = letters[4:6]
)
df_g_3 <- tibble(
  x = c(0,0),
  xend = c(1,3),
  y = c(y_1,4),
  yend = c(y_1,4),
  g = letters[7:8]
)
ggplot(df_g, aes(x,y,groups=g,xend=xend,yend=yend)) +
  geom_segment(data = df_g_2, 
               linetype='dashed') +
  geom_segment(data = df_g_3) +
  geom_hline(yintercept=c(y_1+1,3), col='red', linetype='dashed') +
  geom_line(size=2) +
  geom_point(mapping=aes(color = Typ), size=4) +
  scale_x_continuous("", breaks=1:3,
                     labels=c(expression(bar(X)[1]),
                              expression(bar(X)),
                              expression(bar(X)[2]))) +
  scale_y_continuous("", labels=NULL) 
}
gg_adjust()
```

:::
::: column
```{r}
#| fig-height: 4
#| fig-cap: "Effekt vergrößert sich"

gg_adjust(3.5)
```
:::
::::

## ANCOVA in `R`

## ANCOVA Effect size $\omega^2$

### overall
$$
\hat{\omega}^2=\frac{df_{\text{effect}}(MS_{\text{effect}}-MS_{\text{error}})}{SS_{\text{total}}+MS_{\text{error}}}
$$

### Im Beispiel
$$
\hat{\omega}^2 = \frac{1(2.4 - 4)}{82 + 4} = `r round(1*(2.4-4)/(82+4),2)`
$$

^[Bei $\hat{\omega}^2 < 0$ wird auf $0$ gekappt.]

## Effect size $\omega^2$

```{r}
#| echo: true
effectsize::omega_squared(mod_1, partial=F)
```


## standardized differences between means

$$
\hat{d} = \frac{\bar{Y}_l' - \bar{Y}_m'}{\sqrt{MS_W}}
$$


```{r}
#| echo: true
mod_r <- lm(y ~ group, bw)
emmeans::eff_size(y_bar_j2, sigma = sigma(mod_r), edf = df.residual(mod_r))
```

$MS_W$ = Error in ANOVA-Model: `y ~ g` w/o covariate or $(SS_g + SS_{\text{error}})/(df_g + df_{\text{error}})$ from ANCOVA-Model.

## sample size estimate

\begin{align*}
\sigma_{\epsilon(\text{ANCOVA})}^2 &= \sigma_{\epsilon(\text{CRD})}^2(1-\rho_{xy}^2) \\
f_{\text{ANCOVA}} &= \frac{\sigma_{\text{btw}}}{\sigma_{\epsilon(\text{CRD})}}\frac{1}{\sqrt{1-\rho_{xy}^2}} = \frac{f_{\text{CRD}}}{\sqrt{1-\rho_{xy}^2}} 
\end{align*}

$df_{\text{Residual}} = N - k - 1$ under the ANCOVA model

## sample size Beispiel^[nach @maxwell2004]

In einer CRD-Studie wurde eine Effektstärke für den Unterschied zwischen drei Gruppen ($k = 3$) von $f = 0.41$ gefunden. Wie verändert sich die notwendige Stichprobengröße wenn eine Kovariate mit $\rho = 0.5$ mit der abhängigen Variable hinzugenommen wird?

## sample size example 
\small
Bei einer power von $0.8$ wird eine Stichprobengröße von:

```{r}
#| echo: true

pwr::pwr.anova.test(k=3, f=0.41, sig.level=0.05, power=0.8)$n
```
Wenn die Kovariate modelliert wird, erhöht sich die Effektstärke auf $f = 0.41/\sqrt{1-0.5^2} = 0.47$. Daraus resultiert eine reduzierte Stichprobengröße von:

```{r}
#| echo: true

pwr::pwr.anova.test(k=2, f=0.47, sig.level=0.05, power=0.8)$n
```

## Was passiert wenn die Kovariate interagiert

```{r}
#| fig-cap: "Beispiel für einen Interaktionseffekt zwischen der Treatmentvariablen und der Kovariate"
 

n <- 60
set.seed(1)
df_i <- tibble(
  x = runif(n, -3, 3),
  g = sample(-1:1, n, replace=T),
  y = 3 + 2*g + 3*x + g*x + rnorm(n),
  gruppe = LETTERS[1:3][g+2]
)
p_1 <- ggplot(df_i, aes(x,y,color=gruppe)) + 
  geom_point(size=2) +
  geom_smooth(method='lm', se=F, formula=y~x) +
  scale_color_manual('Gruppe', values=c('dark red','green','blue')) +
  labs(x = 'X', y = 'Y') 
print(p_1)
```

## Modell

$$
y_{it} = \beta_0 + \tau_i + \beta \cdot x_{it} + (\tau\beta)_{it}x_{it} + \epsilon_{it}
$$

## Welcher Unterschied zwischen den Gruppen? 

```{r}
print(p_1)
```

## Modellfit - Interaktionsmodell

```{r}
#| echo: true
#| results: hide

mod <- aov(y ~ x*gruppe, df_i)
anova(mod)
```

```{r}
anova(mod) |> broom::tidy() |> 
  knitr::kable(
    booktabs=T,
    digits = 2,
    col.names = c('Term', 'df', 'SSQ', 'MSQ', 'F', 'p.value'),
    caption="Anova-Tabelle für Interaktionsmodell")
```


## Mehrfachvergleiche - EMS Mittelwerte

```{r}
#| echo: true
 
mod_ems <- emmeans(mod, ~gruppe|x, at=list(x=c(-2,0,2)))
mod_ems
```

## Mehrfachvergleiche - Paarweise Vergleiche

```{r}
#| echo: true
#| results: hide

pairs(mod_ems)
```

```{r}
pairs(mod_ems) |> broom::tidy() |> 
  dplyr::select(x, contrast, estimate, std.error, df, statistic, adj.p.value) |> 
  my_tbl(header=c('x','contrast','estimate','$s_e$', '$df$','t','p'),
         caption="Paarvergleiche",
         escape=F)
```

## Beispiel aus [@maxwell2004, p.429]

```{r}
#| fig-cap: "Depression Beispiel aus Maxwell et al. (2004, p.429)"

tbl_97 <- readr::read_delim('data/maxwell_tbl_9_7.csv',
                     delim = ',', trim_ws = TRUE) |> 
  mutate(Condition = factor(Condition,
                            levels = 1:3,
                            labels = c('SSRI','Placebo','Wait list'))) |> 
  mutate(id = paste0('P',1:n()), .before = 1) |> 
  pivot_longer(-c(id, Condition), names_to = 'time', values_to = 'bdi') |> 
  mutate(time = factor(time, levels = c('Pre','Post')))
ggplot(tbl_97, aes(Condition, bdi, fill=time)) + 
  geom_boxplot() +
  scale_fill_discrete('Zeit') +
  labs(x = 'Kondition', y = 'BDI depression score')
```

## Analyse

```{r}
bdi_w <-tbl_97 |>
  pivot_wider(id_cols = c(id,Condition), names_from=time, values_from=bdi) 
```

```{r}
#| echo: true
mod_bdi <- lm(Post ~ Pre + Condition, bdi_w)
anova(mod_bdi) |> broom::tidy() |> 
  kable(booktabs = T, digits = 3)
```

## Gruppenvergleiche

```{r}
#| echo: true

bdi_em <- emmeans(mod_bdi, ~Condition)
pairs(bdi_em, infer=T)
```

- Unterscheidung zwischen
  - Kovariate für das Untersuchungsdesign
  - Kovariate für die Analyse der Daten

## Zum Nachlesen

### Allgemein
[@maxwell2004, p.451-467]

### Pre-post ANCOVA
@wan2021

### Regression to the mean
@shephard2003, @barnett2005, @nevill2004

