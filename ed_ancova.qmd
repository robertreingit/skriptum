# ANCOVA 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```
```{r defs, echo = FALSE, message = FALSE, warning=FALSE}
require(emmeans)
my_tbl <- function(df, header, caption='', ...) {
  knitr::kable(df,
               booktabs = TRUE,
               digits = 2,
               col.names = header,
               caption = caption,
               linesep = '',
               ...)
}
```

In den vorhergehenden Kapiteln zu CRD bzw. CRFD haben wir uns angeschaut, wie wir den Einfluss einer oder mehrerer nominaler, unabhängiger Variablen auf eine abhängige Variable modellieren können. In diesem Zusammenhang haben wir uns auch mit der Varianzzerlegung auseinandergesetzt und immer wieder gesehen, dass diese Zerlegung auch als der Vergleich von verschiedenen Modellen miteinander betrachtet werden kann. Im Rahmen der ANCOVA führen wir jetzt wieder eine kontinuierliche Variable in unser Modell ein, wie wir das schon im Rahmen der multiplen linearen Regression getan haben. Diese zusätzliche, kontinuierliche Variable spielt dabei die Rolle einer Kontrollvariablen. Mit Hilfe dieser Kontrollvariable soll ebenfalls Varianz von $Y$ erklärt werden. Der Effekt der Kontrollvariablen auf $Y$ ist allerdings nicht das Primärinteresse der Untersuchung sondern dient nur die Präzision des Modells zu erhöhen. Letztendlich führt dies dazu, dass auch die Power der Untersuchung erhöht wird.

Ein Beispiel könnte eine Untersuchung zu Trainingseffekten sein. Aus der Literatur wissen wir bereits, das das Alter der Teilnehmerinnen und Teilnehmer eine Rolle auf den Trainingseffekt hat. Daher macht es Sinn für den Effekt des Alters im Rahmen der Modells zu kontrollieren. Das primäre Interessiere der Untersuchung liegt auf dem Effekt des Trainings. Die Variable Alter wird in diesem Fall als Kovariate bezeichnet, wodurch sich auch die Namensgebung ANCOVA als Abkürzung für Analysis of Covariance herleitet. Welche Variablen die Rolle der primären Variablen und der Kovariaten spielen ist dabei von der konkreten Untersuchung abhängig. Es kann genauso vorkommen, dass eine nominale Variable die Rolle der Kovariaten spielt und eine kontinuierliche Variable die Primärvariable der Untersuchung ist.

Konzeptionell wird durch die Integration einer Kovariaten Information über Unterschiede zwischen den beiden Gruppen die vor der Beobachtungsphase bestehen in das Modell mit einbezogen. D.h. trotzdem wir die Beobachtungseinheiten randomisiert in beispielsweise zwei Gruppen unterteilt haben, wissen wir, das das Alter einen Effekt auf die abhängige Variable hat. Bei einer perfekten, randomisierten Zuweisung sollte das Alter eigentlich keinen mehr Einfluss haben, da beide Gruppen die gleiche Altersstruktur haben sollten. Trotzdem sind wir in der Lage die Einbeziehung zusätzliche Varianz aufzuklären und können so den Effekt der Primärvariablen hoffentlich besser isolieren. Oft kann zum Beispiel der Startwert der abhängigen Variable als Kovariate verwendet werden. Die Kovariate ist dann auf der gleichen Skala wie die Zielvariable.

::: {#exm-ancova-01}
In @fien2019 wurde unter anderem der Einfluss einer Trainingsintervention auf die Gehgeschwindigkeit in einem zweiarmigen Untersuchungsdesign untersucht. Als Zielvariable wurde die Gehgeschwindigkeit nach der Interventionsphase verwendet. Um die bestehenden Unterschiede zwischen den Teilnehmerinnen und Teilnehmer vor der Untersuchung mit einzubeziehen, wurde die Gehgeschwindigkeit vor der Intervention als Kovariate verwendet.
:::

::: {#def-covariate}
## Kovariate

Eine Kovariate\index{Kovariate} ist eine Variable, die verwendet wird, um den Einfluss auf die abhängige Variable zu kontrollieren um genauere Schätzungen der Beziehungen zwischen den primären unabhängigen Variablen und der abhängigen Variable zu erhalten. 

Alternativ werden in der Literatur auch die Begriffe Störvariable (engl. nuisance factor) oder concomitant variable (engl.) verwendet. Wenn die Kovariate auf der gleichen Skala wie die Primärvariable ist, wird sie auch als commensurate (engl.) bezeichnet.
:::

Beginnen wir mit einem einfachen konzeptionellen Modell (siehe @fig-ed-ancova-01).

```{r}
#| fig-cap: "Zusammenhang einer abhängigen Variable mit einer Kovariate und einer nominalen Variable (treatment)"
#| label: fig-ed-ancova-01

dat_0 <- tibble(
  x = c(-1,1),
  A = 3*x,
  B = 3*x + 1
) |> tidyr::pivot_longer(-x, values_to='y')
ggplot(dat_0, aes(x, y, color=name)) +
  geom_line(linewidth=2) +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL) +
  scale_color_discrete("Treatment") 
```

@fig-ed-ancova-01 zeigt den Zusammenhang zwischen zwei Gruppen $A$ und $B$ und einer abhängigen Variablen DV sowie den Zusammenhang einer Kovariate ($x$-Achse) mit DV. Zwischen der Kovariaten und der DV besteht ein positiver Zusammenhang und der Effekt von Treatment $A$ ist kleiner als derjenige von Treatment $B$. Der Effekt der Kovariaten ist dabei in beiden Gruppen gleich und es besteht keine Interaktion zwischen der Kovariaten und den Gruppen. Dies führt dazu, dass die beiden Geraden parallel zueinander sind. Letztendlich haben wir dieses Modell schon bei der Besprechung der Intergration von nominalen Variablen in das multiple Regressionsmodell behandelt.

Wenn wir die beiden Gruppen miteinander vergleichen sind mehrere unterschiedliche Vergleiche möglich. Nehmen wir zum Beispiel einen Datenpunkt $P1$ aus Gruppe $A$. Dann können wir den $P1$ mit mehreren verschiedenen Datenpunkten aus Gruppe $B$ vergleichen. In @fig-ed-ancova-02 sind drei mögliche Vergleiche eingezeichnet.

```{r}
#| fig-cap: "Verschiedene Vergleiche der beiden Gruppen miteinander"
#| label: fig-ed-ancova-02

df_pts <- tibble(x = rep(0,3), xend = c(-.5,0,.5),
                 y = rep(0,3), yend = c(-.5,1,2.5))
ggplot(dat_0, aes(x, y, color=name)) +
  geom_line(linewidth=2) +
  geom_point(data = df_pts, aes(x=xend, y=yend), color = 'red', size=3) +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL) +
  scale_color_discrete("Treatment") +
  annotate("segment", x = rep(0,3),
            y = rep(0,3), 
            xend = c(-.5,0,.5),
            yend = c(-.5,1,2.5),
            arrow = arrow(length=unit(.08, 'inch'), ends = 'both',
                          type='closed')) +
  annotate("label", x = 0, y = 0, label = 'P1')

```

Letztendlich erscheint aber nur einer der Vergleiche sinnvoll, nämlich der Vergleich wenn die beiden Gruppenwerte den gleichen Wert in der Kovariate haben. Wäre zum Beispiel die Kovariate das Alter, dann würde ein Vergleich von zwei Personen die sich im Alter unterscheiden wenig sinnvoll da nicht klar ist ob ein beobachteter Unterschied zwischen den beiden Personen in der abhängigen Variable auf den Unterschied im Alter oder auf den Unterschied im Treatment zurück zu führen ist. Genau dieses Problem wird mit Hilfe der ANCOVA gelöst. Die ANCOVA liefert daher eine Antwort auf die Frage:

*Wie unterschieden sich die Gruppen voneinander, wenn sie die gleichen Werte in der Kovariate hätten?*

Schauen wir uns ein weiteres Beispiel an. In @fig-ed-ancova-03 sind diesmal Datenpunkte eingezeichnet und scheinbar ist bei der Zuweisung der Teilnehmerinnen und Teilnehmer etwas grundsätzlich schief gelaufen.

```{r}
#| fig-cap: "Probleme durch die Kovariate"
#| label: fig-ed-ancova-03

set.seed(1)
slope <- 0.2
trt <- 8
dat_1 <- tibble(
  x = rep(seq(10, 80, 10), each=2),
  trt = rep(c(trt,0), each=8),
  trt_f = factor(trt, labels=c('A','B')),
  y = slope * x + trt + rnorm(16, 0, sd=1),
)
p1 <- ggplot(dat_1, aes(x, y, color=trt_f)) +
  geom_point(size=3) +
  geom_abline(slope = slope, linetype='dashed') +
  geom_abline(slope = slope, intercept = trt, linetype='dashed') +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL) +
  scale_color_discrete("Treatment") 
p1
```

Die Personen in Gruppe $B$ haben alle einen kleineren Wert in der Kovariate als die Personen in Gruppe $A$. Gleichzeitig hat die Kovariate aber einen positiven Einfluss auf die DV. Hätte wir keine Information über die Kovariate und würden die beiden Gruppenmittelwerte miteinander vergleichen, dann würden wir wahrscheinlich keinen Unterschied zwischen den beiden Gruppen finden (siehe @fig-ed-ancova-04). 

```{r}
#| fig-cap: "Mittelwerte der Gruppen (schwarze Punkte) mit unterschiedlichen Kovariaten"
#| label: fig-ed-ancova-04

dat_1_bar <- dat_1 |> group_by(trt_f) |>
    summarize(y = mean(y), x = mean(x))
p1 + 
  geom_point(data = dat_1_bar, color='black', size=4)
```

Um die beiden Gruppen miteinander vergleichen zu können, müssen wir die Unterschiede in den Mittelwerten der Kovariaten korrigieren um die Gruppen miteinander vergleichbar zu machen. D.h. wie würden die Unterschied aussehen, wenn beide Gruppen die gleiche Verteilung in der Kovariaten hätten.

```{r}
#| fig-cap: "Vergleich der Gruppen bei koorigierten Kovariaten"
#| label: fig-ed-ancova-05

ggplot(dat_1, aes(x, y, color=trt_f)) +
  geom_point(size=3) +
  geom_abline(slope = slope, linetype='dashed') +
  geom_abline(slope = slope, intercept = trt, linetype='dashed') +
  scale_x_continuous("Kovariate", labels = NULL) +
  scale_y_continuous("DV", labels = NULL, limits = c(0,25)) +
  scale_color_discrete("Treatment") +
  geom_point(data = dat_1 |> group_by(trt_f) |>
    summarize(y = mean(y), x = mean(x)), color='black', size=4) +
  annotate(geom = 'segment', x = dat_1_bar$x[1], xend = dat_1_bar$x[1],
          y = dat_1_bar$y[1], yend = dat_1_bar$y[1]+7,
          arrow = arrow(type = 'closed', length=unit(.15,'inch'))) +
  annotate(geom = 'segment', x = dat_1_bar$x[2], xend = dat_1_bar$x[2],
          y = dat_1_bar$y[2], yend = dat_1_bar$y[2]-7,
          arrow = arrow(type = 'closed', length=unit(.15,'inch')))
```

In @fig-ed-ancova-05 sind die eigentlich sinnvollen Vergleiche angezeigt. Dabei wird auch noch einmal klar, dass in diesem Modell sobald wir für die Werte der Kovariaten kontrolliert haben, die Position des Vergleichs unerheblich ist, da wir von einem Modell ausgehen, bei dem der Effekt der Kovariaten in beiden Gruppen gleich ist. Dies führt zu den parallelen Linien.

## Das Modell

Übertragen wir die Beispiele nun wieder in eine Modellformulierung. Letztendlich können wir, wie bereits angemerkt, das uns schon bekannte Modell aus der multiple linearen Regression anwenden.

\begin{equation}
Y_{it} = \mu + \tau_i + \beta x_{it} + \epsilon_{it} \quad \epsilon_{it} \sim \mathcal{N}(0,\sigma^2), i = 1,\ldots,K
\label{eq-ed-ancova-model}
\end{equation}

In Model \eqref{eq-ed-ancova-model} kommt dementsprechend nichts Neues dazu, sondern unser bekanntes lineares Modell. Der einzige Unterschied besteht in der Terminologie, während wir vorher $\alpha_i$ für die nominale Variable verwendet haben, wird der nominale Faktor im ANCOVA-Modell $\tau_i$ bezeichnet. Das sind aber nur Unterschiede in den Buchstaben die leider auch in der Literatur unterschiedlich verwendet werden.

Um die spätere Interpretation der Koeffizienten zu vereinfachen, wird auch oft ein in der Kovariaten zentriertes Modell verwendet. Dies hat jedoch keine Auswirkung auf das Ergebnis.

\begin{equation}
Y_{it} = \mu + \tau_i + \beta (x_{it} - \bar{x}_{..}) + \epsilon_{it}
\label{eq-ed-ancova-model-c}
\end{equation}

Ein interessante Interpretation der ANCOVA erhalten wir, wenn wir in Formel \eqref{eq-ed-ancova-model-c} auf beiden Seiten $\mu + \tau_i$ abziehen (siehe [@casella2008, p.65]).

\begin{equation*}
Y_{it} - \beta (x_{it} - \bar{x}_{..}) = \mu + \tau_i + \epsilon_{it}
\end{equation*}

Auf der linken Seite stehen die Residuen einer Regression, die Differenz der beobachteten Werte von denen mittels der Regression auf die Kovariate vorhergesagten Werten. Auf der rechten Seite haben wir das Modell der CRD. D.h. durch die ANCOVA werden die beobachteten Werte korrigiert und dadurch deren Varianz reduziert. 

Da es sich bei der ANCOVA aber insgesamt wieder nur um eine Variante des linearen Modell handelt, ergeben sich entsprechend auch keine unbekannten Voraussetzungen:

- Experimental units sind randomisiert den $K$ Gruppen zugewiesen worden
- Varianz $\sigma^2$ ist konstant über Gruppen und Werte der Kovariate
- Die Kovariate und das Treatment sind statistisch unabhängig voneinander

Der letzte Punkte, die Unabhängigkeit zwischen dem Treatment und der Kovariate ist wichtig. Dies bedeutet, dass der Einfluss der Kovariaten sind nicht im Zusammenhang mit dem Treatment verändert. Der der ANCOVA zugrundeliegende Test beruht dann wie immer auf einen  Modellvergleich eines vollen Modell (Model \eqref{eq-ed-ancova-model}) mit einem reduzierten Modell. Das reduzierte Modell beinhaltet dann nur die Kovariate, da wir den Unterschied in Bezug auf den Effekt der Primärvariable überprüfen wollen.

\begin{align*}
y_{ij} &= \mu + \tau_{j} + \beta X_{ij} + \epsilon_{ij} \quad \text{full} \\
y_{ij} &= \mu + \beta X_{ij} + \epsilon_{ij} \quad \text{reduced}
\end{align*}

Die $H_0$ für den Treatmenteffekt ist:

\begin{equation*}
H_0: \tau_1 = \tau_2 = \cdots = tau_K = 0
\end{equation*}

Der Unterschied zwischen den Treatmentstufen wird dabei für den Wert $\bar{x}_{..}$, als den Mittelwert der Kovariate über alle Gruppenhinweg bestimmt.

Die $H_0$ für die Kovariate ist:

\begin{equation*}
H_0: \beta = 0
\end{equation*}

Das Ergebnis der Analyse wird oft auch in Form einer Varianz-Tabelle dargestellt (siehe @tbl-ed-ancova-ssq).

| Term | $df$ | $SSQ$ | $MSQ$ | F |
| --- | --- | --- | --- | --- |
| $T|\beta$ | $K-1$ | $ss(T|\beta)$ | $\frac{ss(T|\beta)}{K-1}$ | $\frac{ms(T|\beta)}{msE}$ |
| $\beta|T$ | $1$ | $ss(\beta|T)$ | $\frac{ss(\beta|T)}{1}$ | $\frac{ms(\beta|T)}{msE}$ |
| Error | $N-K-1$ | $ssE$ | $msE$ |  |

: Varianztabelle der ANCOVA {#tbl-ed-ancova-ssq} 

Die Schreibweise $T|\beta$ bezeichnet den Effekt des Treatments nachdem für die Kovariate kontrolliert wurde während $\beta|T$ den Effekt der Kovariate nachdem für das Treatment kontrolliert wurde beschreibt. Hier tritt eine Besonderheit, die Summe der Quadratsummen addiert sich nicht zur totalen Varianz von $Y$. Dies kommt dadurch zustande das nicht die Hierarchie vom einfachsten zum vollen Modell aufsummiert werden, sondern Vergleiche zwischen dem vollen Modell und jeweils einem Modell bei dem die andere Variable bereits vorhanden ist. Diese Quadratsummen werden als sogenannte Type-II Quadratsummen bezeichnet und verlieren die additive Eigenschaft. Im Spezialfall wenn beide Gruppen den gleichen Mittelwert in der Kovariaten $X$ haben, sind die Quadratsummen dann doch wieder additive. Die beiden Effekt Treatment und Kovariate sind dann orthogonal zueinander.

Schauen wir uns die Analyse in einem Spielzeugbeispiel an. In @tbl-ed-ancova-max-01 ist ein Beispieldatensatz aus @maxwell2004 abgebildet.

```{r}
#| tbl-cap: "Ein einfacher ANCOVA-Datensatz"
#| label: tbl-ed-ancova-max-01
bw <- tibble(
  id = paste0('S', 1:6),
  group = rep(c('TRT','CON'), each=3),
  x = c(1,2,3,3,4,5),
  y = c(4,9,8,12,11,16)
)
bw |> kable(
  col.names=c('ID','Gruppe','x','y'),
  caption="Beispieldaten",
  linesep = "",
  booktabs = TRUE
)
```

Wir haben zwei Gruppen (TRT und CON) mit jeweils $N = 3$ mit einer Kovariate $x$.

Ein Vergleich des vollen und des reduzierten Modells führt zu folgendem Ergebnis:

```{r}
#| tbl-cap: "Vergleich full vs. reduced model."
#| label: tbl-ed-ancova-toy-1

mod_0 <- lm(y ~ x, bw)
mod_1 <- lm(y ~ x + group, bw)
broom::tidy(anova(mod_0, mod_1)) |>
  knitr::kable(booktabs=T,
               digits=3)
```

Wie wir @tbl-ed-ancova-toy-1 sehen können finden wir keinen statistisch signifikanten Effekt für das Treatment nachdem wir für die Kovariate $X$ kontrolliert haben. Dargestellt als Varianztabelle erhalten wir die folgende Dokumentation (siehe @tbl-ed-ancova-ex-01):

```{r}
#| label: tbl-ed-ancova-ex-01
#| tbl-cap: "Varianztabelle"

car::Anova(mod_1) |> broom::tidy() |>
  dplyr::mutate(MSQ = sumsq/df, .before=4) |> 
  kable(booktabs = TRUE,
  digits = 3,
  col.names = c("Term", "SSQ","df","MSQ","F","p-Wert"))
```

Hier finden wir ebenfalls keinen statisch signifikaten Effekt für beide Variablen, die Wert für die Treatmentvariable sinnd in beiden Tabellen auch gleich. Schauen wir uns die Summe der Quadratsummen an.

```{r}
ssq <- car::Anova(mod_1) |> broom::tidy() |> dplyr::pull(sumsq)
```
$$
SSQ_x + SSQ_{\text{group}} + SSE = `r paste(ssq, collapse="+")` = `r sum(ssq)`
$$

Aber die totale Quadratsumme von $y$ ist $SST = `r var(bw$y)*5`$. D.h. die Summer der Quadratsummen addiert sich nicht zu $SST$.

Schauen wir aber rein interessehalber an, was passiert wenn wir den Treatmenteffekt gegen ein auf den $y$-Achsenabschnitt reduziertes Modell testen. Wir ignorieren die Information aus der Kovariate.

```{r}
#| label: tbl-ed-ancova-mod00
#| tbl-cap: "Modellvergleich von $y_i = \\beta_0 + \\epsilon_i$ gegen $y_i = \\beta_0 + \\tau_i + \\epsilon_i$" 

mod_0a <- lm(y ~ 1, bw)
mod_1a <- lm(y ~ group, bw)
anova(mod_0a, mod_1a) |> broom::tidy() |> 
  kable(
    booktabs = TRUE,
    digits = 4)
```

In @tbl-ed-ancova-mod00 haben wir nun einen statistisch signifikanten Effekt gefunden. Wie kann das denn sein? Schauen wir uns dazu eine graphische Darstellung der Daten an (siehe @fig-ed-ancova-mod01).

```{r}
#| fig-cap: "Streudiagramm der Rohdaten"
#| label: fig-ed-ancova-mod01

ggplot(bw, aes(x, y)) +
  geom_point(aes(pch=group), size=4) +
  scale_shape_discrete('Gruppe') +
  scale_x_continuous("Kovariate x")
```

In @fig-ed-ancova-mod01 können wir sehen, dass die beiden Gruppen sich deutlich in der Kovariate $x$ voneinander unterscheiden. Dies führt dazu, dass die Mittelwerte der beiden Gruppen auch entsprechend unterschiedlich voneinander sind. Dadurch führt ein Test für den Unterschied zwischen den beiden Gruppen dazu, dass es zu einem statistisch signifikanten Ergebnis für das Treatment kommt. Letztendlich wird dieser Unterschied nur durch die Kovariate verursacht. Wird für die Kovariate kontrolliert, dann verschwindet der Effekt (siehe @fig-ed-ancova-mod02).

```{r}
#| fig-cap: "Streudiagramm der Rohdaten mit den Geraden aus dem ANCOVA-Modell"
#| label: fig-ed-ancova-mod02

ggplot(bw, aes(x,y,color=group)) +
  geom_point(size=4) +
  geom_smooth(method='lm', se=F) +
  scale_color_discrete("Gruppe") +
  scale_x_continuous("Kovariate x")
```

In @fig-ed-ancova-mod02 sehen wir, dass wenn die beiden parallen Geraden für die Kovariate auf Basis des ANCOVA-Modells eingefügt werden, dann ist der Unterschied zwischen den beiden Gruppen deutlich geringer. Dies betont noch einmal, dass ein Vergleich nur sinnvoll ist, wenn das level der Kovariaten zwischen den beiden Gruppen gleich ist. Es wird in diesem Fall dann von adjusted means $\bar{Y}_l'$ \index{adjusted means} gesprochen. Dazu wird der Mittelwert $\bar{X}_{..}$ der Kovariaten $X$ über alle Gruppen gebildet und dann der Effekt der Gruppe berechnet.

\begin{equation*}
E[\bar{Y}_{i.}] = \mu + \tau_i + \beta\bar{x}_{..}
\label{eq-ed-ancova-adjusted-mean}
\end{equation*}

Im Beispiel werden die Gruppen daher wie folgt miteinander verglichen (siehe @fig-ed-ancova-adjusted-means)

```{r}
#| fig-cap: "Korrigierte Mittelwerte der Gruppen bei $\\bar{x}$."
#| label: fig-ed-ancova-adjusted-means

x_new <- tibble(x = mean(bw$x), group=c('TRT','CON'))
y_bar_j <- predict(mod_1, newdata = x_new)
mod_slopes <- tibble(
  x = rep(coef(mod_1)[2],2),
  y = c(coef(mod_1)[1] + c(0, coef(mod_1)[3])),
  group = c('CON','TRT'))
x_new <- x_new |> dplyr::mutate(y = y_bar_j)
ggplot(bw, aes(x,y,shape=group)) +
  geom_point(size=4) +
  geom_abline(data = mod_slopes, aes(slope=x, intercept=y),
              linetype='dashed') +
  geom_point(data = x_new, size=4, col='red') +
  annotate(geom = 'segment', x=x_new$x[1], y=x_new$y[1],
                             xend=x_new$x[2], yend=x_new$y[2],
            arrow=arrow(length=unit(0.1,"inch"), type='closed', ends='both')) +
  scale_shape_discrete("Gruppe") 
```

Wie wir an dem Beispiel sehen konnten, führt die Kombination von Mittelwerten in der Kovariaten $X$ dazu, dass der Effekt kleiner wird nachdem für die Kovariate kontrolliert wurde. Dies ist nicht immer der Fall sondern hängt davon ab, wie groß der Effekt ist und wie die Anordnung der Mittelwerte $\bar{X}_j$ in den Gruppen ist.


```{r}
#| fig-cap: "Effekt verkleinert sich"
#| label: fig-ed-ancova-adjusted-means-2

gg_adjust <- function(y_1=1) {
df_g <- tibble(
  x = c(1,2,2,3),
  y = c(y_1,y_1+1,3,4),
  g = rep(letters[1:2],each=2),
  Typ = c('raw','adj','adj','raw'),
  xend = 1:4,
  yend = 1:4
)
df_g_2 <- tibble(
  x = 1:3, xend=1:3,
  y = rep(0,3), yend=c(y_1,max(y_1+1,3),4),
  g = letters[4:6]
)
df_g_3 <- tibble(
  x = c(0,0),
  xend = c(1,3),
  y = c(y_1,4),
  yend = c(y_1,4),
  g = letters[7:8]
)
ggplot(df_g, aes(x,y,groups=g,xend=xend,yend=yend)) +
  geom_segment(data = df_g_2, 
               linetype='dashed') +
  geom_segment(data = df_g_3) +
  geom_hline(yintercept=c(y_1+1,3), col='red', linetype='dashed') +
  geom_line(size=2) +
  geom_point(mapping=aes(color = Typ), size=4) +
  scale_x_continuous("", breaks=1:3,
                     labels=c(expression(bar(X)[1]),
                              expression(bar(X)),
                              expression(bar(X)[2]))) +
  scale_y_continuous("", labels=NULL) 
}
gg_adjust()
```

```{r}
#| fig-cap: "Effekt vergrößert sich"
#| label: fig-ed-ancova-adjusted-means-3

gg_adjust(3.5)
```

## Analyse einer ANCOVA in `R`

Für die Analyse in `R` können wir die üblichen Herangehensweise mittels `lm()` verwenden. Einzig, wenn wir die Varianztabelle nach dem Muster in @tbl-ed-ancova-ssq erzeugen wollen und nicht von Hand die Modellvergleiche durchführen wollen, müssen wir auf die Funktion `ANOVA()` aus dem package `car` zurückgreifen. Beispielweise für das Spielzeugbeispiel (Daten sind im `tibble` `bw`) ergibt sich der folgende Code:

```{r}
#| echo: true

mod <- lm(y ~ group + x, bw)
car::Anova(mod)
```

Über die Modellvergleiche:

```{r}
#| echo: true

mod_full <- lm(y ~ group + x, bw)
mod_r1 <- lm(y ~ group, bw)
mod_r2 <- lm(y ~ x, bw)
anova(mod_r1, mod_full)
anova(mod_r2, mod_full)
```

Wenn wir die Standard-`anova()`-Funktion auf das `lm`-Modell anwenden erhalten wir einen sequentiellen Modellvergleich bei dem es darauf ankommt in welcher Reihenfolge wir die unabhängigen Variablen in das Modell eingefügt haben.

```{r}
#| echo: true

mod_g_x <- lm(y ~ group + x , bw)
mod_x_g <- lm(y ~ x + group , bw)
anova(mod_g_x)
anova(mod_x_g)
```

## Effektstärke bei der ANCOVA

Für die ANCOVA können wir natürlich auch wieder eine Effektstärke berechnen. Wir verwenden wieder eine $\Omega^2$-Typ Effektstärke für den Gesamteffekt des Modells (siehe Formel \eqref{ed-ancova-omega_sqr}.

\begin{equation}
\hat{\omega}^2=\frac{df_{\text{effect}}(MS_{\text{effect}}-MS_{\text{error}})}{SS_{\text{total}}+MS_{\text{error}}}
\label{ed-ancova-omega_sqr}
\end{equation}

Für das Spielzeugbeispiel erhalten wir den folgenden Wert:

$$
\hat{\omega}^2 = \frac{1(2.4 - 4)}{82 + 4} = `r round(1*(2.4-4)/(82+4),2)`
$$

Per Konvention wird bei $\hat{\omega}^2 < 0$ der Wert auf $0$ gekappt. D.h. in diesem Fall ist die Effektstärke gleich $0$. Die Effektstärke wird dabei bei Vernachlässigung der Kovariaten bestimmt. Die Kovariate wird als intrinsische Variable betrachtet und daher gehört die durch die Kovariate verursachte Varianz zur Varianz der abhängigen Variablen. Daher wird bei der ANCOVA der Gesamteffekt unter Einbeziehung der Kovariatenvarianz berechnet. D.h. es wird nicht der partielle Effekt bestimmt.

Wenn wir die Effektstärke in `R` berechnen wollen, können wir wieder auf das package `effectsize` zurückgreifen und die `omega_squared()` Funktion anwenden. Hierbei sollte der Parameter `partial` wieder auf `FALSE` gesetzt werden um den globalen Effekt zu berechnen. 

```{r}
#| echo: true

effectsize::omega_squared(mod_1, partial=F)
```

## Mehrfachvergleiche bei der ANCOVA

Sollten wir einen statistisch signifikanten Effekt für die Treatmentvariable gefunden haben, dann können wir, wie üblich, auch Mehrfachvergleiche berechnen. Dies macht nur Sinn wenn $K>2$ gilt, da ansonsten der einzelne $\tau_i$-Koeffizient im Modell direkt den Vergleich der beiden Gruppen gibt. Auf die Herleitung der Varianz der Kontraste verzichten wir hier, da sich außer umfangreiche Algebra nichts grundlegendes Neues ergibt, außer das ein zusätzlicher Term für die Kovariate besteht.

$$
Var\left(\sum_{i}c_i \hat{\tau_i}\right) = MSE\left(\sum_i\frac{c_i^2}{r_i} + \frac{(\sum_i c_i \bar{x}_{i.})^2}{\sum_{i=1}^K \sum_{t=1}^{r_i} (x_{it}-\bar{x}_{i.})^2} \right)
$$
Der interessante Punkte hier, das die Varianz mit dem Abstand der Mittelwerte der Kovariate in den Gruppen $\bar{x}_{i.}$ größer wird. Deshalb ist eine möglichst ähnliche Verteilung der Kovariaten in den Gruppen zu bevorzugen. Um das nominelle Signifikanzniveau dann wieder für Mehrfachtestung zu kontrollieren können entweder eine Bonferroni- (pre-planned) oder die die Scheffé-;ethode verwendet werden. Für die Tukey-Methode gibt es keinen geschlossenen Beweis, obwohl wahrscheinlich auch die Tukey-Methode möglich ist [vgl. @dean1999, p.294].

## Mehrfachvergleiche in `R`

Um Mehrfachvergleiche in `R` durchzuführen, verwenden wir wieder das `emmeans`-package. Schauen wir uns dazu ein Beispiel hypothetisches Beispiel aus [@maxwell2004, p.429] mit drei Stufen für die Treatmentvariable an (siehe @fig-ed-ancova-max-01). Es wurde drei Patientengruppen mit Depression in drei Gruppen unterteilt. Eine Gruppe fungierte als Kontrollgruppe (`wait list`), eine Gruppe bekam ein Medikament (SSRI) und eine Gruppe bekam ein Placebo. Die Patienten wurde vor nach dem Treatment auf einer Depressionskala getestet.

```{r}
#| fig-cap: "Depression Beispiel aus Maxwell et al. (2004, p.429)"
#| label: fig-ed-ancova-max-01

tbl_97 <- readr::read_delim('data/maxwell_tbl_9_7.csv',
                     delim = ',', trim_ws = TRUE) |> 
  mutate(Condition = factor(Condition,
                            levels = 1:3,
                            labels = c('SSRI','Placebo','Wait list'))) |> 
  mutate(id = paste0('P',1:n()), .before = 1) |> 
  pivot_longer(-c(id, Condition), names_to = 'time', values_to = 'bdi') |> 
  mutate(time = factor(time, levels = c('Pre','Post')))
ggplot(tbl_97, aes(Condition, bdi, fill=time)) + 
  geom_boxplot() +
  scale_fill_discrete('Zeit') +
  labs(x = 'Kondition', y = 'BDI depression score')
```

Da davon auszugehen ist, dass die schwere der Depression vor Beginn des Untersuchung einen Einfluss auf das Ergebnis hat, wurde die Eingangsmessung als eine Kovariate behandelt (commensurate covariate). Die Analyse der Daten (in `tibble` `bdi_w`) führt zu folgendem Ergebnis:

```{r}
bdi_w <-tbl_97 |>
  pivot_wider(id_cols = c(id,Condition), names_from=time, values_from=bdi) 
```

```{r}
#| echo: true
#| lst-label: lst-ed-ancova-max-ex
#| lst-cap: "Ergebnis der ANCOVA-Analyse"

mod_bdi <- lm(Post ~ Pre + Condition, bdi_w)
car::Anova(mod_bdi)
```

Es wurde ein statistisch signifikanter Effekt für die Gruppenzugehörigkeit gefunden. Den nachfolgenden Mehrfachvergleich können wir für die paarweisen Vergleiche wie folgt berechnen.

```{r}
#| echo: true

bdi_em <- emmeans(mod_bdi, ~Condition)
pairs(bdi_em, infer=T, adjust='scheffe')
```

D.h. wir finden nur für den Vergleich zwischen der medikamentös behandelten Gruppe und der Kontrollgruppe einen statistisch signifikanten Effekt.

### Effektstärken für Vergleiche

Oft möchten wir für Mehrfachvergleiche eine Cohen's D-artige Effektstärke berechnen. Dazu werden die sogenannte standardized differences between means \index{standardized differences between means} verwendet. Der einzige Schritt der etwas problematischer ist, ist die Berechnung der Standardabweichung. Hier wird auch wieder die Restvarianz $MS_W$ ohne die Reduktion durch die Kovariate verwendet.

\begin{equation*}
\hat{d} = \frac{\bar{Y}_l' - \bar{Y}_m'}{\sqrt{MS_W}}
\end{equation*}

Für die Berechnung von $MS_W$ muss daher ein Modell ohne die Kovariate gefittet werden und der Term $MSE$ verwendet werden. Alternativ kann mit Hilfe der Werte aus dem ANCOVA Modell die folgende Formel verwendet werden: $MS_W = \sqrt{(SS_X + SS_{\text{error}})/(N-K)}$.

In `R` könnte dies wie folgt mittels der Funktion `eff_size()` aus dem package `emmeans` berechnet werden:

```{r}
#| echo: true

y_bars <- emmeans(mod_bdi, ~Condition)
mod_r <- lm(Post ~ Condition, bdi_w)
eff_size(y_bars, sigma = sigma(mod_r), edf = df.residual(mod_r))
```

Unter Verwendung der Varianztabelle (siehe @lst-ed-ancova-max-ex) aus der ANCOVA können die standardized differences between means äquivalent wie folgt berechnet werden.

```{r}
#| echo: true

df_W <- 30 - 3
MS_W <- sqrt((756.33 + 313.37)/df_W)
eff_size(y_bars, sigma = MS_W, edf = df_W)
```


- Unterscheidung zwischen
  - Kovariate für das Untersuchungsdesign
  - Kovariate für die Analyse der Daten

## Bestimmung der Anzahl der Replikationen 

\begin{align*}
\sigma_{\epsilon(\text{ANCOVA})}^2 &= \sigma_{\epsilon(\text{CRD})}^2(1-\rho_{xy}^2) \\
f_{\text{ANCOVA}} &= \frac{\sigma_{\text{btw}}}{\sigma_{\epsilon(\text{CRD})}}\frac{1}{\sqrt{1-\rho_{xy}^2}} = \frac{f_{\text{CRD}}}{\sqrt{1-\rho_{xy}^2}} 
\end{align*}

$df_{\text{Residual}} = N - k - 1$ under the ANCOVA model

sample size Beispiel^[nach @maxwell2004]

In einer CRD-Studie wurde eine Effektstärke für den Unterschied zwischen drei Gruppen ($k = 3$) von $f = 0.41$ gefunden. Wie verändert sich die notwendige Stichprobengröße wenn eine Kovariate mit $\rho = 0.5$ mit der abhängigen Variable hinzugenommen wird?

::: {#exm-ed-ancova-sample-size} 
Bei einer power von $0.8$ wird eine Stichprobengröße von:

```{r}
#| echo: true

pwr::pwr.anova.test(k=3, f=0.41, sig.level=0.05, power=0.8)$n
```
Wenn die Kovariate modelliert wird, erhöht sich die Effektstärke auf $f = 0.41/\sqrt{1-0.5^2} = 0.47$. Daraus resultiert eine reduzierte Stichprobengröße von:

```{r}
#| echo: true

pwr::pwr.anova.test(k=2, f=0.47, sig.level=0.05, power=0.8)$n
```

:::


## Was passiert wenn die Kovariate interagiert

```{r}
#| fig-cap: "Beispiel für einen Interaktionseffekt zwischen der Treatmentvariablen und der Kovariate"
 

n <- 60
set.seed(1)
df_i <- tibble(
  x = runif(n, -3, 3),
  g = sample(-1:1, n, replace=T),
  y = 3 + 2*g + 3*x + g*x + rnorm(n),
  gruppe = LETTERS[1:3][g+2]
)
p_1 <- ggplot(df_i, aes(x,y,color=gruppe)) + 
  geom_point(size=2) +
  geom_smooth(method='lm', se=F, formula=y~x) +
  scale_color_manual('Gruppe', values=c('dark red','green','blue')) +
  labs(x = 'X', y = 'Y') 
print(p_1)
```

Modell

$$
y_{it} = \beta_0 + \tau_i + \beta \cdot x_{it} + (\tau\beta)_{it}x_{it} + \epsilon_{it}
$$

### Welcher Unterschied zwischen den Gruppen? 

```{r}
print(p_1)
```

### Modellfit - Interaktionsmodell

```{r}
#| echo: true
#| results: hide

mod <- aov(y ~ x*gruppe, df_i)
anova(mod)
```

```{r}
anova(mod) |> broom::tidy() |> 
  knitr::kable(
    booktabs=T,
    digits = 2,
    col.names = c('Term', 'df', 'SSQ', 'MSQ', 'F', 'p.value'),
    caption="Anova-Tabelle für Interaktionsmodell")
```

```{r}
#| echo: true
 
mod_ems <- emmeans(mod, ~gruppe|x, at=list(x=c(-2,0,2)))
mod_ems
```

```{r}
#| echo: true
#| results: hide

pairs(mod_ems)
```

```{r}
pairs(mod_ems) |> broom::tidy() |> 
  dplyr::select(x, contrast, estimate, std.error, df, statistic, adj.p.value) |> 
  my_tbl(header=c('x','contrast','estimate','$s_e$', '$df$','t','p'),
         caption="Paarvergleiche",
         escape=F)
```

## Zum Nach- und Weiterlesen

Allgemein
[@maxwell2004, p.451-467]

Pre-post ANCOVA
@wan2021


