# Eine kleine Welt der Unsicherheit 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```

In den einleitenden Problem aus dem vorhergehenden Abschnitt mit einem Vergleich zwischen zwei Gruppen ist warum überhaupt die Berechnung einer Statistik notwendig ist. Bei der Beantwortung der Frage sind wahrscheinlich Begründungen gefallen wie: *"Weil das Ergebnis zufällig sein könnte"* oder *"Weil wir wissen wollen ob der Unterschied auch signifikant ist"* und ähnliche. Diese Antworten sind im Grunde genommen alle korrekt aber es sind zunächst ein paar Konzepte einzuführen um das Problem tatsächlich strukturiert angehen zu können. Diese Konzepte werden in dem folgenden Kapitel entwickelt.

```{r}
n <- 20
set.seed(123)
world <- tibble(ID = paste0('P',stringr::str_pad(1:n, width=2, pad="0")),
                Kraft = sample(2000:2500, n))
world$Kraft[13] <- 1800
world$Kraft[17] <- 3200
d_gr <- 100
d_x <- 2
```

Zunächst wird einem übersichtlichen Konstrukt einer hypothetischen Welt gestartet um das notwendige statistische Modell so einfach wie möglich zu halten. Die Welt, über die eine Aussage getroffen werden soll, besteht aus nur insgesamt $20$ Personen. In @fig-small-world sind die Bewohner dieser Welt einzeln zu dargestellt. Um nicht $20$ Namen zu verwenden, sind die Bewohner durchnummeriert von $1$ bis $20$ mit einem Prefix $P$.

```{r}
#| fig-cap: "Eine kleine Welt"
#| label: fig-small-world
#| fig-height: 4

include_graphics('pics/small_world.png')
```

Der Gesamtheit aller Personen, oder auch allgemeiner Objekte, über die eine Aussage getroffen werden soll wird jetzt ein Name gegeben. Diese Menge soll als Population\index{Population} bezeichnet werden.

::: {#def-population}

## Population

Die Gesamtheit aller Objekte/Dinge/Personen, über die eine Aussage getroffen werden soll, wird als Population oder Grundgesamtheit bezeichnet.
:::

Jeder statistischen Aussage liegt zunächst eine Menge von Objekten/Personen zugrunde über die eine Aussage getroffen werden soll. Im vorliegenden Fall ist die Population sehr übersichtlich, während sie in den meisten Fällen deutlich größer ist. Zum Beispiel alle Personen zwischen $15-64$ Jahren (ungefähr $5$ Milliarden Personen) oder alle aktiven Tischtennisspieler in Deutschland (ungefähr $500.000$) oder Sportstudierende in Deutschland (über 30.000) oder an Krebs neuerkrankte Personen in der EU (etwa $3$ Millionen). Die Population hängt damit immer mit der konkreten wissenschaftlichen Fragestellung zusammen die untersucht werden soll.

## Ein Experiment

Basierend auf einer theoretischen Überlegung ist zum Beispiel ein neuer Krafttrainingsansatz entwickelt worden. Nun soll mittels eines Experiments überprüft werden, ob der neue Ansatz dazu führt, dass sich die Beinkraft stärker erhöht als bei einem traditionellen Training. Unglücklicherweise stehen selbst bei der kleinen Welt nur sehr wenige Ressourcen zur Verfügung und es können daher nur sechs Messungen durchführt werden. Aus einem kürzlich durchgeführten Zensus sind jedoch die Beinkraftwerte der gesamten Population bekannt. Sei daher zunächst einmal die Verteilung der Kraftwerte betrachtet. Eine einfache Möglichkeit, die Kraft, eine numerische Variable, darzustellen, ist in Form einer Tabelle (siehe @tbl-sts-basics-world).

```{r}
#| tbl-cap: "Kraftwerte (in Newton) der Lummerländer an der einbeinigen Beinpresse"
#| label: tbl-sts-basics-world

#world_wide <- cbind(world[1:10,],world[11:20,]) 
world |> 
  kable(
    booktabs=TRUE, 
    col.names = c('ID', 'Kraft[N]')) #,'ID','Kraft[N]')) 
```

Selbst bei $20$ Werten ist die Darstellung der Rohwerte mittels einer Tabelle allerdings leider wenig übersichtlich. Die Werte müssen Zeile für Zeile in der Tabelle durchgegangen werden und spezifische Kennwerte müssen notiert werden, um Vergleiche zwischen den Werten durchführen zu können. Beispielsweise zeigt die Tabelle, dass der Maximalwert der Beinkraft bei $`r max(world$Kraft)`$N für `r world$ID[which.max(world$Kraft)]` und der Minimalwert von `r world$ID[which.min(world$Kraft)]` bei $`r min(world$Kraft)`$N liegen. Aber wirklich übersichtlich ist die Darstellung in Form einer Tabelle nicht. Für solche univariaten Daten (uni = eins) kann eine übersichtlichere Darstellung mittels eines sogenannten Dotplots erreicht werden (siehe @fig-sts-basics-lummer-dotplot).

```{r}
#| fig-cap: "Dotplot der Lummerlandkraftdaten"
#| label: fig-sts-basics-lummer-dotplot
#| fig-height: 1.5

ggplot(world,
       aes(Kraft, 1)) +
  geom_point(size=3) +
  scale_x_continuous('Kraftwerte[N]', breaks = seq(1800, 3200, 200)) +
  scale_y_continuous('', breaks = NULL)
```

Der Dotplot erlaubt deutlich einfacher sich einen Überblick über die Daten zu verschaffen. Beispielsweise welchen Wert das Minimum bzw. das Maximum annimmt ist direkt ersichtlich. Die grafische Darstellung erlaubt weiterhin direkt abzuschätzen, in welchem Wertebereich der Großteil der Daten liegt. Allerdings wird durch diese Art der Darstellung die Information darüber, welche Person die jeweiligen Werte besitzt, nicht mehr dargestellt. Dies stellt jedoch nicht zwingend ein Problem dar, da in den meisten Fällen sowieso Aussagen über die Gruppe und weniger über einzelne Personen gemacht werden sollen. Ein Dotplot hat gleichzeitig den Vorteil, dass die Verteilung der Werte abgeschätzt werden kann. In welchem Bereich liegen die meisten Datenwerte? Liegen die Werte eng beieinander oder streuen die Werte sehr stark? Gibt es einzelne Werte, die sehr unterschiedlich von den anderen Werten sind? Dies sind alles Fragen, die notwendig sind, um einen Datensatz und dessen Eigenschaften beurteilen zu können. Generell erfordert es etwas Erfahrung und Ausprobieren um eine effektive Darstellung der Daten zu finden. Dies hängt auch oft mit der Fragestellung zusammen, da unterschiedliche Darstellungen üblicherweise auch unterschiedliche Aspekte der Daten betonen bzw. in den Hintergrund rücken.

Zurück zum Kraftexperiment. Da in der kleinen Welt nur evidenzbasierte Entscheidungen getroffen werden, soll empirisch überprüft werden, ob das *neue* Training wirklich zu einer Verbesserung der Beinkraft führt. Um das Experiment zu vereinfachen, und da es sich mehr um ein Gedankenexperiment handelt, sei von von einem *perfekten* Krafttraining ausgegangen. Das heißt, Intervention ist dahingehend perfekt, dass die Intervention zu der gleichen Verbesserung bei allen Teilnehmerinnen und Teilnehmern führt. Dies ist natürlich eine unrealistische Annahme aber sie vereinfacht die Problembetrachtung bzw. Problemanalyse und ändert tatsächlich zunächst auch nichts an der inhaltlichen Problemstellung.

Das Beinkrafttraining sei also perfekt und verbessert die Kraftleistung um einen einzigen präzisen Wert. Sei die Verbesserung mit $+`r d_gr`$N gegeben. Dieser Kraftzuwachs ist unabhängig davon, welche Person aus der Population das Training durchführt. Um die Effektivität des Trainings abzuschätzen, sollen nun zwei Gruppen miteinander verglichen werden: eine Interventionsgruppe, welche das Krafttraining durchläuft, und eine Kontrollgruppe. In beiden Gruppen sollen jeweils $n_{\text{TRT}} = n_{\text{CON}} = 3$ Teilnehmerinnen bzw. Teilnehmer einbezogen werden. Die Kontrollgruppe führt ebenfalls ein Krafttraining durch. Das Krafttraining der Kontrollgruppe sei aber perfekt uneffektiv. D.h. es das Training führt zu keiner Verbesserung der Kraftfähigkeiten der Teilnehmerinnen und Teilnehmer. Um das Experiment besser zu charakterisieren, sind allerdings erst noch ein paar Begrifflichkeiten notwendig.

::: {#def-dep-var}
## Abhängige Variable \index{abhängige Variable}

Die abhängige Variable ist diejenige Variable, die in einer Studie beobachtet, gemessen oder analysiert wird. Die abhängige Variable wird oft als "Effekt" betrachtet.
:::

::: {#def-indep-var}
## Unabhängige Variable \index{unabhängige Variable}

Die unabhängige Variable ist die Variable, die in einer Studie oder einem Experiment manipuliert oder kontrolliert wird. Die unabhängige Variable wird oft als "Ursache" betrachtet, da sie den potenziellen Einfluss auf die abhängige Variable repräsentiert.
:::

Bezogen auf das vorliegende Experiment stellt die Gruppenzugehörigkeit somit die unabhängige Variable dar, während die Beinkraft die abhängige Variable darstellt. In dem Experiment wird somit der Effekt der Gruppenzugehörigkeit auf die Beinkraft untersucht. Die Zugehörigkeit zu einer der beiden Gruppe ist die Ursache für mögliche Effekte auf die Beinkraft.

Im folgenden wird nun so getan, als ob die Daten aus dem Zensus nicht vorliegen würden. Es stellen sich nun zwei Fragen: 1) Wie werden die sechs Personen aus der Population ausgewählt, und 2) wenn sechs Personen ausgewählt worden sind, wie werden diese Personen in die beiden Gruppen aufgeteilt?

Bezogen auf die zweite Frage, könnte eine Möglichkeit sein, die ersten drei Personen der Interventionsgruppe zuzuteilen und die verbleibenden drei Personen der Kontrollgruppe zuzuweisen. Implizit ist dabei festgelegt, dass die beiden Gruppen die gleiche Größe haben. Dies soll auch in der weiteren Diskussion beibehalten werden. Bei dieser sequentiellen Zuweisung kann es allerdings passieren, dass wenn die Personen in irgendeiner Form nach der Beinkraft schon vorsortiert sind, z.B. allgemeiner Gesundheitsstatus, Arbeitstätigkeit usw., dann würde sich diese Sortierung auf die Gruppen übertragen. Wenn die Personen von schwächer nach stärker sortiert sind, würden in der Interventionsgrupps die insgesamt schwächere Personen zugeteilt werden als in der Kontrollgruppe. Die initiale Beinkraft würde dann die Funktion einer sogenannten Störvariable\index{Störvariable} einnehmen. Die Störvariable würde dazu führen, das das Ergebnis verfälscht  würde.

::: {#def-confounder}
## Störvariable 

Eine Störvariable ist eine Variable, die einen Einfluss auf die abhängige Variable hat, deren Einfluss jedoch nicht kontrolliert wurde. Eine Störvariable ist nicht von Hauptinteresse für die Untersuchung.
:::

In realen Fällen kann davon ausgegangen werden, dass immer eine ganze Reihe von Störvariablen vorliegen. Unglücklicherweise gehören dazu auch Störvariablen, die gar nicht bekannt sein müssen. Beispielsweise genetische Prädispositionen die noch nicht erforscht sind oder vielleicht noch nicht gemessen werden können. Daher wird ein Mechanismus benötigt der dafür sorgt, dass die Störvariablen möglichst wenig Einfluss auf den gesuchten Effekt ausüben. D.h. die Teilnehmerinnen und Teilnehmer müssen so den beiden Gruppen zugewiesen werden, dass die Störvariablen möglichst in gleichen Anteilen in den beiden Gruppen vorkommen. Der Mechanismus der dazu verwendet wird ist eine zufällige Zuteilung der Personen in die beiden Gruppen. Es wird eine Randomisierung durchgeführt.

::: {#def-randomisierung}
## Randomisierung \index{Randomisierung}

Mit Randomisierung wird der Prozess der zufälligen Zuweisung von Probanden oder Elementen zu verschiedenen Gruppen oder Bedingungen in einem Experiment bezeichnet. Die Randomisierung wird verwendet, um sicherzustellen, dass die Auswahl und Zuordnung der Elemente frei von systematischer Beeinflussung erfolgt. 
:::

Mit Hilfe der Randomisierung kann sichergestellt werden, dass *im Mittel* die Störvariablen gleichmäßig auf die beiden Gruppen verteilt sind. Ohne diese Annahmen, dass die Störvariablen gleichmäßig verteilt sind, ist es nicht möglich eine ursächliche Beziehung zwischen der abhängigen und der unabhängigen Variablen zu etablieren. Sind die Störvariablen nicht gleich verteilt, dann könnte ein möglicher Unterschied zwischen den Variablen auch nur auf Grund der Störvariablen zustande kommen. Die Randomisierung der Stichprobe in die Gruppen ist natürlich kein $100\%$ Verfahren. *Per Zufall* kann es dazu kommen, dass Störvariablen nicht gleichmäßig verteilt sind, was bei unbekannten Störvariablen, auch nicht zu überprüfen ist. Dieses Problem wird umso größer umso kleiner die Anzahl der Personen ist. Seine zum Beispiel $10$ Personen gegeben, von denen $3$ Personen Merkmal A haben und $7$ Personen Merkmal B. Die Wahrscheinlichkeit dafür, dass alle As der gleichen Gruppe zugeteilt werden liegt bei knapp $17\%$. Bei dem gleichen Verhältnis mit $100$ Personen und zwei Gruppen à $50$ Personen ist die Wahrscheinlichkeit nur noch $3.2e-10$. Damit ist die zweite Frage der Zuteilung beantwortet. Bleibt noch die Frage wie die sechs Personen aus der Population ausgewählt werden sollen.  

Letztendlich ist bei der Auswahl der Stichprobe ein ähnliches Problem wie bei der Zuteilung in die beiden Gruppen zu lösen. Allerdings aus einer etwas anderen Perspektive. Die Ergebnisse die anhand der Stichprobe beobachtet werden, sollen letztendlich auf die Gesamtpopulation übertragen werden. D.h. wenn in der Population die eine Hälfe Merkmal A trägt und die andere Merkmal B und in der Stichprobe nur Personen mit Merkmal A sind, dann wird es schwierig bis unmöglich werden, das Ergebnis auf basierend auf der Stichprobe auf die Population zu übertragen. D.h. bei der Wahl der Stichprobe muss darauf geachtet werden, dass diese Stichprobe tatsächlich repräsentativ für die Population ist. Hier ist wieder das gleich Problem vorhanden, dass a-priori nicht klar ist, welche *Merkmale* relevant sind, daher können diese Merkmale auch nicht alle bestimmt werden und somit sichergestellt werden, dass die Merkmale in gleichem Maße in der Stichprobe repräsentiert sind, wie in der Population. Wieder ist die Lösung für das Problem eine Anwendung des Zufalls, nämlich indem eine sogenannte **Zufallsstichprobe** gewählt wird. Formaler:

::: {#def-sample}
## Stichprobe

Eine Stichprobe\index{Stichprobe} ist eine Teilmenge von Objekten aus der Population.
:::

::: {#def-random-sample}
## Zufallsstichprobe

Eine Zufallsstichprobe\index{Zufallsstichprobe} ist eine Teilmenge von Objekten aus der Population, die *zufällig* ausgewählt wurde.
:::

Bei der Zufallsstichprobe haben alle Personen in der Population vor dem Experiment die gleiche Wahrscheinlichkeit, gezogen zu werden. Dadurch kann sichergestellt werden, dass in der Stichprobe unterliegende Störvariablen, ob messbar oder nicht messbar, ebenso in der Stichprobe verteilt sind.

::: {exm-random-sample}

Eine kleine Simulation veranschlicht das Prinzip. Sei eine Population der Größe $N = 100$ gegeben, in der $30$ Objekte das Merkmal A haben und $70$ Objekte das Merkmal B. Es werden nun wiederholt Zufallsstichproben der Größe $N = 20$ aus dieser Population gezogen und für jede Stichprobe wird der Anteil der As berechnet.

```{r}
set.seed(25)
```

In `R` lässt sich eine solche Simulation relativ einfach umsetzen, die hier der Übersicht halber $20$ mal durchgeführt wird.

```{r}
#| echo: true

pop <- rep(c("A","B"), c(30,70))
n_sam <- 20
res <- numeric(n_sam)
for (i in 1:n_sam) {
  sam <- sample(pop, 20)
  res[i] <- mean(sam == 'A')
}
res
```

Wir die Ausgabe von `res` zeigt, dass tatsächlich in den meisten Fällen der Anteil von As in der Stichprobe in der Nähe der $30\%$ aus der Population liegt. Nicht in allen Fällen, es gibt Schwankungen um diesen Wert herum, aber im Großen und Ganzen spiegelt die Stichprobe in Bezug auf die Verteilung von Merkmalen A und B die Population gut wieder. Das heißt, es handelt sich um eine *repräsentative* Stichprobe.
:::

In Abhängigkeit von der Forschungsfragestellung kann die Anzahl der Merkmale relativ schnell anwachsen, in diesem Fall spielt die Größe der Stichprobe ebenfalls eine wichtige Rolle. Seien zum Beispiel für eine Fragestellung möglicherweise $15$ Merkmale wie Alter, Geschlecht, sportliche Aktivität usw. relevant und es wird eine Stichprobe mit $N = 16$ gewählt, dann ist es natürlich gar nicht möglich die Merkmale selbst wenn bekannt gleichmäßig in zwei Gruppen zu unterteilen. Daher ist die Repräsentativität einer solchen Stichprobe nur sehr eingeschränkt.

```{r}
id_s1 <- c(8, 9, 3, 7, 10, 20)
```

Zurück zum *Kleine Welt Beispiel*. Um jetzt für das Experiment eine Stichprobe zu ermitteln, wird genutzt, dass die Population bereits durchnummeriert ist. Nun kann eine Zufallszahlengenerator verwendet werden, der zunächst sechs Zahlen für die Stichprobe bestimmt. Beispielsweise die Zahlen $i = \{`r paste(sort(id_s1), collapse=',')`\}$. Die entsprechenden Personen werden aus der Population anhand der ID ausgewählt. Anschließend teilt wieder ein Zufallszahlengenerator die sechs Personen in die beiden Gruppen auf (siehe @fig-stats-basics-sample-01).

```{mermaid}
%%| fig-cap: "Ablaufdiagramm der Gruppenzuweisung."
%%| label: fig-stats-basics-sample-01

flowchart TD
    A{Population} --> B(Zufallszahlengenerator)
    B --> C[Stichprobe]
    C --> D(Zufallszahlengenerator)
    D --> E[Kontrollgruppe]
    D --> F[Interventionsgruppe]
```

Wie bereits hergeleitet, ist dieser Prozess der zufälligen Ziehung und zufälligen Zuteilung kritisch, um das Ergebnis des Experiments eindeutig interpretieren zu können und eine Generalisierung über die bestehenden Objekte hinaus durchführen zu können. Leider ist der erste Schritt, die zufällige Ziehung von Objekten aus der Population, in der Realität nur sehr schwer realisierbar.

In @tbl-sts-basics-experiment-1 ist die Stichprobe und Zuteilung in die Gruppen zu sehen.

```{r}
#| tbl-cap: "Zufällig ausgewählte Stichprobe der Größe $N=6$ und die Zuteilung in Kontroll- (CON) und Interventionsgruppe (TRT)."
#| label: tbl-sts-basics-experiment-1

world_ex_1 <- world[id_s1,] |> mutate(Gruppe=rep(c('CON','TRT'),each=3))
world_ex_1 |> 
  kable(
    booktabs=TRUE, 
    col.names = c('ID', 'Kraft[N]','Gruppe'))
```

Mit diesen sechs Personen sollen nun das Experiment durchgeführt werden. Die drei Personen aus der Kontrollgruppe durchlaufen im Interventionszeitraum nur ein Standardtraining, während die Interventionsgruppe zweimal die Woche für 12 Wochen das *perfekte* Krafttraining durchführt. Nach diesem Zeitraum wird die Beinkraft aller Personen aus beiden Gruppen gemessen. Es wird das folgende Ergebnis erhalten (siehe @tbl-sts-basics-sample-1). Es sei angenommen, dass die Werte aus dem Zensus nicht bekannt sind.

```{r}
#| label: tbl-sts-basics-sample-1
#| tbl-cap: "Ergebnis der Intervention in Experiment 1 für die Kontroll- und die Interventionsgruppe."
#| tbl-subcap:
#|   - "Kontrollgruppe"
#|   - "Interventionsgruppe"
#| layout-ncol: 2

world_ex_1 <- world_ex_1 |>
  rows_update(world_ex_1 |> filter(Gruppe == 'TRT') |>
                mutate(Kraft = Kraft + d_gr),
              by = 'ID')

dat_kon <- world[id_s1[1:3],]
dat_int <- world[id_s1[4:6],] |> 
  mutate(Kraft = Kraft + d_gr)

add_mean <- function(tib) {
  if (dim(tib)[2] == 2) {
    tib |> add_row(
      tibble(ID = '$\\bar{K}$', Kraft = round(mean(tib$Kraft)))
    )
  }
  else {
    tib |> add_row(
      tibble(ID = '$\\bar{K}$', Kraft = NA, Kraft_2 = round(mean(tib$Kraft_2)))
    )
  }
}

kable(dat_kon |> add_mean(),
  booktabs=T,
  col.names=c('ID','Kraft[N]'))

kable(dat_int |> add_mean(),
  booktabs=T,
  col.names=c('ID','Kraft[N]'))
```

Für beide Gruppen ist in @tbl-sts-basics-sample-1 jeweils noch der Mittelwert\index{Mittelwert} $\bar{K}$ dokumentiert, um die Gruppen leichter miteinander vergleichen zu können. Später werden noch weitere Maße eingeführt, die es ermöglichen, zwei Mengen von Werten miteinander zu vergleichen. Der Mittelwert ist ein Maß, dass aber schon bekannt sein sollte.

::: {#def-Mittelwert}
## Mittelwert

Der Mittelwert $\bar{x}$ über $n$ Werte berechnet sich nach der Formel:

$$
\bar{x} = \frac{\sum_{i=1}^n x_i}{n}
$$ {#eq-mean}

Der Mittelwert wird mit einem Strich über der Variable dargestellt.
:::

Wenn die Schreibweise mit dem Summenzeichen $\Sigma$ etwas verwirrend erscheind, dann sind im Anhang noch mal die wichtigsten Infos zum Rechnen mit Summen angegeben. Mit dem Mittelwert ist auch gleichzeitig das zentrale und namensgebende Konzept aus der Statistik eingeführt worden. Die Statistik\index{Statistik}. Ein Wert, der mittels der Werte aus einer Stichprobe berechnet wird, wird als **Statistik** bezeichnet.

::: {#def-Statistik}
## Statistik

Ein auf einer Stichprobe berechneter Wert wird als Statistik bezeichnet.
:::

Der Definition folgend, ist somit der Mittelwert $\bar{X}$ einer Stichprobe eine Statistik. Das Gleiche würde gelten, wenn anstatt des Mittelwerts der Maximalwert oder der Minimalwert einer Stichprobe ermittelt wird. Da beide Werte anhand der Werte aus der Stichprobe berechnet werden, stellen der Maximalwert und der Minimalwert ebenfalls eine Statistik dar.

Um nun den Unterschied zwischen den beiden Gruppen zu bestimmen, gibt es eine ganze Reihe von verschiednen Ansätzen. Ein sehr direkte und auch intuitiv nachvollziehbare Möglichkeit ist die Differenz $D$ zwischen den beiden Mittelwerten zu berechnen. Dabei ist es notwendig eine Richtung zu bestimmen bzw. welcher der beiden Mittelwerte den Minuenden und welcher den Subtrahenden darstellt. Hier gibt es keine Vorgaben, sondern die Richtung kann frei bestimmt werden und muss nur entsprechend dokumentiert werden. Im vorliegenden Fall soll die Interventionsgruppe von der Kontrollgruppe abgezogen werden. Da ausgegangen wird, dass die Intervention zu einer Krafterhöhung führt sollte mit dieser Konvention ein positiven Unterschied erhalten werden. Dies führt dann zur Definition \eqref{eq-sts-basics-ex1-d}.

\begin{equation}
D := \bar{K}_{\text{TRT}} - \bar{K}_{\text{CON}}
\label{eq-sts-basics-ex1-d}
\end{equation}

```{r}
world_ex_1_hat <- world_ex_1 |> group_by(Gruppe) |> summarize(Kraft = round(mean(Kraft)))
D_1 <- (world_ex_1_hat |> summarize(D = diff(Kraft)))$D
```

Für das Beispiel des kleine Welt Experiment werden dementsprechend der folgenden Wert erhalten:

$$
D = `r world_ex_1_hat$Kraft[2]`N - `r world_ex_1_hat$Kraft[1]`N = `r D_1` N
$$ 

Da der Wert $D$ wiederum auf den Daten der Stichprobe berechnet wird, handelt es sich ebenfalls um eine Statistik.

```{r}
#| fig.cap: "Dotplot der beiden Stichproben. Senkrechte Striche zeigen die jeweiligen Mittelwerte an."
#| label: fig-sts-basics-ex-1-dotplot
#| fig.height: 1.5

diff_dotplot(world_ex_1, world_ex_1_hat)
```

In @fig-sts-basics-ex-1-dotplot sind die Werte der beiden Gruppen, deren Mittelwerte $\bar{K}_{\text{CON}}$ und $\bar{K}_{\text{TRT}}$ und der Unterschied $D$ zwischen diesen graphisch abgetragen. Wie erwartet zeigt die Interventionsgruppe den höheren Kraftwert im Vergleich zu der Kontrollgruppe. Allerdings ist der Wert mit $D = `r D_1`$ größer als der tatsächliche Zuwachs von $\Delta_{\text{Training}} = `r d_gr`$. Der Unterschied zwischen den beiden Gruppen ist natürlich auch zum Teil auf die Unterschiede, die zwischen den beiden Gruppen vor der Intervention bestanden haben, zurückzuführen. Dies führt zu der Frage was denn passiert wäre, wenn eine andere Stichprobe gezogen worden wäre?

```{r}
id_s2 <- c(12,2,19,4,8,16)
```

Sei $i = \{`r paste(id_s2, collapse=',')`\}$ eine zweite Zufallsstichprobe. Dies würde zu den folgenden Werten nach der Intervention führen.

```{r}
#| label: tbl-sts-basics-sample-2
#| tbl-cap: "Ergebnis der Intervention in Experiment 2 für die Kontroll- und die Interventionsgruppe."

world_ex_2 <- world[id_s2,] |> mutate(Gruppe=rep(c('CON','TRT'),each=3))
world_ex_2 <- world_ex_2 |>
  rows_update(world_ex_2 |> filter(Gruppe == 'TRT') |>
                mutate(Kraft = Kraft + d_gr),
              by = 'ID')
world_ex_2_hat <- world_ex_2 |> group_by(Gruppe) |> summarize(Kraft = mean(Kraft))
D_2 <- round(diff(world_ex_2_hat$Kraft))

world_ex_2 |> 
  kable(
    booktabs=TRUE, 
    col.names = c('ID', 'Kraft[N]','Gruppe'))
```

```{r}
#| fig-cap: "Dotplot der beiden Stichproben in Experiment 2. Senkrechte Striche zeigen die jeweiligen Mittelwerte an."
#| label: fig-sts-basics-ex-2-dotplot
#| fig-height: 1.5

diff_dotplot(world_ex_2, world_ex_2_hat)
```

In @fig-sts-basics-ex-2-dotplot sind wieder die Datenpunkte, Mittelwerte und der Unterschied in den Mittelwerten zwischen den beiden Gruppen abgetragen. In diesem Fall ist allerdings die Differenz zwischen den beiden Gruppen genau in der anderen Richtung $D = `r D_2`$. Daher würde dieses Ergebnis tatsächlich genau in der anderen Richtung hin interpretiert werden. Das Krafttraining führt nicht nur zu keiner Verbesserung in der Kraftfähigkeit, sondern sogar zu einer Verschlechterung!

```{r}
id_s3 <- c(6,5,7,20,14,16) 
```

Es hätte aber auch sein können, dass noch eine andere Stichprobe gezogen worden wäre, z.B. $i = \{`r paste(id_s3, collapse=',')`\}$. Mit dieser Stichprobe würden das folgende Ergebnis beobachtet werden (siehe @tbl-sts-basics-ex-3). 

```{r}
#| tbl-cap: "Mittelwertsdaten aus Experiment 3 und der Unterschied $D$ zwischen den beiden Gruppenmittelwerten"
#| label: tbl-sts-basics-ex-3

world_ex_3 <- world[id_s3,] |>
  mutate(Gruppe=rep(c('CON','TRT'),each=3)) 
world_ex_3_hat <-  world_ex_3 |> 
  rows_update(world_ex_3 |> filter(Gruppe == 'TRT') |>
                mutate(Kraft = Kraft + d_gr),
              by = 'ID')  |> 
  group_by(Gruppe) |> summarize(Kraft = mean(Kraft)) 
D_3 <- round(diff(world_ex_3_hat$Kraft))

world_ex_3_hat |> 
  bind_rows(world_ex_3_hat |> summarize(Gruppe = '$D$', Kraft = diff(Kraft))) |> 
  kable(
    booktabs=T,
    digits = 0,
    col.names = c('Gruppe', 'Kraft[N]')
  ) #|> 
  #kableExtra::row_spec(2, extra_latex_after = "\\cmidrule{1-2}")
  
```

In diesem Fall haben ist zwar ein positiver Unterschied zwischen den beiden Gruppen in der zu erwartenden Richtung gefunden worden, der Unterschied von $D = `r D_3`$ ist allerdings deutlich kleiner als der tatsächliche Unterschied $\Delta = `r d_gr`$. Daher könnte das Ergebnis möglicherweise so interpretieren werden, das das Krafttraining als ineffektiv bewertet wird und keine Empfehlung für das Training ausgesprochen wird.

Zu beachten ist, dass keines der Ergebnisse 100% korrekt ist. Entweder ist der Unterschied zwischen den beiden Gruppen deutlich zu groß, in der falschen Richtung oder deutlich zu klein. Das Ergebnis des Experiments hängt ursächlich damit zusammen, welche Zufallsstichprobe gezogen wurde und wie diese Stichprobe in die Gruppen unterteilt wird. Denn natürlich würden sich die $D$-Werte ebenfalls ändern, wenn die Stichprobe gleich gehalten würde aber die Zuteilung geändert wird. Daraus folgt, dass bei Wiederholungen des Experiments generell jeweils unterschiedliche Werte beobachtet werden und dieses Phänomen ist eine Folge der notwendigen Randomisierungsschritte. Allgemein wird das Phänomen, dass der Wert der berechneten Statistik zwischen Wiederholungen des Experiments schwankt, als Stichprobenvariabilität bezeichnet.  

::: {#def-sample-variability}
## Stichprobenvariabilität

Durch die Anwendung von Zufallsstichproben variiert eine auf den Daten berechnete Statistik. Diese Variabilität wird als Stichprobenvariabilität\index{Stichprobenvariabilität} bezeichnet.
:::

Streng genommen führt die Stichprobenvariabilität allein noch nicht dazu, dass sich die Statistik zwischen Wiederholungen des Experiments verändert, sondern die zu untersuchenden Werte in der Population müssen selbst auch eine Streuung aufweisen. Wenn eine Population untersucht würde, bei der alle Personen die gleiche Beinkraft hätten, würden unterschiedliche Stichproben immer den gleichen Mittelwert haben und wiederholte Durchführungen des Experiments würden immer wieder zu demselben Ergebnis führen. Dieser Fall ist in der Realität jedoch praktisch nie gegeben, und sämtliche interessante Parameter zeigen immer eine natürliche Streuung in der Population. Diese Streuung in der Population führt daher zu dem besagten Phänomen, dass das gleiche Experiment mehrmals wiederholt zu unterschiedlichen Zufallsstichproben und dementsprechend immer zu unterschiedlichen Ergebnissen führt. Das Ergebnis ist inhärent variabel bzw. **unsicher**. Dieses grundlegende Prinzip liegt allen Datenanalysen zugrunde. Bei nicht-experimentellen Daten ergeben sich noch weitere Probleme, im weiteren wird aber vor allem die experimentelle Herangehensweise mit randomisierten Experimenten behandelt, da dieses die dominante Herangehensweise darstellen kausale Effekte zwischen abhängigen und unabhängigen Variablen zu erstellen. Die zentrale Aufgabe der Disziplin Statistik ist somit mit dieser Variabilität umzugehen und Forscherinnen in die Lage zu versetzen, trotz dieser Unsicherheit rationale Entscheidungen zu treffen.

Eine implizite Kernannahme bei diesem Ansatz ist, dass mit Hilfe von Daten überhaupt etwas über die Welt erlernt werden kann. Das heißt, dass die Erhebung von Daten einen in die Lage versetzt, rationale Entscheidungen zu treffen. Entscheidungen wie ein spezialisiertes Krafttraining mit einer klinischen Population durchzuführen oder eine bestimmte taktische Variante mit meiner Mannschaft zu trainieren, um die Gegner besser auszuspielen. Alle diese Entscheidungen sollten rational vor dem Hintergrund von Variabilität und Unsicherheit getroffen werden und zwar möglichst so, das möglichst oft korrekte Entscheidungen getroffen werden. Wie noch gezeigt wird, kann auch die Statistik leider nicht garantieren, dass immer die korrekte Entscheidung getroffen wird. Es kann auch mal vorkommen, dass beim Würfelwurf zehnmal hintereinander ein sechs gewürfelt wird, ohne dass der Würfel in irgendeiner Art und Weise manipuliert wurde. Nochmals auf den Punkt gebracht nach @wild2000 [p.28]:

> The subject matter of statistics is the process of finding out more about the real world by collecting and then making sense of data.

Sei zunächst noch einmal das Phänomen weiter untersucht, dass Wiederholungen desselben Experiments zu unterschiedlichen Ergebnissen führen. Im Beispiel liegt der unrealistische Vorteil vor, dass die tatsächliche *Wahrheit* bekannt ist. Dieser Umstand soll nun verwendet werden. In @fig-sts-basics-d-dist-1 ist die Verteilung der drei bisherigen $D$s abgetragen.

```{r}
#| fig-cap: "Bisherige Verteilung der Unterschiede $D$"
#| label: fig-sts-basics-d-dist-1
#| fig-height: 1.8

ggplot(tibble(D = c(D_1, D_2, D_3)), aes(x = D)) +
  geom_histogram(bins = 30) +
  scale_y_continuous('Anzahl', breaks = c(0, 1)) +
  scale_x_continuous('D[N]')
```

Die drei Werte liegen relativ weit auseinander. Eine Anschlussfrage könnte daher sein: "*Welche weiteren Werte sind denn überhaupt mit der vorliegenden Population möglich?*".

## Die Stichprobenverteilung

Um die Frage zu beantworten, kann das Experiment einfach noch mehrere Male wiederholt werden. In @fig-sts-basics-sample-combination sind dazu $15$ weitere Zufallsstichproben abgetragen. In jeder Zeile sind alle $20$ Personen der Population angetragen und die sechs jeweils gezogenen TeilnehmerInnen sind farbig markiert. Drei für die Kontrollgruppe und drei für die Interventionsgruppe. Für jede dieser Zeilen können nun wieder die Gruppenmittelwerte berechnet und der Unterschied $D$ bestimmen werden.

```{r}
#| fig-cap: "Beispiele für verschiedene Möglichkeiten, zwei Stichproben mit jeweils $n_i = 3$ aus der Population zu ziehen." 
#| label: fig-sts-basics-sample-combination
#| fig-height: 3

foo <- function(id, n=20, k=3) {
  x <- 1:n
  y <- rep(id,n)
  t <- rep('ungezogen',n)
  id <- sample(20, 2*k)
  t[id[1:k]] <- 'Kontrol'
  t[id[(k+1):(2*k)]] <- 'Intervention'
  tibble(x,y,t)
}
n_rep <- 15
dat <- purrr::map_dfr(1:n_rep,foo)
ggplot(dat, aes(x,y,color=t,pch=t)) +
  geom_hline(yintercept = 1:n_rep) +
  geom_point(size=4) +
  scale_x_continuous('Probanden ID', breaks=1:20) +
  scale_y_continuous('Mögliche Kombination[#]', breaks=1:n_rep) +
  scale_color_discrete('Kategorie') +
  guides(pch = "none") +
  theme_minimal()
```

Tatsächlich ist es nicht notwendig sich nur auf $15$ Zufallsstichproben zu beschränken. Dadurch, dass die Population relativ übersichtlich ist, ist es relativ einfach möglich alle Möglichkeiten zu ermitteln. Die Herleitung benötigt allerdings etwas Mathematik aus der Schule, im speziellen die Kombinatorik, die sich mit dem Zählen von Möglichkeiten befasst. Beispielsweise mit der Frage, wie viele Möglichkeiten es gibt aus einer Urne mit $20$ nummerierten Kugeln sechs Kugeln zu ohne Zurücklegen zu ziehen. Eine direkte Herleitung könnte so gehen. Bei sechs Kugeln ohne zurückziehen, kann die erste Kugel $20$ unterschiedliche Werte haben, die zweite $19$ unterschiedliche Werte, da eine Kugel schon entnommen wurde, die dritte Kugel hat $18$ mögliche Werte usw bis zur sechsten Kugel für die es $15$ Möglichkeiten gibt.

\begin{equation*}
\text{Möglichkeiten} = 20 \cdot 19 \cdot 18 \cdot 17 \cdot 16 \cdot 15
\end{equation*}

Mit der Definition der Fakultät $!$, 

\begin{equation*}
n! = n \cdot (n-1) \cdot (n-2) \cdots 1
\end{equation*}

kann dies kürzer geschrieben werden mit:

\begin{equation*}
\text{Möglichkeiten} = \frac{20!}{(20-6)!} = \frac{20!}{14!}
\end{equation*}

Da die Reihenfolge der Ziehung keine Rolle spielt müssen noch zum Beispiel die Fälle $[1,2,3,4,5,6]$ und $[2,3,4,5,6,1]$ und alle weiteren Permutationen der Menge $\{1,2,3,4,5,6\}$ berücksichtigt werden. Hier funktioniert auch wieder das Abzählverfahren von eben. Wenn die sechs Kugel gezogen wurden und es sind sechs freie Plätze vorhanden, dann kann der erste Platz mit sechs Kugeln belegt werden, der zweite Platz mit fünf Kugeln, der dritte Platz mit vier Kugeln usw.. Das heißt es ergibt sich insgesamt:

\begin{equation*}
\text{Permutationen} = 6 \cdot 5 \cdot 4 \cdot 3 \cdot 2 \cdot 1 = 6!
\end{equation*}

D.h. die oben hergeleitete Anzahl von Möglichkeiten muss noch durch diese Anzahl der Permutationen geteilt werden um insgesamt die Anzahl der Möglichkeiten sechs Kugeln aus zwanzig Kugeln ohne zurücklegen und ohne Rücksicht auf die Reihenfolge zu bestimmten.

\begin{equation*}
\text{Möglichkeiten sechs aus zwanzig} = \frac{20!}{14!6!} = `r choose(20,6)`
\end{equation*}

Wenn der Ansatz verallgemeinert wird mit $N = 20$ und $K = 6$ folgt daraus die Formel für den sogenannten **Binomialkoeffizienten** der als $N$ über $K$ gelesen wird.

\begin{equation}
\text{Anzahl} = \binom{N}{K} = \frac{N!}{K!(N-K)!}
\label{eq-binom-coef}
\end{equation}

Die Anzahl der Möglichkeiten sechs aus zwanzig zu ziehen ist damit hergeleitet. Es fehlt noch die Aufteilung in die beiden Gruppen. Sei dazu die Treamentgruppe betrachtet, d.h. aus den sechs gezogenen Personen (Kugeln) sollen drei in die Treatmentgruppe gesteckt werden. Wenn diese drei Personen bestimmt wurden, ist automatisch auch die Kontrollgruppe bestimmt und die Kontrollgruppe braucht nicht weiter betrachtet werden. Letztendlich ist diese Problemstellung genau wieder die gleiche wie auch bei der Ziehung der Stichprobe. Daher folgt mit $N = 6$ und $K = 3$.

\begin{equation*}
\text{Gruppenzuteilung} = \binom{6}{3} = `r choose(6,3)`
\end{equation*}

Insgesamt folgt für die Anzahl der möglichen Stichprobenkombinationen somit:

```{r}
count_all_exp <- choose(20,6)*choose(6,3)
```

\begin{equation*}
\text{Anzahl} = \binom{20}{6}\binom{6}{3} = `r count_all_exp`
\label{eq-count-experiment}
\end{equation*}

Dies sind natürlich selbst bei dieser kleinen Population eine große Menge an *einzelnen* Experimenten. Aber dafür sind Computer da (Stichwort `for`-Schleife). In `R` stellt diese Aufgabe kein Problem dar. In @fig-sts-basics-all-combinations-d100 ist die Verteilung aller möglichen Experimentenausgänge, d.h. alle möglichen Differenzen $D$ zwischen der Interventions- und der Kontrollgruppe, abgebildet.

```{r}
#| fig-cap: "Verteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe bei einer Intervention mit $\\Delta = 100$ (im Graphen mittels der roten Linie angezeigt)."
#| label: fig-sts-basics-all-combinations-d100
#| fig-height: 3

differences <- readr::read_csv('data/combinations_differences.csv')
ggplot(differences |> dplyr::mutate(d = d + d_gr), aes(d)) +
  geom_histogram(aes(y=after_stat(density)), bins=50) +
  geom_vline(xintercept = d_gr, color='red', linetype='dashed') +
  labs(x = 'Differenzen D[N]', y = 'relative Häufigkeit') +
  lims(x = c(-800, 800)) 
```

Auf der x-Achse sind die möglichen Differenzen $D$ abgetragen, während auf der y-Achse die relative Häufigkeit, d.h. die Häufigkeit für einen bestimmten $D$-Wert geteilt durch die Anzahl $`r count_all_exp`$ aller möglichen Werte. Diese Verteilung der Statistik $D$s wird als **Stichprobenverteilung** bezeichnet.

::: {#def-sample-distribution}

Die Stichprobenverteilung\index{Stichprobenverteilung} einer Statistik beschreibt die Verteilung der Statistik. Wenn beispielsweise die Statistik der Mittelwert $\bar{x}$ ist, dann beschreibt die Stichprobenverteilung die Verteilung der möglichen Mittelwerte.
:::

@fig-sts-basics-all-combinations-d100 zeigt, dass die überwiegende Anzahl der Ausgänge tatsächlich auch im Bereich von $\Delta = `r d_gr`$ liegt. Noch präziser: Das Maximum der Verteilung, also die höchste relative Häufigkeit, liegt genau auf der roten Linie. Dies sollte tatsächlich etwas beruhigen, denn es zeigt, dass die Art der Herangehensweise mittels zweier Stichproben auch tatsächlich in den meisten Fällen einen nahezu korrekten Wert ermittelt. Allerdings zeigt die Stichprobenverteilung auch, dass Werte am rechten Ende, die deutlich zu hoch sind, wie auch Werte am linken Ende der Verteilung, die deutlich in der falschen Richtung liegen, möglich sind. Das bedeutet, wenn ein Experiment nur einziges Mal durchgeführt, kann man sich eigentlich nie sicher sein, welches dieser vielen Experimente durchgeführt wurde. Es ist zwar wahrscheinlicher, dass eines aus der Mitte der Verteilung durchgeführt wird, einfach da die Anzahl größer ist, aber es gibt keine 100%-ige Garantie, dass ein Experiment eine *Niete* ist und das Experiment ganz links mit $D = -500$ oder aber auch Experiment ganz rechts mit $D = 700$ durchgeführt wurde. Diese Unsicherheit kann leider keine Art von Experiment vollständig auflösen können. Eine weitere Eigenschaft der Verteilung ist ihre Symmetrie bezüglich des Maximums mit abnehmenden relativen Häufigkeiten, je weiter von Maximum $D$ entfernt ist (Warum macht das heuristisch Sinn?).

::: {.callout-note}
Die Darstellungsform von @fig-sts-basics-all-combinations-d100 wird als Histogramm bezeichnet und eignet sich vor allem dazu, die Verteilung einer Variablen z.B. $x$ darzustellen. Dazu wird der Wertebereich von $x$ zwischen dem Minimalwert $x_{\text{min}}$ und dem Maximalwert $x_{\text{max}}$ in $k$ gleich große Intervalle unterteilt, und die Anzahl der Werte innerhalb jedes Intervalls wird abgezählt und durch die Anzahl der Gesamtwerte geteilt, um die relative Häufigkeit zu bestimmen.

```{r}
hist_ex <- tibble(
  x_i = c(1, 1.5, 1.8, 2.1, 2.2, 2.7, 2.8, 3.5, 4),
  y_i = rep(c(1.5, 2.5, 3.5), c(3,4,2)),
  c_i = unlist(purrr::map(c(3,4,2), ~1:.x))
)
```

Zum Beispiel für die Werte:

$$
x_i \in \{`r paste(hist_ex$x_i, collapse=',')` \}
$$

könnte das Histogram ermittelt werden, indem der Bereich von $x_{\text{min}} = `r min(hist_ex$x_i)`$ bis $x_{\text{max}} = `r max(hist_ex$x_i)`$ in vier Intervalle unterteilt wird und dann die Anzahl der Werte in den jeweiligen Intervallen ermittelt wird (siehe @fig-sts-basics-hist-example). Die ermittelte Anzahl würde dann noch durch die Gesamtanzahl $`r length(hist_ex$x_i)`$ der Elemente geteilt um die relative Häufigkeit zu berechnen.

```{r}
#| label: fig-sts-basics-hist-example
#| fig-cap: "Beispiel für die Darstellung eines Histogramms für die Daten $x_i$."
#| fig-width: 3

ggplot(hist_ex, aes(y_i, c_i)) +
  geom_point(size=4) +
  scale_x_continuous('x-Werte',
                     limits = c(1,4),
                     breaks = 1:4,
                     minor_breaks = NULL) +
  scale_y_continuous('Anzahl',
                     minor_breaks = NULL) +
  theme(
    panel.grid.major.x = element_line(color = 'red', linetype = 'dashed')
  )
```

Die Form des Histogramms hängt davon ab, wie viele Intervalle verwendet werden. Die Auflösung wird mit mehr Intervallen besser, aber gleichzeitig verringert sich die Anzahl pro Intervall. Andersherum wird die Auflösung mit weniger Intervallen geringer, aber die Anzahl der Elemente pro Intervall wird größer und somit stabiler. Daher sollte in den meisten praktischen Fällen die Anzahl variiert werden, um sicherzugehen, dass nicht nur zufällig eine spezielle Darstellung gefunden wurde.

:::

Wie bereits besprochen, sind alle Werte zwischen etwa $D = -500N$ und $D = 700$N plausibel bzw. möglich nach @fig-sts-basics-all-combinations-d100. Sei einmal betrachtet, was passiert, wenn das Training überhaupt nichts bringt und es keine Verbesserung gibt, also $\Delta = 0$.

```{r}
#| fig-cap: "Verteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe, wenn $\\Delta = 0$ (rote Linie)."
#| label: fig-sts-basics-all-combinations-d0
#| fig-height: 3

ggplot(differences, aes(d)) +
  geom_histogram(aes(y=..density..), bins=50) +
  geom_vline(xintercept = 0, color='red', linetype='dashed') +
  labs(x = 'Differenzen D[N]', y = 'relative Häufigkeit') +
  lims(x = c(-800, 800)) 
```

Die Verteilung in @fig-sts-basics-all-combinations-d0 sieht praktisch genau gleich aus wie diejenige für $\Delta = `r d_gr`$. Der einzige Unterschied ist lediglich, dass sie nach links verschoben ist, und zwar scheinbar genau um die $100$N Unterschied zwischen den beiden $\Delta$s. Dies ist letztendlich auch nicht weiter verwunderlich, bei der Berechnung des Unterschieds $D$ zwischen den beiden Gruppen kommen in beiden Fällen genau die gleichen Kombinationen vor. Bei $\Delta = 100$ wird aber zu der Interventionsgruppe das $\Delta$ addiert, bevor die Differenz der Mittelwerte berechnet wird. Da jedoch gilt:

$$
D = \frac{1}{3}\sum_{i=1}^3 x_{\text{KON}i} - \frac{1}{3}\sum_{j=1}^3 (x_{\text{TRT}j} + \Delta) = \bar{x}_{\text{KON}} - \bar{x}_{\text{TRT}} + \Delta
$$

Daher bleibt die Form der Verteilung genau gleich und wird lediglich um den Wert $\Delta$ im Vergleich zur Nullintervention nach rechts verschoben. Mit Nullintervention ist umgangssprachlich die Intervention gemeint, bei der nichts passiert, also $\Delta = 0$ gilt.

Sei nun davon ausgegangen, dass eine dieser beiden Annahmen korrekt ist. Entweder ist die Intervention effektiv mit $\Delta = `r d_gr`$ oder die Intervention zieht keine Verbesserung nach $\Delta = 0$. Wenn die beiden Verteilungen übereinander gelegt, entsteht die Abbildung @fig-sts-basics-all-combinations-both. Die Darstellungsform ist etwas verändert worden und eine Kurve wurde durch die relativen Häufigkeiten gelegt. Dieser Graph wird jetzt nicht mehr als Histogramm, sondern als **Dichtegraph**\index{Dichtegraph} bezeichnet.

```{r}
#| fig-cap: "Verteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe bei $\\Delta = 0$ und $\\Delta = 100$."
#| label: fig-sts-basics-all-combinations-both

n_sim <- dim(differences)[1]
dat <- tibble(
  di = c(differences$d + d_gr, differences$d),
  hypo = rep(c('H100','H0'), c(n_sim,n_sim))
)
p_both <- ggplot(dat, aes(di)) +
  geom_density(aes(fill=hypo), alpha=0.5) +
  geom_vline(xintercept = c(0, d_gr), color = 'red', linetype = 'dashed') +
  scale_x_continuous('Differenzen D[N]', breaks = c(-500, 0, 100, 500)) +
  scale_y_continuous('relative Häufigkeit')  +
  scale_fill_discrete("Annahme") 
print(p_both)
```

In @fig-sts-basics-all-combinations-both ist klar zu sehen, dass die beiden Graphen zu großen Teilen überlappen. Dazu kommt weiterhin, dass die Überlappung in dem Bereich liegt, in dem beide Verteilungen ihre höchsten relativen Häufigkeiten haben. D.h. die Bereiche in die Verteilungen die größte Wahrscheinlichkeit haben beobachtbare Werte zu generieren. Das Problem besteht nun darin, dass bei der Durchführung eines Experiments nicht a-priori bekannt ist, welchen Effekt das Training auf die Stichprobe hat. Wenn der Effekt bereits bekannt wäre, dann müsste das Experiment gar nicht mehr durchgeführt werden. Nach der Durchführung des Experiments wird nun ein Unterschied $d$ zwischen den beiden Gruppen betrachtet (siehe @fig-sts-bascis-all-combinations-decision)

```{r}
#| label: fig-sts-basics-all-combinations-decision
#| fig-cap: "Zuweisung eines beobachteten Unterschieds $d$ (roter Punkt) nach einem Experiment"

p_both + 
  annotate("segment", x = 50, y = 0, xend = 0, yend = 0.0018, color = 'black', 
           arrow=arrow(length=unit(3,"mm"), angle=20)) +
  annotate("segment", x = 50, y = 0, xend = 100, yend = 0.0018, color = 'black',
           arrow=arrow(length=unit(3,'mm'), angle=20)) +
  geom_point(data = tibble(di = 50, y = 0, hypo = 'H0'), aes(y=y), color = 'red', size=4) 
```

Sei zum Beispiel der Wert $d = 50$ beobachtet. Dann entsteht ein Zuweisungsproblem (siehe @fig-sts-basics-all-combinations-decision). Wie wird das beobachtete Ergebnis den beiden möglichen Realitäten zugewiesen? Einmal kann es sein, dass das Krafttraining nichts gebracht hat und lediglich eine der vielen möglichen Stichprobenkombinationen beobachtet wurde, die zu einem positiven Wert für $D$ führen. Oder aber das Krafttraining ist effektiv gewesen und hat zu einer Verbesserung von $\Delta = 100$N geführt, und es wurde lediglich eine Stichprobenkombination gezogen, die zu einem Ergebnis von $D = 50$ führt. In der Realität ist leider nicht bekannt, welche der beiden Annahmen korrekt ist, und es kann leider nie vollständig bekannt sein. Denn egal wie viele Experimente durchgeführt werden, es bleibt immer die Möglichkeit, dass zufällig nur Werte aus dem linken oder rechten Teil der Verteilung beobachtet wurden. Es ist eben auch mit einem fairen Würfel möglich zehnmal hintereinander eine sechs zu würfeln. Diese Unsicherheit lässt sich leider durch keine Art von Experiment vollständig auflösen.

Als Fazit sollte nun nachvollziehbar sein, dass jede Statistik, die auf einer Stichprobe berechnet wurde, inhärent unsicher ist. In der Realität ist der Sachverhalt noch komplexer und es tritt nicht nur die Variabilität aufgrund der Randomisierung auf, sondern es kommen viele weitere Einflussgrößen zum tragen, die das Ergebnis eines Experiments bei Wiederholungen beeinflussen können. Mithilfe einer statistischen Analyse wird nun versucht, diese Unsicherheit zu quantifizieren bzw. abzuschätzen und in den Entscheidungsprozesse auf der Basis der beobachteten Daten einfließen zu lassen. Die Methoden der Statistik liefern daher Werkzeuge an die Hand, um trotzdem rational zu entscheiden, welche Annahmen möglicherweise plausibler ist. Die statistische Analyse kann dabei immer nur etwas über die beobachteten Daten aussagen und nur indirekt etwas über die zugrundeliegenden wissenschaftlichen Theorien.

## Things to know

- Population
- (Zufalls-)Stichprobe
- Randomisierung
- Statistik
- Stichprobenverteilung
- Abhängige und unabhängige Variable
