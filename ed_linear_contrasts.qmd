# Lineare Kontraste

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
#source('../resources/nice_format_helper_fcn.R')
n <- 20
k <- 3
set.seed(11)
kaffee <- tibble(
  Zeit = rnorm(k*n, rep(c(1917,1927,1927), each=n), 8),
  Gruppe = gl(k,n,labels=c('Koffein','Placebo','Control'))
)
mod_aov <- aov(Zeit ~ Gruppe, data = kaffee)
```

## Omnibus-Test

\centering
```{r}
#| out.width="80%"

knitr::include_graphics('pics/omnibus.jpg')
```

## Individual comparison and Post-hoc tests

```{r, fig.cap="Einfluss von Koffeine auf die Laufleistung über 8km", fig.height=2}
ggplot(kaffee, aes(Gruppe, Zeit)) +
  geom_boxplot() + 
  geom_jitter(width = 0.2, color = 'red', size = 2, alpha=.5) +
  labs(y = 'Zeit [s]',
       x = 'Gruppe') 
```

## Das multiple-comparison Problem

Sei $m$ die Anzahl der getesten Hypothesen.
$$
P(\text{min. }1\text{ Type-I Fehler}) = 1 - (1-\alpha)^m 
$$

^[Unter der Annahme das für alle Test die $H_0$-Hypothese zutrifft [siehe auch @rothman1990].]

```{r}
#| fig.cap="Inflation des $\\alpha$-Fehlers mit $\\alpha=0.05$",
#| fig.height=1.3,
#| fig.width=3

ggplot(tibble(m = 1:20, p = 1 - (1-0.05)**m),
       aes(m, p)) +
  geom_line() +
  labs(x = 'Anzahl der Tests', y = 'P min 1\nTyp-I Fehler')
```


## Unterscheidung von Fehlern

\begin{figure}
\centering
\begin{tikzpicture}[scale=0.7]
\tikzstyle{level 1}=[sibling distance=40mm]
\tikzstyle{level 2}=[sibling distance=20mm]
\tikzstyle{level 3}=[sibling distance=7mm]
\node {Experiment}
    child {node[text width=1.5cm, align=center] {Primary Endpoint}
    child {node {Factor 1}
    child {node {$\bar{Y}_{1}$}}
    child {node {$\bar{Y}_{2}$}}
    child {node {$\bar{Y}_{3}$}}}
    child {node {Factor 2}
    child [dashed]{node {}}
    child [dashed]{node {}}}
    child [dashed] {node {}}}
    child {node[text width=1.5cm, align=center]{Secondary Endpoint}
    child [dashed]{node {}}
    child [dashed]{node {}}}
    child [dashed] {node {}};
    \scriptsize
    \node [text width=2.5cm, align=center] at (-10,-4.7) (a) {error rate per test $\alpha_{PC}$};
    \node [text width=2.5cm, align=center] at (-10,-3) (a) {error rate per family $\alpha_{FW}$};
    \node [text width=3.5cm, align=center] at (-10,-1) (a) {error rate per experiment $\alpha_{EW}$};
\end{tikzpicture}
\end{figure}


## Kontraste $\psi$

Vergleiche zwischen den Gruppen werden mittels Kontrasten berechnet. Allgemein:

$$
\psi = \sum_{i=1}^k c_i \tau_i, \quad \text{mit } \sum_{i=1}^k c_i=0
$$

Konkret werden die Kontraste mittels der Gruppenmittelwerte gebildet.

$$
\hat{\psi} = \sum_{i=1}^k c_i \hat{\tau_i} = \sum_{i=1}^k c_i \bar{y}_{i.}
$$

## Paarweise Kontrastdefinition für das Beispiel 

\begin{table}
\centering
\caption{Paarvergleiche der Gruppen aus dem Beispiel}
\begin{tabular}{lcccc}
\toprule
Kontrast  & Koffein & Placebo & Control & $\sum_{i=1}^k c_i$ \\ 
\midrule
$\Delta_{\text{Koffein-Placebo}}$ & $1$ & $(-1)$ & 0  & 0 \\
$\Delta_{\text{Koffein-Control}}$ & $1$ & $0$ & $(-1)$ & 0  \\
$\Delta_{\text{Placebo-Control}}$ & $0$ & $1$ & $(-1)$ & 0  \\
\bottomrule
\end{tabular}
\end{table}

## Kontraste konkret

```{r}
k_bar <- kaffee |> dplyr::group_by(Gruppe) |> 
  dplyr::summarize(m = round(mean(Zeit),1))  
k_bar |> 
  knitr::kable(booktabs=T,
               col.names = c('Gruppe', '$\\bar{y}_{i.}$'),
               escape=F,
               caption="Gruppenmittelwerte")
```

Ein Vergleich bespielsweise zwischen Koffein und Placebo kann mittels des Kontrasts $c_{\text{K-C}} = (1,-1,0)$ berechnet werden.

$$
\hat{\psi}_{\text{K-C}} = \sum_{i=1}^k c_i \bar{y}_{i.} = 1 \cdot `r k_bar$m[1]` + (-1) \cdot `r k_bar$m[2]` + 0 \cdot `r k_bar$m[3]` = `r round(k_bar$m[1] - k_bar$m[2], 1)`
$$

## Unterscheidung von Kontrasten

### Paarweise Vergleiche: Einfache Kontraste

$$
c_i = 1, c_j = -1, c_k = 0, \forall k \neq i,j
$$

### Sonstige Vergleiche: Komplexe Kontraste

z.B. Vergleich der Mittelwerte von $\tau_1, \tau_2$ mit $\tau_3$.

$$
c_1 = \frac{1}{2}, c_2 = \frac{1}{2}, c_3 = -1, c_i = 0, \forall i \neq 1,2,3
$$

## Beispiel für einen komplexen Kontrast $\psi$

```{r}
k_bar <- kaffee |> dplyr::group_by(Gruppe) |> 
  dplyr::summarize(m = round(mean(Zeit),1))  
k_bar |> 
  knitr::kable(booktabs=T,
               col.names = c('Gruppe', '$\\bar{y}_{i.}$'),
               escape=F,
               caption="Gruppenmittelwerte")
```

Vergleich zwischen dem Mittelwert von Koffein und Placebo gegen Kontrolle mittels $c = (1/2,1/2,-1)$.

$$
\hat{\psi} = \sum_{i=1}^k c_i \bar{y}_{i.} = \frac{1}{2} \cdot `r k_bar$m[1]` + \frac{1}{2} \cdot `r k_bar$m[2]` + (-1) \cdot `r k_bar$m[3]` = `r round(sum(k_bar$m[1:2])/2 - k_bar$m[3],2)`
$$

## Reminder - Standardfehler und Varianz des Stichprobenmittelwerts

:::: columns
::: column
```{r}
#| fig.cap="Population",
#| fig.height=4.5

tibble(
  x = seq(-3, 3, length.out=100),
  d = dnorm(x)
) |> 
  ggplot(aes(x,d,ymin=0, ymax=d)) +
  geom_ribbon(alpha=0.3) +
  geom_line() +
  scale_x_continuous('Werte',
                     breaks = -2:2,
                     labels=c(
                       expression(-2*sigma),
                       expression(-sigma),
                       expression(mu),
                       expression(sigma),
                       expression(2*sigma)
                     )) +
  labs(y = 'Dichte') 
```

:::
::: column

**Standardfehler des Mittelwerts**

$$
s_{\bar{x}} = \frac{\sigma}{\sqrt{n}}
$$

**Varianz des Mittelwerts**

$$
Var(\bar{x}) = \frac{\sigma^2}{n}
$$

:::
::::

## Varianz von Kontrasten

### In der Population
$$
Var(\psi) = Var\left(\sum c_i \bar{Y}_{i.}\right) = \sum c_i^2 Var(\bar{Y}_{i.}) = \sum c_i^2(\sigma^2/n_i) = \sigma^2\sum(c_i^2/n_i)
$$

### Geschätzt anhand der Stichprobe
$$
\widehat{Var}(\psi) = \widehat{Var}\left(\sum c_i \bar{y}_{i.}\right) = MS_w\sum (c_i^2/n_i)
$$

### Standardfehler des Kontrasts
$$
s_{\psi} = \sqrt{MS_w\sum (c_i^2/n_i)}
$$

^[$n_i$ = Stichprobengröße in Gruppe i, $\hat{\sigma}^2 = MS_w$]


## Varianz von Kontrasten bei Paarvergleichen

Vergleich von Gruppe $i$ und $j$

$$
Var\left(\hat{\tau}_i - \hat{\tau}_j\right) = \sigma^2\left(\frac{1}{n_i} + \frac{1}{n_j}\right)
$$

Standardfehler bei gleicher Stichprobengröße $n_i = n_j = n, 2n = N$

$$
s_{\psi} = s_{\Delta} = \sqrt{\sigma^2\left(\frac{1}{N/2}
+\frac{1}{N/2}\right)}=\sqrt{\sigma^2\frac{2}{N/2}} = \sigma\sqrt\frac{4}{N}=\frac{2\sigma}{\sqrt{N}}
$$

## Reminder - Dualität von Signifikanztests und Konfidenzintervall

Wenn das Konfidenzintervall mit Niveau $1-\alpha\%$ die $H_0$ nicht beinhaltet, dann wird auch bei einem Signifikanztest die $H_0$ bei einer Irrtumswahrscheinlichkeit von $\alpha$ abgelehnt.

\begin{figure}
\centering
\begin{tikzpicture}
    \draw[dashed,thick] (0,-1) -- (0,1);
    \node[anchor=north] at (0,-1) {$H_0$};
    \fill[red] (2,0) circle (4pt);
    \draw[thick, color=red] (0.08,0) -- (3.92,0);
    \node[red] at (0.1,0) {(};
    \node[red] at (3.9,0) {)};
    \draw [->, thick] (-1,-1) -- (5,-1);
\end{tikzpicture}
\caption{Relation von $H_0$ und Konfidenzintervall}
\end{figure}

## Konfidenzintervalle von Kontrasten

### Berechnungsmuster

\begin{gather*}
\psi = \sum_i c_i \hat{\tau}_i \pm w \sqrt{\widehat{Var}\left(\sum c_i \hat{\tau}_i\right)} = w \times s_{\psi}\\
\text{estimate } \pm (\text{kritischer Wert}) \times (\text{Standardfehler})
\end{gather*}

Zwischen verschiedenen Methoden unterscheidet sich der kritische Wert $w$.

## Minimum significant difference ($msd$) 

\begin{figure}
\centering
\begin{tikzpicture}
    \draw[dashed,thick] (0,-1) -- (0,1);
    \node[anchor=north] at (0,-1) {$H_{0:\psi}$};
    \fill[red] (2,0) circle (4pt);
    \draw[thick, color=red] (0.08,0) -- (3.92,0);
    \node at (2,0.5) {$\hat{\psi}$};
    \node at (1,-0.5) {$-w\times s_{\psi}$};
    \node at (3,-0.5) {$+w\times s_{\psi}$};
    \node[red] at (0.1,0) {(};
    \node[red] at (3.9,0) {)};
    \draw [->, thick] (-1,-1) -- (5,-1);
\end{tikzpicture}
\caption{Kontrastkonfidenzintervall}
\end{figure}

$$
msd = w \sqrt{\widehat{Var}\left(\sum c_i \hat{\tau}_i\right)}=w \times s_{\psi}
$$


## Einteilung der Mehrfachvergleiche

Table: Systematik Mehrfachvergleiche

| Name | Zeitpunkt | Kontraste | Kontrolliert |
| --- | --- | --- | --- | 
| Bonferroni | pre-planned | einfache und komplexe | Ja |
| Tukey | pre-planned | alle paarweisen | Ja |
| Scheffé | post-hoc | einfache und komplexe | Ja |
| Dunnet | pre-planned | paarweise TRT gegen CON | Ja |
| FisherLSD| post-hoc | einfache und komplexe | Nein^[Außer wenn $K=3$] |

## Mehrfachvergleiche in `R`

### Package `emmeans()`

Zweistufiger Ablauf:

1) Berechnen der Zellmittelwerte mit der Funktion \
`emmeans(<MODEL>, ~<FAKTOR>)`
2) Vergleiche werden entweder mittels `pairs()` (paarweise Vergleiche) oder mit `contrast()` (beliebige Vergleiche) berechnet 

Alternative: `package:multcomp`

## Bonferroni (pre-planned)

Das Signifikanzlevel $\alpha$ wird angepasst indem ein neuer $\alpha$-Level, $\alpha^*$, mittels:

$$
\alpha^* = \alpha / m
$$

berechnet wird. $m$ ist die Anzahl der Kontraste.

Kontrolliert Gesamt-$\alpha$ für einfache und/oder komplexe Kontraste.

## Beispiel Bonferroni

Einfacher Vergleich Koffein geben Placebo und komplexer Vergleich des Mittelwerts von Koffein und Placebo gegen Kontrolle.

\scriptsize
```{r, echo=T}
library(emmeans)
mod_em <- emmeans(mod_aov, ~Gruppe)
contrast(mod_em, adjust='bonferroni', infer=T ,
         method = list(
           "Koffein vs. Placebo" = c(1, -1, 0),
           "Tablette vs. CON" = c(1/2, 1/2, -1)
         ))
```


## Tukey (H)onest (S)ignifikant (D)ifference (pre-planned)

Optimiert für alle paarweisen Kontraste.

\scriptsize
```{r, echo=T}
pairs(mod_em, adjust="tukey", infer=T)
```
^[TukeyHSD ist auch default wenn keine Argument für `adjust` angegeben wird.]

## Scheffé (post-hoc)

Sichert post-hoc $\alpha$-Level für alle möglichen Kontraste (beliebige Anzahl) ab.

Beispielsweise die gleichen Kontraste wie beim Bonferroni-Beispiel.
\scriptsize
```{r, echo=T}
contrast(mod_em, adjust='scheffe', infer=T ,
         method = list(
           "Koffein vs. Placebo" = c(1, -1, 0),
           "Tablette vs. CON" = c(1/2, 1/2, -1)
         ))
```


## Dunnett (pre-planned)

Optimiert für den Vergleich von Treatmentkonditionen gegen eine Kontrollkondition.
\vspace{.5cm}
\scriptsize
```{r, echo=T}
contrast(mod_em, method='trt.vs.ctrl', infer=T, ref='Control')
```


## Fisher (L)east (S)ignificant (D)ifference (post-hoc)

Durchführung von post-hoc Tests wenn ein statistisch signifikanter Haupteffekt über die ANOVA abgesichert wurde.
\vspace{.5cm}
\scriptsize
```{r, echo=T}
pairs(mod_em, adjust='none', infer=T)
```

\Large
\alert{Do not like!!!}^[Außer bei einem Faktor mit genau drei Stufen (siehe @levin1994)]

## Vergleich der kritischen Werte $w$

```{r}
tibble(
  'no_groups' = 2:7,
  'per_com' = qf(0.95, 1, 12),
  'tukey' = qtukey(0.95, no_groups, 12)**2/2,
  'bonferroni' = qf(1-0.05/(no_groups*(no_groups-1)/2), 1, 12),
  'scheffe' = (no_groups-1)*qf(0.95, no_groups-1, 12)
) |> 
  knitr::kable(
    booktabs=T,
    col.names=c('Stufen', '$\\alpha_{PC}$', 'Tukey', 'Bonferroni','Scheffé'),
    caption="Kritische Werte $w$ für alle $k(k-1)/2$ paarweisen Vergleiche bei $df_{\\text{error}}=12$.",
    digits=2,
    linesep = '',
    escape=F
  )
```

## Optional - Cohen's d für post-hocs

\scriptsize
```{r, echo=T}
eff_size(mod_em, sigma=sigma(mod_aov),
                 edf=df.residual(mod_aov))
```


## Dokumentation

\small
Eine einfaktorielle ANOVA mit dem Faktor Gruppe ergabe einen statistisch signifikanten Haupteffekt für Gruppe $F(2, 57) = 22,6, p < 0,001$.  Überprüfung auf Varianzgleichheit zwischen den Gruppen mittels eines Levene-Tests deutete auf keine Verletzung der Voraussetzungen hin, $F(2, 57) = 0,38, p = 0,69$. Daher wird die $H_0$, das kein Unterschied zwischen den Gruppen besteht, abgelehnt. Die beobachtete Effektstärke $\omega^2 = 0,42$,  CI$95\%[0,22, 0,56]$ ist als großer Effekt zu interpretieren. Pre-planned Paarweisetestung mittels Tukey-Korrektur deutete auf statistisch signifikate Unterschiede zwischen den Gruppen Koffein und Placebo $z = -10.4$, CI95\%$[-15,5, -5,5], p < 0,001$, und Koffein und Kontrolle, $z = -13,3$, CI95$\%[-18,4, -8,3], p < 0,001$, hin. Insgesamt deuten die Ergebnisse daher darauf hin, dass die Gabe von Koffein zu einer bedeutsamen Leistungssteigerung $(>5-10s)$ in der beobachteten Untersuchungsgruppe geführt hat.

## Zum Nacharbeiten

### Multiple-comparisons
@feise2002, @rothman1990
