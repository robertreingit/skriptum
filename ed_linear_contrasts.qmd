# Lineare Kontraste

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
#source('../resources/nice_format_helper_fcn.R')
n <- 20
k <- 3
set.seed(11)
kaffee <- tibble(
  Zeit = rnorm(k*n, rep(c(1917,1927,1927), each=n), 8),
  Gruppe = gl(k,n,labels=c('Koffein','Placebo','Control'))
)
mod_aov <- aov(Zeit ~ Gruppe, data = kaffee)
```

Bei der Analyse eines CRDs haben wir bisher nur die untersucht, ob es irgendwo zwischen den verschiedenen Faktorstufen einen relevanten Unterschied gibt. Im nächsten Schritt wollen wir daher bestimmen zwischen welchen Faktorstufen auch tatsächlich ein Unterschied besteht. Im einfachen Fall aus unsererm Laufbeispiel mit drei Faktorstufen (Koffein, Placebo und Control, siehe @fig-ed-lc-01) können drei verschiedene, paarweise Vergleiche durchgeführt werden.

```{r}
#| fig-cap: "Einfluss von Koffeine auf die Laufleistung über 8km"
#| label: fig-ed-lc-01

ggplot(kaffee, aes(Gruppe, Zeit)) +
  geom_boxplot() + 
  geom_jitter(width = 0.2, color = 'red', size = 2, alpha=.5) +
  labs(y = 'Zeit [s]',
       x = 'Gruppe') 
```

Wir können Koffein mit Placebo, Koffein mit Control und Placebo mit Control vergleichen. In allen drei Fällen vergleichen wir die Mittelwert der jeweiligen beteiligten Faktorstufen miteinander. Allerdings haben wir hier das Problem, dass jede Faktorstufe in mehreren (im Beispiel zweimal) Vergleichen beteiligt ist. Wenn wir mehr Faktorstufen haben entsprechend noch öfter. Das führt zu dem Problem der Mehrfachvergleiche.

## Das multiple-comparison Problem

Allgemein gilt, wenn wir mehrere statistische Tests durchführen, und uns den $\alpha$-Fehler betrachten, dass über die Gesamtheit der Test der $\alpha$-Fehler nicht mehr gleich dem nominalen Level ist. Die Überlegung dazu ist die folgende. Wir testen $m$ Hypothesen, jede mit einer Irrtumswahrscheinlichkeit von $\alpha$ und in allen Fällen sei die $H_0$ zutreffend. Dann haben wir für jeden einzelnen Test eine Wahrscheinlichkeit von $1 - \alpha$ die korrekte Entscheidung zu treffen. Wenn wir nun $m$ unabhängige Hypothesentestungen durchführen, wird die Wahrscheinlichkeit sich korrekt zu entscheiden insgesamt $m$-Mal miteinander multipliziert.

\begin{equation}
P(\text{korrekte Entscheidung}) = (1-\alpha)\cdots(1-\alpha) = (1-\alpha)^m
\end{equation}

Daraus folgt, dass die Wahrscheinlichkeit mindestens einen $\alpha$-Fehler zu machen $1 - P(\text{korrekte Entscheidung})$ ist.

\begin{equation}
P(\text{min. }1\text{ Type-I Fehler}) = 1 - (1-\alpha)^m 
\end{equation}

Tragen wir diese Wahrscheinlichkeit gegen die Anzahl der Test ab, erhalten wir folgenden Zusammenhang (siehe @fig-ed-lc-02).

```{r}
#| fig-cap: "Inflation des $\\alpha$-Fehlers mit $\\alpha=0.05$"
#| label: fig-ed-lc-02

ggplot(tibble(m = 1:20, p = 1 - (1-0.05)**m),
       aes(m, p)) +
  geom_line() +
  labs(x = 'Anzahl der Tests', y = 'P min 1\nTyp-I Fehler')
```

In @fig-ed-lc-02 können wir sehen, dass die Wahrscheinlichkeit für mindestens einen $\alpha$ sehr schnell mit der Anzahl der Tests ansteigt. D.h. ab etwa 15 Tests liegt die Wahrscheinlichkeit für ein statistisch signifikantes Ergebnis bei etwas $50\%$. Daher müssen wir für die Anzahl der Tests kontrollieren (siehe @rothman1990 für eine Gegenposition).

Ein Umstand macht die Kontrolle der $\alpha$-Fehlerrate allerdings etwas undurchsichtig, da nicht eindeutig ist auf welchem Level die Fehlerkontrolle stattfinden soll. In @fig-ed-lc-errors ist eine typische Struktur eines Experiments dargestellt.

```{dot}
//| fig-cap: "Einteilung der Fehler."
//| label: fig-ed-lc-errors

graph G {
Ex [label="Experiment"]
E1 [label="Primary Endpoint", fillcolor="magenta", style=filled]
E2 [label="Secondary Endpoint", fillcolor="magenta", style=filled]
F1 [label="Faktor 1", fillcolor="orange", style=filled]
F2 [label="Faktor 2", fillcolor="orange", style=filled]
Y1 [label="MW1", fillcolor="yellow", style=filled]
Y2 [label="MW2", fillcolor="yellow", style=filled]
Y3 [label="MW3", fillcolor="yellow", style=filled]
subgraph cluster_0 {
    label="Experiment wise error rate"
    bgcolor="lightgray"
    E1; E2;
}
subgraph cluster_1 {
    label="Family wise error rate"
    bgcolor="lightgray"
    F1; F2;
}
subgraph cluster_2 {
    label="Error rate per test"
    bgcolor="lightgray"
    Y1; Y2; Y3
}
Ex -- E1;
Ex -- E2;
E1 -- F1;
E1 -- F2;
F1 -- Y1;
F1 -- Y2;
F1 -- Y3;
}
```

Wir haben zwei Endpunkte in dem Experiment und beide Endpunkte wurden unter jeweils zwei verschiedenen Faktoren untersucht. Faktor 1 besitzt drei Faktorstufen. D.h. wir können wiederum drei paarweise Vergleiche zwischen den Mittelwerten (MW) der drei Stufen durchführen. Ähnliches trifft aber auch auf Faktor 2 zu. Bei zwei Endpunkten verdoppelt sich noch einmal die Anzahl der Test bzw. wenn wir noch weitere Endpunkte haben entsprechend mehr. Das führt dazu, dass wir entweder auf der Ebene der Endpunkte, der Ebene der Faktor innerhalb eines Endpunktes oder auf der Ebene der Faktorstufen innerhalb eines Faktors innerhalb eines Endpunktes kontrollieren können. Von oben nach unten werden diese Ebenen als *Experiment*, *family* und *test* wise error rates bezeichnet und sind von unten nach oben immer strikter da die Anzahl der zu berücksichtigenden Test immer größer wird. Dazu kommt, dass es leider in der Literatur dazu keinen klaren Konsens gibt auf welcher Ebene die Mehrfachtestung berücksichtigt werden solle, so dass in den meisten Fällen wohl auf *test*-Ebene kontrolliert wird.

## Kontraste $\psi$

Im folgenden werden wir ein etwas allgemeineres Rahmenwerk aufbauen um die Vergleiche zwischen den Faktorstufen durchzuführen. Dazu führen wir zunächst das Konzept eines Kontrasts für Mittelwertsvergleiche ein. 

::: {#def-contrast}
### Kontrast
Ein Kontrast\index{Kontrast} ist eine Linearkombination von Modellparametern deren Koeffizienten sich zu Null addieren.
:::

Nehmen wir zum Beispiel den Fall des Modells aus dem CRD.

\begin{equation}
Y_{ij} = \mu + \tau_i + \epsilon_{ij}
\end{equation}

Die jeweiligen Effekte der Faktorstufen werden durch die Parameter $\tau_i,i=1,\ldots,K$ repräsentiert. Eine linearkombination der $\tau_i$ sieht dann folgendermaßen aus.

\begin{equation}
\sum_{i=1}^K c_i \tau_i
\end{equation}

D.h. die $\tau_i$ werden jeweils mit einem Faktor $c_i$ multipliziert und die Produkte werden aufsummiert. Die Terme $c_i$ werden als Kontrastgewichte oder allgemein Gewichte bezeichnet. Wenn die $c_i$s nun noch die Eigenschaften haben, dass deren Summe $\sum_{i=1}^K c_i = 0$ ist, dann wird aus der Linearkombination ein Kontrast $\psi$:

\begin{equation}
\psi = \sum_{i=1}^k c_i \tau_i, \quad \text{mit } \sum_{i=1}^k c_i=0
\label{eq-ed-lc-contrats}
\end{equation}

Da wir in unserem Fall in den meisten Fällen die Gruppen Mittelwerte miteinander vergleichen wollen, werden wir meistens Kontraste der Gruppenmittelwerte erstellen, da diese als Schätzer für Gruppeneffekte dienen. Also der Effekt der $i$-ten Stufe setzt sich nach dem Modell zusammen aus $\mu + \tau_i$ und dieser ist bei einem CRD gleich dem Gruppenmittelwert. D.h. unser Schätzer für einen Kontrasts $\hat{\psi}$ ist.

\begin{equation}
\hat{\psi} = \sum_{i=1}^K c_i (\hat{\mu} + \hat{\tau_i}) = \sum_{i=1}^K c_i \bar{y}_{i.}
\end{equation}

Aber es gilt:
\begin{equation*}
\psi=\sum_{i=1}^Kc_i(\mu + \tau_i) = \sum_{i=1}^Kc_i \mu + \sum_{i=1}^K c_i\tau_i=\mu\underbrace{\sum_{i=1}^K c_i}_{=0} + \sum_{i=1}^K c_i\tau_i = \sum_{i=1}^K c_i\tau_i
\end{equation*}

D.h. über den Vergleich der Mittelwerte erhalten wir den Vergleich der Modellparameter $\tau_i$.

Durch eine schlaue Kombination von $c_i$ sind wir jetzt in der Lage die gewünschten Gruppenvergleiche durchzuführen. Gehen wir zurück zu unserem Beispiel der Koffeindaten. Mit der folgenden Kombination von $c_i$s können wir die Gruppenvergleich als Kontraste definieren (siehe @tbl-ed-lc-contrast-01).


| Kontrast  | Koffein $(c_1)$ | Placebo $(c_2)$ | Control $(c_3)$ | $\sum_{i=1}^K c_i$ | 
|  --- | --- | --- |  --- | --- |
|$\Delta_{\text{Koffein-Placebo}}$ | $1$ | $(-1)$ | 0  | 0 | 
|$\Delta_{\text{Koffein-Control}}$ | $1$ | $0$ | $(-1)$ | 0 | 
|$\Delta_{\text{Placebo-Control}}$ | $0$ | $1$ | $(-1)$ | 0 | 

: Paarvergleiche der Gruppen aus dem Beispiel {#tbl-ed-lc-contrast-01}

Schauen wir uns konkret anhand des Beispiels an wie die Kontraste berechnet werden. In @tbl-ed-lc-coffein-psi sind die Gruppenmittelwerte aus dem Koffeinbeispiel abgebildet.

```{r}
#| tbl-cap: "Gruppenmittelwerte aus der Koffeinstudie"
#| label: tbl-ed-lc-coffein-psi

k_bar <- kaffee |> dplyr::group_by(Gruppe) |> 
  dplyr::summarize(m = round(mean(Zeit),1))  
k_bar |> 
  knitr::kable(booktabs=T,
               col.names = c('Gruppe', '$\\bar{y}_{i.}$'),
               escape=F)
```

Wollen wir nun einen Vergleich zwischen den Gruppen Koffein und Placebo bestimmen, dann wählen wir aus @tbl-ed-lc-contrast-01 den ersten Kontrast $c_{\text{K-C}} = (1,-1,0)$ aus. Angewendet auf die Mittelwert der Gruppen folgt daraus.

\begin{equation*}
\hat{\psi}_{\text{K-C}} = \sum_{i=1}^k c_i \bar{y}_{i.} = 1 \cdot `r k_bar$m[1]` + (-1) \cdot `r k_bar$m[2]` + 0 \cdot `r k_bar$m[3]` = `r round(k_bar$m[1] - k_bar$m[2], 1)`
\end{equation*}

D.h. wir beobachten einen Unterschied von $`r round(k_bar$m[1] - k_bar$m[2], 1)`s$ zwischen den beiden Gruppen. Die beiden verbleibenden paarweisen Vergleichen können parallel durchgeführt werden.

Allgemein wird zwischen zwei Arten von Kontrasten unterschieden: Einfache und komplexe Kontraste. Einfache Kontraste sind dabei die paarweisen Vergleiche und alle anderen Arten von Kontrasten als komplexe Kontraste bezeichnet werden. Aus dem Beispiel sehen wir, dass bei paarweisen Kontrasten immer ein Kontrastgewicht $c_i = 1$ ist und ein weiterer $c_j = -1$ gesetzt wird, während alle anderen Gewichte $c_l = 0, \forall l \neq i,j$ sind.

Erstellen wir nun einen komplexen Kontrast. Wir wollen zum Beispiel untersuchen ob es einen Unterschied zwischen der Kontrollgruppe und den beiden Gruppen die eine Pille bekommen haben unabhängig davon ob in der Pille ein Wirkstoff (Koffein) oder nicht (Placebo) war. Mittels eines Kontrasts können wir diesen Vergleich wie folgt darstellen.

\begin{equation*}
c_1 = \frac{1}{2}, c_2 = \frac{1}{2}, c_3 = -1
\end{equation*}

D.h. wir Mitteln die Mittelwerte von Koffein und Placebo und vergleichen diesen Mittelwert mit dem Mittelwert der Kontrollgruppe. Wenn wir die Summe der Gewichte bilden erhalten wir $\frac{1}{2} + \frac{1}{2} - 1 = 0$. Wir haben es also tatsächlich mit einem Kontrast zu tun Angewendet auf das Beispiel erhalten wir:

\begin{equation*}
\hat{\psi} = \sum_{i=1}^k c_i \bar{y}_{i.} = \frac{1}{2} \cdot `r k_bar$m[1]` + \frac{1}{2} \cdot `r k_bar$m[2]` + (-1) \cdot `r k_bar$m[3]` = `r round(sum(k_bar$m[1:2])/2 - k_bar$m[3],2)`
\end{equation*}

D.h. der Effekt der Pillengabe unabhängig von Wirkstoff ist $`r round(sum(k_bar$m[1:2])/2 - k_bar$m[3],2)`s$.

Insgesamt haben wir mittels der Kontraste einen flexiblen Mechanismus um beliebige Vergleiche zwischen Faktorstufen durchzuführen bzw. Modellparameter miteinander zu vergleichen. Die üblichen paarweisen Vergleich bilden hierbei nur einen Spezialfall der einfachen Kontraste. Um nun zu bewerten ob ein beobachter Kontrast auch wirklich bedeutsam ist, benötigen wir nun aber auch Information über seine Varianz.

Um die Varianz von Kontrasten herzuleiten hier noch einmal kurz zur Wiederholung der Standardfehler des Mittelwerts

\begin{equation}
s_{\bar{x}} = \frac{\sigma}{\sqrt{n}}
\end{equation}

Die Varianz ist dementsprechend das Quadrat des Standardfehlers $s_{\bar{x}}$. Als zweites Wiederholungsitem die Varianz einer Linearkombination von unabhängigen Zufallsvariablen berechnet sich nach (siehe Formel \eqref{eq-stats-hypo-sum-var})

\begin{equation*}
Var\left(\sum_{i=1}^n a_i X_i\right) = \sum_{i=1}^n a_i^2 Var(X_i)
\end{equation*}

Wichtig für die weiteren Herleitungen ist insbesondere das Beispiel @exm-ed-hypo-var-diff. Angewendet auf einen Kontrast folgt für den Kontrast auf der Population.

\begin{equation}
Var(\psi) = Var\left(\sum c_i \bar{Y}_{i.}\right) = \sum c_i^2 Var(\bar{Y}_{i.}) = \sum c_i^2(\sigma^2/n_i) = \sigma^2\sum(c_i^2/n_i)
\label{eq-ed-lc-var-con-pop}
\end{equation}

Da wir üblicherweise die Varianz $\sigma^2$ anhand der Stichprobe abschätzen mittels der $MSE$ bzw. in der Terminologie des CRD $MS_{\text{within}}. Daraus folgt für die Varianz des Kontrasts.

\begin{equation}
\widehat{Var}(\psi) = \widehat{Var}\left(\sum c_i \bar{y}_{i.}\right) = MS_w\sum (c_i^2/n_i)
\label{eq-ed-lc-var-con}
\end{equation}

Daraus folgt das der Standardfehler des Kontrasts entsprechend:

\begin{equation}
s_{\psi} = \sqrt{MS_w\sum (c_i^2/n_i)}
\label{eq-ed-lc-se-contrast}
\end{equation}

Mit $n_i$ = Stichprobengröße in Gruppe i und $\hat{\sigma}^2 = MS_w = MSE$. Angewendet auf den Kontrast bei Paarvergleichen folgt für den Vergleich von Gruppe $i$ und $j$:

$$
Var\left(\hat{\tau}_i - \hat{\tau}_j\right) = \sigma^2\left(\frac{1}{n_i} + \frac{1}{n_j}\right)
$$

Standardfehler bei gleicher Stichprobengröße $n_i = n_j = n, 2n = N$

$$
s_{\psi} = s_{\Delta} = \sqrt{\sigma^2\left(\frac{1}{N/2}
+\frac{1}{N/2}\right)}=\sqrt{\sigma^2\frac{2}{N/2}} = \sigma\sqrt\frac{4}{N}=\frac{2\sigma}{\sqrt{N}}
$$

## Reminder - Dualität von Signifikanztests und Konfidenzintervall

Wenn das Konfidenzintervall mit Niveau $1-\alpha\%$ die $H_0$ nicht beinhaltet, dann wird auch bei einem Signifikanztest die $H_0$ bei einer Irrtumswahrscheinlichkeit von $\alpha$ abgelehnt.

\begin{figure}
\centering
\begin{tikzpicture}
    \draw[dashed,thick] (0,-1) -- (0,1);
    \node[anchor=north] at (0,-1) {$H_0$};
    \fill[red] (2,0) circle (4pt);
    \draw[thick, color=red] (0.08,0) -- (3.92,0);
    \node[red] at (0.1,0) {(};
    \node[red] at (3.9,0) {)};
    \draw [->, thick] (-1,-1) -- (5,-1);
\end{tikzpicture}
\caption{Relation von $H_0$ und Konfidenzintervall}
\end{figure}

## Konfidenzintervalle von Kontrasten

### Berechnungsmuster

\begin{gather*}
\psi = \sum_i c_i \hat{\tau}_i \pm w \sqrt{\widehat{Var}\left(\sum c_i \hat{\tau}_i\right)} = w \times s_{\psi}\\
\text{estimate } \pm (\text{kritischer Wert}) \times (\text{Standardfehler})
\end{gather*}

Zwischen verschiedenen Methoden unterscheidet sich der kritische Wert $w$.

## Minimum significant difference ($msd$) 

\begin{figure}
\centering
\begin{tikzpicture}
    \draw[dashed,thick] (0,-1) -- (0,1);
    \node[anchor=north] at (0,-1) {$H_{0:\psi}$};
    \fill[red] (2,0) circle (4pt);
    \draw[thick, color=red] (0.08,0) -- (3.92,0);
    \node at (2,0.5) {$\hat{\psi}$};
    \node at (1,-0.5) {$-w\times s_{\psi}$};
    \node at (3,-0.5) {$+w\times s_{\psi}$};
    \node[red] at (0.1,0) {(};
    \node[red] at (3.9,0) {)};
    \draw [->, thick] (-1,-1) -- (5,-1);
\end{tikzpicture}
\caption{Kontrastkonfidenzintervall}
\end{figure}

$$
msd = w \sqrt{\widehat{Var}\left(\sum c_i \hat{\tau}_i\right)}=w \times s_{\psi}
$$


## Einteilung der Mehrfachvergleiche

Table: Systematik Mehrfachvergleiche

| Name | Zeitpunkt | Kontraste | Kontrolliert |
| --- | --- | --- | --- | 
| Bonferroni | pre-planned | einfache und komplexe | Ja |
| Tukey | pre-planned | alle paarweisen | Ja |
| Scheffé | post-hoc | einfache und komplexe | Ja |
| Dunnet | pre-planned | paarweise TRT gegen CON | Ja |
| FisherLSD| post-hoc | einfache und komplexe | Nein^[Außer wenn $K=3$] |

## Mehrfachvergleiche in `R`

### Package `emmeans()`

Zweistufiger Ablauf:

1) Berechnen der Zellmittelwerte mit der Funktion \
`emmeans(<MODEL>, ~<FAKTOR>)`
2) Vergleiche werden entweder mittels `pairs()` (paarweise Vergleiche) oder mit `contrast()` (beliebige Vergleiche) berechnet 

Alternative: `package:multcomp`

## Bonferroni (pre-planned)

Das Signifikanzlevel $\alpha$ wird angepasst indem ein neuer $\alpha$-Level, $\alpha^*$, mittels:

$$
\alpha^* = \alpha / m
$$

berechnet wird. $m$ ist die Anzahl der Kontraste.

Kontrolliert Gesamt-$\alpha$ für einfache und/oder komplexe Kontraste.

## Beispiel Bonferroni

Einfacher Vergleich Koffein geben Placebo und komplexer Vergleich des Mittelwerts von Koffein und Placebo gegen Kontrolle.

\scriptsize
```{r, echo=T}
library(emmeans)
mod_em <- emmeans(mod_aov, ~Gruppe)
contrast(mod_em, adjust='bonferroni', infer=T ,
         method = list(
           "Koffein vs. Placebo" = c(1, -1, 0),
           "Tablette vs. CON" = c(1/2, 1/2, -1)
         ))
```


## Tukey (H)onest (S)ignifikant (D)ifference (pre-planned)

Optimiert für alle paarweisen Kontraste.

\scriptsize
```{r, echo=T}
pairs(mod_em, adjust="tukey", infer=T)
```
^[TukeyHSD ist auch default wenn keine Argument für `adjust` angegeben wird.]

## Scheffé (post-hoc)

Sichert post-hoc $\alpha$-Level für alle möglichen Kontraste (beliebige Anzahl) ab.

Beispielsweise die gleichen Kontraste wie beim Bonferroni-Beispiel.
\scriptsize
```{r, echo=T}
contrast(mod_em, adjust='scheffe', infer=T ,
         method = list(
           "Koffein vs. Placebo" = c(1, -1, 0),
           "Tablette vs. CON" = c(1/2, 1/2, -1)
         ))
```


## Dunnett (pre-planned)

Optimiert für den Vergleich von Treatmentkonditionen gegen eine Kontrollkondition.
\vspace{.5cm}
\scriptsize
```{r, echo=T}
contrast(mod_em, method='trt.vs.ctrl', infer=T, ref='Control')
```


## Fisher (L)east (S)ignificant (D)ifference (post-hoc)

Durchführung von post-hoc Tests wenn ein statistisch signifikanter Haupteffekt über die ANOVA abgesichert wurde.
\vspace{.5cm}
\scriptsize
```{r, echo=T}
pairs(mod_em, adjust='none', infer=T)
```

\Large
\alert{Do not like!!!}^[Außer bei einem Faktor mit genau drei Stufen (siehe @levin1994)]

## Vergleich der kritischen Werte $w$

```{r}
tibble(
  'no_groups' = 2:7,
  'per_com' = qf(0.95, 1, 12),
  'tukey' = qtukey(0.95, no_groups, 12)**2/2,
  'bonferroni' = qf(1-0.05/(no_groups*(no_groups-1)/2), 1, 12),
  'scheffe' = (no_groups-1)*qf(0.95, no_groups-1, 12)
) |> 
  knitr::kable(
    booktabs=T,
    col.names=c('Stufen', '$\\alpha_{PC}$', 'Tukey', 'Bonferroni','Scheffé'),
    caption="Kritische Werte $w$ für alle $k(k-1)/2$ paarweisen Vergleiche bei $df_{\\text{error}}=12$.",
    digits=2,
    linesep = '',
    escape=F
  )
```

## Optional - Cohen's d für post-hocs

\scriptsize
```{r, echo=T}
eff_size(mod_em, sigma=sigma(mod_aov),
                 edf=df.residual(mod_aov))
```


## Dokumentation

\small
Eine einfaktorielle ANOVA mit dem Faktor Gruppe ergabe einen statistisch signifikanten Haupteffekt für Gruppe $F(2, 57) = 22,6, p < 0,001$.  Überprüfung auf Varianzgleichheit zwischen den Gruppen mittels eines Levene-Tests deutete auf keine Verletzung der Voraussetzungen hin, $F(2, 57) = 0,38, p = 0,69$. Daher wird die $H_0$, das kein Unterschied zwischen den Gruppen besteht, abgelehnt. Die beobachtete Effektstärke $\omega^2 = 0,42$,  CI$95\%[0,22, 0,56]$ ist als großer Effekt zu interpretieren. Pre-planned Paarweisetestung mittels Tukey-Korrektur deutete auf statistisch signifikate Unterschiede zwischen den Gruppen Koffein und Placebo $z = -10.4$, CI95\%$[-15,5, -5,5], p < 0,001$, und Koffein und Kontrolle, $z = -13,3$, CI95$\%[-18,4, -8,3], p < 0,001$, hin. Insgesamt deuten die Ergebnisse daher darauf hin, dass die Gabe von Koffein zu einer bedeutsamen Leistungssteigerung $(>5-10s)$ in der beobachteten Untersuchungsgruppe geführt hat.

## Zum Nacharbeiten

### Multiple-comparisons
@feise2002, @rothman1990
