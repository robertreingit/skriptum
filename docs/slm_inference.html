<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="de" xml:lang="de"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Skriptum - Fortgeschrittene Statistik - 12&nbsp; Inferenz</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./slm_model_fit.html" rel="next">
<link href="./slm_basics.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "Keine Treffer",
    "search-matching-documents-text": "Treffer",
    "search-copy-link-title": "Link in die Suche kopieren",
    "search-hide-matches-text": "Zusätzliche Treffer verbergen",
    "search-more-match-text": "weitere Treffer in diesem Dokument",
    "search-more-matches-text": "weitere Treffer in diesem Dokument",
    "search-clear-button-title": "Zurücksetzen",
    "search-detached-cancel-button-title": "Abbrechen",
    "search-submit-button-title": "Abschicken",
    "search-label": "Suchen"
  }
}</script>
<script>
  MathJax = {
    tex: {
      tags: 'ams'  // should be 'ams', 'none', or 'all'
    }
  };
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./slm_title.html">Das einfache Regressionmodell</a></li><li class="breadcrumb-item"><a href="./slm_inference.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Inferenz</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Seitenleiste umschalten" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Skriptum - Fortgeschrittene Statistik</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Suchen"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Vorwort</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./r_startup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Eine Schnelleinführung in R</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r_intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Eine Übersicht über <code>R</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r_kickoff.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title"><code>R</code> Kickoff</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r_flowcontrol.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Ablaufkontrolle</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r_basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Einfache Datenbearbeitung und Visualisierung in <code>R</code></span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./r_literate_programming.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Literate programming in <code>R</code></span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./stats_title.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Statistik</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stats_basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Eine kleine Welt der Unsicherheit</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stats_significance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Statistische Signifikanz, p-Wert und Power</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stats_estimation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Parameterschätzung</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stats_distributions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Theoretische Verteilungen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stats_hypotheses.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Hypothesen testen</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./slm_title.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Das einfache Regressionmodell</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-3" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-3" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./slm_basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Einführung</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./slm_inference.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Inferenz</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./slm_model_fit.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Modellfit</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./slm_prediction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Vorhersage</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./mlm_title.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Multiple Regression</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-4" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-4" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlm_basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Einführung</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlm_interactions.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Interaktionseffekte</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlm_dummy_coding.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Integration von nominalen Variablen</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./mlm_hierarchies.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Modellhierarchien</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./lm_title.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Das allgemeine lineare Modell</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-5" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-5" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./lm_basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">Synthese</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./ed_title.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Experimentelles Design</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-6" aria-expanded="true" aria-label="Abschnitt umschalten">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-6" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ed_basics.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">Einführung</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ed_crd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">21</span>&nbsp; <span class="chapter-title">Completely Randomized Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ed_linear_contrasts.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">22</span>&nbsp; <span class="chapter-title">Lineare Kontraste</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ed_crfd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">23</span>&nbsp; <span class="chapter-title">Completely Randomized Factorial Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ed_ancova.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">24</span>&nbsp; <span class="chapter-title">ANCOVA</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ed_crbd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">25</span>&nbsp; <span class="chapter-title">Completely Randomized Block Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ed_irbd.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">26</span>&nbsp; <span class="chapter-title">Incomplete Randomized Block Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ed_split_plot.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">27</span>&nbsp; <span class="chapter-title">Split-plot Design</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ed_cross_over.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">28</span>&nbsp; <span class="chapter-title">Cross-over Design</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Literatur</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Inhaltsverzeichnis</h2>
   
  <ul>
  <li><a href="#statistische-überprüfung-von-beta_1-und-beta_0" id="toc-statistische-überprüfung-von-beta_1-und-beta_0" class="nav-link active" data-scroll-target="#statistische-überprüfung-von-beta_1-und-beta_0"><span class="header-section-number">12.1</span> Statistische Überprüfung von <span class="math inline">\(\beta_1\)</span> und <span class="math inline">\(\beta_0\)</span></a></li>
  <li><a href="#herleitung-der-eigenschaften-von-hatbeta_1" id="toc-herleitung-der-eigenschaften-von-hatbeta_1" class="nav-link" data-scroll-target="#herleitung-der-eigenschaften-von-hatbeta_1"><span class="header-section-number">12.2</span> Herleitung der Eigenschaften von <span class="math inline">\(\hat{\beta}_1\)</span></a></li>
  <li><a href="#maximum-likelihood-methode-bei-der-einfachen-linearen-regression" id="toc-maximum-likelihood-methode-bei-der-einfachen-linearen-regression" class="nav-link" data-scroll-target="#maximum-likelihood-methode-bei-der-einfachen-linearen-regression"><span class="header-section-number">12.3</span> Maximum-likelihood Methode bei der einfachen linearen Regression(*)</a></li>
  <li><a href="#konfidenzintervalle-für-die-koeffizienten" id="toc-konfidenzintervalle-für-die-koeffizienten" class="nav-link" data-scroll-target="#konfidenzintervalle-für-die-koeffizienten"><span class="header-section-number">12.4</span> Konfidenzintervalle für die Koeffizienten</a></li>
  <li><a href="#weiteres-material" id="toc-weiteres-material" class="nav-link" data-scroll-target="#weiteres-material"><span class="header-section-number">12.5</span> Weiteres Material</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Inferenz</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<p>Nachdem wir im vorhergehenden Kapitel gelernt haben, wie wir eine Regressionsgerade an einen Datensatz fitten, stellt sich nun die Frage ob die Regressionsgerade tatsächlich einen relevanten Zusammenhang zwischen den beiden Variablen <span class="math inline">\(x\)</span> und <span class="math inline">\(y\)</span> beschreibt.</p>
<p>Da das einfache lineare Modelle zwei Parameter <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> (siehe Formel <span class="math inline">\(\eqref{eq-slm-psform-beta}\)</span> beinhaltet kann diese Fragestellung auf beide Koeffizienten angewendet werden. D.h. wir können uns fragen ob das Modell einen statistisch signifikanten Zusammenhang zwischen den beiden Variablen beschreibt. Bezogen auf die beiden Parameter, ist der Parameter <span class="math inline">\(\hat{\beta}_0\)</span> statistisch signifikant und ist der Parameter <span class="math inline">\(\hat{\beta}_1\)</span> statistisch signifikant? Um unseren Werkzeugsatz zur statistischen Signifikanz anwenden zu können brauchen wir aber erst einmal wieder eine Verteilung bei der wir kritische Bereiche identifizieren können um zu entscheiden ob eine beobachtete Statistik statistisch signifikant ist. Wir behalten dabei immer im Hinterkopf, das statistische Signifikanz nicht das Gleiche ist wie praktische Relevanz bzw. der Beweis einer Abweichung von einer gegebenen statistischen Hypothese.</p>
<section id="statistische-überprüfung-von-beta_1-und-beta_0" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="statistische-überprüfung-von-beta_1-und-beta_0"><span class="header-section-number">12.1</span> Statistische Überprüfung von <span class="math inline">\(\beta_1\)</span> und <span class="math inline">\(\beta_0\)</span></h2>
<p>Der erste Schritt um eine Referenzverteilung zu erhalten ist besteht zunächst erst einmal wieder darin, dass wir zunächst einmal eine Zufallsvariable benötigen. Bisher haben wir den Zusammenhang zwischen Variablen über die Formel</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 \cdot x_i
\]</span></p>
<p>beschrieben. In dieser Form ist allerdings noch gar kein zufälliges Element vorhanden. Für ein gegebenes <span class="math inline">\(x_i\)</span> bekommen wir ein genau ein spezifiziertes <span class="math inline">\(y_i\)</span>. Allerdings hatten wir schon bei der Herleitung gesehen, dass reale Daten in den seltensten Fällen genau auf der Gerade liegen, sondern wir die Parameter <span class="math inline">\(\hat{\beta}_0\)</span> und <span class="math inline">\(\hat{beta}_1\)</span> so gewählt haben, dass die quadrierten Abweichungen, die Residuen <span class="math inline">\(\epsilon_i\)</span> minimal werden. Diese Residuen verwenden wir nun um eine zufälliges Element in unsere Regression rein zu bekommen. Dazu müssen wir den Residuen <span class="math inline">\(\epsilon_i\)</span> eine Verteilung zuweisen. Wir hatten im Rahmen der vorhergehenden Herleitung zur statistischen Signifikanz auch schon verschiedene theoretische Verteilungen kennengelernt. In diesem Zusammenhang hat sich die Normalverteilung als besonders praktsich erwiesen bzw. als eine Verteilung in in verschiedenen Anwendung eine passable Nährung an reale Daten liefert. Daher gehen im folgenden davon aus, dass die Residuen <span class="math inline">\(\epsilon_i\)</span> einer Normalverteilung folgen. Intuitive bei der Herleitung der Geradengleichung mittels der Methode der kleinsten Quadrate hatten wir gesehen, dass die Abweichungen in etwa, in Abhängigkeit von der absoluten Abweichung, gleichmäßig oberhalb und unterhalb der Geraden verteilt waren.</p>
<p>In behandelten Weitsprungbeispiel hatten wir informell hergeleitet, dass die Weitsprungleistung von unzähligen Faktoren beeinflusst werden kann, welche dazu führen, dass für eine gegebene Anlaufgeschwindigkeit nicht immer die gleiche Weitsprungweite erzielt wird. Generell, ist diese Art der Begründung bei biologischen System meistens plausibel. In vorhergehenden Abschnitt haben wir dazu aber auch noch gesehen, dass die Normalverteilung eben gut geeignet ist, um solche Prozesse, bei denen viele kleine additive Effekt auftreten. Dieser Argumentation folgend ist es also durchaus plausibel diese Einflüsse auch bei der Regression mittels einer Normalverteilung zu modellieren.</p>
<p>Insgesamt erlaubt uns dies diese Annahme wie folgt mathematisch zu formulieren.</p>
<p><span class="math display">\[\begin{equation}
\epsilon_i \sim \mathcal{N}(0, \sigma^2)
\label{eq-slm-inf-epsilon-norm}
\end{equation}\]</span></p>
<p>In Formel <span class="math inline">\(\eqref{eq-slm-inf-epsilon-norm}\)</span> drücken wir aus, dass die Residuen <span class="math inline">\(\epsilon_i\)</span> also die Abweichungen vom vorhergesagten Wert <span class="math inline">\(\hat{y}_i\)</span> zum beobachtetgen Wert <span class="math inline">\(y_i\)</span> einer Normalverteilung folgen mit einem Mittelwert von <span class="math inline">\(\mu = 0\)</span> und einer noch näher zu spezifizierenden Varianz <span class="math inline">\(\sigma^2\)</span>. Der Mittelwert <span class="math inline">\(\mu=0\)</span> drückt dabei unsere Erwartung aus, dass im Mittel die Abweichung von der Geraden nach oben und nach unten sich gegenseitig aufheben. Der Skalenparameter <span class="math inline">\(\sigma^2\)</span> drückt dabei die Streuung der Werte um die Gerade herum aus. D.h. wenn <span class="math inline">\(\sigma^2\)</span> größer wird, dann streuen die Werte stärker um die Gerade herum bzw. entsprechend entgegengesetzt wenn <span class="math inline">\(\sigma^2\)</span> kleiner ist.</p>
<p>Insgesamt führt dies zu der folgenden Formulierung des einfachen Regressionsmodells.</p>
<p><span class="math display">\[\begin{equation}
Y_i = \beta_0 + \beta_1 \cdot x_i + \epsilon_i, \quad \epsilon_i \sim \mathcal{N}(0, \sigma^2)
\label{eq-slm-inf-simple-reg}
\end{equation}\]</span></p>
<p>Bezüglich der Residuen <span class="math inline">\(\epsilon_i\)</span> lässt sich noch eine weitere Spezifikation machen, auf die wir später noch öfter zurückgreifen werden. Bisher sind wir davon ausgegangen, dass die einzelnen Datenpunkt unabhängig voneinander sind. D.h. jeder einzelne Wert ist nicht beeinflusst durch einen der anderen Werte. In unserem Beispiel waren die Anlaufgeschwindigkeit-Sprungweit-Paare jeweils von unterschiedlichen Athleten. In diesem Fall sind die Kovariancen zwischen den Residuen <span class="math inline">\(=0\)</span>, formale <span class="math inline">\(cov(e_i,e_j) = 0,~für~i\neq j\)</span>. Daher lassen sich die Varianzen und Kovarianzen von <span class="math inline">\(\epsilon_i\)</span> in Form einer sogenannten Varianz-Kovarianz-Matrize schreiben. Matrizen hatten wir schon in der Einführung zu <code>R</code> kennengelernt. Die Varianz-Kovarianz-Matrize bekommt per Konvention das Zeichen <span class="math inline">\(\Sigma\)</span> und <span class="math inline">\(\mathbf{I}_n\)</span> bezeichnet die Einheitsmatrize.</p>
<p><span class="math display">\[\begin{equation*}
\Sigma = \begin{pmatrix}
\sigma^2 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; \sigma^2 &amp; &amp; \vdots \\
\vdots &amp;  &amp; \ddots &amp;  \\
0 &amp; \cdots &amp; &amp; \sigma^2
\end{pmatrix} = \sigma^2 \begin{pmatrix}
1 &amp; 0 &amp; \cdots &amp; 0 \\
0 &amp; 1 &amp; &amp; \vdots \\
\vdots &amp;  &amp; \ddots &amp;  \\
0 &amp; \cdots &amp; &amp; 1
\end{pmatrix} = \sigma^2 \mathbf{I}_n
\end{equation*}\]</span></p>
<p>Die Annahmen des Modells, das ein linearer Zusammenhang zwischen <span class="math inline">\(Y\)</span> und <span class="math inline">\(X\)</span> besteht, die einzelnen <span class="math inline">\(N\)</span> Datenpunkte unabhängig voneinander sind und die Residuen einer multivariaten Normalverteilung mit <span class="math inline">\(\epsilon \sim \mathcal{N}(0,\sigma^2\mathbf{I}_n)\)</span> folgen werden als Gauss-Markov-Modell bezeichnet.</p>
<div id="def-gauss-markov" class="theorem definition">
<p><span class="theorem-title"><strong>Definition 12.1 (Gauss-Markov-Modell) </strong></span>Besteht zwischen <span class="math inline">\(N\)</span> unabhängigen Datenpunkten <span class="math inline">\((y_i,x_i)\)</span> ein linearer Zusammenhang der Form <span class="math inline">\(Y = \beta_0 + \beta_1 \cdot X + \epsilon\)</span> zwischen den Variablen <span class="math inline">\(X\)</span> und <span class="math inline">\(Y\)</span> und sind die Datenpunkte unabhängigvoneinander und die <span class="math inline">\(\epsilon\)</span> folgen einer multivariaten Normalverteilung <span class="math inline">\(\epsilon \sim \mathcal{N}(0, \sigma^2 \mathbf{I}_n)\)</span> dann wird dieses Modell als Gauss-Markov-Modell bezeichnet.</p>
</div>
<p><span class="math inline">\(Y\)</span> wird jetzt groß geschrieben, da es sich um eine Zufallsvariable handelt. Unter einer multivariaten Normalverteilung können wir uns Verallgemeinerung der uns bekannten Normalverteilung vorstellen. Beispielsweise hat eine zweidimensionale Normalverteilung die Form eines Zuckerhuts. Dieser Teil ist für unsere weitere Betrachtung aber erst einmal nicht von weiterem Interesse. Unserer Formulierung des Regressionsmodells nach Formel <span class="math inline">\(\eqref{eq-slm-inf-simple-reg}\)</span> führt nun dazu, dass wir das Regressionsmodell in zwei Teile unterscheiden können. Einmal einen deterministischen Teil <span class="math inline">\(\beta_0 + \beta_1 \cdot x\)</span> und einen stochastischen Teil <span class="math inline">\(\epsilon_i\)</span>. Da <span class="math inline">\(Y_i\)</span> durch die Addition der beiden Teile berechnet führt, führt dies dazu, dass <span class="math inline">\(Y_i\)</span> ebenfalls stochastisch ist und somit zu einer Zufallsvariable wird.</p>
<p>Schauen wir uns weiter an, wie sich <span class="math inline">\(Y_i\)</span> verhält, wenn wir <span class="math inline">\(X_i\)</span> als Konstante <span class="math inline">\(X\)</span> mit ein bestimmten Wert annehmen. Dann wird aus Formel<span class="math inline">\(\eqref{eq-slm-inf-simple-reg}\)</span> <span class="math inline">\(Y_i = \beta_0 + \beta_i \cdot x + \epsilon_i\)</span>. Folglich bleibt der deterministische Teil immer gleich, wird zu einer Konstante. Da <span class="math inline">\(\epsilon_i\)</span> normalverteilt ist ist <span class="math inline">\(Y_i\)</span> ebenfalls normalverteilt. Der Mittelwert der Normalverteilung von <span class="math inline">\(Y_i\)</span> <span class="math inline">\(\mu_{Y_i}\)</span> ist allerdings nicht gleich Null, sondern die Normalverteilung von <span class="math inline">\(\epsilon_i\)</span> wird um die Konstante <span class="math inline">\(\beta_0 + \beta_1 \cdot x\)</span> verschoben (siehe <a href="#fig-slm-inf-epsilon-1">Abbildung&nbsp;<span>12.1</span></a>). Das führt dazu, dass <span class="math inline">\(Y_i\)</span> der Verteilung <span class="math inline">\(\mathcal{N}(\beta_0 + \beta_1 x)\)</span> folgt.</p>
<div id="fig-slm-inf-epsilon-1" class="cell quarto-layout-panel">
<figure class="figure">
<div class="quarto-layout-row quarto-layout-valign-top">
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-slm-inf-epsilon-1-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="slm_inference_files/figure-html/fig-slm-inf-epsilon-1-1.png" class="img-fluid figure-img" data-ref-parent="fig-slm-inf-epsilon-1" width="672"></p>
<figcaption class="figure-caption">(a) Verteilung von <span class="math inline">\(\epsilon_i\)</span></figcaption>
</figure>
</div>
</div>
<div class="cell-output-display quarto-layout-cell quarto-layout-cell-subref" style="flex-basis: 50.0%;justify-content: center;">
<div id="fig-slm-inf-epsilon-1-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="slm_inference_files/figure-html/fig-slm-inf-epsilon-1-2.png" class="img-fluid figure-img" data-ref-parent="fig-slm-inf-epsilon-1" width="672"></p>
<figcaption class="figure-caption">(b) Verteilung von <span class="math inline">\(Y_i\)</span></figcaption>
</figure>
</div>
</div>
</div>
<p></p><figcaption class="figure-caption">Abbildung&nbsp;12.1: Relation der Lageparameter von <span class="math inline">\(e_i\)</span> und <span class="math inline">\(Y_i\)</span></figcaption><p></p>
</figure>
</div>
<p>Daraus folgt jetzt aber zusätzlich, dass für jedes gegebenes <span class="math inline">\(X\)</span> die <span class="math inline">\(Y\)</span>-Werte einer Normalverteilung folgen. Lediglich die Verschiebung des Mittelwert der jeweiligen <span class="math inline">\(Y\)</span>-Normalverteilung hängt von <span class="math inline">\(X\)</span> über die Formel <span class="math inline">\(\beta_0 + \beta_1 \cdot X\)</span> zusammen. Formal:</p>
<p><span class="math display">\[
Y|X \sim N(\beta_0+ \beta_1 X,\sigma^2)
\]</span></p>
<p>Die Schreibweise <span class="math inline">\(|X\)</span> wird übersetzt für gegenbenes <span class="math inline">\(X\)</span> und sagt aus, dass die Verteilung von <span class="math inline">\(Y\)</span> von <span class="math inline">\(X\)</span> abhängt. Es handelt sich dabei um eine bedingte Wahrscheinlichkeit. Die Varianz der jeweiligen <span class="math inline">\(Y\)</span>-Werte ist dabei die zuvor angenommen Varianz der <span class="math inline">\(\epsilon_i\)</span> also <span class="math inline">\(\sigma^2\)</span>. Eine wichtige Annahme die noch mal betont werden sollte, wir gehen davon aus, dass die einzelnen Punkte unabhängig voneinander sind. Im Weitsprungbeispiel würde dies bedeuten, dass jeder Sprung von einem anderen Athleten kommen muss.</p>
<p>Wenn wir die Verteilungen von <span class="math inline">\(Y\)</span> graphisch führ beispielweise drei verschiedene <span class="math inline">\(X\)</span>-Wert darstellen, dann folgt daraus die folgende Abbildung (siehe <a href="#fig-slm-inf-epsilon-2">Abbildung&nbsp;<span>12.2</span></a>). D.h. für jeden <span class="math inline">\(X\)</span>-Wert werden mehrere <span class="math inline">\(Y\)</span>-Werte beobachtet, die jeweils einer Normalverteilung folgen.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-slm-inf-epsilon-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="pics/Stats_Figures.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Abbildung&nbsp;12.2: Verteilung der Daten für verschiedene <span class="math inline">\(x\)</span>-Werte</figcaption>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-slm-inf-epsilon-2">Abbildung&nbsp;<span>12.2</span></a> ist klar zu sehen, wie für jeden der drei Punkte von <span class="math inline">\(X\)</span> die beobachteten <span class="math inline">\(Y\)</span>-Werte einer Normalverteilung folgen. Die Streuung der Verteilung ist an jedem der <span class="math inline">\(X\)</span>-Punkte gleich, nämlich <span class="math inline">\(=\sigma^2\)</span>. Dagegen ist der Mittelwert der Verteilung der <span class="math inline">\(Y_i\)</span>-Wert der Gleichung <span class="math inline">\(\beta_0 + \beta_1 X\)</span> folgend entlang der Regressionsgerade verschoben.</p>
<p>Wenn wir uns zurück an die Ausführungen zur statistischen Signifikanz erinnern, dann haben wir in dem Zusammenhang vom einem datengenerierenden Prozess gesprochen (<a href="stats_significance.html#def-dgp">Definition&nbsp;<span>7.1</span></a>) (DGP). In unserem jetzigen Modell können wir dementsprechend zwei Komponenten als Teile des DGP identizifieren. Entsprechend Formel<span class="math inline">\(\eqref{eq-slm-inf-simple-reg}\)</span> besteht der DGP aus dem deterministischen Teil <span class="math inline">\(\beta_0 + \beta_1 X\)</span> und dem stochastischen Teil <span class="math inline">\(\epsilon_i \sim \mathcal{N}(0,\sigma^2)\)</span>. Diese Einsicht können wir verwenden um die Eigenschaften dieses Modells zu möglichen Aussagen hinsichtlich statistisches Signifikanz zu untersuchen.</p>
<p>Wir fokussieren uns jetzt auf ein vereinfachtes Modell bei dem wir zusätzlich noch <span class="math inline">\(\beta_0 = 0\)</span> setzen, und wir uns erst mal nur für die Eigenschaften von <span class="math inline">\(\beta_1\)</span> interessieren. Gehen wir nun davon aus, dass zwischen <span class="math inline">\(X\)</span> und <span class="math inline">\(Y\)</span> der Zusammenhang <span class="math inline">\(\beta_1 = 1\)</span> besteht. D.h. wenn <span class="math inline">\(X\)</span> um eine Einheit vergrößert wird, dann wird <span class="math inline">\(Y\)</span> ebenfalls um eine Einheit größer.</p>
<p><span id="eq-slm-inf-sim-mod-1"><span class="math display">\[
Y = 0 + 1 \cdot X + \epsilon, \quad \epsilon\sim\mathcal{N}(0,\sigma^2)
\tag{12.1}\]</span></span></p>
<p>Jetzt müssen wir noch einen Wert für <span class="math inline">\(\sigma^2\)</span> festlegen. Sei dieser einfach einmal <span class="math inline">\(\sigma = \frac{1}{2}\)</span>. Jetzt können wir <code>R</code> benutzen um <em>Experimente</em>, also Beobachtungen, anhand dieses DGP zu simulieren. Der Einfachheit halber legen wir ein übersichtliches <span class="math inline">\(N = 12\)</span> fest und nehmen uns jeweils drei <span class="math inline">\(X\)</span>-Werte z.B. mit <span class="math inline">\(X \in \{-1, 0, 1\}\)</span>, d.h. wir ziehen für jeden <span class="math inline">\(X\)</span>-Wert vier <span class="math inline">\(Y\)</span>-Werte.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">12</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>beta_0 <span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>beta_1 <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">/</span><span class="dv">2</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>dat_sim_1 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">x_i =</span> <span class="fu">rep</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span>, <span class="at">each=</span><span class="dv">4</span>),</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">y_i =</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x_i <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wenn wir uns die generierten Daten anschauen, dann sehen wir wenig überraschend 12 verschiedene Werte für <span class="math inline">\(y_i\)</span> und jeweils <span class="math inline">\(3 \times 4\)</span> verschiedene Werte für <span class="math inline">\(x_i\)</span> (siehe <a href="#tbl-slm-inf-sim-1">Tabelle&nbsp;<span>12.1</span></a>).</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-slm-inf-sim-1" class="anchored">
<table class="table table-sm table-striped small">
<caption>Tabelle&nbsp;12.1: Eine Simulation des Modells <a href="#eq-slm-inf-sim-mod-1">Gleichung&nbsp;<span>12.1</span></a></caption>
<thead>
<tr class="header">
<th style="text-align: right;">x_i</th>
<th style="text-align: right;">y_i</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">-1</td>
<td style="text-align: right;">-1.00</td>
</tr>
<tr class="even">
<td style="text-align: right;">-1</td>
<td style="text-align: right;">-0.59</td>
</tr>
<tr class="odd">
<td style="text-align: right;">-1</td>
<td style="text-align: right;">-0.96</td>
</tr>
<tr class="even">
<td style="text-align: right;">-1</td>
<td style="text-align: right;">-1.23</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.40</td>
</tr>
<tr class="even">
<td style="text-align: right;">0</td>
<td style="text-align: right;">-0.31</td>
</tr>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.79</td>
</tr>
<tr class="even">
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.14</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.18</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">1.27</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.71</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.83</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Wenn wir die Daten graphisch darstellen erhalten wir (<a href="#fig-slm-inf-sim-1">Abbildung&nbsp;<span>12.3</span></a>):</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(dat_sim_1, <span class="fu">aes</span>(x_i, y_i)) <span class="sc">+</span> </span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>()</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-slm-inf-sim-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="slm_inference_files/figure-html/fig-slm-inf-sim-1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Abbildung&nbsp;12.3: Streudiagramm der Daten aus <a href="#tbl-slm-inf-sim-1">Tabelle&nbsp;<span>12.1</span></a></figcaption>
</figure>
</div>
</div>
</div>
<p>Ebenfalls wenig überraschend, die Punkte sind auf den <span class="math inline">\(x\)</span>-Werten <span class="math inline">\(-1, 0\)</span> und <span class="math inline">\(1\)</span> zentriert und liegen nicht alle aufeinander, da sie einer Zufallsstichprobe aus <span class="math inline">\(\mathcal{N}(0, \frac{1}{4})\)</span> entspringen.</p>
<p>Jetzt können für diese Daten unsere Normalengleichungen anwenden und Werte für <span class="math inline">\(\hat{\beta}_0\)</span> und <span class="math inline">\(\hat{\beta}_1\)</span> berechnen. Oder wir lassen das von <code>R</code> machen.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>mod_sim_1 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_i <span class="sc">~</span> x_i, dat_sim_1)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_sim_1)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)         x_i 
 0.01928823  0.84742748 </code></pre>
</div>
</div>
<p>Wir sehen, dass die berechneten Werte für <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> schon in der Nähe der tatsächlichen Werte liegen (siehe <span class="quarto-unresolved-ref">?eq-slm-inf-mod-1</span>), aber auf Grund der Stichprobenvariabilität eben nicht genau auf diesen Werten. Was passiert denn jetzt, wenn ich das Ganze noch einmal durchlaufen lassen?</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>dat_sim_2 <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">x_i =</span> <span class="fu">rep</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span>, <span class="at">each=</span><span class="dv">4</span>),</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">y_i =</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x_i <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>mod_sim_2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_i <span class="sc">~</span> x_i, dat_sim_2)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(mod_sim_2)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>(Intercept)         x_i 
 0.06918968  1.03838734 </code></pre>
</div>
</div>
<p>Wieder wenig überraschend, da jedes Mal wenn ich <code>rnom()</code> eine neue Ziehung aus der Normalverteilung generiert wird, erhalte ich neue Werte für <span class="math inline">\(y_i\)</span> und dementsprechend andere Werte für <span class="math inline">\(\hat{\beta}_0\)</span> und <span class="math inline">\(\hat{\beta}_1\)</span>. Nochmal, warum? <strong>Stichprobenvariabilität</strong>! Jetzt sind wir wieder bei dem gleichen Prinzip, das wir im Rahmen der kleinen Welt ausgiebig behandelt haben. Schauen wir uns jetzt doch einfach mal was passiert wenn wir die Simulation nicht <span class="math inline">\(2\times\)</span> sondern z.B. <span class="math inline">\(1000\times\)</span> durchführen.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>N_sim <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>beta_1_s <span class="ot">&lt;-</span> <span class="fu">numeric</span>(N_sim)</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>x_i <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="sc">-</span><span class="dv">1</span><span class="sc">:</span><span class="dv">1</span>, <span class="at">each=</span><span class="dv">4</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span>N_sim) {</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  daten_temporaer <span class="ot">&lt;-</span> <span class="fu">tibble</span>(x_i,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>                            <span class="at">y_i =</span> beta_0 <span class="sc">+</span> beta_1 <span class="sc">*</span> x_i <span class="sc">+</span> <span class="fu">rnorm</span>(N, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma))</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>  model_temporaer <span class="ot">&lt;-</span> <span class="fu">lm</span>(y_i <span class="sc">~</span> x_i, daten_temporaer)</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  beta_1_s[i] <span class="ot">&lt;-</span> <span class="fu">coef</span>(model_temporaer)[<span class="dv">2</span>]</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Wir erhalten jetzt einen Vektor <code>beta_1_s</code> mit <span class="math inline">\(1000\)</span> beobachteten <span class="math inline">\(\hat{\beta}_1\)</span>. Da das etwas viele Werte sind um die uns einzeln anzuschauen, erstellen ein Histogramm der <span class="math inline">\(\hat{\beta}_1\)</span>s. (<a href="#fig-slm-inf-hist-sim-1">Abbildung&nbsp;<span>12.4</span></a>).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(beta_1_s, <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">hat</span>(beta)[<span class="dv">1</span>]), <span class="at">main=</span><span class="st">''</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> beta_1, <span class="at">col=</span><span class="st">'red'</span>, <span class="at">lty=</span><span class="dv">2</span>)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-slm-inf-hist-sim-1" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="slm_inference_files/figure-html/fig-slm-inf-hist-sim-1-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Abbildung&nbsp;12.4: Histogram der auf den simulierten Daten berechneten <span class="math inline">\(\hat{\beta}_1\)</span>. Wahrer Wert von <span class="math inline">\(\beta_1\)</span> rot eingezeichnet.</figcaption>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-slm-inf-hist-sim-1">Abbildung&nbsp;<span>12.4</span></a> begegnet uns zunächst einmal wieder unsere altbekannte Glockenkurve. Schön ist, dass deren Mittelwert im Bereich des wahren Werts von <span class="math inline">\(\beta_1\)</span> liegt und Werte mit größer werdender Abweichung vom wahren Wert in ihrer Häufigkeit abnehmen. Aber die Häufigkeit ist nicht Null, sondern eben nur geringer. Werte in der Nähe von <span class="math inline">\(\beta_1\)</span> weisen dagegen eine größere Häufigkeit aufweisen. Das sollte uns jetzt auch irgendwie zufrieden stimmen, denn dies bedeutet, dass wir in der Lage sind mit unserem Regressionsmodell im Mittel tatsächlich den korrekten Wert abzuschätzen. Allerdings, wie immer, bei einer einzelnen Durchführung des Experiments können wir alles von perfekt spot-on bis komplett danebenliegen und würden es nicht wissen.</p>
<p>Wir können jetzt aber auch wieder ganz parallel zu unseren Herleitungen in der kleinen Welt einen Entscheidungsprozess spezifizieren. Wenn <a href="#fig-slm-inf-hist-sim-1">Abbildung&nbsp;<span>12.4</span></a> den DGP beschreibt und das die Verteilung der zu erwartenden <span class="math inline">\(\hat{\beta}_1\)</span> unter dem Modell sind. Bei der Dürchführung eines neuen Experiments, dann würden wir sagen, dass wenn unserer beobachteter Wert in den Rändern der Verteilung von <a href="#fig-slm-inf-hist-sim-1">Abbildung&nbsp;<span>12.4</span></a> liegt, das wir eher nicht davon ausgehen, dass unserer neues Experiment den gleichen DGP zugrundeliegen hat. D.h wir definieren uns jetzt Grenzen am oberen und am unteren Rand der Verteilung. Wenn jetzt ein neuer beobachteter Wert entweder unterhalb der unteren Grenze oder oberhalb der oberen Grenze liegt, dann sagen wir: <em>Wir sind jetzt aber sehr überrascht diesen Wert zu sehen, wenn der dem gleichen datengenerierenden Prozess entstammen soll. Daher glauben wir nicht, dass dieses Experiment den gleichen DGP besitzt.</em></p>
<p>Um diese Entscheidung treffen zu können, müssen wir also Grenzen definieren. Dazu können wir zunächst einmal einfach die Quantilen der Verteilung nehmen und schneiden z.B. unten <span class="math inline">\(2.5\%\)</span> und oben <span class="math inline">\(2.5\%\)</span> ab. So kommen wir dann insgesamt auf <span class="math inline">\(5\%\)</span>, um auf die übliche Irrtumswahrscheinlichkeit von <span class="math inline">\(\alpha = 0.05\)</span> zu kommen. Dazu benutzen wir <code>R</code> und zwar <code>quantile()</code>-Funktion^[Im folgenden Snippet werden die Werte auf zwei Kommastellen mit <code>round()</code> der besseren Darstellung wegen gerundet).</p>
<div class="cell">
<div class="cell-output cell-output-stdout">
<pre><code> 2.5% 97.5% 
 0.65  1.35 </code></pre>
</div>
</div>
<p>Mittels dieser Werte können wir zwei disjunkte Wertmenge definieren, einmal die Werte innerhalb von <span class="math inline">\(\hat{\beta}_1 \in [0.65,1.35]\)</span> bei denen wir nicht überrascht sind, und die unter der Annahme <span class="math inline">\(\beta_1 = 1\)</span> erwartbar sind und die Werte <span class="math inline">\(\hat{\beta}_1 \notin [0.65,1.35]\)</span> diejenigen Werte die uns überraschen würden unter der Annahme. Ins Histogramm übertragen (siehe <a href="#fig-slm-inf-hist-sim-2">Abbildung&nbsp;<span>12.5</span></a>).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-slm-inf-hist-sim-2" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="slm_inference_files/figure-html/fig-slm-inf-hist-sim-2-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Abbildung&nbsp;12.5: Histogram der auf den simulierten Daten berechneten <span class="math inline">\(\hat{\beta}_1\)</span>. Wahrer Wert von <span class="math inline">\(\beta_1\)</span> rot eingezeichnet und kritische Werte grün.</figcaption>
</figure>
</div>
</div>
</div>
<p>Führen wir nun ein Experiment noch einmal durch. Wir beobachten einen Wert für <span class="math inline">\(\hat{\beta}_1\)</span> von <span class="math inline">\(1.46\)</span>. Dieser Wert liegt außerhalb unseres definierten Intervalls <span class="math inline">\([0.65, 1.35]\)</span>, daher sehen wir diesen Wert als derart unwahrscheinlich unter dem angenommenen DGP, das wir sagen: <em>Wir glauben nicht, dass diesem Experiment nicht der angenommene DGP zugrunde liegt</em>. Graphisch wieder dargestellt (siehe <a href="#fig-slm-inf-hist-sim-3">Abbildung&nbsp;<span>12.6</span></a>).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-slm-inf-hist-sim-3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="slm_inference_files/figure-html/fig-slm-inf-hist-sim-3-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Abbildung&nbsp;12.6: Histogram der auf den simulierten Daten berechneten <span class="math inline">\(\hat{\beta}_1\)</span>. Wahrer Wert von <span class="math inline">\(\beta_1\)</span> rot eingezeichnet und kritische Werte grün und der beobachtete Wert als roter Punkt.</figcaption>
</figure>
</div>
</div>
</div>
<p>Daher würden wir diesen Wert als statisisch signifikant bezeichnen und würden unsere Annahme ablehnen.</p>
<p>Jetzt sind wir aber etwas hin und her zwischen Experiment, Annahmen und Schlussfolgerungen gesprungen. Normalerweise kennen wir die Stichprobenverteilung nicht vor dem Experiment, sondern, wir sind am dem Wert <span class="math inline">\(\beta_1\)</span> interessiert. Wenn wir den Wert schon wissen würden, dann müssten wir ja gar kein Experiment mehr durchführen. D.h. wir haben eigentlich noch keinen klaren Vorkenntnisse. Mit welcher Annahme gehen wir dann in das Experiment rein? Nun, wir schon bei kleinen Welt Beispiel, starten wir mit der Annahme das zwischen den beiden Variablen kein Zusammenhang besteht. Übertragen auf die Modellparameter also, dass kein linearer Zusammenhang zwischen den beiden Variablen besteht.</p>
<p><span class="math display">\[\begin{align*}
H_0: \beta_1 &amp;= 0 \\
H_1: \beta_1 &amp;\neq 0
\end{align*}\]</span></p>
<p>Um die Stichprobenverteilung unter der <span class="math inline">\(H_0\)</span> formal Herleitung zu können, ist der Erwartungswert von <span class="math inline">\(\hat{\beta}_1\)</span> und dessen Standardfehler notwendig. Es lässt sich zeigen, dass die folgenden Zusammenhänge unter den gesetzten Annahmen bestehen:</p>
<p><span class="math display">\[
E[\hat{\beta}_0] = \beta_0
\]</span></p>
<p>Also der Schätzer von <span class="math inline">\(\beta_1\)</span> ist erwartungstreu (biased) und der Standardfehler des Schätzer lässt sich wie folgt bestimmen.</p>
<p><span id="eq-slm-beta1-se"><span class="math display">\[
\sigma_{\beta_1} = \sqrt{\frac{\sigma^2}{\sum{(X_i - \bar{X})^2}}}
\tag{12.2}\]</span></span></p>
<p>Hier taucht jetzt zum ersten Mal der Parameter <span class="math inline">\(\sigma^2\)</span> formal auf. Wo kommt diese Variance her? Sie gehört zu unserer Annahme der Verteilung der <span class="math inline">\(\epsilon_i \sim \mathcal{N}(0,\sigma^2)\)</span>. Bisher haben wir aber noch gar keine Möglichkeit kennen gelerntm, diese abzuschätzen. Wieder nach etwas motivierten Starren auf die verschiedenen Formeln, könnte heuristisch plausibel sein, dass die Varianz, also die Streuung der <span class="math inline">\(\epsilon_i\)</span> mit der Streuung unserer Werte um die Regressionsgerade zusammenhängen könnten. Formal hatten wir diese als Residuen bezeichnet und mit <span class="math inline">\(e_i = \hat{y}_i - y_i\)</span> bezeichnet. Vormals hatten wir diese Abweichungen als Fehler bezeichnet, aber unter den jetzt eingeführten Annahmen, handelt es sich nicht wirklich um Fehler, sondern die Abweichungen sind eine Folge davon, dass <span class="math inline">\(Y_i\)</span> für jeden Wert von <span class="math inline">\(X_i\)</span> nicht nur einen einzigen Wert hat, sondern eben einer Verteilung folgt <span class="math inline">\(Y_i|X_i \sim \mathcal{N}(\beta_0 + beta_1, \sigma^2)\)</span> deren Form über die <span class="math inline">\(\epsilon_i\)</span> bestimmt wird.</p>
<p>Die <span class="math inline">\(e_i\)</span> sind tatsächlich die Schätzer für die <em>wahren</em> <span class="math inline">\(\epsilon_i\)</span> also <span class="math inline">\(e_i = \hat{\epsilon_i} = \hat{y}_i - y_i\)</span>. Es lässt sich nun wieder zeigen, dass mittels dieser <span class="math inline">\(e_i\)</span> ein erwartungstreuer Schätzer für <span class="math inline">\(\sigma^2\)</span> erzeugen lässt. Nämlich die mittleren quadrierten Abweichungen (MSE).</p>
<p><span id="eq-slm-sigma"><span class="math display">\[
\hat{\sigma} = \frac{\sqrt{\sum_{i=1}^N e_i^2}}{N-2} = \frac{\text{SSE}}{N-2} = \text{MSE}
\tag{12.3}\]</span></span></p>
<p>Da das später immer wieder auftauchen wird, hier auch noch mal in die zwei Komponenten zerlegt. Der Zähler wird als Summe der quadrierten Abweichungen (SSE) bezeichnet und durch den Term <span class="math inline">\(N-2\)</span>, der als Freiheitsgerade bezeichnet wird, geteilt. Dann mit die Formel und deren Bezeichnung <em>mittlere</em> Abweichung zusammenpasst, wäre es schöner wenn die Summe durch die Anzahl <span class="math inline">\(N\)</span> der Terme geteilt wird, allerdings verhält sich das in diesem Fall ähnlich wie bei der Varianz einer Stichprobe wo die Summe auch durch <span class="math inline">\(N-1\)</span> geteilt wird (zur Erinnerung <span class="math inline">\(s = \frac{\sum_{i=1}^N (x_i - \bar{x})^2}{N-1}\)</span>). Jetzt wird dementsprechend nicht durch <span class="math inline">\(N-1\)</span> sondern durch <span class="math inline">\(N-2\)</span> geteilt.</p>
<p>Für unser Problem der Stichprobenverteilung ist jetzt aber wichtiger, dass wir mittels <a href="#eq-slm-sigma">Gleichung&nbsp;<span>12.3</span></a> den Standardfehler von <span class="math inline">\(\hat{\beta}_1\)</span> bestimmen können, indem wir für <span class="math inline">\(\sigma^2\)</span> das mittels der Daten ermittelte <span class="math inline">\(\hat{\sigma}^2\)</span> einsetzen.</p>
<p><span id="eq-slm-hatbeta1-se"><span class="math display">\[
\hat{\sigma}_{\beta_1} = \sqrt{\frac{\hat{\sigma}^2}{\sum{(X_i - \bar{X})^2}}}
\tag{12.4}\]</span></span></p>
<p>Dies erlaubt uns jetzt nach unserem bereits bekannten Muster eine Teststatistik für die <span class="math inline">\(H_0\)</span> herzuleiten:</p>
<p><span class="math display">\[
t = \frac{\hat{\beta}_1 - \beta_1}{\hat{\sigma}_{\beta_1}}
\]</span></p>
<p>Unter der <span class="math inline">\(H_0\)</span> mit <span class="math inline">\(\beta_1 = 0\)</span> wird daraus</p>
<p><span id="eq-slm-beta1-statistic"><span class="math display">\[
t = \frac{\hat{\beta}_1}{\hat{\sigma}_{\beta_1}}
\tag{12.5}\]</span></span></p>
<p>Diese Teststatistik folgt einer t-Verteilung mit <span class="math inline">\(N-2\)</span> Freiheitsgeraden. Da diese Formel wieder etwas aus der Luft gegriffen erscheint, hier noch mal eine Simulation zusammen mit der theoretischen Testverteilung.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">45</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>n_sim <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">runif</span>(N, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>experiment <span class="ot">&lt;-</span> <span class="cf">function</span>() {</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  y <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(N, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> sigma)</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(y<span class="sc">~</span>x)</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  b <span class="ot">&lt;-</span> <span class="fu">coef</span>(mod)[<span class="dv">2</span>]</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(<span class="at">beta_0 =</span> <span class="fu">coef</span>(mod)[<span class="dv">1</span>],</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>    <span class="at">beta_1 =</span> <span class="fu">coef</span>(mod)[<span class="dv">2</span>],</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>    <span class="at">sigma =</span> <span class="fu">sigma</span>(mod))</span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>betas <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">replicate</span>(n_sim, <span class="fu">experiment</span>()))</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>betas <span class="ot">&lt;-</span> <span class="fu">tibble</span>(<span class="at">beta_0 =</span> betas[,<span class="dv">1</span>],</span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a>                <span class="at">beta_1 =</span> betas[,<span class="dv">2</span>],</span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a>                <span class="at">sigma =</span> betas[,<span class="dv">3</span>]) <span class="sc">|&gt;</span> </span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a>   <span class="at">s_e_beta_1 =</span> <span class="fu">sqrt</span>(sigma<span class="sc">**</span><span class="dv">2</span><span class="sc">/</span><span class="fu">sum</span>( (x <span class="sc">-</span> <span class="fu">mean</span>(x))<span class="sc">**</span><span class="dv">2</span>)),</span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a>   <span class="at">t =</span> beta_1 <span class="sc">/</span> s_e_beta_1)</span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a>t_theoretical <span class="ot">&lt;-</span> <span class="fu">tibble</span>(</span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">t =</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">3</span>, <span class="dv">3</span>, <span class="at">length.out =</span> <span class="dv">150</span>),</span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">p =</span> <span class="fu">dt</span>(t, N <span class="sc">-</span> <span class="dv">2</span>)</span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(betas, <span class="fu">aes</span>(t)) <span class="sc">+</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_histogram</span>(<span class="fu">aes</span>(<span class="at">y =</span> ..density..), <span class="at">bins =</span> <span class="dv">20</span>) <span class="sc">+</span></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">data =</span> t_theoretical, <span class="fu">aes</span>(t, p), <span class="at">color =</span> <span class="st">'red'</span>) <span class="sc">+</span></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">"t"</span>, <span class="at">y =</span> <span class="st">'Relative Häufigkeit'</span>) </span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-slm-inf-beta1-dist" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="slm_inference_files/figure-html/fig-slm-inf-beta1-dist-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Abbildung&nbsp;12.7: Verteilung von t bei 1000 Simulationen unter der Annahme der <span class="math inline">\(H_0\)</span> und die theoretische Verteilung von t (rot).</figcaption>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-slm-inf-beta1-dist">Abbildung&nbsp;<span>12.7</span></a> können wir sehen, dass die theoretische Verteilung in rot die beobachtete Verteilung sehr gut abschätzt.</p>
<p>In <code>R</code> kann der Wert <span class="math inline">\(\hat{\sigma}^2\)</span> über die Funktion <code>sigma()</code> aus dem gefitteten <code>lm()</code>-Modell extrahiert werden.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sigma</span>(mod)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.2369055</code></pre>
</div>
</div>
<p>Schauen wir uns die Stichprobenverteilung von <span class="math inline">\(\hat{\sigma}^2\)</span> anhand unserer Simulation an. Es ist wieder zu beobachten, das im Mittel der korrekte, im Modell definierte, Wert von <span class="math inline">\(\sigma = 1\)</span> beobachtet wird (siehe <a href="#fig-slm-inf-sigma-dist">Abbildung&nbsp;<span>12.8</span></a>).</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-slm-inf-sigma-dist" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="slm_inference_files/figure-html/fig-slm-inf-sigma-dist-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Abbildung&nbsp;12.8: Verteilung von <span class="math inline">\(\hat{\sigma}\)</span> in der Simulation und der wahre Wert in rot eingezeichnet</figcaption>
</figure>
</div>
</div>
</div>
<p>Aber wie immer, leider steht uns bei einem realen Experiment diese Information nicht zur Verfügung und wir haben nur einen einzelnen Wert, der alles von komplett daneben bis ziemlich perfekt sein kann.</p>
<p>Schauen wir uns noch einmal die Ausgabe zu unserem Weitsprungmodell mittels <code>summary()</code> an. Unter Residual Standard Error sehen wir, dass hier <span class="math inline">\(\hat{\sigma}\)</span> angegeben wird. Dieser Wert wird auch als mittlerer Schätzfehler bezeichnet und kann als Maß verwendet werden, welche Abweichung das Modell im Mittel hat. Die Einheit sind wieder in den Einheiten der abhängigen Variable, so kann auch schon abgeschätzt werden mit welcher Präzision das Modell die Daten fittet.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
Call:
lm(formula = jump_m ~ v_ms, data = jump)

Residuals:
     Min       1Q   Median       3Q      Max 
-0.44314 -0.22564  0.02678  0.19638  0.42148 

Coefficients:
            Estimate Std. Error t value Pr(&gt;|t|)    
(Intercept) -0.13854    0.23261  -0.596    0.555    
v_ms         0.76110    0.02479  30.702   &lt;2e-16 ***
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Residual standard error: 0.2369 on 43 degrees of freedom
Multiple R-squared:  0.9564,    Adjusted R-squared:  0.9554 
F-statistic: 942.6 on 1 and 43 DF,  p-value: &lt; 2.2e-16</code></pre>
</div>
</div>
<p>In unserem Fall beobachten wir <span class="math inline">\(0.24m\)</span>. Diesen Wert muss jetzt unsere Trainerin im Sinne der Weitsprungleistung der deren Varianz interpretieren und ein Abschätzung treffen zu können.</p>
<p>Nach der Herleitung der Teststatistik für <span class="math inline">\(\beta_1\)</span>, können wir jetzt auch weitere Teil der Ausgabe von <code>summary()</code> interpretieren. In der Tabelle stehen entsprechend die Standardfehler für <span class="math inline">\(\hat{\beta}_1\)</span> und <span class="math inline">\(\hat{\beta}_0\)</span>. Für <span class="math inline">\(\beta_0\)</span> wird genau die gleiche Vorgehensweise wie auch bei <span class="math inline">\(\beta_1\)</span> angewendet. Die Nullhypothese <span class="math inline">\(H_0\)</span> ist hier ebenfalls das der Parameter standardmäßig als Null angesetzt wird. Der Standardfehler von <span class="math inline">\(\beta_0\)</span> errechnet sich nach:</p>
<p><span class="math display">\[\begin{equation}
\sigma^2[\beta_0] = \sigma^2\left(\frac{1}{n} + \frac{\bar{x}^2}{\sum_{i=1}^n (x_i - \bar{x})^2}\right)
\label{eq-slm-inf-beta0-se}
\end{equation}\]</span></p>
<p>An Formel <span class="math inline">\(\eqref{eq-slm-inf-beta-0-se}\)</span> ist zu erkennen, dass wenn die <span class="math inline">\(X\)</span>-Werte den Mittelwert <span class="math inline">\(0\)</span> haben, dass <span class="math inline">\(\sigma^2[\beta_0]\)</span> gleich dem Standardfehler für den Mittelwert SEM wird. Was auch wiederum Sinn macht, da in diesem Fall <span class="math inline">\(\beta_0 = \bar{y}\)</span> gilt.</p>
<p>Dies führt dies zu den beiden zu überprüfenden Hypothesen für <span class="math inline">\(\beta_0\)</span>:</p>
<p><span class="math display">\[\begin{align*}
H_0: \beta_0 &amp;= 0 \\
H_1: \beta_0 &amp;\neq 0
\end{align*}\]</span></p>
<p>Dementsprechend überprüft die Hypothesentestung ob der <span class="math inline">\(y\)</span>-Achsenabschnitt gleich Null ist. Hier sollte berücksichtigt werden, dass diese Hypothese in den seltensten Fällen tatsächlich auch von Interesse ist und lediglich besagt, dass entweder der <span class="math inline">\(y\)</span>-Achsenabschnitt durch den Nullpunkt geht, oder dass wenn tatsächlich <span class="math inline">\(\beta_1 = 0\)</span> gilt, der Mittelwert von <span class="math inline">\(y\)</span> gleich Null ist, was ebenfalls in den seltensten Fällen von Interesse ist.</p>
<p>Die Spalten 3 und 4 in <code>summary()</code> unter <code>Coefficients:</code> können jetzt interpretiert werden, da es sich hierbei um die <span class="math inline">\(t\)</span>-Teststatistik handelt und den entsprechenden p-Wert unter der jeweiligen <span class="math inline">\(H_0\)</span>. Die Hypothesen sind ungerichtet.</p>
</section>
<section id="herleitung-der-eigenschaften-von-hatbeta_1" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="herleitung-der-eigenschaften-von-hatbeta_1"><span class="header-section-number">12.2</span> Herleitung der Eigenschaften von <span class="math inline">\(\hat{\beta}_1\)</span></h2>
<p>Um den Schätzer <span class="math inline">\(\hat{\beta}_1\)</span> für <span class="math inline">\(\beta_1\)</span> formal herzuleiten. Beginnen wir zunächst mit der folgenden Formel, wobei wir im folgenden den Schätzer mit <span class="math inline">\(b_1\)</span> bezeichnen.</p>
<p><span id="eq-b1-k1Yi"><span class="math display">\[
b_1 = \sum k_i Y_i
\tag{12.6}\]</span></span></p>
<p>D.h. wir zeigen zunächst, dass <span class="math inline">\(b_1\)</span> durch eine lineare Kombination der <span class="math inline">\(Y_i\)</span>-Werte berechnet werden kann. Die Koeffizienten <span class="math inline">\(k_i\)</span> der Summe sind dabei wie folgt definiert:</p>
<p><span id="eq-defn-ki"><span class="math display">\[
k_i = \frac{X_i - \bar{X}}{\sum(X_i - \bar{X})^2}
\tag{12.7}\]</span></span></p>
<p>Der Grund für diese zunächst etwas uneinsichtige Definition wird im Weiteren klarer werden. Zunächst haben die <span class="math inline">\(k_i\)</span> verschieldene Eigenschaften die wir uns später zunutze machen wollen. Zunächst erst einmal noch ein paar Identitäten die wir später auch noch verwenden.</p>
<p>Die erste Identität bezieht sich auf das Kreuzprodukt der Abweichungen von <span class="math inline">\(X_i\)</span> und <span class="math inline">\(Y_i\)</span> von ihren jeweiligen Mittelwerten.</p>
<p><span class="math display">\[\begin{align*}
\sum(X_i-\bar{X})(Y_i-\bar{Y}) &amp;= \sum(X_i - \bar{X})Y_i  -\underbrace{\sum(X_i - \bar{X})}_{=0}\bar{Y}  \\
&amp;= \sum(X_i - \bar{X})Y_i
\end{align*}\]</span></p>
<p>Wenn wir in der Formel <span class="math inline">\((Y_i-\bar{Y})\)</span> durch <span class="math inline">\((X_i-\bar{X})\)</span> austauschen, folgt noch eine weitere nützliche Identität:</p>
<p><span class="math display">\[
\sum(X_i-\bar{X})^2 = \sum(X_i - \bar{X})X_i
\]</span></p>
<p>Werden die jeweiligen <span class="math inline">\(k_i\)</span> mit den dazugehörigen <span class="math inline">\(X_i\)</span> multipliziert und die Definition der <span class="math inline">\(k_i\)</span> (siehe <a href="#eq-defn-ki">Gleichung&nbsp;<span>12.7</span></a>) beachten, erhalten wir:</p>
<p><span class="math display">\[
\sum k_i X_i = \frac{\sum(X_i - \bar{X})X_i}{\sum(X_i-\bar{X})^2} = \frac{\sum(X_i-\bar{X})^2}{\sum(X_i-\bar{X})^2} = 1
\]</span></p>
<p>D.h. Die Summe der <span class="math inline">\(k_i X_i\)</span> ist gleich <span class="math inline">\(1\)</span>. Aus der Definition <a href="#eq-defn-ki">Gleichung&nbsp;<span>12.7</span></a> folgt weiterhin.</p>
<p><span class="math display">\[
\sum k_i = \sum \left(\frac{X_i-\bar{X}}{\sum(X_i-\bar{X})^2}\right)= \frac{\sum(X_i-\bar{X})}{\sum(X_i-\bar{X})^2} = \frac{0}{\sum(X_i-\bar{X})^2} = 0
\]</span></p>
<p>D.h. die Summe der <span class="math inline">\(k_i\)</span> ist gleich Null.</p>
<p>Wenn wir jetzt wieder die Definition unseres Schätzer für <span class="math inline">\(\beta_1\)</span> verwenden (siehe <span class="quarto-unresolved-ref">?eq-slm-basics-norm1</span>). Dann erhalten unter der Verwendung der Identität der Kreuzprodukte den gewünschten Zusammenhang zwischen <span class="math inline">\(b_1\)</span> und <span class="math inline">\(Y_i\)</span>.</p>
<p><span class="math display">\[\begin{align*}
b_1 &amp;= \frac{\sum(X_i - \bar{X})(Y_i - \bar{Y})}{\sum(X_i - \bar{X})^2} \\
&amp;= \frac{\sum(X_i - \bar{X})Y_i}{\sum(X_i - \bar{X})^2} = \sum k_i Y_i\\
\end{align*}\]</span></p>
<p>Wenden wir jetzt den Erwartungswert auf <span class="math inline">\(Y_i\)</span> an, dann werden die <span class="math inline">\(k_i\)</span> als konstant angesehen und nur die <span class="math inline">\(Y_i\)</span> sind Zufallsvariablen. Da aber <span class="math inline">\(Y_i = \beta_0 + \beta_1 X_i + \epsilon_i\)</span> gilt und in dieser Formel wiederum nur <span class="math inline">\(\epsilon_i\)</span> eine Zufallsvariable mit <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1 X_i\)</span> konstant ist und zudem die <span class="math inline">\(\epsilon \sim \mathcal{N}(0,\sigma^2)\)</span> also <span class="math inline">\(E[\epsilon_i] = 0\)</span> laut der Annahme gilt, folgt:</p>
<p><span class="math display">\[\begin{align*}
    E[b_1] &amp;= E\left[\sum k_i Y_i\right] = \sum k_i E[Y_i] = \sum k_i (\beta_0 + \beta_1 X_i) \\
    &amp;= \beta_0 \sum k_i + \beta_1 \sum k_i X_i = \beta_1
\end{align*}\]</span></p>
<p>D.h. <span class="quarto-unresolved-ref">?eq-slm-basics-norm1</span> ist ein erwartungstreuer Schätzer für <span class="math inline">\(\beta_1\)</span>. Das gleiche gilt auch für den Schätzer <span class="math inline">\(b_0\)</span> für <span class="math inline">\(\beta_0\)</span>.</p>
<p>Leiten wir noch eine weitere Identität über die Summe der <span class="math inline">\(k_i^2\)</span> her:</p>
<p><span class="math display">\[
\sum k_i^2 = \sum \left[\frac{X_i-\bar{X}}{\sum(X_i-\bar{X})^2}\right]^2 = \frac{\sum(X_i-\bar{X})^2}{\left[\sum(X_i-\bar{X})^2\right]^2} = \frac{1}{\sum(X_i-\bar{X})^2}
\]</span> Können wir auch noch die Varianz bzw. den Standardfehler unseres Schätzers für <span class="math inline">\(\beta_1\)</span> herleiten. Es gilt nämlich:</p>
<p><span class="math display">\[\begin{align*}
    \sigma^2[b_1] &amp;= \sigma^2\left[\sum k_i Y_i\right] = \sum k_i^2 \sigma^2[Y_i] \\
    &amp;= \sum k_i^2 \sigma^2 = \sigma^2 \sum k_i^2 \\
    &amp;= \sigma^2 \frac{1}{\sum(X_i-\bar{X})^2}
    \label{eq-slm-inf-beta1-deriv}
\end{align*}\]</span></p>
<p>Wir erhalten die bereits eingeführte Formel. Wiederum eine Einsicht aus der Herleitung der Formel folgt, dass die Varianz <span class="math inline">\(\sigma^2\)</span> als konstant angesehen wird, d.h. <span class="math inline">\(\sigma_i^2 = \sigma^2\)</span>. Dies hat uns erlaubt im zweiten Schritt <span class="math inline">\(\sigma^2\)</span> aus der Summe heraus zu ziehen. Wenn die Varianz <span class="math inline">\(\sigma^2\)</span> nicht konstant ist, dann ist der berechnete Standardfehler für <span class="math inline">\(\hat{\beta}_1 = b_1\)</span> nicht korrekt.</p>
<p>Eine interessante Eigenschaft des Standardfehler von <span class="math inline">\(\hat{\beta}_1\)</span> ist in Formel <span class="math inline">\(\eqref{eq-slm-inf-beta1-deriv}\)</span> zu sehen. Im Nenner stehen die Abweichungen der <span class="math inline">\(X\)</span>-Werte vom Mittelwert <span class="math inline">\(\hat{X}\)</span>. D.h. wenn die <span class="math inline">\(X\)</span>-Werte weiter auseinander sind, dann führt dies dazu, dass der Standardfehler <span class="math inline">\(\sigma^2[b_1]\)</span> kleiner wird. Intuitive macht dies auch Sinn, wenn ich eine Gerade bestimmen will, dann ist es einfacher die Gerade anhand weit auseinander liegenden Stütztwerten zu bestimmen im Vergleich zu wenn ich eng beinander liegende <span class="math inline">\(X\)</span>-Werte verwende.</p>
</section>
<section id="maximum-likelihood-methode-bei-der-einfachen-linearen-regression" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="maximum-likelihood-methode-bei-der-einfachen-linearen-regression"><span class="header-section-number">12.3</span> Maximum-likelihood Methode bei der einfachen linearen Regression(*)</h2>
<p>Ein anderer Herleitung für <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> kann über die sogenannten Maximum-Likelihood-Methode durchgeführt werden. Dabei gehen die Verteilungsannahmen der Variablen direkt in die Herleitung ein.</p>
<p>Im Zuge der theoretischen Verteilungen haben wir die Dichtefunktion kennengelernt. Für eine gegebene Zufallsvariable kann die Dichte für einen gegebenen Wert, z.B. <span class="math inline">\(y_i\)</span>, über die Dichtefunktion berechnet werden. Wenn ein Zufallsvariable <span class="math inline">\(X\)</span> einer Normalverteilung folgt, dann wird die Verteilung von <span class="math inline">\(X\)</span> mittels der bereits kennengelernte Dichtefunktion der Normalverteilung beschrieben.</p>
<p><span class="math display">\[\begin{equation*}
f(X|\mu,\sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left(-\frac{1}{2}\frac{(X - \mu)^2}{\sigma^2}\right)
\end{equation*}\]</span></p>
<p>Hier wird die Dichte von <span class="math inline">\(X\)</span> als eine Funktion von <span class="math inline">\(\mu\)</span> und <span class="math inline">\(\sigma^2\)</span> aufgefasst. D.h. ich gebe die Wert von <span class="math inline">\(\mu\)</span> und <span class="math inline">\(\sigma\)</span> vor, da ich sie brauche um die Dichte auszurechnen.</p>
<p>Jetzt wird ein Perspektivwechsel durchgeführt. Ich kann nämlich auch anders herum die Zufallsvariable <span class="math inline">\(X\)</span> als gegeben ansehen und die Dichte für verschiedene Werte von <span class="math inline">\(\mu\)</span> und <span class="math inline">\(\sigma^2\)</span> abtragen. Der Einfachheit halber gehen wir davon aus, dass <span class="math inline">\(\sigma^2\)</span> gegeben bzw. bekannt sei und wir wollen <span class="math inline">\(\mu\)</span> ermitteln. Eine mögliche Fragestellung ist jetzt, für einen beobachteten Wert <span class="math inline">\(x\)</span>, welcher Wert für <span class="math inline">\(\mu\)</span> ist am plausibelsten? Dazu tragen wir verschiedene Dichtewerte für ein gegebenes <span class="math inline">\(x\)</span> in Abhängigkeit von <span class="math inline">\(\mu\)</span> ab. D.h. wir interpretieren die Funktion als:</p>
<p><span class="math display">\[
f(\mu|x,\sigma^2) = \frac{1}{\sqrt{2 \pi \sigma^2}} \exp\left(-\frac{1}{2}\frac{(X - \mu)^2}{\sigma^2}\right)
\]</span></p>
<p>Diese Funktion wird als die likelihood-Funktion bezeichnet. Das Maximum dieser Funktion kann als derjenige Wert interpretiert werden bei dem derjenige Wert von <span class="math inline">\(\mu\)</span> die maximal mögliche Dichte einnimmt.</p>
<p>Nehmen wir ein konkretes Beispiel. Wir haben einen Wert <span class="math inline">\(x = 3\)</span> beobachtet und wir wissen das <span class="math inline">\(\sigma = 1\)</span> ist. Natürlich ist klar, dass ein einzelner Wert nicht ausreicht um irgendwas zu bestimmen aber wir wollen erst einmal das Prinzip verstehen. Fangen wir mit einer Tabelle an. Wir nehmen die Wert <span class="math inline">\(mu_i = [0,1,2,3,4,5,6]\)</span> Und berechenen für jeder dieser Werte die Dichte <span class="math inline">\(f(\mu|x=3,\sigma^2=1)\)</span> aus (siehe <a href="#tbl-slm-inf-ml-01">Tabelle&nbsp;<span>12.2</span></a>).</p>
<div class="cell">
<div class="cell-output-display">
<div id="tbl-slm-inf-ml-01" class="anchored">
<table class="table table-sm table-striped small">
<caption>Tabelle&nbsp;12.2: Dichte für verschiedene Werte für <span class="math inline">\(\mu\)</span> für <span class="math inline">\(x = 3\)</span></caption>
<thead>
<tr class="header">
<th style="text-align: right;"><span class="math inline">\(\mu\)</span></th>
<th style="text-align: right;">Dichte</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0</td>
<td style="text-align: right;">0.004</td>
</tr>
<tr class="even">
<td style="text-align: right;">1</td>
<td style="text-align: right;">0.054</td>
</tr>
<tr class="odd">
<td style="text-align: right;">2</td>
<td style="text-align: right;">0.242</td>
</tr>
<tr class="even">
<td style="text-align: right;">3</td>
<td style="text-align: right;">0.399</td>
</tr>
<tr class="odd">
<td style="text-align: right;">4</td>
<td style="text-align: right;">0.242</td>
</tr>
<tr class="even">
<td style="text-align: right;">5</td>
<td style="text-align: right;">0.054</td>
</tr>
<tr class="odd">
<td style="text-align: right;">6</td>
<td style="text-align: right;">0.004</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<p>Wenn wir uns die Werte in <a href="#tbl-slm-inf-ml-01">Tabelle&nbsp;<span>12.2</span></a> anschauen, da sehen wir, dass der Wert bei <span class="math inline">\(\mu = 3\)</span> die größte Dichte hat. Nun die Tabelle ist etwas grob, stellen wir das Ganze als kontinuierlichen Graphen dar.</p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-slm-inf-ml-01" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="slm_inference_files/figure-html/fig-slm-inf-ml-01-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Abbildung&nbsp;12.9: Likelihood-Funktion für <span class="math inline">\(x = 3\)</span></figcaption>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-slm-inf-ml-01">Abbildung&nbsp;<span>12.9</span></a> sehen wir, das das Maximum der Likelihood-Funktion beim Wert <span class="math inline">\(\mu = 3\)</span> auftritt. D.h. die Normalverteilung mit <span class="math inline">\(\mathcal{N}(\mu=3, \sigma=1)\)</span> scheint diejenige zu sein, die die höchste Dichte produziert und daher auch diejenige die den höchsten likelihood hat als Verteilung unseren beobachteten Wert produziert zu haben. Macht bei einigen draufstarren auch Sinn, wenn unserer Wert aus einer Normalverteilung kommt und wir nur einen einzigen Wert haben, dann macht diejenige Normalverteilung am meisten Sinn die ihren Mittelwert <span class="math inline">\(\mu\)</span> an der Stelle des beobachteten Werts hat. Das Beispiel ist natürlich ein bisschen künstlich.</p>
<p>Schauen wir uns zwei Werte an <span class="math inline">\(x_1 = 1, x_2 = 2\)</span>. Wir gehen wieder davon aus, das die beiden Wert unabhängig voneinander sind. Dadurch können wir die Dichten für die beiden Wert einfach miteinander multiplizieren. Unsere likelihood-Funktion <span class="math inline">\(L\)</span> nimmt dann die Form.</p>
<p><span class="math display">\[\begin{equation*}
L = f(\mu|x_1,\sigma) \cdot f(\mu|x_2,\sigma)
\end{equation*}\]</span></p>
<p>Erstellen wir wieder einen Graphen von <span class="math inline">\(L\)</span> für verschiedene <span class="math inline">\(\mu\)</span> bei gegebenem <span class="math inline">\(\sigma = 1\)</span></p>
<div class="cell">
<div class="cell-output-display">
<div id="fig-slm-inf-ml-02" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="slm_inference_files/figure-html/fig-slm-inf-ml-02-1.png" class="img-fluid figure-img" width="672"></p>
<figcaption class="figure-caption">Abbildung&nbsp;12.10: Likelihood-Funktion <span class="math inline">\(L\)</span> für <span class="math inline">\(x_1 = 1\)</span> und <span class="math inline">\(x_2 = 2\)</span>.</figcaption>
</figure>
</div>
</div>
</div>
<p>In <a href="#fig-slm-inf-ml-02">Abbildung&nbsp;<span>12.10</span></a> ist jetzt das Maximum von <span class="math inline">\(L\)</span> an der Stelle <span class="math inline">\(\mu = 1.5\)</span> was aus nicht ganz zufälligen Gründen der Mittelwert <span class="math inline">\(\bar{x} = \frac{1}{2}\sum_{i=1}^2 x_i\)</span> der beiden Werte ist. Intuitiv kann das mit motiviertem Starren auch hergeleitet werden. Wenn beiden Werten die gleiche Bedeutung zugemessen wird, dann ist die Verteilung die genau in der Mitte zwischen den beiden Werten liegt, dijenige die am kompatibelsten mit der Erzeugung der beiden Werte ist.</p>
<p>Die Likelihood-Funktion <span class="math inline">\(L\)</span> ist also eine Funktion, die die Wahrscheinlichkeit beschreibt, mit der eine gegebene Stichprobe, in Abhängikeit von den Parametern aus einer bestimmten Verteilung stammt. Die Likelihood-Funktion <span class="math inline">\(L\)</span> gibt an, wie gut die beobachteten Daten zu einem bestimmten Satz von Parametern, im Beispiel ein Parameter <span class="math inline">\(\mu\)</span>, passen. Per Konvention werden die Parameter oft mit dem Symbol <span class="math inline">\(\theta\)</span> bezeichnet. Im Beispiel damit wiederum <span class="math inline">\(\theta = \mu\)</span>.</p>
<p>Formal wird die Likelihood-Funktion <span class="math inline">\(L\)</span> als die gemeinsame Wahrscheinlichkeitsdichte der Stichprobe beschrieben, betrachtet als Funktion der Parameter <span class="math inline">\(\theta\)</span>. Dabei werden die beobachteten Werte als festgelegt und die Parameter als Variablen betrachtet. <span class="math inline">\(L\)</span> wird eine Funktion der Parameter <span class="math inline">\(L(\theta)\)</span> interpretiert. Die Daten werden als gegeben angesehen. Die Likelihood-Funktion <span class="math inline">\(L\)</span> ist aber keine Dichtefunktion und beschreibt somit keine Wahrscheinlichkeiten. Dementsprechend ist gilt für das Integral der Likelihood-Funktion <span class="math inline">\(\int L(\mu|X,\sigma^2) d\mu \neq 1\)</span>. Bzw. das Integral <span class="math inline">\(=1\)</span> dann nur per <em>Zufall</em>.</p>
<p>In unserem Regressionsfall nimmt die Likelihood-Funktion <span class="math inline">\(L\)</span> für einen einzelnen Wert die folgende Form an:</p>
<p><span class="math display">\[\begin{equation}
L(\beta_0, \beta_1, \sigma^2|y_i) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_i - \beta_0 - \beta_1 x_i)^2}{2\sigma^2}\right)
\label{eq-slm-inf-lik-01}
\end{equation}\]</span></p>
<p>D.h. die Parameter <span class="math inline">\(\theta\)</span> von <span class="math inline">\(L\)</span> sind <span class="math inline">\(\beta_0, \beta_1\)</span> und <span class="math inline">\(\sigma\)</span>. Bei unserer Regressionsanalyse haben wir jedoch nicht nur ein einzelnes beobachtetes Wertepaar <span class="math inline">\((y_i, x_i)\)</span> sondern <span class="math inline">\(N\)</span> beobachtete Wertepaare. Laut dem Gauss-Markov-Modell sind die Werte unabhängig voneinander, können die jeweiligen likelihoods wieder miteinander multipliziert werden. Die resultierende Likelihood-Funktion <span class="math inline">\(L\)</span> nimmt dann die folgenden etwas involviertere Form an:</p>
<p><span class="math display">\[\begin{align*}
L(\beta_0, \beta_1, \sigma^2) &amp;= \prod_{i=1}^{N} f(y_i | x_i; \beta_0, \beta_1, \sigma^2) \\
&amp;= \prod_{i=1}^{N} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y_i - \beta_0 - \beta_1 x_i)^2}{2\sigma^2}\right) \\
\end{align*}\]</span></p>
<p>Wobei wir jetzt nicht anderes gemacht haben als Formel <span class="math inline">\(\eqref{eq-slm-inf-lik-01}\)</span> eingesetzt haben. Wenn wir uns aber der Rechenregeln für Exponenten aus der Schule erinnern <span class="math inline">\(e^a e^b = e^{a+b}\)</span> dann können wir die Formel etwas vereinfachen.</p>
<p><span class="math display">\[\begin{align*}
L(\beta_0, \beta_1, \sigma^2|y_i) &amp;= \left(\frac{1}{\sqrt{2\pi \sigma^2}}\right)^N \exp\left(\sum_{i=1}^N \frac{(y_i - \beta_0 - \beta_1 x_i)^2}{2 \sigma^2}\right) \\
&amp;= \left(\frac{1}{2\pi \sigma^2}\right)^{N/2} \exp\left(\sum_{i=1}^N \frac{(y_i - \beta_0 - \beta_1 x_i)^2}{2 \sigma^2}\right) \\
\end{align*}\]</span></p>
<p>Die Idee ist jetzt wieder die Gleiche wie in den Beispieln oben. Wir versuchen das Maximum von <span class="math inline">\(L\)</span> zu finden, da die Werte <span class="math inline">\(\beta_0, \beta_1\)</span> und <span class="math inline">\(\sigma^2\)</span> dann so gewählt sind, dass sie die höchste likelihood haben. Jetzt schauen wir uns aber nicht einen Graphen an, sondern benutzten den gleichen Ansatz wie der Methode der kleinsten Quadrate; ableiten und <span class="math inline">\(=0\)</span> setzen. Der Ansatz erfolgt wieder mechanisch, indem wie bei der Herleitung der Normalengleichungen, die partiellen Ableitungen berechnet werden, diese gleich Null gesetzt werden und das resultierende Gleichungssystem gelöst wird. Zu beachten hierbei ist, wir haben in jedem Produktterm die gleichen Parameter <span class="math inline">\(\beta_0, \beta-1\)</span> und <span class="math inline">\(\sigma^2\)</span> und die jeweiligen beobachteten <span class="math inline">\((y_i, x_i)\)</span> Tuple werden als gegeben angesehen.</p>
<p>Um die Berechnungn zu vereinfachen, bietet sich bei der Likelihood-Funktion <span class="math inline">\(L\)</span> ein Trick an. Es wird nicht <span class="math inline">\(L\)</span> direkt abgeleitet, sondern der Logarithmus der Likelihood-Funktion. D.h. die Funktion wird transformiert. Bei der Logarithmus-Funktion handelt es sich um eine bijektive Funktion. Eine bijektive Funktion ist eine Funktion die jedem Element in der Ursprungsmenge genau ein Element in der Zielmenge zuordnet und ebenfalls umgekehrt. Dadurch kommt es zu keinen Kollisionen oder Auslassungen. Einfach gesagt, wenn die Funktion <span class="math inline">\(y = f(x) = log(x)\)</span> ist, dann wird jedem <span class="math inline">\(x\)</span> genau ein <span class="math inline">\(y\)</span> zugeordnet. Bzw. anders herum, wenn ich <span class="math inline">\(y\)</span> kenne, dann kenne ich auch den Wert von <span class="math inline">\(x\)</span> mit <span class="math inline">\(f(x) = y\)</span> bzw. <span class="math inline">\(x = f^{-1}(y) = \exp(y)\)</span>. Dadurch, das die Logarithmus-Funktion bijektiv ist, führt dies dazu, dass das Maximum der ursprünglichen Funktion <span class="math inline">\(L(\beta_0, \beta_1, \sigma^2)\)</span> an der gleichen Stelle auftritt wie bei der transformierten Funktion <span class="math inline">\(\ln L(\beta_0, \beta_1, \sigma^2)\)</span>.</p>
<p>Wenn jetzt die Eigenschaften der Logarithmusfunktion, speziell des natürlichen Logarithmus, beachtet werden, dann wird auch klar, warum es Sinn machen könnte die Likelihood-Funktion mit dem Logarithmus zu transformieren, da aus den Produkten Summen werden mit denen einfacher umgegangen werden kann:</p>
<p><span class="math display">\[\begin{align*}
\log(xy) &amp;= \log(x) + \log(y) \\
\log\left(\frac{x}{y}\right) &amp;= \log(x) - \log(y) \\
\log(x^n) &amp;= n\log(x) \\
\log(\exp(x)) &amp;= x \\
\log(1) &amp;= 0
\end{align*}\]</span></p>
<p>Der Logarithmus angewendet auf <span class="math inline">\(L(\beta_0, \beta_1, \sigma^2)\)</span> resultiert dann in der folgenden Funktion:</p>
<p><span class="math display">\[\begin{align*}
\ell(\beta_0, \beta_1, \sigma^2) &amp;= \ln L(\beta_0, \beta_1, \sigma^2) \\
&amp;= \ln \left[\left(\frac{1}{2\pi \sigma^2}\right)^{N/2} \exp\left(-\sum_{i=1}^N \frac{(y_i - \beta_0 - \beta_1 x_i)^2}{2 \sigma^2}\right)\right] \\
&amp;= \ln \left[\left(\frac{1}{2\pi \sigma^2}\right)^{N/2} \right] + \ln \left[\exp\left(-\sum_{i=1}^N \frac{(y_i - \beta_0 - \beta_1 x_i)^2}{2 \sigma^2}\right)\right] \\
&amp;= \frac{N}{2} \ln \left[\left(\frac{1}{2\pi \sigma^2}\right) \right] -\sum_{i=1}^N \frac{(y_i - \beta_0 - \beta_1 x_i)^2}{2 \sigma^2} \\
&amp;= -\frac{n}{2}\ln(2\pi) - \frac{n}{2}\ln(\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^{N}(y_i - \beta_0 - \beta_1 x_i)^2
\end{align*}\]</span></p>
<p>Wird die Funktion <span class="math inline">\(\ell(\beta_0, \beta_1, \sigma^2)\)</span> wieder partiell nach <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> abgeleitet und gleich Null gesetzt erhalten wir das gleiche Gleichungssystem wie bei den vorhergehenden Herleitungen über die Abweichungen von der Regressionsgeraden sprich den Normalengleichungen. z.B.</p>
<p><span class="math display">\[\begin{align*}
\frac{\partial \ell(\beta_0, \beta_1, \sigma^2)}{\partial \beta_0} &amp;= \frac{\partial}{\partial \beta_0} \left[-\frac{n}{2}\ln(2\pi) - \frac{n}{2}\ln(\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^{N}(y_i - \beta_0 - \beta_1 x_i)^2\right] \\
&amp;= \frac{2}{2\sigma^2}\sum_{i=1}^N (y_i - \beta_0 - \beta_1 x_i)
\end{align*}\]</span> Wenn dieser Ausdruck gleich Null gesetzt erhalten wir den gleichen Ausdruck wie formals unter den Normalengleichungen für <span class="math inline">\(\beta_0\)</span>.</p>
<p><span class="math display">\[\begin{alignat}{2}
&amp;&amp; \frac{2}{2\sigma^2}\sum_{i=1}^N (y_i - \beta_0 - \beta_1 x_i) = 0 \nonumber \\
\Leftrightarrow\mkern40mu &amp;&amp; \sum (y_i - \beta_0- \beta_1 x_i) = 0 \nonumber \\
\Leftrightarrow\mkern40mu &amp;&amp; \sum y_i - \sum \beta_0- \sum \beta_1 x_i = 0 \nonumber \\
\Leftrightarrow\mkern40mu &amp;&amp; n \bar{y} - n \beta_0- \beta_1 n \bar{x} = 0 \nonumber \\
\Leftrightarrow\mkern40mu &amp;&amp; \bar{y} - \beta_0- \beta_1 \bar{x} = 0 \nonumber \\
\Leftrightarrow\mkern40mu &amp;&amp; \bar{y} - \beta_1 \bar{x} = \beta_0\nonumber \\
\Leftrightarrow\mkern40mu &amp;&amp; \beta_0= \bar{y} - \beta_1 \bar{x}
\end{alignat}\]</span></p>
<p>Die Herleitung für <span class="math inline">\(\beta_1\)</span> ist ebenfalls gleich derjenigen die aus den Normalengleichungen entsteht. Nochmal zum Unterschied, bei den Normalengleichungen sind keine Annahmen über die Verteilung der Werte eingeflossen. Einzig, wir haben eine Methode gesucht, die die quadrierten Residuen minimiert. Dagegen beruht die Herleitung der Gleichungen aus der Maximum-Likelihood Methode direkt auf eine spezifischen Verteilungsannahme. Im Fall der lineare Regression führen beide Methoden zum gleichen Ergebnis. Die Maximum-Likelihood-Methode kann jedoch auch in Fällen angewendet werden bei denen die Methode der quadrierten Abweichungen nicht funktioniert. Wichtig für unsere Anwendung ist das zugrundeliegende Prinzip bzw. den Unterschied zu verstehen.</p>
</section>
<section id="konfidenzintervalle-für-die-koeffizienten" class="level2" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="konfidenzintervalle-für-die-koeffizienten"><span class="header-section-number">12.4</span> Konfidenzintervalle für die Koeffizienten</h2>
<p>Wie wir im oberen Abschnitt gesehen haben, sind unsere Schätzer für die Koeffizienten <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> mit Unsicherheiten behaftet die sich in Form der Standardfehler ausdrücken. Wir können nun, diese standardfehler wiederum verwenden um Konfidenzintervalle für die Koeffizienten zu bestimmen.</p>
<p><span class="math display">\[\begin{equation}
\hat{\beta_j} \pm q_{t_{\alpha/2,df=N-2}} \times \hat{\sigma}_{\beta_j}
\label{eq-slm-inf-conf-0}
\end{equation}\]</span></p>
<p>Wie in Formel<span class="math inline">\(\eqref{eq-slm-inf-conf-0}\)</span> zu sehen berechnet sich das Konfidenzintervall nach dem üblichen Muster: Schätzer <span class="math inline">\(\pm\)</span> Quantile <span class="math inline">\(\times\)</span> Standardfehler. Im vorliegenden Falle wird die Quantile aus der <span class="math inline">\(t\)</span>-Verteilung mit <span class="math inline">\(N-2\)</span> Freiheitsgarden bestimmt. Wie vorher bereits betont, das Konfidenzintervall erlaubt keine Aussage über die Wahrscheinlichkeit mit der der wahre Koeffizient in dem Intervall liegt, sondern gibt an welche <span class="math inline">\(H_0\)</span>-Hypothesen mit den Daten kompatibel sind. Daher soll in der Ergebnisdokumentation das Konfidenzintervall angegeben und spätenstens in der Diskussion die obere und die untere Schranke diskutiert werden.</p>
<p>In <code>R</code> kann das Konfidenzintervall mit der Funktion <code>confint()</code> berechnet und ausgegeben werden.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(mod)</span></code><button title="In die Zwischenablage kopieren" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                 2.5 %    97.5 %
(Intercept) -0.6076488 0.3305767
v_ms         0.7111082 0.8110957</code></pre>
</div>
</div>
<p>Wie die Koeffizienten haben die Konfidenzintervall die gleiche Einheit wie die abhängige Variable und können daher direkt interpretiert werden. Im vorliegenden Fall sollte daher besprochen werden welche Bedeutung ein Koeffizient von <span class="math inline">\(\beta_1 = 0.7\)</span> bzw. von <span class="math inline">\(\beta_1 = 0.8\)</span> für die Interpretation des Modell hat.</p>
<p>Noch einmal zu erwähnen ist, dass die beiden Parameter <span class="math inline">\(\hat{\beta}_0\)</span> und <span class="math inline">\(\hat{\beta}_1\)</span> welche die Regressionsgerade beschreiben, Schätzer für die Parameter aus einer Population sind der die beiden Parameter <span class="math inline">\(\beta_0\)</span> und <span class="math inline">\(\beta_1\)</span> den zugrundeliegenden Zusammenhang zwischen den beiden Variablen beschreiben. Diese betrachtung ist parallel zu derjenigen, wenn wir z.B. anhand des Mittelwerts <span class="math inline">\(\bar{x}\)</span> den währenen Populationsmittelwert <span class="math inline">\(\mu\)</span> versuchen zu schätzen. D.h. wir haben eine Populationsregressionsgerade, die wir mit Hilfe der Daten versuchen zu schätzen. Die wahre Regressionsgerade werden wird aber niemals mit 100%-iger Sicherheit bestimmen, eben genausowenig wie wir den Populationsmittelwert <span class="math inline">\(\mu\)</span> nicht mittels <span class="math inline">\(\bar{x}\)</span> bestimmen können.</p>
</section>
<section id="weiteres-material" class="level2" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="weiteres-material"><span class="header-section-number">12.5</span> Weiteres Material</h2>
<p>Eine schnelle Zusammenfassung findet ihr in <span class="citation" data-cites="pos_simple_regression">Altman und Krzywinski (<a href="references.html#ref-pos_simple_regression" role="doc-biblioref">2015</a>)</span>, während <span class="citation" data-cites="kutner2005">Kutner u.&nbsp;a. (<a href="references.html#ref-kutner2005" role="doc-biblioref">2005</a>)</span> das die Lineare Regression detailliert herleiten. Für die eben besprochenen Themen ist vor allem Abschnitt (S.40-48) von Interesse.</p>


<div id="refs" class="references csl-bib-body hanging-indent" role="list" style="display: none">
<div id="ref-pos_simple_regression" class="csl-entry" role="listitem">
Altman, Naomi, und Martin Krzywinski. 2015. <span>„Points of Significance: Simple linear regression.“</span> <em>Nature methods</em> 12 (11).
</div>
<div id="ref-kutner2005" class="csl-entry" role="listitem">
Kutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. <em>Applied Linear Statistical Models</em>. 5. Aufl. McGraw-Hill Irwin New York.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Kopiert");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Kopiert");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./slm_basics.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Einführung</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./slm_model_fit.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Modellfit</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>