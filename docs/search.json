[
  {
    "objectID": "slm_inference.html#teststatistik-informell-herleiten",
    "href": "slm_inference.html#teststatistik-informell-herleiten",
    "title": "6  Inferenz",
    "section": "6.1 Teststatistik informell herleiten",
    "text": "6.1 Teststatistik informell herleiten\n\n\n\n\n\nAcht Zufallsziehung unter der \\(H_0\\)"
  },
  {
    "objectID": "slm_inference.html#stichprobenverteilung-von-beta_1-unter-der-annahme-beta_1-0",
    "href": "slm_inference.html#stichprobenverteilung-von-beta_1-unter-der-annahme-beta_1-0",
    "title": "6  Inferenz",
    "section": "6.1 Stichprobenverteilung von \\(\\beta_1\\) unter der Annahme \\(\\beta_1 = 0\\)",
    "text": "6.1 Stichprobenverteilung von \\(\\beta_1\\) unter der Annahme \\(\\beta_1 = 0\\)\n\n\n\n\n\nVerteilung der \\(\\beta_1\\)s - 1000 Simulationen unter der Annahme der \\(H_0\\).\n\n\n\n\nEine kurze Überlegung zeigt, dass wenn zwischen der Prädiktorvariablen und \\(y\\) kein Zusammenhang besteht, dann sollte der Steigungskoeffizient \\(\\beta_1\\) gleich Null sein bzw. auf Grund von Stichprobenvariabilität in der Nähe von Null sein. Daher ist eine plausible Hypothese die sich statistisch Überprüfung lässt:\n\\[\nH_0: \\beta_1 = 0\n\\]"
  },
  {
    "objectID": "slm_inference.html#inferenz",
    "href": "slm_inference.html#inferenz",
    "title": "6  Inferenz",
    "section": "6.1 Inferenz",
    "text": "6.1 Inferenz\n\n6.1.1 Modellannahmen\n\\[\\begin{align*}\ny_i &= \\beta_0 + \\beta_1 x_i + \\epsilon_i \\quad i=1,\\ldots,N \\\\\n\\epsilon_i &\\sim N(0,\\sigma^2) \\quad \\textrm{identisch, unabhängig verteilt}\n\\end{align*}\\]"
  },
  {
    "objectID": "slm_inference.html#modellannahmen---verteilung-der-werte-für-gegebene-x-werte",
    "href": "slm_inference.html#modellannahmen---verteilung-der-werte-für-gegebene-x-werte",
    "title": "6  Inferenz",
    "section": "6.2 Modellannahmen - Verteilung der Werte für gegebene x-Werte",
    "text": "6.2 Modellannahmen - Verteilung der Werte für gegebene x-Werte"
  },
  {
    "objectID": "slm_inference.html#statistische-hypothesen",
    "href": "slm_inference.html#statistische-hypothesen",
    "title": "6  Inferenz",
    "section": "6.3 Statistische Hypothesen",
    "text": "6.3 Statistische Hypothesen\n\n6.3.1 Ungerichtet\n\\[\\begin{gather*}\nH_0: \\beta_1 = 0  \\\\\nH_1: \\beta_1 \\neq 0\n\\end{gather*}\\]\n\n\n6.3.2 Gerichtet\n\\[\\begin{gather*}\nH_0: \\beta_1 \\leq 0  \\\\\nH_1: \\beta_1 > 0\n\\end{gather*}\\]\n\n\n6.3.3 in R\n\nsigma(mod)\n\n[1] 0.2369055"
  },
  {
    "objectID": "slm_inference.html#verteilung-der-statistik-unter-der-h_0",
    "href": "slm_inference.html#verteilung-der-statistik-unter-der-h_0",
    "title": "6  Inferenz",
    "section": "6.4 Verteilung der Statistik unter der \\(H_0\\)",
    "text": "6.4 Verteilung der Statistik unter der \\(H_0\\)\nUnter den Annahmen des Regressionsmodells und der \\(H_0\\) gilt:\n\\[\n\\frac{\\beta_1}{\\sigma_{\\beta_1}} \\sim t_{N-2}\n\\]\nMittels \\(\\alpha\\) lässt sich daher wieder ein kritischer Wert bestimmen ab dem die \\(H_0\\) verworfen wird."
  },
  {
    "objectID": "slm_inference.html#verteilung-der-statistik-unter-der-h_0-1",
    "href": "slm_inference.html#verteilung-der-statistik-unter-der-h_0-1",
    "title": "6  Inferenz",
    "section": "6.6 Verteilung der Statistik unter der \\(H_0\\)",
    "text": "6.6 Verteilung der Statistik unter der \\(H_0\\)\nUnter den Annahmen des Regressionsmodells und der \\(H_0\\) gilt:\n\\[\n\\frac{\\beta_1}{\\sigma_{\\beta_1}} \\sim t_{N-2}\n\\]\nMittels \\(\\alpha\\) lässt sich daher wieder ein kritischer Wert bestimmen ab dem die \\(H_0\\) verworfen wird."
  },
  {
    "objectID": "slm_inference.html#teststatistik",
    "href": "slm_inference.html#teststatistik",
    "title": "6  Inferenz",
    "section": "6.6 Teststatistik",
    "text": "6.6 Teststatistik\n\n\n\n\n\nVerteilung von \\(\\frac{\\beta_1}{s_{\\beta_1}}\\),Dichtefunktion der t-Verteilung (rot) mit \\(df = n - 2\\)"
  },
  {
    "objectID": "slm_inference.html#verteilung-der-hatsigma-sqrtsum_i1n-e_i2n-k",
    "href": "slm_inference.html#verteilung-der-hatsigma-sqrtsum_i1n-e_i2n-k",
    "title": "6  Inferenz",
    "section": "6.5 Verteilung der \\(\\hat{\\sigma} = \\sqrt{\\sum_{i=1}^N e_i^2/(N-K)}\\)",
    "text": "6.5 Verteilung der \\(\\hat{\\sigma} = \\sqrt{\\sum_{i=1}^N e_i^2/(N-K)}\\)\n\n\n\n\n\nVerteilung von \\(\\hat{\\sigma}\\)"
  },
  {
    "objectID": "slm_inference.html#nochmal-summary",
    "href": "slm_inference.html#nochmal-summary",
    "title": "6  Inferenz",
    "section": "6.6 Nochmal summary()",
    "text": "6.6 Nochmal summary()\n\nsummary(mod)\n\n\nCall:\nlm(formula = jump_m ~ v_ms, data = jump)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.44314 -0.22564  0.02678  0.19638  0.42148 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.13854    0.23261  -0.596    0.555    \nv_ms         0.76110    0.02479  30.702   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2369 on 43 degrees of freedom\nMultiple R-squared:  0.9564,    Adjusted R-squared:  0.9554 \nF-statistic: 942.6 on 1 and 43 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "slm_inference.html#konfidenzintervalle-für-die-koeffizienten",
    "href": "slm_inference.html#konfidenzintervalle-für-die-koeffizienten",
    "title": "6  Inferenz",
    "section": "6.7 Konfidenzintervalle für die Koeffizienten",
    "text": "6.7 Konfidenzintervalle für die Koeffizienten\n\n6.7.1 Formel\n\\[\n\\hat{\\beta_j} \\pm q_{t_{\\alpha/2,df=N-2}} \\times \\hat{\\sigma}_{\\beta_j}\n\\]\n\n\n6.7.2 In R\n\nconfint(mod)\n\n                 2.5 %    97.5 %\n(Intercept) -0.6076488 0.3305767\nv_ms         0.7111082 0.8110957"
  },
  {
    "objectID": "slm_inference.html#zum-nacharbeiten",
    "href": "slm_inference.html#zum-nacharbeiten",
    "title": "6  Inferenz",
    "section": "6.8 Zum Nacharbeiten",
    "text": "6.8 Zum Nacharbeiten\nAltman und Krzywinski (2015) und Kutner u. a. (2005, p.40–48)\n\n\n\n\nAltman, Naomi, und Martin Krzywinski. 2015. „Points of Significance: Simple linear regression.“ Nature methods 12 (11).\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "slm_model_fit.html#residuen",
    "href": "slm_model_fit.html#residuen",
    "title": "7  Modellfit",
    "section": "7.1 Residuen",
    "text": "7.1 Residuen"
  },
  {
    "objectID": "slm_model_fit.html#was-sind-noch-mal-residuen-epsilon_i-bzw.-deren-schätzer-hatepsilon_i-e_i",
    "href": "slm_model_fit.html#was-sind-noch-mal-residuen-epsilon_i-bzw.-deren-schätzer-hatepsilon_i-e_i",
    "title": "7  Modellfit",
    "section": "7.2 Was sind noch mal Residuen \\(\\epsilon_i\\) bzw. deren Schätzer \\(\\hat{\\epsilon}_i = e_i\\)",
    "text": "7.2 Was sind noch mal Residuen \\(\\epsilon_i\\) bzw. deren Schätzer \\(\\hat{\\epsilon}_i = e_i\\)\n\\[\ny_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i\n\\]\n\n\n\n\n\nSpielzeugbeispiel mit Residuen \\(\\hat{\\epsilon}_i = e_i = y_i - \\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#annahme-epsilon_i-sim-mathcaln0-sigma2",
    "href": "slm_model_fit.html#annahme-epsilon_i-sim-mathcaln0-sigma2",
    "title": "7  Modellfit",
    "section": "7.3 Annahme: \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)",
    "text": "7.3 Annahme: \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)\n\n\n\n\n\nVerteilung der Werte für verschiedene x-Werte (rote Punkte) und die resultierende Regressionsgerade mit den Vorhersagewerte \\(\\hat{y}_i\\) (schwarze Punkte)"
  },
  {
    "objectID": "slm_model_fit.html#übersicht-residuen",
    "href": "slm_model_fit.html#übersicht-residuen",
    "title": "7  Modellfit",
    "section": "7.4 Übersicht Residuen",
    "text": "7.4 Übersicht Residuen\n\nÜbersicht über verschiedene Arten von Residuen1\n\n\n\n\n\n\n\nTyp\nBerechnung\nZiel\n\n\n\n\nEinfache Residuen\n\\(e_i = y_i - \\hat{y}_i\\)\nVerteilungsannahme\n\n\nStandardisierte Residuen\n\\(e_{Si} = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_i}}\\)\nVerteilungsannahme\n\n\nStudentized Residuen\n\\(e_{Ti} = \\frac{e_i}{\\hat{\\sigma}_{(-i)}\\sqrt{1-h_i}}\\)\nEinfluss auf Modell"
  },
  {
    "objectID": "slm_model_fit.html#residuen-in-r-berechnen-mit-residuals-und-freunden",
    "href": "slm_model_fit.html#residuen-in-r-berechnen-mit-residuals-und-freunden",
    "title": "7  Modellfit",
    "section": "7.5 Residuen in R berechnen mit residuals() und Freunden",
    "text": "7.5 Residuen in R berechnen mit residuals() und Freunden\n\nresiduals(mod)[1:5] # einfache Residuen\n\n         1          2          3          4          5 \n -9.300928  -9.368288 -11.217658  -5.572108  -6.363565 \n\nrstandard(mod)[1:5] # standardisierte Residuen\n\n         1          2          3          4          5 \n-1.4592936 -1.4598906 -1.7440573 -0.8724351 -0.9916310 \n\nrstudent(mod)[1:5] # studentized Residuen\n\n         1          2          3          4          5 \n-1.4814779 -1.4821191 -1.7928881 -0.8697060 -0.9914135"
  },
  {
    "objectID": "slm_model_fit.html#residuen-in-r-inspizieren",
    "href": "slm_model_fit.html#residuen-in-r-inspizieren",
    "title": "7  Modellfit",
    "section": "7.6 Residuen in R inspizieren",
    "text": "7.6 Residuen in R inspizieren\n\ny_hat <- predict(mod)\nplot(y_hat, residuals(mod))\nplot(y_hat, rstandard(mod))\nplot(y_hat, rstudent(mod))"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---einfache-residuen-hatepsilon_i-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---einfache-residuen-hatepsilon_i-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.7 Diagnoseplot - Einfache Residuen \\(\\hat{\\epsilon_i} \\sim \\hat{y_i}\\)",
    "text": "7.7 Diagnoseplot - Einfache Residuen \\(\\hat{\\epsilon_i} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der Residuen \\(\\hat{\\epsilon_i}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---standardisierte-residuen-hatepsilon_si-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---standardisierte-residuen-hatepsilon_si-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.8 Diagnoseplot - Standardisierte Residuen \\(\\hat{\\epsilon}_{Si} \\sim \\hat{y_i}\\)",
    "text": "7.8 Diagnoseplot - Standardisierte Residuen \\(\\hat{\\epsilon}_{Si} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der standardisierten Residuen \\(\\hat{\\epsilon}_{Si}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---studentized-residuen-hatepsilon_ti-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---studentized-residuen-hatepsilon_ti-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.9 Diagnoseplot - Studentized Residuen \\(\\hat{\\epsilon}_{Ti} \\sim \\hat{y_i}\\)",
    "text": "7.9 Diagnoseplot - Studentized Residuen \\(\\hat{\\epsilon}_{Ti} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der studentized Residuals \\(\\hat{\\epsilon}_{Ti}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus",
    "href": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus",
    "title": "7  Modellfit",
    "section": "7.10 Diagnoseplot - Wie sehen Probleme aus?",
    "text": "7.10 Diagnoseplot - Wie sehen Probleme aus?\n\n\n\n\n\nBeispielstreudiagramm"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus-1",
    "href": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus-1",
    "title": "7  Modellfit",
    "section": "7.11 Diagnoseplot - Wie sehen Probleme aus?",
    "text": "7.11 Diagnoseplot - Wie sehen Probleme aus?\n\n\n\n\n\nBeispielstreudiagramm"
  },
  {
    "objectID": "slm_model_fit.html#wie-kann-die-verteilung-der-residuen-überprüft-werden",
    "href": "slm_model_fit.html#wie-kann-die-verteilung-der-residuen-überprüft-werden",
    "title": "7  Modellfit",
    "section": "7.12 Wie kann die Verteilung der Residuen überprüft werden?",
    "text": "7.12 Wie kann die Verteilung der Residuen überprüft werden?\n\n\n\nSpielzeugbeispieldaten mit \\(n=5\\)\n\n\ny\n\n\n\n\n-2.0\n\n\n5.0\n\n\n-1.2\n\n\n0.1\n\n\n7.0\n\n\n\n\n\n\n\n\n\n\nDichtefunktion der Standardnormalverteilung"
  },
  {
    "objectID": "slm_model_fit.html#konstruktion-eines-qq-graphen",
    "href": "slm_model_fit.html#konstruktion-eines-qq-graphen",
    "title": "7  Modellfit",
    "section": "7.13 Konstruktion eines qq-Graphen",
    "text": "7.13 Konstruktion eines qq-Graphen\n\n\n\n\n\n\nSortierte Datenwerte\n\n\nkleinster\n2.kleinster\nmittlerer\n2.größter\ngrößter\n\n\n\n\n-2\n-1.2\n0.1\n5\n7"
  },
  {
    "objectID": "slm_model_fit.html#konstruktion-eines-qq-graphen-1",
    "href": "slm_model_fit.html#konstruktion-eines-qq-graphen-1",
    "title": "7  Modellfit",
    "section": "7.14 Konstruktion eines qq-Graphen",
    "text": "7.14 Konstruktion eines qq-Graphen\n\n\n\n\n\nStreudiagramm der empirischen Werte gegen die theoretischen Quantilen"
  },
  {
    "objectID": "slm_model_fit.html#beispiele-für-qq-graphen-mit-qqnorm-und-qqline",
    "href": "slm_model_fit.html#beispiele-für-qq-graphen-mit-qqnorm-und-qqline",
    "title": "7  Modellfit",
    "section": "7.15 Beispiele für qq-Graphen mit qqnorm() und qqline()",
    "text": "7.15 Beispiele für qq-Graphen mit qqnorm() und qqline()"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---qq-diagramm",
    "href": "slm_model_fit.html#diagnoseplot---qq-diagramm",
    "title": "7  Modellfit",
    "section": "7.16 Diagnoseplot - QQ-Diagramm",
    "text": "7.16 Diagnoseplot - QQ-Diagramm\n\n\n\n\n\nQQ-Diagramm der Residuen des ADAS-ADCS-Modells\n\n\n\n\n2"
  },
  {
    "objectID": "slm_model_fit.html#summary",
    "href": "slm_model_fit.html#summary",
    "title": "7  Modellfit",
    "section": "7.17 summary()",
    "text": "7.17 summary()\n\n\n\nCall:\nlm(formula = adcs ~ adas, data = adl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.2177  -3.8033  -0.4663   2.7950  20.9634 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  26.5445     4.3052   6.166 3.05e-07 ***\nadas         -0.2638     0.1015  -2.599   0.0131 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.516 on 39 degrees of freedom\nMultiple R-squared:  0.1477,    Adjusted R-squared:  0.1258 \nF-statistic: 6.757 on 1 and 39 DF,  p-value: 0.01312"
  },
  {
    "objectID": "slm_model_fit.html#neue-idee-zu-residuen",
    "href": "slm_model_fit.html#neue-idee-zu-residuen",
    "title": "7  Modellfit",
    "section": "7.18 Neue Idee zu Residuen",
    "text": "7.18 Neue Idee zu Residuen\n\n\n\n\n\nSpielzeugbeispiel mit Residuen \\(\\hat{\\epsilon}_i = e_i = y_i - \\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#zum-nacharbeiten",
    "href": "slm_model_fit.html#zum-nacharbeiten",
    "title": "7  Modellfit",
    "section": "7.19 Zum Nacharbeiten",
    "text": "7.19 Zum Nacharbeiten\nKutner u. a. (2005, p.100–114) Altman und Krzywinski (2016b) Fox (2011, p.285–296)"
  },
  {
    "objectID": "slm_model_fit.html#hebelwerte",
    "href": "slm_model_fit.html#hebelwerte",
    "title": "7  Modellfit",
    "section": "7.20 Hebelwerte",
    "text": "7.20 Hebelwerte\n\n\n\n\n\n\n\n\nStreudiagramm der ADCS-MCI-ADL scores gegen ADAS-cos scores\n\n\n\n\n\n\n\n\n\nHebelwerte der jeweiligen \\(x_i\\)s\n\n\n\n\n\n\n\n\n\nHebelwerte der jeweiligen Datenpunkte"
  },
  {
    "objectID": "slm_model_fit.html#dffits",
    "href": "slm_model_fit.html#dffits",
    "title": "7  Modellfit",
    "section": "7.21 DFFITS",
    "text": "7.21 DFFITS\nMit Hilfe der Hebelwerte lassen sich verschiedene Maße erstellen um den Einfluss von Datenpunkten auf das Modell zu überprüfen. Ein Maß wird als bezeichnet (siehe Gleichung 7.1)\n\\[\n(DFFITS)_i = \\frac{\\hat{y}_i - \\hat{y}_{i(i)}}{\\sqrt{\\hat{\\sigma}^2h_i}}\n\\tag{7.1}\\]\nIm Zähler kommen vin Gleichung 7.1 zweimal vorhergesagte \\(y\\)-Werte vor. \\(\\hat{y}_i\\) ist dabei der ganz normale Vorhersagewert der uns mittlerweile schon mehrfach begegnet ist. Der zweite Wert \\(\\hat{y}_{i(i)}\\) bezeichnet den vorhergesagten Wert aus dem Modell aus dem der Wert \\(y_i\\) weggelassen wurde. D.h, dass Modell ist mit einem Wert weniger gefittet worden. Daher misst die Differenz \\(\\hat{y}_i - \\hat{y}_{i(i)}\\) den Unterschied in den Vorhersagewerte zwischen zwei Modellen bei denen einmal der Wert \\(y_i\\) zum fitten verwendet wurde und einmal wenn \\(y_i\\) nicht zum fitten verwendet wurde. Umso größer der Unterschied zwischen diesen beiden Werte umso größer ist der Einfluss des Wertes \\(y_i\\) auf den Modellfit. Den Nenner von Gleichung 7.1 lassen wir mal fallen, da es sich dabei nur um einen Normierungswert handelt. Dementsprechend, wird mittels DFFITS für jeden Datenpunkt ein Wert ermittelt und umso größer dieser Wert ist umso größer ist der Einfluss des jeweiligen Datenpunktes auf den Modellfit.\nIm idealen Fall sollte alle Datenpunkt ungefähr den gleichen Einfluss haben und einzelne Datenpunkte die einen übermäßig großen Einfluss auf das Modell haben sollten noch einmal genauer inspiziert werden.\n\n\n\n\n\n\nTipp\n\n\n\nAls Daumenregel, kann für kleine bis mittlere Datensätze ein DFFITS von \\(\\approx 1\\) auf Probleme hindeuten, während bei großen Datensätzen \\(\\approx 2\\sqrt{k/N}\\) als Orientierungshilfe verwendet werden kann (k := Anzahl der Prediktoren, N := Stichprobengröße).\n\n\n\n\n\n\n\n\nWarnung\n\n\n\nWenn ein Wert außerhalb der Daumenregel liegt, heißt das nicht, dass er automatisch ausgeschlossen werden muss/soll, sondern lediglich inspiziert werden sollte und das Modell mit und ohne diesen Wert interpretiert werden sollte.\n\n\nIn R können die DFFITS werden mittels der dffits()-Funktion berechnet werden. Als Parameter erwartet dffits() das gefittete lm()-Objekt. Ähnlich wie bei den Residuen, werden die DFFITS-Werte gegen die vorhergesagten \\(y_i\\)-Werte graphisch abgetragen um die Wert zu inspizieren und Probleme in der Modellspezifikation zu identifizieren.\n\nplot(adl$y_hat, dffits(mod),\n     ylim=c(-2,2),\n     xlab=expression(hat(y)[i]),\n     ylab='DFFIT-Wert')\nabline(h=c(-1,1), col='red', lty=2)\n\n\n\n\nAbbildung 7.1: Beispiel für DFFITS gegen \\(\\hat{y}_i\\)\n\n\n\n\nIn Abbildung 7.1 sind die DFFITS-Werte gegen die vorhergesagten Werte \\(\\hat{y}_i\\) abgetragen und zusätzlich die Daumenregel \\(\\pm1\\) eingezeichnet. Hier ist ein Wert nur gerade so außerhalb des vorgeschlagenen Bereichs. Hier könnte daher sich dieser Datenpunkt noch einmal genauer angeschaut werden, ob bei Ausschluß des Wertes es zu einer qualitativ anderen Interpretation der Daten kommt oder ob bespielsweise Übertragungsfehler für diesen Wert vorliegen oder sonstige Gründe."
  },
  {
    "objectID": "slm_model_fit.html#cooks-abstand",
    "href": "slm_model_fit.html#cooks-abstand",
    "title": "7  Modellfit",
    "section": "7.22 Cooks-Abstand",
    "text": "7.22 Cooks-Abstand\nEin Maß um den Einfluss von einzelnen Datenpunkten auf die Vorhersagewerte \\(\\hat{y}_i\\) über alle Werte abzuschätzen.\n\\[\nD_i = \\frac{\\sum_{j=1}^N(\\hat{y_j} - \\hat{y}_{j(i)})}{k\\hat{\\sigma}^2}\n\\]\n\n7.22.1 Daumenregel\n\\(D_i > 1\\)\n\n\n7.22.2 In R\ncooks.distance()"
  },
  {
    "objectID": "slm_model_fit.html#cooks-abstand-plot",
    "href": "slm_model_fit.html#cooks-abstand-plot",
    "title": "7  Modellfit",
    "section": "7.23 Cooks-Abstand plot",
    "text": "7.23 Cooks-Abstand plot\n\n\n\n\n\nCook’s \\(D_i\\) gegen \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#dfbetas",
    "href": "slm_model_fit.html#dfbetas",
    "title": "7  Modellfit",
    "section": "7.24 DFBETAS",
    "text": "7.24 DFBETAS\nEin Maß für die Veränderung der \\(\\beta\\)-Koeffizienten durch einzelne Datenpunkte \\(i\\).\n\\[\n(DFBETAS)_{k(i)} = \\frac{\\hat{\\beta}_k - \\hat{\\beta}_{k(i)}}{\\sqrt{\\hat{\\sigma}^2c_{kk}}}\n\\]\n\n7.24.1 Daumenregel\nFür kleine bis mittlere Datensätze \\(\\approx 1\\)\nFür große Datensätze \\(\\approx 2/\\sqrt{N}\\)\n\n\n7.24.2 In R\ndfbeta()3"
  },
  {
    "objectID": "slm_model_fit.html#dfbetas-1",
    "href": "slm_model_fit.html#dfbetas-1",
    "title": "7  Modellfit",
    "section": "7.25 DFBETAS",
    "text": "7.25 DFBETAS\n\n\n\n\n\nDFBETA-Werte für \\(\\beta_0\\) und \\(\\beta_1\\) gegen \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#zusammenfassung",
    "href": "slm_model_fit.html#zusammenfassung",
    "title": "7  Modellfit",
    "section": "7.26 Zusammenfassung",
    "text": "7.26 Zusammenfassung\n\nÜbersicht über die verschiedene Einflussmaße zur Bewertung der Modellgüte\n\n\nTyp\nVeränderung\nDaumenregel\n\n\n\n\n\\((DFFITS)_i\\)\nVorhersagewert i\n\\(2\\sqrt{k/N}\\)\n\n\nCook\nDurchschnittliche Vorhersagewerte\n\\(>1\\)\n\n\n\\((DFBETAS)_{k(i)}\\)\nKoeffizient i\n\\(2\\sqrt{N}\\)\n\n\n\\(e_{Ti}\\)\nResiduum i\nt-Verteilung(n-k-2)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplots-in-r-mit-plotmod",
    "href": "slm_model_fit.html#diagnoseplots-in-r-mit-plotmod",
    "title": "7  Modellfit",
    "section": "7.27 Diagnoseplots in R mit plot(mod)",
    "text": "7.27 Diagnoseplots in R mit plot(mod)\n\nplot(mod)"
  },
  {
    "objectID": "slm_model_fit.html#zum-nacharbeiten-1",
    "href": "slm_model_fit.html#zum-nacharbeiten-1",
    "title": "7  Modellfit",
    "section": "7.28 Zum Nacharbeiten",
    "text": "7.28 Zum Nacharbeiten\nAltman und Krzywinski (2016a) Fox (2011, p.294–302)\n\n7.28.1 Weiterführendes\nYoung (2019)\n\n\n\n\nAltman, Naomi, und Martin Krzywinski. 2016a. „Points of significance: Analyzing outliers: influential or nuisance“. Nature Methods 13 (4): 281–82.\n\n\n———. 2016b. „Points of significance: regression diagnostics“. Nature Methods 13 (5): 385–86.\n\n\nFox, John. 2011. An R companion to applied regression. 2. Aufl. SAGE Publication Inc., Thousand Oaks.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York.\n\n\nYoung, Alwyn. 2019. „Channeling fisher: Randomization tests and the statistical insignificance of seemingly significant experimental results“. The Quarterly Journal of Economics 134 (2): 557–98."
  },
  {
    "objectID": "slm_prediction.html#vorhergesagte-werte-haty_i",
    "href": "slm_prediction.html#vorhergesagte-werte-haty_i",
    "title": "8  Vorhersage",
    "section": "8.1 Vorhergesagte Werte \\(\\hat{y}_i\\)",
    "text": "8.1 Vorhergesagte Werte \\(\\hat{y}_i\\)\n\n\n\nWenn ein einfaches lineares Modell gefittet wurde ist eine zentrale Frage welche Vorhersagen anhand des Modell getroffen werden können. Die Vorhersagen \\(\\hat{y}_i\\) liegen auf der vorhergesagten Regressionsgerade und berechnen sich nach dem Modell für einen gegeben \\(x\\)-Wert.\n\\[\n\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_0} x\n\\]\nWie schon mehrfach besprochen unterliegt die Regressionsgerade inherent der Unsicherheit bezüglich der geschätzen Modellkoeffizienten \\(\\hat{\\beta}_0\\) und \\(\\hat{\\beta}_1\\). Diese Unsicherheit überträgt sich auf die geschätzen Werte \\(\\hat{y}_i\\) und muss daher bei deren Interpretation berücksichtigt werden.\nIn Abbildung 8.1 sind die bereits behandelten Sprungdaten gegen die Anlaufgeschwindigkeiten zusammen mit der Regressionsgeraden und vorhergesagten Werten (rot) abgetragen.\n\n\n\n\n\nAbbildung 8.1: Vorhersagewerte \\(\\hat{y}_i\\) (rote Punkte) für die Sprungdaten.\n\n\n\n\nIn R können die vorhergesagten Werte des mittels lm() gefitteten Modells mit der Hilfsfunktion predict() bestimmt werden. Wenn der Funktion predict() keine weiteren Parameter außer dem lm-Objekt übergeben werden, berechnet predict() die vorhergesagten Werte \\(\\hat{y}_i\\) für alle die \\(x\\)-Werte die auch zum fitten des Modells benutzt wurden. Die Reihenfolge der Werte \\(\\hat{y}_i\\) enspricht dabei den Werten im Original-data.frame().\n\npredict(mod)[1:5] \n\n       1        2        3        4        5 \n4.523537 4.725140 4.856256 4.761778 5.416207 \n\n\nWir haben uns hier nur die ersten fünf Werte ausgeben lassen, da nur demonstriert werden soll wie die predict()-Funktion angewendet werden kann. Um eine Anwendung zu geben, so können mittels predict() die Residuen auch von Hand ohne die resid()-Funktion erhalten werden.\n\n(jump$jump_m - predict(mod))[1:5]\n\n          1           2           3           4           5 \n-0.16267721 -0.41248842 -0.29359256 -0.01047071  0.09927500 \n\nresid(mod)[1:5]\n\n          1           2           3           4           5 \n-0.16267721 -0.41248842 -0.29359256 -0.01047071  0.09927500 \n\n\nWiederum nur zur Demonstration die ersten fünf Wert um die Äquivalenz der beiden Methoden zu demonstrieren.\nMeistens liegt das Interesse jedoch weniger auf den vorhergesagten Werten \\(\\hat{y}_i\\) für die gemessenen Werte, sondern es sollen Werte vorhergesagt werden für \\(x\\)-Werte die nicht im Datensatz enthalten sind. Operational ändert sich nichts, es wird immer noch das gefittete Modell verwendetet und es müssen lediglich neue \\(x\\)-Werte übergeben werden.\nIn R kann dies mittels des zweite Parameter in predict() erreicht werden. Soll zum Beispiel die Sprungweite für eine Anlaufgeschwindigkeit von \\(v = 11.5[m/s]\\) berechnen werden, muss zunächst ein neues tibble() erstellt werden, welches den gewünschten \\(x\\)-Wert enthält. Dabei muss der Spaltenname in dem neuen tibble() demjenigen im Original-tibble() entsprechen. Ansonsten funktioniert die Anwendung von predict() nicht.\n\ndf <- tibble(v_ms = 11.5)\ndf\n\n# A tibble: 1 x 1\n   v_ms\n  <dbl>\n1  11.5\n\n\nDieses tibble() kann nun zusammen mit dem lm()-Objekt an predict() übergeben werden.\n\npredict(mod, newdata = df)\n\n       1 \n8.614136 \n\n\nD.h., bei einer Anlaufgeschwindigkeit von \\(v = 11.5[m/s]\\) ist anhand des Modells eine Sprungweite von \\(8.6m\\) zu erwarten."
  },
  {
    "objectID": "slm_prediction.html#unsicherheit-in-der-vorhersage",
    "href": "slm_prediction.html#unsicherheit-in-der-vorhersage",
    "title": "8  Vorhersage",
    "section": "8.2 Unsicherheit in der Vorhersage",
    "text": "8.2 Unsicherheit in der Vorhersage\nWie schon angesprochen ist unser Modell natürlich mit Unsicherheiten behaftet. Diese drücken sich in den Standardfehler für die beiden Koeffizienten \\(\\hat{\\beta_0}\\) und \\(\\hat{\\beta_1}\\) (siehe Tabelle 8.1).\n\n\n\n\nTabelle 8.1: Modellparameter und Standardfehler\n\n\n\nSchätzer\n\\(s_e\\)\n\n\n\n\n(Intercept)\n-0.14\n0.23\n\n\nv_ms\n0.76\n0.02\n\n\n\n\n\n\nDer vorhergesagte Wert \\(\\hat{y}\\) ist daher für sich alleine ist noch nicht brauchbar, da auch Informationen über dessen Unsicherheit notwendig sind um die Ergebnisse korrekt zu interpretieren.\nEs können zwei unterschiedliche Anwendungsfälle voneinander unterschieden werden.\n\nDer mittlere, erwartete Wert \\(\\hat{\\bar{y}}_{neu}\\)\nDie Vorhersage eines einzelnen Wertes \\(\\bar{y}_{neu}\\)\n\nIm konkreten Fall werden damit zwei unterschiedliche Fragestellungen beantwortet. Im 1. Fall lautet die Frage, ich habe eine Trainingsgruppe und möchte wissen was der mittlere Wert der Gruppe anhand des Modells ist, wenn alle eine bestimmte Anlaufgeschwindigkeit \\(v_{neu}\\) haben. Im 2. Fall lautet die Frage welche Weite eine einzelne Athletin für die Anlaufgeschwindigkeit \\(v_{neu}\\) springen sollte. In beiden Fällen werden keiner genau den Wert des Regressionsmodells treffen, aber im 1. Fall der Gruppe werden sich Streuungen nach oben bzw. nach unten gegenseitig im Schnitt ausbalancieren während im 2. Fall der einzelnen Athletin dies nicht der Fall ist. Daher hat die Vorhersage im 2. Fall eine höhere Unsicherheit. Diese Unterschied sollte sich dementsprechend in den Varianzen der beiden Vorhersagen wiederspiegeln.\nWie bereits erwähnt, der vorhergesagte Wert \\(\\hat{y}_{neu}\\) ist in beiden Fällen gleich und entsprecht der oben beschriebenen Methode anhand des Modell \\(y_{neu} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\times x_{\\text{neu}}\\).\nFür den erwarteten Mittelwert errechnet sich die Varianz nach:\n\\[\\begin{equation}\nVar(\\hat{\\bar{y}}_{neu}) = \\hat{\\sigma}^2 \\left[\\frac{1}{n} + \\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\\right] = \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}^2\n\\end{equation}\\]\nDas dazugehörige Konfidenzintervall errechnet sich danach mittels:\n\\[\\begin{equation}\n\\hat{\\bar{y}}_{neu} \\pm q_{t(1-\\alpha/2;n-2)} \\times \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}\n\\end{equation}\\]\nDie Varianz für die Vorhersage eines einzelnen Wertes errechnet sich:\n\\[\\begin{equation}\nVar(\\hat{y}_{neu}) = \\hat{\\sigma}^2 \\left[1 + \\frac{1}{n} + \\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\\right] = \\hat{\\sigma}^2 + \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}^2 = \\hat{\\sigma}_{\\hat{y}_{neu}}^2\n\\end{equation}\\]\nWas wiederum zu dem folgenden Konfidenzintervall führt:\n\\[\\begin{equation}\n\\hat{y}_{neu} \\pm q_{t(1-\\alpha/2;n-2)} \\times \\hat{\\sigma}_{\\hat{y}_{neu}}\n\\end{equation}\\]\nIn beiden Fällen ist der Term\n\\[\n\\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\n\\]\nenthalten. Anhand des Zählers kann abgeleitet werden, dass die Unsicherheit der Vorhersage mit dem Abstand vom Mittelwert der \\(x\\)-Werte zunimmt. Rein heuristisch macht dies Sinn, da davon ausgegangen werden kann, dass um den Mittelwert der \\(x\\)-Werte auch die meiste Information über \\(y\\) vorhanden ist und dementsprechend umso weiter die Werte sich vom \\(\\bar{x}\\) entfernen die Information abnimmt. Im Nenner ist wiederum wie auch beim Standardfehler \\(\\sigma_{\\beta_1}\\) des Steigungskoeffizienten \\(\\beta_1\\) zu sehen, dass die Varianz abnimmt mit der Streuung der \\(x\\)-Werte. Daher, wenn eine Vorhersage in einem bestimmten Bereich von \\(x\\)-Werten durchgeführt werden soll, dann sollte darauf geachtet werden möglichst diesen Bereich auch zu samplen um die Unsicherheit so klein wie möglich zu halten."
  },
  {
    "objectID": "slm_prediction.html#vorhersagen-in-r-mit-predict",
    "href": "slm_prediction.html#vorhersagen-in-r-mit-predict",
    "title": "8  Vorhersage",
    "section": "8.3 Vorhersagen in R mit predict()",
    "text": "8.3 Vorhersagen in R mit predict()\n\n8.3.1 Erwarteter Mittelwert\n\ndf <- data.frame(v_ms = 11.5) # oder tibble(v_ms = 11.5)\npredict(mod, newdata = df, interval = 'confidence')\n\n       fit      lwr      upr\n1 8.614136 8.482039 8.746234\n\n\n\n\n8.3.2 Individuelle Werte\n\npredict(mod, newdata = df, interval = 'prediction')\n\n       fit      lwr      upr\n1 8.614136 8.118445 9.109827"
  },
  {
    "objectID": "slm_prediction.html#konfidenzintervalle-graphisch",
    "href": "slm_prediction.html#konfidenzintervalle-graphisch",
    "title": "8  Vorhersage",
    "section": "8.4 Konfidenzintervalle graphisch",
    "text": "8.4 Konfidenzintervalle graphisch\n\n\n\n\n\nWeiterführende Literatur sind Kutner u. a. (2005)"
  },
  {
    "objectID": "slm_prediction.html#r2-und-root-mean-square",
    "href": "slm_prediction.html#r2-und-root-mean-square",
    "title": "8  Vorhersage",
    "section": "8.5 \\(R^2\\) und Root-mean-square",
    "text": "8.5 \\(R^2\\) und Root-mean-square"
  },
  {
    "objectID": "slm_prediction.html#einfaches-modell",
    "href": "slm_prediction.html#einfaches-modell",
    "title": "8  Vorhersage",
    "section": "8.6 Einfaches Modell",
    "text": "8.6 Einfaches Modell\n\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n\n\nCall:\nlm(formula = y ~ x, data = simple)\n\nResiduals:\n      1       2       3       4 \n-0.5817  0.9898 -0.2345 -0.1736 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.8414     0.7008   2.628    0.119\nx             0.4574     0.3746   1.221    0.346\n\nResidual standard error: 0.8376 on 2 degrees of freedom\nMultiple R-squared:  0.4271,    Adjusted R-squared:  0.1406 \nF-statistic: 1.491 on 1 and 2 DF,  p-value: 0.3465"
  },
  {
    "objectID": "slm_prediction.html#nochmal-abweichungen",
    "href": "slm_prediction.html#nochmal-abweichungen",
    "title": "8  Vorhersage",
    "section": "8.7 Nochmal Abweichungen",
    "text": "8.7 Nochmal Abweichungen\n\nGesamtvarianz: \\[\nSSTO := \\sum_{i=1}^N (y_i - \\bar{y})^2\n\\]\nRegressionsvarianz: \\[\nSSR :=\\sum_{i=1}^N(\\hat{y}_i - \\bar{y})^2\n\\]\nResidualvarianz: \\[\nSSE := \\sum_{i=1}^N (y_i - \\hat{y}_i)^2\n\\]\n\n\n\n\n\n\nMinimalmodell der Abweichungen"
  },
  {
    "objectID": "slm_prediction.html#verhältnis-von-ssr-zu-ssto",
    "href": "slm_prediction.html#verhältnis-von-ssr-zu-ssto",
    "title": "8  Vorhersage",
    "section": "8.8 Verhältnis von \\(SSR\\) zu \\(SSTO\\)",
    "text": "8.8 Verhältnis von \\(SSR\\) zu \\(SSTO\\)\n\n\n\n\n\nPerfekter Zusammenhang\n\n\n\n\n\\[\n\\frac{SSR}{SSTO} = 1\n\\]\n\n\n\n\n\nKein Zusammenhang\n\n\n\n\n\\[\n\\frac{SSR}{SSTO} = 0\n\\]"
  },
  {
    "objectID": "slm_prediction.html#determinationskoeffizient-r2",
    "href": "slm_prediction.html#determinationskoeffizient-r2",
    "title": "8  Vorhersage",
    "section": "8.9 Determinationskoeffizient \\(R^2\\)",
    "text": "8.9 Determinationskoeffizient \\(R^2\\)\nEs gilt: \\(SSTO = SSR + SSE\\)\n\\[\nR^2 = \\frac{SSR}{SSTO} = 1 - \\frac{SSE}{SSTO} \\in [0,1]\n\\] 1\n\n8.9.1 Korrigierter Determinationskoeffizient \\(R_a^2\\)\n\\[\nR_a^2 = 1 - \\frac{\\frac{SSE}{n-p}}{\\frac{SSTO}{n-1}} = 1 - \\frac{n-1}{n-p}\\frac{SSE}{SSTO}\n\\]\n\n\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  }
]