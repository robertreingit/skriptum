[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scriptum - Fortgeschrittene Statistik",
    "section": "",
    "text": "Vorwort\nDies ist das Skriptum für den Master-Statistikkurse Fortgeschrittene Statistik und ist die Vorlage für die Kurse LTC4 und SBG4. Es werden in den Kursen nicht alle Themen des Skriptums behandelt. Das Skriptum befindet sich derzeit noch in einem frühen Stadium, so dass die Inhalte noch nicht vollständig ausgearbeitet sind."
  },
  {
    "objectID": "stats_title.html",
    "href": "stats_title.html",
    "title": "Statistik",
    "section": "",
    "text": "Die erste Frage die sich im Umgang mit der Anwendung von Verfahren der Statistik stellt ist: Wofür benötigen wir Statistik überhaupt?\nBeispielsweise wurden ein Datensatz gesammelt, bei dem zwei Gruppen miteinander verglichen werden, eine Treatmentgruppe (TRT) und eine Kontrollgruppe (CON). In beiden Gruppen wurden jeweils \\(N_i = 20\\) Personen untersucht. Es wurde das folgende Ergebnis erhalten (siehe Abbildung 1).\n\n\n\n\n\nAbbildung 1: Boxplot der Kontroll- und der Treatmentgruppe bezüglich einer abhängigen Variable\n\n\n\n\nOffensichtlich sind die Werte in der Treatmentgruppe deutlich höher als diejenigen in der Kontrollgruppe. Warum ist es nicht ausreichend das offensichtliche zu dokumentieren? Warum ist eine statistische Analyse der Daten notwendig?\nDiese Fragestellung wird in dem folgenden Abschnitt untersucht. Gleichzeitig werden die notwendigen Werkzeuge entwickelt um die verschiendenen Schritte die einer statistische Analyse von Daten zugrundeliegenen zu verstehen und anwenden zu können."
  },
  {
    "objectID": "stats_basics.html#ein-experiment",
    "href": "stats_basics.html#ein-experiment",
    "title": "1  Eine kleine Welt der Unsicherheit",
    "section": "1.1 Ein Experiment",
    "text": "1.1 Ein Experiment\nWir wollen nun eine Krafttrainingsstudie durchführen um die Beinkraft zu erhöhen. Wir haben allerdings nur sehr wenige Ressourcen (bzw. wir sind faul) und können insgesamt nur sechs Messungen durchführen. Aus einem kürzlich durchgeführten Census haben wir aber die Kraftwerte der ganzen Population. Wir stellen die Kraftwerte zunächst mittels einer Tabelle dar (siehe Tabelle 1.1)\n\n\n\n\nTabelle 1.1: Kraftwerte (in Newton) der Lummerländer an der einbeinigen Beinpresse\n\n\nID\nKraft[N]\nID\nKraft[N]\n\n\n\n\nP01\n2414\nP11\n2243\n\n\nP02\n2462\nP12\n2497\n\n\nP03\n2178\nP13\n1800\n\n\nP04\n2013\nP14\n2152\n\n\nP05\n2194\nP15\n2089\n\n\nP06\n2425\nP16\n2090\n\n\nP07\n2305\nP17\n3200\n\n\nP08\n2117\nP18\n2196\n\n\nP09\n2298\nP19\n2485\n\n\nP10\n2228\nP20\n2440\n\n\n\n\n\n\nSelbst bei 20 Werten ist diese Darstellung wenig übersichtlich. Wir könnten zwar Zeile für Zeile durchgehen und nach etwas notieren und suchen würden wir sehen das der Maximalwert bei \\(3200\\)N für P17 und der Minimalwert von Person P13 bei \\(1800\\)N liegt. Aber wirklich einfach ist diese Darstellung nicht. Für solche univariaten Daten (uni = eins) kann eine übersichtlichere Darstellung mittels eines sogenannten Dotplots erreicht werden (siehe Abbildung 1.2).\n\n\n\n\n\nAbbildung 1.2: Dotplot der Lummerlandkraftdaten\n\n\n\n\nHier kann deutlich schneller abgelesen werden was das Minimum und das Maximum der Daten ist, sowie es kann auch direkt abgeschätzt werden in welchem Bereich sich der Großteil der Daten befindet. Allerdings wird durch diese Art der Darstellung die Information über welche Person die jeweiligen Werte besitzt nicht mehr dargestellt. Dies stellt in den meisten Fällen allerdings kein Problem dar, da wir in den meisten Fällen aussagen über die Gruppe und weniger über einzelne Personen machen wollen.\nGehen wir jetzt von der folgenden Fragestellung aus. Wir wollen den Gesundheitsstatus unserer Lummerländer verbessern und wollen dazu ein Krafttraining durchführen. Da evidenzbasiert arbeiten wollen, möchten wir überprüfen ob wirklich ein Verbesserung der Kraft durch das Training stattgefunden hat. Da es sich aber gleichzeitig um unsere selbst geschaffene Welt handelt führen wir natürlich ein perfektes Krafttraining, eine perfekte Intervention, durch. D.h wir stellen uns immer wieder als unwissend da und geben vor das wir gar nicht wissen, das das Training perfekt effektiv ist.\nD.h. wir führen gleichzeitig ein Gedankenexperiment durch. Wir führen ein Krafttraining für die Beine durch. Das Training ist perfekt und verbessert die Kraftleistung um genau \\(+100\\)N. Dieser Kraftzuwachs unabhängig davon welche Person aus unserer Population das Training durchführt (Warum ist das keine realistische Annahme?). Wir wollen zwei Gruppen miteinander vergleichen eine Interventionsgruppe und eine Kontrollgruppe. In beiden Gruppen sollen jeweils \\(n_{\\text{TRT}} = n_{\\text{CON}} = 3\\) TeilnehmerInnen bzw. Teilnehmer einbezogen werden da wir nicht mehr Ressourcen für mehr ProbandInnen haben.\nDie erste Frage die sich nun stellt ist wie wählen wir die sechs Personen aus unserer Population aus und wie teilen wir die sechs Personen in die beiden Gruppen? Nach etwas überlegen kommen wir darauf, dass wir am besten eine zufällige Stichprobe ziehen sollten (Warum?).\n\nDefinition 1.2 (Stichprobe) Eine Stichprobe ist eine Teilmenge der Objekte aus der Population.\n\n\nDefinition 1.3 (Zufallsstichprobe) Eine Zufallsstichprobe ist eine Teilmenge der Objekte aus der Population die zufällig ausgewählt wurde.\n\nDiese sechs Personen, unsere Stichprobe, wird dann wiederum zufällig auf die beiden Gruppen aufgeteilt.\n\n\n\nEin Zufallszahlengenerator hat die Zahlen \\(i = \\{3,7,8,9,10,20\\}\\) gezogen. Die entsprechenden Personen werden aus der Population ausgewählt und wiederum zufällig in die beiden Gruppen aufgeteilt (siehe Tabelle 1.2).\n\n\n\n\nTabelle 1.2: Zufällig ausgewählte Stichprobe der Kontrollgruppe (CON) und der Interventionsgruppe (TRT).\n\n\nID\nKraft[N]\nGruppe\n\n\n\n\nP08\n2117\nCON\n\n\nP09\n2298\nCON\n\n\nP03\n2178\nCON\n\n\nP07\n2305\nTRT\n\n\nP10\n2228\nTRT\n\n\nP20\n2440\nTRT\n\n\n\n\n\n\nMit diesen sechs Personen führen wir jetzt unser Experiment durch. Die drei Personen aus der Kontrollgruppe, unterlaufen im Interventionszeitraum nur ein Stretchtraining während die Interventionsgruppe zweimal die Woche für 12 Wochen unser perfektes Krafttraining durchführt. Nach diesem Zeitraum messen wir alle Personen aus beiden Gruppen und erhalten das folgende Ergebnis (siehe Tabelle 1.3).\n\n\nTabelle 1.3: Ergebnis der Intervention in Experiment 1 für die Kontroll- und die Interventionsgruppe.\n\n\n\n\n(a) Kontrollgruppe\n\n\nID\nKraft[N]\n\n\n\n\nP08\n2117\n\n\nP09\n2298\n\n\nP03\n2178\n\n\n\\(\\bar{K}\\)\n2198\n\n\n\n\n\n\n(b) Interventionsgruppe\n\n\nID\nKraft[N]\n\n\n\n\nP07\n2405\n\n\nP10\n2328\n\n\nP20\n2540\n\n\n\\(\\bar{K}\\)\n2424\n\n\n\n\n\n\nFür beide Gruppen ist jeweils der Mittelwert berechnet worden, um die Wert miteinander vergleichen zu können. Später werden wir noch weitere Maße kennenlernen die es ermöglichen zwei Mengen von Werten miteinander zu vergleichen.\n\nDefinition 1.4 (Mittelwert) Der Mittelwert über \\(n\\) Werte berechnet sich nach der Formel:\n\\[\n\\bar{x} = \\frac{\\sum_{i=1}^n x_i}{n}\n\\tag{1.1}\\]\nDer Mittelwert wird mit einem Strich über der Variable dargestellt.\n\nDamit lernen wir direkt auch ein neues Konzept kennen. Nämlich das der Statistik. Ein Wert der auf der erhobenen Stichprobe berechnet wird, wird als Statistik bezeichnet.\n\nDefinition 1.5 (Statistik) Ein auf einer Stichprobe berechnet Wert, wird als Statistik bezeichnet.\n\nUm jetzt Unterschied zwischen den beiden Gruppen zu untersuchen berechnen wir die Differenz D zwischen den beiden Mittelwerten \\(D = \\bar{K}_{\\text{TRT}} - \\bar{K}_{\\text{CON}}\\). Die Differenz kann natürlich auch in die andere Richtung berechnet werden und es würde sich das Vorzeichen ändern. Hier gibt es keine Vorgaben, sondern die Richtung kann frei bestimmt werden. Wenn bekannt ist in welcher Richtung der Unterschied berechnet wird, dann stellt dies keine Problem dar. Im vorliegenden Fall ziehen wir die Interventionsgruppe von der Kontrollgruppe ab, da wir davon ausgehen, dass die Intervention zu einer Krafterhöhung führt und wir dadurch einen positiven Unterschied erhalten (vgl. Gleichung 1.2)\n\n\n\n\\[\nD = 2424N - 2198N = 226 N\n\\tag{1.2}\\]\nDa der Wert D, wiederum auf den Daten der Stichprobe berechnet wird, handelt es sich ebenfalls um eine Statistik.\n\n\n\n\n\nAbbildung 1.3: Dotplot der beiden Stichproben. Senkrechte Striche zeigen die jeweiligen Mittelwerte an.\n\n\n\n\nIn Abbildung 1.3 sind die Werte der beiden Gruppen, deren Mittelwerte \\(\\bar{K}_{\\text{CON}}\\) und \\(\\bar{K}_{\\text{TRT}}\\) und der Unterschied \\(D\\) zwischen diesen abgebildet. Wie erwartet zeigt die Interventionsgruppen den höheren Kraftwert im Vergleich zu der Kontrollgruppe. Allerdings ist der Wert mit \\(D = 226\\) größer als der tatsächliche Zuwachs von \\(\\Delta_{\\text{Training}} = 100\\) (Warum ist das so?).\nDer Unterschied zwischen den beiden Gruppen ist natürlich auch zum Teil auf die Unterschiede die zwischen den beiden Gruppen vor der Intervention bestanden haben zurück zu führen. Was wäre denn passiert, wenn wir eine andere Stichprobe gezogen hätten?\n\n\n\nSei \\(i = \\{12,2,19,4,8,16\\}\\) eine zweite Stichprobe. Dies würde zu den folgenden Werten führen nach der Intervention führen.\n\n\n\n\nTabelle 1.4: Ergebnis der Intervention in Experiment 2 für die Kontroll- und die Interventionsgruppe.\n\n\nID\nKraft[N]\nGruppe\n\n\n\n\nP08\n2117\nCON\n\n\nP09\n2298\nCON\n\n\nP03\n2178\nCON\n\n\nP07\n2405\nTRT\n\n\nP10\n2328\nTRT\n\n\nP20\n2540\nTRT\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 1.4: Dotplot der beiden Stichproben in Experiment 2. Senkrechte Striche zeigen die jeweiligen Mittelwerte an.\n\n\n\n\nIn Abbildung 1.4 sind wiederum die Datenpunkte, Mittelwerte und der Unterschied abgetragen. In diesem Fall ist allerdings die Differenz zwischen den beiden Gruppen genau in der anderen Richtung \\(D = -308\\), so dass die Interpretation des Ergebnisses genau in der anderen Richtung wäre. Nämlich, nicht nur hat das Krafttraining zu keiner Verbesserung in der Kraftfähigkeit geführt, sondern zu einer Verschlechterung!\n\n\n\nEs hätte aber auch sein können, das wir noch eine andere Stichprobe gezogen hätten, z.B. \\(i = \\{6,5,7,20,14,16\\}\\). Dies würde zu dem folgenden Ergebnis führen (siehe Tabelle 1.5).\n\n\n\n\nTabelle 1.5: Mittelwertsdaten aus Experiment 3 und der Unterschied \\(D\\) zwischen den beiden Gruppenmittelwerten\n\n\nGruppe\nKraft[N]\n\n\n\n\nCON\n2308\n\n\nTRT\n2327\n\n\n\\(D\\)\n19\n\n\n\n\n\n\nIn diesem Fall haben wird zwar wieder einen positiven Unterschied zwischen den beiden Gruppen in der zu erwartenden Richtung gefunden. Der Unterschied von \\(D = 19\\) ist allerdings deutlich kleiner als das tatsächlichen \\(\\Delta = 100\\). Daher würden wir möglicherweise das Ergebnis so interpretieren, führen, dass wir das Krafttraining als ineffektiv bewerten würden und keine Empfehlung ausprechen.\nZusammengenommen, ist keines der Ergebnisse 100% korrekt. Entweder der Unterschied zwischen den beiden Gruppen ist deutlich zu groß, oder in der anderen Richtung oder deutlich zu klein. Das Ergebnis des Experiments hängt ursächlich damit zusammen, welche Stichprobe gezogen wird. Diese Einsicht gilt in jedem Fall generell für jedes Ergebnis eines Experiments.\nDas Phänomen, das der Wert der berechneten Statistik zwischen Wiederholungen des Experiments schwankt wird als Stichprobenvariabilität bezeichnet.\n\nDefinition 1.6 (Stichprobenvariabilität) Durch die Anwendung von Zufallsstichproben, variiert eine auf den Daten berechnete Statistik. Die Variabilität wird als Stichprobenvariabilität bezeichnet.\n\nStreng genommen, führt die Stichprobenvariabilität für sich genommen noch nicht dazu, das sich die Statistik zwischen Wiederholungen des Experiments verändert, sondern die zu untersuchenden Werte in der Population müssen selbst auch noch eine Streuung aufweisen. Wenn wir eine Population untersuchen würden, bei der alle Personen die gleiche Beinkraft hätten, würden unterschiedliche Stichproben immer den gleichen Mittelwert haben und wiederholte Durchführung des Experiment würden immer wieder zu dem selben Ergebnis führen. Dieser Fall ist in der Realität aber praktisch nie gegeben und sämtlich Parameter für die wir uns hier interessieren zeigen immer eine natürlich Streuung in der Population. Diese Streuung in der Population führt daher zu dem besagten Ergebnis, das das gleiche Experiment mehrmals wiederholt zu unterschiedlichen Zufallsstichproben führt und dementsprechend immer zu unterschiedlichen Ergebnissen führt.\nDaher ist eine der zentrale Aufgabe der Statistik mit dieser Variabilität umzugehen und die Forscherin trotzdem in die Lage zu versetzen rationale Entscheidungen zu treffen. Eine implizite Kernannahme dabei ist, das wir mit Hilfe von Daten überhaupt etwas über die Welt lernen können. D.h. das uns die Erhebung von Daten überhaupt auch in die Lage versetzt rationale Entscheidungen zu treffen. Entscheidungen wie ein spezialisiertes Krafttraining mit einer klinischen Population durchzführen oder eine bestimmte taktische Variante mit meiner Mannschaft zu trainieren um die Gegner besser auszuspielen. Alle diese Entscheidungen sollten rational vor dem Hintergrund von Variabilität getroffen werden und auch möglichst oft korrekte Entscheidungen zu treffen. Wie wir sehen werden, kann uns die Statistik leider nicht garantieren immer die korrekte Entscheidungen zu treffen. Nochmal auf den Punkt gebracht nach Wild und Seber (2000, p.28)\n\nThe subject matter of statistics is the process of finding out more about the real world by collecting and then making sense of data.\n\nUntersuchen wir jedoch zunächst unsere Einsicht, das Wiederholungen des gleichen Experiments zu unterschiedlichen Ergebnissen führt, weiter. In unserem Beispiel aus Lummerland haben wir nämlich den Vorteil, das uns die Wahrheit bekannt ist. In Abbildung 1.5 ist die Verteilung unsere bisheringen drei \\(D\\)s abgetragen.\n\n\n\n\n\nAbbildung 1.5: Bisherige Verteilung der Unterschiede \\(D\\)\n\n\n\n\nDie drei Werte liegen ja relativ weiter auseiander. Eien Anschlussfrage könnte jetzt sein: “Welche weiteren Werte sind denn überhaupt möglich mit der vorliegenden Population?”."
  },
  {
    "objectID": "stats_basics.html#die-stichprobenverteilung",
    "href": "stats_basics.html#die-stichprobenverteilung",
    "title": "1  Eine kleine Welt der Unsicherheit",
    "section": "1.2 Die Stichprobenverteilung",
    "text": "1.2 Die Stichprobenverteilung\nWir können jetzt ja einfach mal das Experiment anfangen zu wiederholen. In Abbildung 1.6 sind mal 15 verschiedene Stichproben abgetragen. Wir haben in jeder Zeile jeweils sechs TeilnehmerInnen gezogen. Drei für die Kontrollgruppe und drei für die Inervationsgruppe. Für jede dieser Zeilen können wir jeweils den Gruppenmittelwert berechnen und den Unterschied \\(D\\) bestimmen.\n\n\n\n\n\nAbbildung 1.6: Beispiele für verschiedene Möglichkeiten zwei Stichproben mit jeweils \\(n_i = 3\\) aus der Population zu ziehen\n\n\n\n\nWarum eigentlich bei 15 aufhören. Wir haben ja den Vorteil, das unsere Population relativ übersichtlich ist. Vielleicht können wir uns ja noch aus unserer Schulezeit an Kombinatorik erinnern. Da haben wir den Binomialkoeffizienten kennengelernt. Die Anzahl der möglichken Kombination von \\(k\\) Elementen aus einer Menge von \\(n\\) Elementen berechnet sich nach:\n\\[\n\\text{Anzahl} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\tag{1.3}\\]\nIn unserem Fall wollen wir zunächst sechs Elemente aus \\(N = 20\\) auswählen und dann drei Elemente aus den sechs gezogenen Elementen auswählen um diese entweder der Interventionsgruppe oder der Kontrollgruppe zu zuweisen (Warum brauchen wir uns nur eine Gruppe anzuschauen?). Die Anzahl der möglichen Stichprobenkombinationen ist folglich:\n\n\n\n\\[\n\\text{Anzahl} = \\binom{20}{6}\\binom{6}{3} = 7.752\\times 10^{5}\n\\tag{1.4}\\]\nDas sind jetzt natürlich selbst bei dieser kleinen Population ein große Menge von einzelnen Experimenten, aber dafür sind Computer da, die können alle diese Experiment in kurzer Zeit durchführen. In Abbildung 1.7 ist die Verteilung aller möglichen Experimentausgänge, d.h. alle Differenzen \\(D\\) zwischen der Interventions- und der Kontrollgruppe, abgebildet.\n\n\n\n\n\nAbbildung 1.7: Verteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe bei einer Intervention mit \\(\\Delta = 100\\) (im Graphen mittels der roten Linie angezeigt).\n\n\n\n\nAuf der x-Achse sind die möglichen Differenzen \\(D\\) abgetragen, während auf der y-Achse die relative Häufigkeit, d.h. die Häufigkeit für einen bestimmten \\(D\\)-Wert geteilt durch die Anzahl \\(7.752\\times 10^{5}\\) aller möglichen Werte. Die Verteilung der D’s wird als Stichprobenverteilung bezeichnet.\n\nDefinition 1.7 Die Stichprobenverteilung kennzeichnet die Verteilung der beobachteten Statistik.\n\nDie Abbildung 1.7 zeigt, dass die überwiegende Anzahl der Ausgänge tatsächlich auch im Bereich von \\(\\Delta = 100\\) liegen. Noch präziser das Maximum der Verteilung, also die höchste relative Häufigkeit liegt genau auf der roten Linie. Dies sollte uns etwas beruhigen, denn es zeigt, das unsere Art der Herangehensweise mittels zweier Stichproben auch tatsächlich in den meisten Fällen einen nahezu korrekten Wert ermittelt. Allerdings zeigt die Stichprobenverteilung auch das Werte am rechten Ende die deutlich zu hoch sind wie auch Werte am linken Ende der Verteilung die deutlich in der falschen Richtung möglich sind. Das bedeutet, wenn wir das Experiment nur einmal durchführen wir uns eigentlich nie sich sein können, welches dieser vielen Experimente wir durchgeführt haben. Es ist zwar warscheinlicher, dass wir eins aus der Mitte der Verteilung durchgeführt haben, einfach da die Anzahl größer ist, aber wir haben keine 100% Versicherung, das wir nicht Pech gehabt haben und das Experiment ganz links mit \\(D = -500\\) oder aber das Experiment ganz rechts mit \\(D = 700\\) durchgeführt haben. Diese Unsicherheit wird leider keine Art von Experiment vollständig auflösen können. Eine weitere Eigenschaft der Verteilung ist ihre Symmetrie bezüglich des Maximums mit abnehmenden relativen Häufigkeiten umso weiter von Maximum \\(D\\) entfernt ist (Warum macht das heuristisch Sinn?).\nDie Darstellungsform von Abbildung 1.7 wird als Histogramm bezeichnet und eignet sich vor allem dazu die Verteilung einer Variablen z.B. \\(x\\) darzustellen. Dazu wird der Wertebereich von \\(x\\) zwischen dem Minimalwert \\(x_{\\text{min}}\\) und dem Maximalwert \\(x_{\\text{max}}\\) in \\(k\\) gleich große Intervalle unterteilt und die Anzahl der Werte innerhalb jedes Intervalls wird abgezählt und durch die Anzahl der Gesamtwerte geteilt um die relative Häufigkeit zu erhalten.\n\n\n\nZum Beispiel für die Werte:\n\\[\nx_i \\in \\{1,1.5,1.8,2.1,2.2,2.7,2.8,3.5,4 \\}\n\\] könnte das Histogram ermittelt werden, indem der Bereich von \\(x_{\\text{min}} = 1\\) bis \\(x_{\\text{max}} = 4\\) in vier Intervalle unterteilt wird und dann die Anzahl der Werte in den jewiligen Intervallen ermittelt wird (siehe Abbildung 1.8). Die ermittelte Anzahl würde dann noch durch die Gesamtanzahl \\(9\\) der Elemente geteilt um die relative Häufigkeit zu berechnen.\n\n\n\n\n\nAbbildung 1.8: Beispiel für die Darstellung eines Histogramms für die Daten \\(x_i\\).\n\n\n\n\nDie Form des Histogramms hängt davon ab wie viele Intervalle verwendet werden, so wird die Auflösung mit mehr Intervallen besser, aber es die Anzahl wird geringer und andersherum wird die Auflösung mit weniger Intervallen geringer aber die Anzahl der Elemente pro Intervall wird größer und somit stabiler. Daher sollte in den meisten praktischen Fällen die Anzahl variiert werden um sicher zu gehen, das nicht nur zufällig eine spezielle Darstellung verwendet wird.\nZurück zu unserer Verteilung von \\(D\\) unter \\(\\Delta = 100\\)N in Abbildung 1.7. Wie schon besprochen sind alle Werte zwischen etwa \\(D = -500N\\) und \\(D = 700\\)N plausibel bzw. möglich. Schauen wir uns doch einmal an, was passiert wenn das Training überhaupt nichts bringen würde und es keine Verbesserung gibt, also \\(\\Delta = 0\\).\n\n\n\n\n\nAbbildung 1.9: Verteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe wenn \\(\\Delta = 0\\) (rote Linie).\n\n\n\n\nDie Verteilung in Abbildung 1.9 sieht praktisch genau gleich aus, wie diejenige für \\(\\Delta = 100\\). Der einzige Unterschied ist lediglich das sie nach links verschoben ist und zwar scheinbar genau um die \\(100\\)N Unterschied zwischen den beiden \\(\\Delta\\)s. Dies ist letztendlich auch nicht weiter verwunderlich, bei der Berechnung des Unterschied \\(D\\) zwischen den beiden Gruppen kommen in beiden Fällen genau die gleichen Kombination vor. Bei \\(\\Delta = 100\\) wird aber zu der Interventionsgruppe das \\(\\Delta\\) dazuaddiert bevor die Differenz der Mittelwerte berechnet wird. Da aber gilt:\n\\[\nD = \\frac{1}{3}\\sum_{i=1}^3 x_{\\text{KON}i} - \\frac{1}{3}\\sum_{j=1}^3 (x_{\\text{TRT}j} + \\Delta) = \\bar{x}_{\\text{KON}} - \\bar{x}_{\\text{TRT}} + \\Delta\n\\]\nDaher bleibt die Form der Verteilung immer genau gleich und wird lediglich um den Wert \\(\\Delta\\) im Vergleich zur Nullintervention verschoben. Wobei mit Nullintervention Umgangssprachlich die Intervention bezeichnet, bei der nichts passiert also \\(\\Delta = 0\\) gilt."
  },
  {
    "objectID": "stats_basics.html#unsicherheit-in-lummerland",
    "href": "stats_basics.html#unsicherheit-in-lummerland",
    "title": "1  Eine kleine Welt der Unsicherheit",
    "section": "1.3 Unsicherheit in Lummerland",
    "text": "1.3 Unsicherheit in Lummerland\nDas führt jetzt aber zu einem Problem für uns. Gehen wir jetzt nämlich von diesen beiden Annahmen aus, das entweder die Intervention effektiv ist \\(\\Delta = 100\\) gilt oder das die Intervention nichts bringt also \\(\\Delta = 0\\) gilt. Wenn wir diese beiden Verteilungen übereinander legen erhalten wir Abbildung 1.10. Wir haben die Darstellung jetzt etwas verändert und eine Kurve durch die relativen Häufigkeiten gelegt. Dieser Graphen wird jetzt nicht mehr als Histogramm sondern als Dichtegraph bezeichnet.\n\n\n\n\n\nAbbildung 1.10: Verteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe wenn \\(\\Delta = 0\\) und \\(\\Delta = 100\\).\n\n\n\n\nIn Abbildung 1.10 ist klar zu sehen, dass die beiden Graphen zu großen Teilen überlappen und dazu noch in einem Bereich wo beide Ergebnisse ihrer höchsten relativen Häufigkeiten, also auch die größte Wahrscheinlichkeit haben unter den jeweiligen Annahmen aufzutreten. Unser Problem besteht jetzt darin, dass wir in der Realität gar nicht diese Information haben welchen Effekt unser Training auf die Stichprobe ausführt. Wenn wir dies wüssten, dann müssten wir das Experiment ja gar nicht durchführen. Wir haben im Normalfall nur ein einziges Ergebnis, nämlich den Ausgang unseres einen Experiments.\n\n\n\n\n\nAbbildung 1.11: Zuweisung eines beobachteten Unterschieds \\(D\\) nach einem Experiment\n\n\n\n\nWenn wir jetzt unser Experiment einmal durchgeführt haben und ein einziges Ergebnis für \\(D\\) erhalten haben, sei zum Beispiel \\(D = 50\\) dann haben wir ein Zuweisungsproblem (siehe Abbildung 1.11). Wie weisen wir unser Ergebnis jetzt den beiden möglichen Realität zu? Einmal kann es sein, das das Krafttraining aber auch gar nichts gebracht hat und wir haben lediglich eine der vielen möglichen Stichprobenkombination beobachtet haben die zu einem positiven Wert für \\(D\\) führt. Oder aber das Krafttraining ist effektiv gewesen und hat zu einer Verbesserung von \\(\\Delta = 100\\)N geführt und wir haben lediglich ein Stichprobenkombination aus den vielen möglichen Stichprobenkombination gezogen die zu einem Ergebnis von \\(D = 50\\) führt. Noch mal, in der Realität wissen wir nicht welche der beiden Annahmen korrekt ist und können es auch nie vollständig wissen. Denn egal wie viele Experimente wir machen, wir können immer den zwar unwahrscheinlichen aber nicht unmöglichen Fall haben, das wir nur Werte beispielsweise aus dem linken Teil der Verteilung beobachten. Das heißt wir haben immer mit einer Ungewissheit zu kämpfen. Wir können nicht im Sinne eines Beweises zeigen, das das Training effektiv ist.\nDie Methoden der Statistik liefern uns nun Werkzeuge an die Hand um trotzdem rational zu Entscheiden welche der beiden Annahmen möglicherweise wahrscheinlicher ist. Gleichzeitig ermöglicht uns die Statistik abzuschätzen respektive zu berechnen wie groß die Unsicherheit in dieser Entscheidung ist. Die Statistik sagt dabei immer nur etwas über die beobachteten Daten aus. Die Statistik sagt jedoch nichts über die zugrundeliegenden wissenschaftlichen Theorien aus.\nSchauen wir uns jetzt als vorläufig letzten Punkt an welche Entscheidungsmöglichkeiten wir haben."
  },
  {
    "objectID": "stats_basics.html#eine-entscheidung-treffen",
    "href": "stats_basics.html#eine-entscheidung-treffen",
    "title": "1  Eine kleine Welt der Unsicherheit",
    "section": "1.4 Eine Entscheidung treffen",
    "text": "1.4 Eine Entscheidung treffen\nWir hatten im Beispiel zwei verschiedene Annahmen, einmal das das Training nichts bringt und keine Verbesserung der Kraftfähigkeit folgt \\(\\Delta = 0N\\). Andererseits hatten wir das Beispiel gestartet damit, dass die Kraftfähigkeit um \\(100N\\) zunimmt, also \\(\\Delta = 100N\\). Wie bezeichnen jetzt diese beiden Annahmen als Hypothesen und bezeichnen \\(\\Delta = 0N\\) als die Nullhypothese \\(H_0\\) und \\(\\Delta = 100N\\) als die Alternativhypothese \\(H_1\\).\nWenn wir jetzt das Experiment durchgeführt haben, können wir uns also entweder für die \\(H_0\\) oder die \\(H_1\\) entscheiden. Aus Gründen der Symmetrie ist dies gleichbedeutend wenn wir uns nur auf die \\(H_0\\) fokussieren und entweder die \\(H_0\\) annehmen bzw. beibehalten oder verwerfen also uns gegen \\(H_0\\) entscheiden.\n\n\n\n\nTabelle 1.6:  Entscheidungsmöglichkeiten wenn entweder H_0 oder H_{1} zutrifft. \n \n\n\nRealität\n\n  \n     \n    $H_0$ \n    $H_1$ \n  \n \n\n  \n    $H_0$ \n    korrekt \n    $\\beta$ \n  \n  \n    $H_1$ \n    $\\alpha$ \n    korrekt \n  \n\n\n\n\n\n\nIn Tabelle 1.6 sind die verschiedenen Entscheidungsmöglichkeiten abgetragen. In der Realität gehen wir, wie gesagt, von zwei Fällen aus. Entweder trifft die \\(H_0\\) oder die \\(H_1\\) zu. Wenn die \\(H_=\\) zutrifft und wir uns für die \\(H_0\\) entscheiden, dann haben wir eine korrekte Entscheidung getroffen. Wenn \\(H_0\\) zutrifft und wir allerdings die \\(H_0\\) ablehnen, also uns für die \\(H_1\\) entscheiden ist unsere Entscheidung falsch und wir begehen einen Fehler. Dieser Fehler wird als Fehler 1. Art bzw. \\(\\alpha\\)-Fehler bezeichnet. Trifft in der Realität dagegen die \\(H_1\\) zu und wir entscheiden uns gegen die \\(H_0\\) und für die \\(H_1\\), dann haben wir wiederum eine korrekte Entscheidung getroffen. Zuletzt, wenn die \\(H_1\\) zutrifft und wir uns aber für die \\(H_0\\) entscheiden, also die \\(H_0\\) beibehalten bzw. uns gegen die \\(H_1\\) entscheiden, treffen wir wieder eine falsche Entscheidung. Dieser Fehler wird als Fehler 2. Art, bzw. \\(\\beta\\)-Fehler bezeichnet.\n\nDefinition 1.8 Wenn eine Entscheidung gegen die \\(H_0\\) getroffen wird, obwohl die \\(H_0\\) korrekt ist, wird dies als \\(\\alpha\\)-Fehler bezeichnet.\n\n\nDefinition 1.9 Wenn eine Entscheidung gegen die \\(H_1\\) getroffen wird, obwohl die \\(H_1\\) korrekt ist, wird dies als \\(\\beta\\)-Fehler bezeichnet.\n\n\n\n\n\nWild, Christopher J, und Georg AF Seber. 2000. Chance encounters: A first course in data analysis and inference. Wiley Press."
  },
  {
    "objectID": "stats_significance.html",
    "href": "stats_significance.html",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "",
    "text": "3 Parameterschätzung"
  },
  {
    "objectID": "stats_significance.html#wie-treffe-ich-eine-entscheidung",
    "href": "stats_significance.html#wie-treffe-ich-eine-entscheidung",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.1 Wie treffe ich eine Entscheidung?",
    "text": "2.1 Wie treffe ich eine Entscheidung?\nIn unserem kleine Welt Bespiel waren wir in der komfortablen Position, das wir genau wussten was passiert bzw. welcher Prozess unseren beobachteten Datenpunkt erzeugt hat. D.h wir kannten den datengenerieren Prozesses.\n\nDefinition 2.1 (Datengenerierender Prozess (DGP)) Der Prozess in der realen Welt der die beobachteten Daten und damit die daraus folgende Statistik erzeugt wird als datengenerierender Prozess bezeichnet.\n\nLetztendlich zielt unsere Untersuchung, unser Experiment, darauf ab, Informationen über den DGP zu erhalten, weil diese Information uns erlaubt Aussagen über die reale Welt zu treffen. Dabei muss allerdings beachtet werden, dass dieser Prozess in den allermeisten Fällen ein starke Vereinfachung des tatsächlichen Prozesses in der Realität darstellt. Meistens sind die Abläufe in der Realität zu komplex um sie ins Gänze abzubilden. Somit wird fast immer nur ein Modell verwendet.\nZurück zu unseren Problem, wenn wir ein Experiment durchführen, dann haben wir normalerweise nur eine einzige beobachtete Statistik. In unseren bisherigen Beispiel also den berechneten Unterschied \\(D\\) in der Kraftfähigkeit nach der Intervention zwischen der Kontroll- und der Interventionsgruppe.\n\n\n\n\n\nAbbildung 2.1: Beobachteter Unterschied nach der Durchführung unseres Experiments\n\n\n\n\nIn Abbildung 2.1 ist der beobachtete Wert, \\(D = 50\\) abgetragen. Wir wissen von vorne herein, dass dieser Wert beeinflusst ist durch die zufällige Wahl der Stichprobe und die daran geknüpfte Streuung der Werte in der Population. Wie können wir den nun überhaupt eine Aussage treffen darüber, ob das Krafttraining was bringt oder vielleicht nur einen sehr kleinen Effekt zeigt oder möglicherweise sogar schädlich ist also zu einer Abnahme der Kraft führt?\nÜberlegen wir uns zunächst, welche Prozesse unseren beobachteten Wert zustande gebracht haben könnten. Wir haben schon zwei Prozesse kennengelernt, einmal den Prozess mit \\(\\Delta = 100\\) wie auch den Prozess mit \\(\\Delta = 0\\)\n\n\n\n\n\nAbbildung 2.2: Mögliche datengenerierende Prozesse für den beobachteten Unterschied \\(D\\) (rot)\n\n\n\n\nIn Abbildung 2.2 ist wieder unser beobachteter Wert \\(D = 50\\) und die beiden Verteilungen abgetragen. Leider können wir nicht eineindeutig sagen, welche der beiden Verteilungen, bzw. deren zugrundeliegende Prozesse, unseren beobachteten Wert erzeugt haben könnte. Da unser beobachteter Wert \\(D\\) genau zwischen den beiden Maxima der Verteilungen liegt. Etwas motiviertes Starren auf die Abbildung wird uns allerdings auf die Idee bringen, dass der beobachtete Wert nicht nur von diesen beiden Verteilungen erzeugt worden sein muss, sondern durchaus noch mehr Verteilungen in Frage kommen.\n\n\n\n\n\nAbbildung 2.3: Beispiele für weitere mögliche Verteilungen als DGP.\n\n\n\n\nAbbildung 2.3 zeigt, dass selbst die Verteilung mit \\(\\Delta = -250N\\) und \\(\\Delta = 350N\\) nicht unplausibel sind den beobachteten Wert erzeugt zu haben. Warum aber bei diesen fünf Verteilungen aufhören, warum sollte \\(Delta\\) nicht \\(-50\\) oder \\(127\\) sein. Und überhaupt, keiner kann behaupten die Natur kennt nur ganzzahlige Werte (siehe \\(\\pi\\)). Warum sollte \\(D\\) also nicht auch \\(123.4567N\\) sein?\nWenn diese Überlegung weitergeführt wird, dann wird schnell klar, dass letztendlich eine unendliche Anzahl von Verteilung in der Lage ist unseren beobachteten Wert plausibel zu generieren. D.h. wir haben ein Experiment durchgeführt und den ganzen Aufwand betrieben und haben wochenlang mit unseren ProbandInnen Krafttraining durchgeführt und sind hinterher eigentlich keinen Schritt weiter da wir immer noch nicht wissen was der datengenerierende Prozess ist. Also können wir selbst nach dem Experiment nicht sagen ob unser Krafttraining tatsächlich wirksam ist.\nZum Glück werden wir später sehen, das unser Unterfangen nicht ganz so aussichtslos ist. Schauen wir uns zum Beispiel die Verteilung für \\(\\Delta = -350N\\) an (Abbildung 2.4).\n\n\n\n\n\nAbbildung 2.4: Verteilung für \\(\\Delta = -350N\\) und der beobachtete Wert \\(D\\)\n\n\n\n\nUnser beobachteter Wert unter der Annahme das \\(\\Delta = -350N\\) ist nicht vollkommen unmöglich, aber so richtig wahrscheinlich erscheint er auch nicht. Der Wert liegt relativ weit am Rand der Verteilung. Die Kurve ist dort schon ziemlich nahe bei Null. D.h. der beobachtete Wert ist zwar durchaus möglich, aber es wäre schon überraschend wenn wir bei einer Durchführung des Experiments ausgerechnet so einen Wert beobachten würden wenn unsere angenommenes \\(\\Delta\\) korrekt ist.\nWenn wir jetzt dagegen von der Annahme ausgehen, dass dem DGP der Wert \\(\\Delta = 50N\\) zugrundeliegen würde, hätten wir die Verteilung in Abbildung 2.5. Zunächst ist dieser Wert möglich unter der Annahme. Zusätzlich liegt der beobachtete Wert mitten drin in dem Teil der Verteilung der auch zu erwarten wäre. D.h. der beobachtete Wert ist durchaus plausibel unter der Annahme und bei der einmaligen Durchführung des Experiments würde uns der beobachtete Wert nicht unbedingt überraschen.\n\n\n\n\n\nAbbildung 2.5: Verteilung für \\(\\Delta = 50N\\) und der beobachtete Wert \\(D\\)\n\n\n\n\nDiesen Ansatz können wir verwenden um mit Hilfe unseres Experiments doch etwas über den DGP auszusagen. Allerdings müssen wir uns noch einmal etwas eingehender mit Verteilungen auseinandersetzen um z.B. genauer zu bestimmen welche Ergebnisse uns überraschen würden. D.h. wir müssen uns erst ein mal ein paar neue Konzepte erarbeiten."
  },
  {
    "objectID": "stats_significance.html#die-verteilung---1.-deep-dive",
    "href": "stats_significance.html#die-verteilung---1.-deep-dive",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.2 Die Verteilung - 1. deep dive",
    "text": "2.2 Die Verteilung - 1. deep dive\nWir versuchen jetzt als erstes zu Verstehen was nochmal genau der Graph der Verteilung bedeutet. Auf der x-Achse werden die verschiedenen möglichen Werte der jeweiligen Statistik abgebildet. In unserem bisherigen Beispiel was das die Unterschiede \\(D\\) zwischen der Kontroll- und der Treatmentgruppe. Der Wert auf der y-Achse was zunächst die relative Häufigkeit was auch Sinn gemacht hatte, da wir nur eine bestimmte endliche Anzahl von möglichen Unterschieden \\(D\\) (ihr erinnert auch an die Zahl) vorliegen hatten. Was passiert aber wenn wir tatsächlich eine kontiuierliche Statistik haben, also eine Statistik die alle Werte innerhalb eines Intervalls einnehmen kann. Um den Fall zu verstehen fangen wir aber erst mal wieder mit einem einfachen Modell an.\n\n2.2.1 Der Münzwurf\nWir fangen mit dem einfachsten Experiment an: dem Münzwurf. Beim Münzwurf haben wir zwei mögliche Ausgänge unseres Experiments, entweder Kopf oder Zahl. Wir gehen von einer perfekten Münze aus, d.h. die Münze ist vollkommen symmetrisch auf beiden System und keine der Seiten ist in irgendeiner Form schwere oder beeinflusst in einer Art den Ausgang.\nWenn wir uns an die Schule zurück erinnern, dann haben wir in Wahrscheinlichkeitstheorie schon mal was gehört, das im Fall gleichwahrscheinlicher Ereignisse die Wahrscheinlichkeit für ein bestimmtes Ereignis, mittels der Anzahl der vorteilhaften Ausgänge geteilt durch die Anzahl der möglichen Ausgänge berechnet wird. Also beim einmaligen Münzwurf haben wir zwei Ausgänge \\(\\{\\text{Kopf}, \\text{Zahl}\\}\\) und jeweils nur vorteilhaften Ausang als entweder Kopf oder Zahl, daher folgt daraus.\n\\[\\begin{align}\nP(\\text{Kopf}) &= \\frac{1}{2} \\\\\nP(\\text{Zahl}) &= \\frac{1}{2}\n\\end{align}\\]\nWenn wir das jetzt als Graphen in Form einer Wahrscheinlichkeitsverteilung abtragen, dann sieht das noch wenig interessant aus (siehe Abbildung 2.6). Das Muster ist aber trotzdem wichtig, damit wir später wissen worauf wir hier eigentlich schauen. Auf der x-Achse haben wir die möglichen Ausgänge, Kopf oder Zahl, und auf der y-Achse haben wir die Wahrscheinlichkeit abgetragen.\n\n\n\n\n\nAbbildung 2.6: Wahrscheinlichkeitsverteilung des einmaligen Münzwurfes\n\n\n\n\nDa sich mit einem Münzwurf aber so wenig anfangen lässt, machen wir das Ganze jetzt etwas komplizierter und schauen uns an, wie unser Experiment aussieht wenn wir zwei Münzwwürfe uns anschauen. Rein operational, wir schmeißen unsere Münze in die Luft, schreiben uns das Ergebnis auf, und machen das Ganze noch ein zweites Mal und schreiben uns das Ergebnis auf. D.h. was auch immer im ersten Durchgang passiert, hat keine Auswirkungen auf das Ergebnis des zweiten Wurfs. Wir könnten auch zwei Münzen nehmen und beide gleichzeitig in die Luft werfen. Das wäre das gleiche Experiment. Welche Ausgänge haben wir jetzt beim zweimaligen Münzwurf? Zunächst einmal haben wir jetzt nicht mehr nur einen einzelnen Ausgang sondern wir haben ein Ausgangstupel, eine Liste mit zwei Elementen. Etwas motiviertes krizteln auf einem Schmierblatt wird wahrscheinlich relativ schnell zu folgender Tabelle führen (siehe Tabelle 2.1)\n\n\nTabelle 2.1: Mögliche Ausgänge bei einem zweimaligen Münzwurf\n\n\nAusgang 1. Wurf\nAusgang 2. Wurf\nTupel\n\n\n\n\nKopf\nKopf\n(Kopf, Kopf)\n\n\nKopf\nZahl\n(Kopf, Zahl)\n\n\nZahl\nKopf\n(Zahl, Kopf)\n\n\nZahl\nZahl\n(Zahl, Zahl)\n\n\n\n\nJetzt können wir uns wieder fragen, was die Wahrscheinlichkeit für die jeweiligen Ereignistupel ist. Eine direkte Methode wäre, wieder mittels der Symmetrie zu argumentieren. Es gibt vier verschiedene Ausgänge von denen jetzt keiner in irgendeiner Weise bevorzugt ist, daraus würde folgen das alle vier Ausgänge eine Wahrscheinlichkeit von \\(P = \\frac{1}{4}\\) haben.\nEine weitere Möglichkeit wäre mit den Wahrscheinlichkeiten aus dem einfachen Wurf an das Problem heran zu gehen. Wir betrachten die beiden Münzwürfe jetzt wieder sequentiell (siehe Abbildung 2.7). Im ersten Schritt können wir entweder Kopf oder Zahl beobachten. Beide Wahrscheinlichkeiten sind \\(P = \\frac{1}{2}\\). Darauf folgend können wir wieder zwei verschiedene Ausgänge beobachten, eben Kopf oder Zahl, wieder mit der Wahrscheinlichkeit \\(P = \\frac{1}{2}\\).\n\n\n\n\n\nflowchart TD\n    A[Start] --&gt; B(Kopf)\n    A --&gt; C(Zahl)\n    B --&gt; D(Kopf)\n    B --&gt; E(Zahl)\n    C --&gt; F(Kopf)\n    C --&gt; G(Zahl)\n\n\nAbbildung 2.7: Auswahlmöglichkeiten beim sequentiellen zweimaligen Münzwurf\n\n\n\n\nDa die Münzwürfe voneinander unabhängig sind und keinen Einfluss aufeinander ausüben, folgt daraus, dass die Wahrscheinlichkeiten für jede spezielle Folge von Kopf oder Zahl sich berechnet nach:\n\\[\nP(\\text{Ausgang}) = P(\\text{1. Wurf}) \\times P(\\text{2. Wurf})\n\\tag{2.1}\\]\nAlso in unseren Fall:\n\\[\nP(\\text{Ausgang}) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\n\\tag{2.2}\\]\nWomit wir wieder beim gleichen Ergebnis wie vorher angekommen sind. Der Vorteil dieser Herangehensweise ist jedoch, dass wir damit eine einfache Möglichkeit gefunden haben das Ergebnis auf mehr als nur zwei Würfe zu verallgemeinern. Nehmen wir zum Beispiel den dreifachen Münzwurf, dann können wir die Wahrscheinlichkeit für die Folge \\(P(\\text{KKZ}) = \\frac{1}{2}\\times \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{8}\\) direkt angeben.\nBleiben wir aber erst noch mal kurz beim zweimaligen Münzwurf und schauen uns die Wahrscheinlichkeitsverteilung an. Hier stoßen wir nämlich auf ein Problem in der Darstellung. Wenn wir bei dem Muster aus Abbildung 2.6 bleiben wollen und auf der x-Achse die möglichen Ergnisse und auf der y-Achse die dazugehörende Wahrscheinlichkeit abtragen wollen, dann ist nicht ganz klar wie wir die Ergebnisse ordnen sollen. Eine mögliche Lösung ist in Abbildung 2.8 zu sehen.\n\n\n\n\n\nAbbildung 2.8: Wahrscheinlichkeitsverteilung des zweimaligen Münzwurfes (K: Kopf, Z: Zahl)\n\n\n\n\nDies ist natürlich nicht die einzige Möglichkeit wie wir die Ereignisse ordenen können sondern wahrscheinlich ist jede der 24 möglichen Anordnungen gleich sinnig. Wir könnten auch beispielsweise nicht mehr die beiden einzelnen Ausgänge als Ereignisse wählen, sondern könnten zum Beispiel nur noch die Anzahl der Köpfe in unseren zwei Würfen zählen. Dies würde zu der folgenden Zuordnung führen (siehe Tabelle 2.2).\n\n\nTabelle 2.2: Zuordnung der Anzahl der Köpfe zu den Ereignissen beim zweimaligen Münzwurf\n\n\nEreignisse\nAnzahl der Köpfe\n\n\n\n\n(Kopf, Kopf)\n2\n\n\n(Kopf, Zahl)\n1\n\n\n(Zahl, Kopf)\n1\n\n\n(Zahl, Zahl)\n0\n\n\n\n\nWir verliegen bei dieser Zuordnung nachtürlich die Information bei welchem Wurf die Zahl beobachtet wurde, aber eigentlich interessiert uns das sowieso nicht so brennend. In der Terminologie der Wahrscheinlichkeitstheorie wird die Anzahl der Köpfe als Zufallsvariable bezeichnet.\n\nDefinition 2.2 (Zufallsvariable) Eine Zufallsvariable ist die Abbildung eines Zufallsereignisses auf eine Zahl.\n\nAnders dargestellt, ist eine Zufallsvariable eine Funktion, die einem Ereignis eine Zahl zuordnet (siehe Abbildung 2.9.\n\n\n\n\n\nflowchart LR \n    A[Ereignis] --&gt; B(Zahl)\n\n\nAbbildung 2.9: Abbildung des Ereignisses auf eine Zahl\n\n\n\n\nWenn wir uns jetzt die Wahrscheinlichkeiten für unsere Zufallsvariable anschauen, dann sehen wir aber, dass wir nicht mehr vier verschiedne Ausgänge haben, sondern nur noch drei und das die gleiche Wahrscheinlichkeit für nicht gleich sind.\n\n\nTabelle 2.3: Wahrscheinlichkeitstabelle für Zufallsvariable “Anzahl der Köpfe beim zweimaligen Münzwurf”.\n\n\n\n\n\n\n\nEreignisse\nZufallsvariale\nWahrscheinlichkeit\n\n\n\n\n(Zahl, Zahl)\nKeine Köpfe\n\\(\\frac{1}{4}\\)\n\n\n(Kopf, Zahl)(Zahl,Kopf)\n1 Kopf\n\\(\\frac{1}{4} + \\frac{1}{4} = \\frac{1}{2}\\)\n\n\n(Kopf,Kopf)\n2 Köpfe\n\\(\\frac{1}{4}\\)\n\n\n\n\nJetzt können wir wieder eine Wahrscheinlichkeitsverteilung für unsere Zufallsvariable abtragen (siehe Abbildung 2.10).\n\n\n\n\n\nAbbildung 2.10: Wahrscheinlichkeitsverteilung für die Anzahl der Köpfe beim zweimaligen Münzwurf\n\n\n\n\nNur um nebenbei noch einmal das offensichtliche Anzusprechen. Die Summe aller Wahrscheinlichkeiten aller Ereignisse muss \\(1\\) sein. Das sollte auch direkt einsichtig sein. Wenn ich alle möglichen Ereignisse abfrage also: “Was ist die Wahrscheinlichkeit das ich keine Köpfe, 1 Kopf oder 2 Köpfe beim zweimaligen Münzwurf erhalte”, dann sind das alle möglichen Ausgänge und dementsprechend sollte die Wahrscheinlichkeit dafür “1” sein oder mathematisch ausgedrückt:\n\\[\nP(\\text{0 Köpfe} \\cup \\text{1 Kopf} \\cup \\text{2 Köpfe}) = \\frac{1}{4} + \\frac{1}{2} + \\frac{1}{4} = 1\n\\]\nJetzt gehen wir zum nächst komplizierteren Fall. Die Anzahl der Köpfe bei drei Münzwürfen. Welche Möglichkeiten gibt es hier? Nun bei drei Würfen kann entweder \\(0, 1, 2\\) oder \\(3\\) Kopf auftreten. Wenn wir die Wahrscheinlichkeiten für diese vier Ereignisse berechnen wollen, können wir aber nicht einfache \\(\\frac{1}{4}\\) für jedes Ereignis als Wahrscheinlichkeit ansetzen (Warum?). Schauen wir uns erst einmal wieder die möglichen Tupel, oder auch die Elemenarereignisse, den wir erinnern uns, dass die Anzahl der Köpfe eine Zufallsvariable ist. Also eine Abbildung der 3-fach Tupel auf eine der Zahlen \\(\\{0, 1, 2, 3\\}\\).\n\n\nTabelle 2.4: Abbildung der 3-fach Tupel auf die Anzahl Kopf beim dreifachen Münzwurf\n\n\nElementarereignis\nAnzahl Kopf\n\n\n\n\n(Z,Z,Z)\n\\(0\\)\n\n\n(K,Z,Z)\n\\(1\\)\n\n\n(Z,K,Z)\n\\(1\\)\n\n\n(Z,Z,K)\n\\(1\\)\n\n\n(K,K,Z)\n\\(2\\)\n\n\n(Z,K,K)\n\\(2\\)\n\n\n(K,Z,K)\n\\(2\\)\n\n\n(K,K,K)\n\\(3\\)\n\n\n\n\nDie Elementarereignisse in Tabelle 2.4 sind wieder alle gleichwahrscheinlich, daher können wir jetzt wieder einfache abzählen. Es gibt insgesamt \\(8\\) mögliche Ausgänge, davon haben jeiweils einer \\(0\\)-mal oder \\(3\\)-mal Kopf und jeweils \\(3\\) Ausgänge haben \\(1\\)-mal oder \\(2\\)-mal Kopf. Daraus folgt für die Wahrscheinlichkeitsfunktion (siehe Tabelle 2.5).\n\n\nTabelle 2.5: Wahrscheinlichkeitsfuntion für den dreifachen Münzwurf\n\n\nAnzahl Kopf\nP\n\n\n\n\n\\(0\\)\n\\(\\frac{1}{8}\\)\n\n\n\\(1\\)\n\\(\\frac{3}{8}\\)\n\n\n\\(2\\)\n\\(\\frac{3}{8}\\)\n\n\n\\(3\\)\n\\(\\frac{1}{8}\\)\n\n\n\n\nDas Ganze auch wieder als Graph (siehe ?fig-sts-coin-toss-3)\n\n\n\n\n\nAbbildung 2.11: Wahrscheinlichkeitsverteilung für die Anzahl der Köpfe beim dreimaligen Münzwurf\n\n\n\n\nBleiben wir noch einmal kurz bei dem Beispiel und versuchen uns die Wahrscheinlichkeiten anders herzuleiten. Sollten wir zum Beispiel einmal in die Verlegenheit kommen und 20 Münzwürfe untersuchen wollen, dann wir die Tabelle relative schnell relativ unhandlich.\nSei \\(N\\) die Anzahl der Würfe die wir durchführen. Wenn wir \\(N\\) kennen, wissen wir auch direkt welche möglichen Ausgänge bei dem Experiment möglich sind, nämlich alle Zahlen zwischen \\(0\\) und \\(N\\). \\(0\\) wenn wir kein Kopf geworfen haben, und \\(N\\) wenn wir nur Kopf geworfen haben. Dementsprechend sind alle Zahlen dazwischen auch noch möglich.\nSchauen wir uns jetzt noch mal den dreimaligen Münzwurf an. Wenn wir kein Kopf werfen in \\(3\\) Würfen und betrachten die Würfe wieder sequentiell, dann haben wir \\(\\frac{1}{2}\\) für die erste Zahl, \\(\\frac{1}{2}\\) für die zweite Zahl und \\(\\frac{1}{2}\\) für die dritte Zahl. Also insgesamt \\(P(1 \\text{ Kopf}) = \\frac{1}{2} \\times \\frac{1}{2}\\times \\frac{1}{2} = \\frac{1}{8}\\). Aber diese Wahrscheinlichkeit hat ja jedes Elementarereignis egal ob es (K,K,K) oder (K,Z,K) oder (Z,Z,K) usw. ist. Jetzt haben wir aber das Problem, das wir für \\(1\\times\\) oder \\(2\\times\\) Kopf nicht nur eine Möglichkeit vorhanden diese Anzahl an Kopf zu beobachten. In Tabelle 2.4 haben wir bereits gezeigt, dass jeweils drei verschiedene Möglichkeiten, Kombination von Kopf und Zahl, möglich sind. D.h. wir haben jetzt ein Abzählproblem. Können wir irgendwie direkt bestimmen wie viele unterschiedliche Möglichkeiten es gibt?\nSchauen wir uns den Fall \\(1\\times\\) Kopf im 3-fach Tupel an. Auf wie viele Arten können wir 3-fach Tupel erzeugen mit nur einem Kopf. Nun, der Kopf ist entweder an der ersten, der zweiten oder der dritten Stelle und die jeweils anderen Position im Tupel sind mit Zahl besetzt. Das hört sich aber ähnlich wie ein Problem an wie wie etwas was wir schon vorher einmal gehört haben. Als wir uns die Anzahl der möglichen Stichproben aus unserer kleinen Welt angeschaut haben. Dort hatten wir das Problem, das wir bestimmen wollten auf wie viele Möglichkeiten wir zwei Stichproben mit jeweils drei Personen aus 20 Personen ziehen können. Dabei sind wir auf den Binomialkoeffizienten gestoßen Gleichung 1.3.\n\\[\n\\text{Anzahl} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\]\nFormal berechnet der Binomialkoeffizient die Möglichkeiten \\(k\\) Objekte aus \\(n\\) Objekten zu ziehen. Wenden wir das mal auf unseren Dreifachwurf an mit \\(n = N = 3\\) und \\(k = 1\\). Ausgeschrieben, auf wie viele Arten können wir \\(1\\times\\) Kopf aus drei Positionen auswählen.\n\\[\n\\text{Kombinationen mit }1\\times\\text{ Kopf} = \\binom{3}{1} = \\frac{3!}{1!(3-1)!} = \\frac{3\\times 2 \\times 1}{1\\times 2 \\times 1} = 3\n\\]\nPasst. Probieren wir das auch direkt mit dem Ereignis \\(2\\times\\) Kopf, also mit \\(N = 3\\) und \\(k = 2\\), aus.\n\\[\n\\text{Kombinationen mit } 2\\times \\text{ Kopf} = \\binom{3}{2} = \\frac{3!}{2!(3-2)!} = \\frac{3\\times 2 \\times 1}{2\\times 1 \\times 1} = 3\n\\]\nPasst auch. Jetzt müssen wir noch nur die beiden Fälle \\(0\\times\\) und \\(3\\times\\) Kopf behandeln. Wenn wir in einem Mathebuch den Binomialkoeffizienten nachschlagen, dann sind dort die beiden folgenden Definition zu finden für die Fälle \\(k=0\\) und \\(k=n\\).\n\\[\\begin{align*}\n\\binom{N}{N} &= 1 \\\\\n\\binom{N}{0} &= 1\n\\end{align*}\\]\nWenn wir diese Definition für die anderen beiden verbleibenden Fälle anwenden, erhalten wir:\n\\[\\begin{align*}\n\\text{Kombinationen mit } 0\\times \\text{ Kopf} &= \\binom{3}{0} = 1 \\\\\n\\text{Kombinationen mit } 3\\times \\text{ Kopf} &= \\binom{3}{3} = 1\n\\end{align*}\\]\nDamit können wir nun für alle möglichen Ausgängen die Anzahl der möglichen Elementarereignisse mittels bestimmen. Allgemein erhalten wir dadurch eine Formel für die Wahrscheinlichkeiten der Ereignisse für den dreifachen Münzwurf.\n\\[\nP(k \\times \\text{Kopf}) = \\binom{3}{k} \\frac{1}{2} \\times \\frac{1}{2} \\times \\frac{1}{2} = \\binom{3}{k} \\left(\\frac{1}{2}\\right)^3\n\\tag{2.3}\\]\nWeil wir natürlich sofort nach einer allgemeinen Lösung streben führen wir jetzt noch ein paar Symbole ein. Die Zufallsvariable, also die Anzahl von Kopf, bezeichnen wir mit dem Großbuchstaben \\(Y\\). Einen speziellen Ausgang bezeichnen wir mit dem Kleinbuchstaben \\(y\\). Damit würden allgemein die Wahrscheinlichkeit für irgend eines der Ereignisse mit \\(Y = y\\) bezeichnen. Und wenn wir sagen wir das Ereignis \\(2\\times\\) Kopf bezeichnen, mit \\(y = 2\\). Also, die Wahrscheinlichkeit für \\(3\\times\\) Kopf mit:\n\\[\nP(Y = 3) = \\binom{3}{3}\\left(\\frac{1}{2}\\right)^3\n\\]\nDie nächste Verallgemeinerung die wir Vornehmen ist dass wir für die Wahrscheinlichkeit das Kopf auftritt das Symbol \\(p\\) benutzen. So könnten wir auch modellieren, wenn wir eine unfaire Münze haben. Wenn jetzt aber \\(p \\neq \\frac{1}{2}\\) gilt, also zum Beispiel die Wahrscheinlichkeit für Kopf \\(p = \\frac{2}{3}\\) wäre, dann ist die Wahrscheinlichkeit für Zahl nicht mehr die Gleiche wie für Kopf. Die Wahrscheinlichkeit für Zahl wäre dann \\(1 - p\\). Wenn wir für die Wahrscheinlichkeit für das Auftreten von Zahl das Symbol \\(q\\) einführen, muss die Wahrscheinlichkeit für Kopf oder Zahl gleich \\(1\\) sein, formal:\n\\[\np + q = 1\n\\] Daraus folgt, dass \\(q = p - 1\\). Wenn wir das auf unseren Münzwurf übertragen, müssen wir das dementsprechend berücksichtigen. Wir können uns aber zunutze machen, dass wir wissen wie viele Würfe durchgeführt wurden, nämlich \\(N\\), und wie viele davon Kopf waren, nämlich \\(y\\). Damit wissen wir automatisch auch die Anzahl von Zahl, \\(N - y\\). Jede Kopf, hat die Wahrscheinlichkeit \\(p\\) und jede Zahl hat die Wahrscheinlichkeit \\(q = 1 - p\\) und das gilt unabhängig von der Reihenfolge, da z.B. \\(ppqp = qppp\\) ist. Insgesamt haben wir \\(y \\times p\\) und \\((n-y) \\times q\\) also \\(p^y\\) und \\(q^{n-y}\\). Das können wir jetzt alles in eine Formel stecken.\n\\[\nP(Y = y) = \\binom{N}{y}p^y (1-p)^{N-y} = \\binom{N}{y}p^y q^{N-y}\n\\tag{2.4}\\]\nDamit haben wir jetzt auch direkt unsere erste mathematische Verteilung kennengelernt, die in der Statistik eine zentrale Rolle spielt, die Binomialverteilung. Es handelt sich hier um eine Familie von Verteilungen, da jeweils für verschiedene \\(N\\) und \\(p\\) eine eigene Verteilung vorliegt. Schauen wir uns aber noch mal ob wir mit den ganzen Symbolen wirklich unseren dreifachen Münzwurf zurückbekommen. Es gilt \\(N = 3, p = \\frac{1}{2}\\). Daraus folgt das \\(q = 1 - p = 1 - \\frac{1}{2}=\\frac{1}{2}\\). Wenn wir uns jetzt noch an \\(x^a x^b = x^{a+b}\\) aus der Schule erinnern folgt:\n\\[\\begin{align*}\nP(Y = 0) &= \\binom{3}{0} \\left(\\frac{1}{2}\\right)^{0}\\left(\\frac{1}{2}\\right)^3 = \\binom{3}{0}\\left(\\frac{1}{2}\\right)^3 = 1 \\left(\\frac{1}{2}\\right)^3 \\\\\nP(Y = 1) &= \\binom{3}{1} \\left(\\frac{1}{2}\\right)^{1}\\left(\\frac{1}{2}\\right)^2 = \\binom{3}{1}\\left(\\frac{1}{2}\\right)^3 = 3 \\left(\\frac{1}{2}\\right)^3 \\\\\nP(Y = 2) &= \\binom{3}{0} \\left(\\frac{1}{2}\\right)^{2}\\left(\\frac{1}{2}\\right)^1 = \\binom{3}{2}\\left(\\frac{1}{2}\\right)^3 = 3 \\left(\\frac{1}{2}\\right)^3 \\\\\nP(Y = 3) &= \\binom{3}{0} \\left(\\frac{1}{2}\\right)^{3}\\left(\\frac{1}{2}\\right)^0 = \\binom{3}{3}\\left(\\frac{1}{2}\\right)^3 = 1 \\left(\\frac{1}{2}\\right)^3 \\\\\n\\end{align*}\\]\n\n\n2.2.2 Lage- und Skalenparameter\nIn Abbildung 2.3 sind verschiedene Verteilungen abgebildet die sich eigentlich nur in ihrer Position bzw. Lage unterscheiden. Der Parameter der bei einer Verteilungen die Lage steuert ist der Mittelwert den wir bereits schon kennengelernt haben. Hier jetzt aber nicht der Mittelwert \\(\\bar{x}\\) in der Stichprobe, sondern der Mittelwert der zugrundeliegenden Population der dann mit dem Symbol \\(\\mu\\) bezeichnet wird. Die Beschreibung als Parameter der Verteilung heißt nichts anderes das die Verteilung von \\(\\mu\\) abhängt, oder formal das die Verteilung eine Funktion von \\(\\mu\\) ist. Wenn wir uns an Funktionen aus der Schule zurück erinnen wo wir Funktionen \\(f\\) von \\(x\\) kennengelernt haben und als \\(f(x)\\) dargestellt haben. Übertragen auf die Verteilung könnte dies mittels \\(f(\\mu)\\) dargestellt werden.\nNehmen wir nun zwei Verteilungen die sich bezüglich ihrer Mittelwerte \\(\\mu\\) unterscheiden. Zum Beispiel sei \\(\\mu_1 = 0\\) und \\(\\mu_2 = 3\\). Wie in Abbildung 2.12 zu sehen ist, führt dies dazu, das die beiden Verteilungen gegeneinander verschoben sind.\n\n\n\n\n\nAbbildung 2.12: Verteilungen mit zwei unterschiedlichen Mittelwerten\n\n\n\n\nDer Mittelwert \\(\\mu\\) der Verteilung wird auch als Erwartungswert bezeichnet. Dies kann dahingehend interpretiert werden, das wenn Stichproben aus dieser Verteilungen gezogen werden, im Mittel der Wert \\(\\mu\\) erwartet wird. Soweit ist dies eigentlich noch nichts wirklich Neues, sondern hatten dies schon vorher gesehen, als wir alle möglichen Unterschiede zwischen der Kontrollgruppe und der Interventionsgruppe ermittelt haben. Hier war der Mittelwert der Verteilung genau derjenige Wert von \\(\\Delta\\).\nAn dieser Stelle sollte nochmal der Unterschied zwischen \\(\\mu\\) und \\(\\bar{x}\\) klargestellt werden. Der Mittelwert \\(\\mu\\) ist eine Eigenschaft der Population, also letztendlich ein Wert den wir niemals kennen werden ohne die gesamte Population zu untersuchen. Der Mittelwert \\(\\bar{x}\\) ist eine Eigenschaft der Stichprobe aus der Population. Also der konkrete Wert den wir anhand der Stichprobe berechnen. In vielen Fällen versuchen wir über \\(\\bar{x}\\) einen Rückschluss auf \\(\\mu\\) zu ziehen.\nAls zweite Eigenschaft von Verteilungen schauen wir uns jetzt die Streuung in der Population an. Die Streuung in der Population wird als Varianz bezeichnet und wird mit dem Symbol \\(\\sigma^2\\) bezeichnet. Schauen wir uns zunächst an, welchen Einfluss \\(\\sigma^2\\) auf die Form der Verteilung hat. In Abbildung 2.13 sind wieder zwei Verteilungen abgetragen. Dieses Mal ist \\(\\mu\\) in beiden Fällen gleich, aber die Varianzen \\(\\sigma\\) sind mit \\(\\sigma_1^2 = 2\\) und \\(\\sigma_2^2=1\\) unterschiedlich.\n\n\n\n\n\nAbbildung 2.13: Verteilungen mit unterschiedlichen Varianzen\n\n\n\n\n1"
  },
  {
    "objectID": "stats_significance.html#formeln",
    "href": "stats_significance.html#formeln",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.3 Formeln",
    "text": "2.3 Formeln\nn := Anzahl der Stichprobenelemente, \\(x_i\\) := Messwerte"
  },
  {
    "objectID": "stats_significance.html#nebenbei-warum-der-mittelwert-sinn-macht",
    "href": "stats_significance.html#nebenbei-warum-der-mittelwert-sinn-macht",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.4 Nebenbei: Warum der Mittelwert Sinn macht",
    "text": "2.4 Nebenbei: Warum der Mittelwert Sinn macht\n\n\n\n\n\nVerteilung der Mittelwerte von Stichproben der Größe \\(n=10\\), Kleine Welt Population \\(\\mu\\) (rot)"
  },
  {
    "objectID": "stats_significance.html#mit-der-verteilung-die-annimmt-das-nichts-passiert",
    "href": "stats_significance.html#mit-der-verteilung-die-annimmt-das-nichts-passiert",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.5 Mit der Verteilung die annimmt das nichts passiert!",
    "text": "2.5 Mit der Verteilung die annimmt das nichts passiert!\n\n\n\n\n\nVerteilung wenn nichts passiert.\n\n\n\n\n\n\n\n\n\nQuantilefunktion wenn nichts passiert."
  },
  {
    "objectID": "stats_significance.html#signifikanter-wert",
    "href": "stats_significance.html#signifikanter-wert",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.6 Signifikanter Wert",
    "text": "2.6 Signifikanter Wert\n\n\n\n\n\nVerteilung wenn nichts passiert und kritische Regionen.\n\n\n\n\nWenn der Stichprobenwert der Statistik in der kritischen Region auftritt, dann wird von einem statistisch signifikanten Effekt gesprochen. Unter der \\(H_0\\) bin ich überrascht diesen Wert zu sehen!"
  },
  {
    "objectID": "stats_significance.html#der-p-wert",
    "href": "stats_significance.html#der-p-wert",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.7 Der p-Wert",
    "text": "2.7 Der p-Wert\n\n\n\n\n\nDer gelben Flächen zeigen den p-Wert für den Wert der Statistik von d = 2,5 an."
  },
  {
    "objectID": "stats_significance.html#p-werte",
    "href": "stats_significance.html#p-werte",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.8 p-Werte",
    "text": "2.8 p-Werte\nDer p-Wert gibt die Wahrscheinlichkeit für den gefundenen oder einen noch extremeren Wert unter der \\(H_0\\) an.\n\n\n\n\n\nVerschiedene P-Werte"
  },
  {
    "objectID": "stats_significance.html#p-werte-1",
    "href": "stats_significance.html#p-werte-1",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.9 p-Werte",
    "text": "2.9 p-Werte\n“[A] p-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value.” (Wasserstein und Lazar 2016, p.131)\n“[T]he P value is the probability of seeing data that are as weird or more weird than those that were actually observed.” (Christensen 2018, p.38)"
  },
  {
    "objectID": "stats_significance.html#signifikanter-wert---das-kleingedruckte",
    "href": "stats_significance.html#signifikanter-wert---das-kleingedruckte",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.10 Signifikanter Wert - Das Kleingedruckte",
    "text": "2.10 Signifikanter Wert - Das Kleingedruckte\n\nVor dem Experiment wird für ein \\(H_0\\) ein \\(\\alpha\\)-Level angesetzt (per Konvention \\(\\alpha=0,05 = 5\\%\\))\nAnhand des \\(\\alpha\\)-Levels können kritische Werte (\\(k_{lower}, k_{upper}\\)) bestimmt werden. Diese bestimmen die Grenzen der kritischen Regionen.\nWenn der gemessene Wert w der Statistik in die kritische Region fällt, also \\(w \\leq k_{lower}\\) oder \\(w \\geq k_{upper}\\) gilt, dann wird von einem statistisch signifikanten Wert gesprochen und die dazugehörige Hypothese wird abgelehnt. Äquivalent: Der p-Wert ist kleiner als \\(\\alpha\\).\nDa in \\(\\alpha\\)-Fällen ein Wert in der kritischen Region auftritt, auch wenn die \\(H_0\\) zutrifft, wird in \\(\\alpha\\)-Fällen ein \\(\\alpha\\)-Fehler gemacht."
  },
  {
    "objectID": "stats_significance.html#signifikanter-wert---das-kleingedruckte-1",
    "href": "stats_significance.html#signifikanter-wert---das-kleingedruckte-1",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.11 Signifikanter Wert - Das Kleingedruckte",
    "text": "2.11 Signifikanter Wert - Das Kleingedruckte\n\nWenn der Wert w der Statistik nicht in den kritischen Regionen liegt, oder gleichwertig der p-Wert größer als \\(\\alpha\\) ist, wird die \\(H_0\\) beibehalten. D.h. nicht, dass kein Effekt vorliegt, sondern lediglich, dass anhand der Daten keine Evidenz diesbezüglich gefunden werden konnte!\nDie statistische Signifikanz sagt nichts über die Wahrscheinlichkeit der Theorie aus!\nEin p-Wert von \\(p = 0.0001\\) heißt nicht, dass mit 99,99% Wahrscheinlichkeit ein Effekt vorliegt!\nStatistisch signifikant heißt nicht automatisch praktisch relevant!"
  },
  {
    "objectID": "stats_significance.html#nochmal-wenn-die-h_0-nicht-abgelehnt-wird",
    "href": "stats_significance.html#nochmal-wenn-die-h_0-nicht-abgelehnt-wird",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.12 Nochmal, wenn die \\(H_0\\) nicht abgelehnt wird",
    "text": "2.12 Nochmal, wenn die \\(H_0\\) nicht abgelehnt wird\n\n\n\nAusschnitt aus Altman und Bland (1995)"
  },
  {
    "objectID": "stats_significance.html#nochmal-p-wert-wasserstein2016",
    "href": "stats_significance.html#nochmal-p-wert-wasserstein2016",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.13 Nochmal p-Wert (Wasserstein und Lazar (2016))",
    "text": "2.13 Nochmal p-Wert (Wasserstein und Lazar (2016))\n\nP-values can indicate how incompatible the data are with a specified statistical model.\nP-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.\nScientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.\nProper inference requires full reporting and transparency\nA p-value, or statistical significance, does not measure the size of an effect or the importance of a result.\nBy itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis."
  },
  {
    "objectID": "stats_significance.html#was-passiert-nun-aber-wenn-die-andere-hypothese-zutrifft",
    "href": "stats_significance.html#was-passiert-nun-aber-wenn-die-andere-hypothese-zutrifft",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.14 Was passiert nun aber wenn die “andere” Hypothese zutrifft?",
    "text": "2.14 Was passiert nun aber wenn die “andere” Hypothese zutrifft?\n\n\n\n\n\nDifferenzen mit kritischen Regionen (rot) mit einer Wahrscheinlichkeit von \\(\\alpha\\) wenn \\(H_0\\) zutrifft."
  },
  {
    "objectID": "stats_significance.html#wir-machen-einen-beta-fehler",
    "href": "stats_significance.html#wir-machen-einen-beta-fehler",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.15 Wir machen einen \\(\\beta\\)-Fehler!",
    "text": "2.15 Wir machen einen \\(\\beta\\)-Fehler!\n\n\n\n\n\nDifferenzen mit kritischen Regionen (rot) mit einer Wahrscheinlichkeit von \\(\\alpha\\) wenn \\(H_0\\) zutrifft und \\(\\beta\\) (grün) wenn \\(H_1\\) zutrifft."
  },
  {
    "objectID": "stats_significance.html#snap1989---the-power",
    "href": "stats_significance.html#snap1989---the-power",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.16 Snap!(1989) - The Power",
    "text": "2.16 Snap!(1989) - The Power\n\n\n\n\n\n\\(1-\\beta\\) = Power des Tests (blaue Fläche)."
  },
  {
    "objectID": "stats_significance.html#terminologie-noch-mal",
    "href": "stats_significance.html#terminologie-noch-mal",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.17 Terminologie noch mal",
    "text": "2.17 Terminologie noch mal\n\n\\(\\alpha\\): Die Wahrscheinlichkeit sich gegen die \\(H_0\\) zu entscheiden, wenn die \\(H_0\\) zutrifft. \\(\\alpha\\)-Level wird vor dem Experiment festgelegt um zu kontrollieren welche Fehlerrate toleriert wird.\n\\(\\beta\\): Die Wahrscheinlichkeit sich gegen die \\(H_1\\) zu entscheiden, wenn die \\(H_1\\) zutrifft.\nPower := \\(1 - \\beta\\): Die Wahrscheinlichkeit sich für die \\(H_1\\) zu entscheiden, wenn die \\(H_1\\) zutrifft. Sollte ebenfalls vor dem Experiment festgelegt werden."
  },
  {
    "objectID": "stats_significance.html#wie-können-wir-die-power-erhöhen",
    "href": "stats_significance.html#wie-können-wir-die-power-erhöhen",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.18 Wie können wir die Power erhöhen?",
    "text": "2.18 Wie können wir die Power erhöhen?\n\n\n\n\n\nVerteilungen wenn \\(\\delta\\)=500 und \\(\\delta\\)=0 in unserem kleine Welt Beispiel mit n = 3."
  },
  {
    "objectID": "stats_significance.html#stichprobengröße-von-n-3-auf-n-9-erhöhen",
    "href": "stats_significance.html#stichprobengröße-von-n-3-auf-n-9-erhöhen",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.19 Stichprobengröße von n = 3 auf n = 9 erhöhen?",
    "text": "2.19 Stichprobengröße von n = 3 auf n = 9 erhöhen?\n\n\n\n\n\nStichprobenverteilungen der Differenz unter \\(H_0\\) und \\(H_1:\\delta=500\\)N bei einer Stichprobengröße von n = 9"
  },
  {
    "objectID": "stats_significance.html#standardfehler",
    "href": "stats_significance.html#standardfehler",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.20 Standardfehler",
    "text": "2.20 Standardfehler\nDie Standardabweichung der Statistik wird als Standardfehler \\(s_e\\) bezeichnet2. Der Standardfehler ist nicht gleich der Standardabweichung in der Population bzw. der Stichprobe. Es gilt für den Mittelwert:"
  },
  {
    "objectID": "stats_significance.html#problem-bei-einer-dichotomen-betrachtung-der-daten",
    "href": "stats_significance.html#problem-bei-einer-dichotomen-betrachtung-der-daten",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.1 Problem bei einer dichotomen Betrachtung der Daten",
    "text": "3.1 Problem bei einer dichotomen Betrachtung der Daten\n\n\n\n\n\nAbbildung 3.1: Auszug aus Cumming (2013, p.1)"
  },
  {
    "objectID": "stats_significance.html#wie-groß-ist-der-effekt",
    "href": "stats_significance.html#wie-groß-ist-der-effekt",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.2 Wie groß ist der Effekt?",
    "text": "3.2 Wie groß ist der Effekt?\n\n\n\n\n\nStichprobenverteilungen der Differenz unter \\(H_0\\) und \\(H_1:\\delta=500\\)N bei einer Stichprobengröße von n = 9"
  },
  {
    "objectID": "stats_significance.html#schätzung-der-populationsparameter",
    "href": "stats_significance.html#schätzung-der-populationsparameter",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.3 Schätzung der Populationsparameter",
    "text": "3.3 Schätzung der Populationsparameter\nKleine Welt: Experiment wird einmal mit n = 9 durchgeführt\n\n3.3.1 Beobachtete Stichprobenkennwerte\n\\[\\begin{align*}\nd = \\bar{x}_{treat} - \\bar{x}_{con} &= 350 \\\\\ns &= 132 \\\\\ns_e &= 44\n\\end{align*}\\]\nWie präzise ist meine Schätzung und welche anderen Unterschiedswerte sind anhand der beobachteten Daten noch plausibel?"
  },
  {
    "objectID": "stats_significance.html#welche-deltas-sind-plausibel-für-d-350",
    "href": "stats_significance.html#welche-deltas-sind-plausibel-für-d-350",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.4 Welche \\(\\delta\\)s sind plausibel für \\(d = 350\\)?",
    "text": "3.4 Welche \\(\\delta\\)s sind plausibel für \\(d = 350\\)?\n\n\n\n\n\nVerschiedene Verteilungen von Gruppendifferenzen, beobachteter Unterschied (rot)\n\n\n\n\nPlausibel unter einem gegebenem \\(\\alpha\\)-Level!"
  },
  {
    "objectID": "stats_significance.html#alle-möglichen-deltas-die-plausibel-sind",
    "href": "stats_significance.html#alle-möglichen-deltas-die-plausibel-sind",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.5 Alle möglichen \\(\\delta\\)s die plausibel sind",
    "text": "3.5 Alle möglichen \\(\\delta\\)s die plausibel sind\n\n\n\n\n\nKonfidenzintervall (grün), Populationsparameter \\(\\delta\\) und \\(\\alpha\\)-Level für die beobachtete Differenz (gelb)."
  },
  {
    "objectID": "stats_significance.html#was-passiert-wenn-ich-das-experiment-ganz-oft-wiederhole",
    "href": "stats_significance.html#was-passiert-wenn-ich-das-experiment-ganz-oft-wiederhole",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.6 Was passiert wenn ich das Experiment ganz oft wiederhole?",
    "text": "3.6 Was passiert wenn ich das Experiment ganz oft wiederhole?\n\n\n\n\n\nSimulation von \\(n = 100\\) Konfidenzintervallen."
  },
  {
    "objectID": "stats_significance.html#konfidenzintervall---das-kleingedruckte",
    "href": "stats_significance.html#konfidenzintervall---das-kleingedruckte",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.7 Konfidenzintervall - Das Kleingedruckte",
    "text": "3.7 Konfidenzintervall - Das Kleingedruckte\n\nDas Konfidenzintervall für ein gegebenes \\(\\alpha\\)-Niveau gibt nicht die Wahrscheinlichkeit an mit der der wahre Parameter in dem Intervall liegt.\nDas Konfidenzintervall gibt alle mit den Daten kompatiblen Populationsparameter an.\nDas \\(\\alpha\\)-Niveau des Konfidenzintervalls gibt an bei welchem Anteil von Wiederholungen davon auszugehen ist, das das Konfidenzintervall den wahren Populationsparameter enthält."
  },
  {
    "objectID": "stats_significance.html#konfidenzintervall-herleiten-nach-spiegelhalter2019-p.241",
    "href": "stats_significance.html#konfidenzintervall-herleiten-nach-spiegelhalter2019-p.241",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.8 Konfidenzintervall herleiten nach Spiegelhalter (2019, p.241)",
    "text": "3.8 Konfidenzintervall herleiten nach Spiegelhalter (2019, p.241)\n\nWe use probability theory to tell us, for any particular population parameter, an interval in which we expect the observed statistic to lie with 95% probability.\nThen we observe a particular statistic.\nFinally (and this is the difficult bit) we work out the range of possible population parameters for which our statistic lies in their 95% intervals. This we call a “95% confidence interval”.\nThis resulting confidence interval is given the label “95%” since, with repeated application, 95% of such intervals should contain the true value.3\n\nAll clear? If it isn’t, then please be reassured that you have joined generations of baffled students."
  },
  {
    "objectID": "stats_significance.html#konfidenzintervall-berechnen-vorschau",
    "href": "stats_significance.html#konfidenzintervall-berechnen-vorschau",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.9 Konfidenzintervall berechnen (Vorschau)",
    "text": "3.9 Konfidenzintervall berechnen (Vorschau)\n\\[\n\\textrm{CI}_{1-\\alpha} = \\bar{x} \\pm z_{\\alpha/2} \\times s_e\n\\]"
  },
  {
    "objectID": "stats_significance.html#dualität-von-signifikanztests-und-konfidenzintervall",
    "href": "stats_significance.html#dualität-von-signifikanztests-und-konfidenzintervall",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.10 Dualität von Signifikanztests und Konfidenzintervall",
    "text": "3.10 Dualität von Signifikanztests und Konfidenzintervall\nWenn das Konfidenzintervall mit Niveau \\(1-\\alpha\\%\\) die \\(H_0\\) nicht beinhaltet, dann wird auch bei einem Signifikanztest die \\(H_0\\) bei einer Irrtumswahrscheinlichkeit von \\(\\alpha\\) abgelehnt.\n\n\n\n\nAltman, Douglas G, und J Martin Bland. 1995. „Statistics notes: Absence of evidence is not evidence of absence“. Bmj 311 (7003): 485.\n\n\nChristensen, Ronald. 2018. Analysis of variance, design, and regression: Linear modeling for unbalanced data. CRC Press.\n\n\nCohen, Jacob. 1988. Statistical power analysis for the behavioral sciences. 2. Aufl. Routledge.\n\n\nCumming, Geoff. 2013. Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis. Routledge.\n\n\nSpiegelhalter, David. 2019. The art of statistics: learning from data. Penguin UK.\n\n\nWasserstein, Ronald L, und Nicole A Lazar. 2016. „The ASA statement on p-values: context, process, and purpose“. Taylor & Francis."
  },
  {
    "objectID": "stats_distributions.html",
    "href": "stats_distributions.html",
    "title": "3  Verteilungen",
    "section": "",
    "text": "4 Die Normalverteilung"
  },
  {
    "objectID": "stats_distributions.html#normalverteilung---fxmusigma2-frac1sqrt2-pi-sigma2eleft-fracx-mu22sigma2right",
    "href": "stats_distributions.html#normalverteilung---fxmusigma2-frac1sqrt2-pi-sigma2eleft-fracx-mu22sigma2right",
    "title": "3  Verteilungen",
    "section": "4.1 Normalverteilung - \\(f(x|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)}\\)",
    "text": "4.1 Normalverteilung - \\(f(x|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)}\\)\n\n\n\n\n\nDichtefunktion der Normalverteilung mit Parametern \\(\\mu\\) und \\(\\sigma\\)."
  },
  {
    "objectID": "stats_distributions.html#zentraler-grenzwertsatz-oder-warum-die-normalverteilung-überall-auftaucht.",
    "href": "stats_distributions.html#zentraler-grenzwertsatz-oder-warum-die-normalverteilung-überall-auftaucht.",
    "title": "3  Verteilungen",
    "section": "4.2 Zentraler Grenzwertsatz oder Warum die Normalverteilung überall auftaucht.",
    "text": "4.2 Zentraler Grenzwertsatz oder Warum die Normalverteilung überall auftaucht.\nSeien \\(X_1, X_2, \\ldots, X_n\\) n unabhängige, gleichverteilte Zufallsvariablen mit \\(E(X_i)=\\mu\\) und \\(Var(X_i)=\\sigma^2\\). \\[\n\\lim_{n\\to\\infty}\\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\ \\rightarrow\\ \\mathcal{N}(\\mu=0,\\sigma^2=1)\n\\]"
  },
  {
    "objectID": "stats_distributions.html#normalverteilung-und-standardabweichung",
    "href": "stats_distributions.html#normalverteilung-und-standardabweichung",
    "title": "3  Verteilungen",
    "section": "4.3 Normalverteilung und Standardabweichung",
    "text": "4.3 Normalverteilung und Standardabweichung\n\n\n\n\n\nDichtefunktion von \\(\\mathcal{N}(\\mu,\\sigma^2)\\)"
  },
  {
    "objectID": "stats_distributions.html#normalverteilung-und-standardabweichung-1",
    "href": "stats_distributions.html#normalverteilung-und-standardabweichung-1",
    "title": "3  Verteilungen",
    "section": "4.4 Normalverteilung und Standardabweichung",
    "text": "4.4 Normalverteilung und Standardabweichung\n\\[P(x\\in[\\mu-1.96\\sigma, \\mu+1.96\\sigma]) = 0.95\\]"
  },
  {
    "objectID": "stats_distributions.html#standardnormalverteilung-phix",
    "href": "stats_distributions.html#standardnormalverteilung-phix",
    "title": "3  Verteilungen",
    "section": "4.5 Standardnormalverteilung \\(\\phi(x)\\)",
    "text": "4.5 Standardnormalverteilung \\(\\phi(x)\\)\n\n\n\n\n\nDichtefunktion der Standardnormalverteilung \\(\\phi(x)\\) mit \\(\\mu=0\\) und \\(\\sigma^2=1\\)"
  },
  {
    "objectID": "stats_distributions.html#abbildung-nmusigma-auf-n01",
    "href": "stats_distributions.html#abbildung-nmusigma-auf-n01",
    "title": "3  Verteilungen",
    "section": "4.6 Abbildung N(\\(\\mu\\),\\(\\sigma\\)) auf N(\\(0\\),\\(1\\))",
    "text": "4.6 Abbildung N(\\(\\mu\\),\\(\\sigma\\)) auf N(\\(0\\),\\(1\\))\n\n\n\n\n\nStandardnormalverteilung mit \\(\\mu=12, \\sigma^2=2\\)\n\n\n\n\n\n\n\n\n\nNormalverteilung mit \\(\\mu=0, \\sigma=1\\)"
  },
  {
    "objectID": "stats_distributions.html#z-transformation-allgemein-bzw.-standardisierung",
    "href": "stats_distributions.html#z-transformation-allgemein-bzw.-standardisierung",
    "title": "3  Verteilungen",
    "section": "4.7 z-Transformation allgemein bzw. Standardisierung",
    "text": "4.7 z-Transformation allgemein bzw. Standardisierung"
  },
  {
    "objectID": "stats_distributions.html#t-verteilung",
    "href": "stats_distributions.html#t-verteilung",
    "title": "3  Verteilungen",
    "section": "5.1 t-Verteilung",
    "text": "5.1 t-Verteilung\n\n\n\n\n\nBeispiel für verschiedene Dichtefunktionen der t-Verteilung"
  },
  {
    "objectID": "stats_distributions.html#chi2-verteilung",
    "href": "stats_distributions.html#chi2-verteilung",
    "title": "3  Verteilungen",
    "section": "5.2 \\(\\chi^2\\)-Verteilung",
    "text": "5.2 \\(\\chi^2\\)-Verteilung\n\n\n\n\n\nBeispiele für verschiedene Dichtefunktion der \\(\\chi^2\\)-Verteilung."
  },
  {
    "objectID": "stats_distributions.html#f-verteilung",
    "href": "stats_distributions.html#f-verteilung",
    "title": "3  Verteilungen",
    "section": "5.3 F-Verteilung",
    "text": "5.3 F-Verteilung\n\n\n\n\n\nBeispiele für verschiedene Dichtefunktion der F-Verteilung."
  },
  {
    "objectID": "stats_hypotheses.html#wahrscheinlichkeitstheorie",
    "href": "stats_hypotheses.html#wahrscheinlichkeitstheorie",
    "title": "4  Hypothesen testen",
    "section": "4.1 Wahrscheinlichkeitstheorie",
    "text": "4.1 Wahrscheinlichkeitstheorie"
  },
  {
    "objectID": "stats_hypotheses.html#schätzer",
    "href": "stats_hypotheses.html#schätzer",
    "title": "4  Hypothesen testen",
    "section": "4.3 Schätzer",
    "text": "4.3 Schätzer\nErwartungstreue"
  },
  {
    "objectID": "stats_hypotheses.html#hypothesentestung",
    "href": "stats_hypotheses.html#hypothesentestung",
    "title": "4  Hypothesen testen",
    "section": "4.4 Hypothesentestung",
    "text": "4.4 Hypothesentestung\n\n4.4.1 Der t-Test\nDas Verhältnis einer standardnormalverteilten Variable z und eine \\(\\chi^2\\)-verteilten Variable s folgt einer \\(t\\)-Verteilung.\n\\[\nT = \\frac{\\hat{\\Delta}}{\\hat{s}_e(\\hat{\\delta})} \\sim t\\text{-Verteilung}\n\\]\n\n\n4.4.2 \\(\\chi^2\\)-Test der Varianz\nSei \\(\\hat{\\sigma}^2\\) ein Schätzer für eine Varianz und \\(H_0: \\sigma^2 = \\sigma_0^2\\) die Nullhypothese, dann lässt sich eine Teststatistik über die folgende Formel konstruieren:\n\\[\nT = d \\frac{\\hat{\\sigma}^2}{\\sigma_0^2} \\sim \\chi^2(d\\text{ Freiheitsgrade})\n\\]\n\n\n4.4.3 F-Test von Varianzverhältnissen\nSeien zwei normalverteilte Stichproben gegeben und deren Varianzen über \\(\\hat{\\sigma}_A^2\\) und \\(\\hat{\\sigma}_B^2\\) abgeschätzt werden dann kann eine Teststatisk über die Gleichheit der beiden Varianzen \\(\\sigma_A^2 = \\sigma_B^2\\) über die folgende Formel konstruiert werden.\n\\[\nT = \\frac{\\hat{\\sigma}^2_A}{\\hat{\\sigma}^2_B} \\sim F(df_A, df_B)\n\\]\nDie beiden Varianzen folgen dabei jeweils einer \\(\\chi^2\\) Verteilung mit Freiheistgraden \\(df_A\\) und \\(df_B\\), so dass die Statistik \\(T\\) einer \\(F\\)-Verteilung mit \\((df_A, df_B)\\) Freiheitsgeraden folgt und die \\(H_0\\) lautet \\(H_0: \\frac{\\sigma_A^2}{\\sigma_B^2} = 1\\)"
  },
  {
    "objectID": "slm_title.html",
    "href": "slm_title.html",
    "title": "Das einfache Regressionmodell",
    "section": "",
    "text": "Wir beginnen nun mit dem einfachen Regressionsmodell. Das Modell knüpft an unsere Vorkenntnisse aus der Schule mit linearen Gleichungen an. Ausgehend von diesem Modell werden schrittweise neue Konzept eingeführt. Diese Herangehensweise hat den Vorteil, dass eine einfaches mentales Template immer wieder auf die neuen Konzepte abgebildet werden kann. Diese stetige Aufbau vollzieht sich über den ersten Teil des einfachen Regressionsmodells und wird dann im folgenden Teil, welcher die multiple Regression behandelt, fortgeführt. Dabei wird auch gezeigt, wie vorher voneinander unabhängig gelernte Methoden, wie die Regression und die ANOVA letztendlich aus dem gleichen Ansatz entstehen und es eigentlich keinen Unterschied zwischen den beiden Ansätzen gibt."
  },
  {
    "objectID": "slm_basics.html#back-to-school",
    "href": "slm_basics.html#back-to-school",
    "title": "5  Einführung",
    "section": "5.1 Back to school",
    "text": "5.1 Back to school\nWir beginnen mit ein Konzept mit dem wir sehr gut umgehen können. Nämlich der Punkt-Steigungsform aus der Schule (siehe Gleichung 5.1).\n\\[\ny = m x + b\n\\tag{5.1}\\]\nWir haben eine abhängige Variable \\(y\\) und eine lineare Formel \\(mx + b\\) die den funktionalen Zusammenhang zwischen den Variablen \\(y\\) und \\(x\\) beschreibt. Um das Ganze einmal konkret zu machen setzen wir \\(m = 2\\) und \\(b = 3\\) fest. Die Formel Gleichung 5.1 wird dann zu:\n\\[\ny = 2 x + 3\n\\tag{5.2}\\]\nUm ein paar Werte für \\(y\\) zu erhalten setzen wir jetzt verschiedene Wert für \\(x\\) ein indem wir \\(x\\) in Einserschritten zwischen \\([0, \\ldots, 5]\\) erhöhen. Um die Werte darzustellen verwenden wir zunächst eine Tabelle (vlg. Tabelle 5.1)\n\n\n\n\nTabelle 5.1: Tabelle der Daten\n\n\nx\ny\n\n\n\n\n0\n3\n\n\n1\n5\n\n\n2\n7\n\n\n3\n9\n\n\n4\n11\n\n\n5\n13\n\n\n\n\n\n\nWenig überraschend nimmt \\(y\\) für den Wert \\(x = 0\\) den Wert \\(3\\) an und z.B. für den Wert \\(x = 3\\) nimmt \\(y\\) den Wert \\(2 \\cdot 3 + 3 = 9\\) an.\nEine andere Darstellungsform ist naturlich eine graphische Darstellung in dem wir die Werte von \\(y\\) gegen \\(x\\) auf einem Graphen abtragen (siehe Abbildung 5.1).\n\n\n\n\n\nAbbildung 5.1: Graphische Darstellung der Daten aus Tabelle 5.1\n\n\n\n\nWiederum wenig überraschen sehen wir einen linearen Zuwachs der \\(y\\)-Wert mit den größerwerdenden \\(x\\)-Werte. Da in der Definition der Formel Gleichung 5.2 nirgends festgelegt wurde, dass diese nur für ganzzahlige \\(x\\)-Werte gilt, haben wir direkt eine Gerade durch die Punkte gelegt. Hier wird auch die Bedeutung von \\(m\\) und \\(b\\) direkt klar. Die Variable \\(m\\) bestimmt die Steigung der Gleichung während \\(b\\) den y-Achsenabschnitt beschreibt.\n\nDefinition 5.1 (\\(y\\)-Achsenabschnitt) Der y-Achsenabschnitt ist der Wert den \\(y\\) einnimmt wenn \\(x\\) den Wert \\(0\\) annimmt. Sei \\(y\\) durch eine lineare Gleichung \\(y = mx + b\\) definiert, dann wird der y-Achsenabschnitt durch den Wert \\(b\\) bestimmt.\n\nDie Variable \\(m\\) dahingehend bestimmt die Steigung der Gerade.\n\nDefinition 5.2 (Steigungskoeffizient) Wenn \\(y\\) durch eine lineare Gleichung \\(y = mx + b\\) definiert ist, dann bestimmt die Variable \\(m\\) die Steiung der dazugehörenden Gerade. D.h. wenn sich die Variable \\(x\\) um einen Einheit vergrößert (verkleinert) wird der Wert von \\(y\\) um \\(m\\) Einheiten größer (kleiner). Gilt \\(m &lt; 0\\) dann umgekehrt.\n\nDiese beiden trivialen Konzepte mit eigenen Definitionen zu versehen erscheint im ersten Moment vielleicht etwas übertrieben. Wie sich allerdings später zeigen wird, sind diese beiden Einsichten immer wieder zentral wenn es um die Interpretation von linearen statistischen Modellen geht.\nSoweit so gut. Führen wir direkt ein paar Symbole ein, die uns später noch behilflich sein werden. Sei jetzt die Menge der \\(x\\)-Werte geben \\(x = [0, 1, 2, 3, 4, 5]\\). Strenggenommen handelt es sich wieder um ein Tupel, da wir jetzt die Reihenfolge nicht mehr ändern. Wir führen nun einen Index \\(i\\) ein, um einzelne Werte in dem Tupel über ihre Position zu bestimmen und wir hängen diesen Index \\(i\\) an \\(x\\) an. Dann wird aus \\(x\\), \\(x_i\\).\n\n\n\n\nTabelle 5.2: \\(x\\)-Werte und ihr Index \\(i\\)\n\n\nIndex \\(i\\)\n\\(x\\)-Wert\n\n\n\n\n1\n0\n\n\n2\n1\n\n\n3\n2\n\n\n4\n3\n\n\n5\n4\n\n\n6\n5\n\n\n\n\n\n\nDamit können wir jetzt einen speziellen Wert zum Beispiel den dritten Wert mit \\(x_3 = 2\\) bestimmen. Wenden wir unseren Index auf unsere Gleichung 5.1 an, folgt daraus, dass \\(y\\) jetzt auch einen Index \\(i\\) erhält.\n\\[\ny_i = m x_i + b \\qquad i \\text{ in } [1,2,3,4,5,6]\n\\]\nWir bezeichnen die beiden Variablen \\(m\\), die Steigung, und \\(b\\), den y-Achsenabschnitt, jetzt auch mit neuen Variablen die auch noch einen Index erhalten. Aus \\(m\\) wird \\(\\beta_1\\) und aus \\(b\\) wird \\(\\beta_0\\). Damit wird der y-Achsenabschnitt mit \\(\\beta_0\\) bezeichnet und die Steigung wird mit \\(\\beta_1\\) bezeichnet. Dann wir aus unserer Gleichung:\n\\[\ny_i = \\beta_0 + \\beta_1 x_i\n\\tag{5.3}\\]\nDas ist immer noch unsere einfache Punkt-Steigungsform, wir haben lediglich den Index \\(i\\) eingeführt um unterschiedliche \\(y-x\\)-Wertepaare zu bezeichnen und wir haben den \\(y\\)-Achsenabschnitt und die Steigung mit neuen Symbolen versehen.\nBei dem bisherigen Zusammenhang handelt es sich um einen funktionalen Zusammenhang zwischen den beiden Variablen \\(x\\) und \\(y\\). Funktional deswegen, weil wir eine definiertes mathematisches Modell angeben können, d.h. wir haben eine mathematische Funktion welche die Beziehung zwischen den beiden Variablen beschreibt. Wenn wir den Wert für \\(x\\) kenne, dann können wir den präzisen Wert für \\(y\\) ausreichen, indem wir ihn in Gleichung 5.1 einsetzen. Aus der Schule kennen wir auch noch die Darstellung \\(y = f(x)\\). Streng genommen ist diese Darstellung für Gleichung 5.1 nicht ausreichend, denn um den Wert für \\(y\\) auszurechnen benötigen wir auch noch Kenntnis über die Werte \\(m\\) und \\(b\\), bzw. in unsere weiteren Darstellung \\(\\beta_0\\) und \\(\\beta_1\\). Daher sollte der Zusammenhang eigentlich mit \\(y = f(x, \\beta_0, \\beta_1)\\) bezeichnet werden. Es gilt aber immernoch, für gegebene \\(x, \\beta_0\\) und \\(\\beta_1\\) ist der Wert für \\(y\\) fest determiniert.\nWenn wir mit realen Daten arbeiten, dann funktioniert dieser Ansatz leider nicht ganz. Selbst wenn wir ein Experiment gleich durchführen werden wir immer etwas unterschiedliche Werte im Sinne der Messungenauigkeit messen. Wenn wir biologische Systeme messen, kommt dazu das diese in den seltensten Fällen zeitstabil sind sondern immer bestimmte Veränderungen von einem Zeitpunkt zum nächsten auftauchen. In Abbildung 5.2 sind Sprungweiten von mehreren Weitspringerinnen gegen die Anlaufgeschwindigkeit abgetragen. Bei der Betrachtung der Daten erscheint ein linearer Zusammenhang zwischen diesen beiden Variablen durchaus als plausibel.\n\n\n\n\n\nAbbildung 5.2: Zusammenhang der Anlaufgeschwindigkeit und der Sprungweite beim Weitsprung\n\n\n\n\nIn Abbildung 5.2 sind zwei Punkte rot markiert. Die beiden Werte haben praktisch die gleichen \\(x\\)-Werte allerdings unterscheiden sich die \\(y\\)-Werte deutlich von einander. Und dies sind nicht die einzigen Beispielpaare bei denen die \\(x\\)-Werte nahe beiandern liegen, während die \\(y\\)-Werte deutlich weiter voneiander entfernt liegen als bei einen funktionalen Zusammenhang nach Gleichung 5.1 zu erwarten wäre. Diese Abweichungen kommen durch zufällige Einflussfaktoren wie eben zum Beispiel die Veränderungen angesprochener biologischer Faktoren, Messunsicherheiten, beim Weitsprung draußen sind auch immer externe Einflüsse mögliche, vielleicht wenn es sich um den gleichen Springer handelt, hat er auch beim zweiten Mal keine Lust mehr gehabt. Wenn die Punkte zwei unterschiedliche Springer sind, dann kommt auch dazu, dass zwei Weitspringer bei identischer Anlaufgeschwindigkeit unterschiedliche Sprungfähigkeiten haben oder auch technisch nicht gleich gesprungen sind und so weiter und so fort. Insgesamt führen alle diese Einflüsse dazu, dass wir nicht mehr einen streng funktionalen Zusammenhang zwischen unseren beiden Variablen \\(x\\) der Anlaufgeschwindigkeit und \\(y\\) der Sprungweite vorfinden. Wie wir mit diesen Einflüssen umgehen ist das zentrale Thema des nächsten Abschnitts und markiert auch unseren Eingang zur einfachen linearen Regression."
  },
  {
    "objectID": "slm_basics.html#die-einfache-lineare-regression",
    "href": "slm_basics.html#die-einfache-lineare-regression",
    "title": "5  Einführung",
    "section": "5.2 Die einfache lineare Regression",
    "text": "5.2 Die einfache lineare Regression\nBleiben wir bei unserem Beispiel aus Abbildung 5.2 und interpretieren das als praktisches Problem. Wir sind eine Weitsprungtrainerin und stehen jetzt vor der Aufgabe in unserem Training etwas zu verändern um die Weitsprungleistung zu verbessern. Wir haben wir haben uns dazu entschlossen am Anlauf etwas zu verbessern wissen jetzt aber nicht ob, das wirklich lohnenswert ist. Von einer befreundeten Trainerin haben wir einen Datensatz bekommen von Anlaufgeschwindigkeiten und den dazugehörigen Sprungweiten. Schauen wir uns zunächst die einmal die Struktur der Daten an.\n\n\n\n\nTabelle 5.3: Ausschnitt der Sprungdaten\n\n\njump_m\nv_ms\n\n\n\n\n4.36\n6.13\n\n\n4.31\n6.39\n\n\n4.56\n6.56\n\n\n4.75\n6.44\n\n\n5.52\n7.30\n\n\n5.63\n7.19\n\n\n5.70\n7.30\n\n\n\n\n\n\nIn Tabelle 5.3 ist ein Ausschnitt Sprungdaten abgebildet. Wir haben eine einfache Struktur der Daten. Wir haben eine Tabelle mit zwei Spalten. jump_m bezeichnet die Sprungweiten und v_ms die Anlaufgeschwindigkeiten. Damit wir die Datenpaare voneinander unterscheiden bzw. identifzieren können führen wir unseren bereits besprochenen Index \\(i\\) und können so einzelne Paare ansprechen.\n\n\n\n\nTabelle 5.4: Ausschnitt der Sprungdaten\n\n\ni\njump_m\nv_ms\n\n\n\n\n1\n4.36\n6.13\n\n\n2\n4.31\n6.39\n\n\n3\n4.56\n6.56\n\n\n4\n4.75\n6.44\n\n\n5\n5.52\n7.30\n\n\n6\n5.63\n7.19\n\n\n7\n5.70\n7.30\n\n\n\n\n\n\nDas waren bisher aber nur Formalitäten. Wir wollen jetzt denn Zusammenhang zwischen den beiden Variablen modellieren. Wir könnten wahrscheinlich auch einfach Pi-mal-Daumen abschätzen wie groß der Zusammenhang ist. Wenn wir jetzt aber einen unserer Läufer haben, der z.B. etwa \\(9m/s\\) anläuft, welchen Vergleichswerte nehmen wir dann aus Abbildung 5.2. Den unteren oder den oberen der beiden roten Werte? Oder vielleicht den Mittelwert? Welchen Wert nehmen wir wenn unserer Athlete \\(9.7m/s\\) anläuft. Da haben wir leider keinen Vergleichswert in unserer Tabelle. Daher wäre es schon ganz praktisch eine Formel nach dem Muster von Gleichung 5.3 zu haben. Wie wir allerdings schon festgestellt haben, geht dies nicht so einfach da wir eben das Problem mit den Einflussfaktoren haben, die dazu führen, dass die Werte eben nicht streng auf eine Gerade liegen. Somit liegt die Herausforderung nun eine Gerade zu finden die möglichst genau die Daten wiederspiegelt.\n\n\n\n\n\nAbbildung 5.3: Mögliche Geraden um den Zusammenhang der Anlaufgeschwindigkeit und der Sprungweite zu modellieren\n\n\n\n\nIn Abbildung 5.3 sind die Daten zusammen mit verschiedenen möglichen Geraden abgebildet. Eine kurze Überlegung macht schnell klar, dass es im Prinzip unendlich viele unterschiedliche Geraden gibt die durch die Datenpunkte gelegt werden können. D.h. es gibt unendlich viele Kombinationen von \\(\\beta_0\\) und \\(\\beta_1\\), die die jeweiligen Geraden bezeichnen. Daher muss jetzt eine Kriterium gefunden werden, welches ermöglicht aus diesen unendlich vielen Geraden eine auszuwählen die im Sinne des Kriterium optimal ist.\nTatsächlich gibt es dort auch verschiedene Möglichkeiten Kriterien anzuwenden, dasjenige dass jedoch am weitesten verbreitet ist aus verschiedenen Gründen sind die quadratierten Abweichungen von der Gerade. Schauen wir uns die Herleitung dazu schrittweise an. In Abbildung 5.4 ist zur Übersicht nur ein Ausschnitt der Daten zusammen mit einer möglichen Gerade eingezeichnet. Die senkrechten Abweichungen der Geraden zu den jeweiligen Datenpunkten sind rot eingezeichnet. Es ist ersichtlich, dass für diese Wahl der Geraden es zwei Punkte gibt die tatsächlich auch ziemlich genau auf der Geraden liegen während die anderen Punkte zum Teil oberhalb bzw. unterhalb der Geraden liegen. Das Kriterium wäre jetzt dementsprechen die jenige Geraden aus den unendlich vielen zu finden, bei der diese Abweichung ein Minimum annehmen.\n\\[\n\\text{min}\\sum_{i=1}^n y_i - (\\beta_0 + \\beta_1 x_i) = \\sum_{i=1}^n y_i - \\beta_0 - \\beta_1 x_i\n\\]\n\n\n\n\n\nAbbildung 5.4: Abweichungen der Gerade von der Datenpunkten für die Daten mit eine Anlaufgeschwindigkeit zwischen \\(8m/s\\) und \\(10m/s\\).\n\n\n\n\nUnglücklicherweise haben die einfachen Abweichungen die unhandliche Eigenschaft, dass dann die Gerade \\(y_i = \\hat{y}\\) optimal ist.\n\\[\n\\sum_{i=1}^n y_i - \\hat{y} = \\sum_i^n y_i - \\sum_{i=1}^n \\hat{y} = \\sum_{i=1}^n y_i - n\\hat{y} = \\sum_{i=1}^n y_i - n\\frac{1}{n}\\sum_{i=1}^n y_i = \\sum_{i=1}^n y_i - \\sum_{i=1}^n y_i= 0\n\\]\nWir können das Kriterium aber auch noch etwas schärfer machen. Wenn wir sagen, dass wir größere Abweichungen stärker gewichten wollen als kleinere Abweichungen. D.h. große Abweichungen zwischen der Gerade und den Datenpunkten sollten stärker berücksichtigt werden, als kleine Abweichungen. Dies können wir erreichen indem wir die Abweichungen noch zusätzlich quadrieren. Dies hat auch noch den Vorteil noch verschiedene andere mathematische Vorteile, unter anderem führt dies dazu, dass wir eine Gerade erhalten, die auch tatsächlich die Steigung der Punkte berücksichtigt und nicht einfache nur eine horizontale Gerade durch die Punkte zeichnet. Dementsprechend erhalten wir die folgende Funktion, die es zu minimieren gilt:\n\\[\n\\text{min} \\sum_{i=1}^n(y_i - (\\beta_0 + \\beta_1 x_i))^2\n\\tag{5.4}\\]\nDie Abweichungen zwischen der zu findenden Gerade und den Datenpunkten werden als Residuen \\(e_i\\) bezeichnet. Dementsprechend ist die Minimierungsgleichung auch als:\n\\[\n\\text{min} \\sum_{i=1}^n e_i^2\n\\] darzustellen, mit \\(e_i := y_i - (\\beta_0 + \\beta_1 x_i)\\). Führen wir noch eine weitere Bezeichnung \\(E\\) ein, mit der wir die Minimierungsfunktion bezeichnen (\\(E\\) nach englisch error).\n\\[\nE = \\sum_{i=1}^n e_i^2 = \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i)^2\n\\]\nDas Minimum läßt sich finden, indem die partiellen Ableitungen von \\(E\\) nach \\(\\beta_0\\) und \\(\\beta_1\\) berechnet werden und, wie wir es aus der Schule kennen, die Ableitungen gleich Null gesetzt werden.\n\\[\\begin{align*}\n\\frac{\\partial E}{\\partial \\beta_0} &= -2 \\sum_{i=1}^n (y_i - \\beta_0 - \\beta_1 x_i) = 0 \\\\\n\\frac{\\partial E}{\\partial \\beta_1} &= -2 \\sum_{i=1}^n x_i (y_i - \\beta_0 - \\beta_1 x_i) = 0\n\\end{align*}\\]\nDiese Gleichungen lassen sich umstellen und nach \\(\\beta_0\\) und \\(\\beta_1\\) auflösen: \\[\n\\begin{align}\n\\hat{\\beta_1} &= \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^n (x_i - \\bar{x})^2} \\\\\n\\hat{\\beta_0} &= \\bar{y} - \\hat{\\beta_1} \\bar{x}\n\\end{align}\n\\tag{5.5}\\]\n\\(\\bar{x}\\) und \\(\\bar{y}\\) sind wieder die Mittelwerte von \\(x_i\\) und \\(y_i\\). Diese beiden Gleichungen werden als die Normalengleichungen bezeichnet.\nWir führen noch einen weiteren Term ein, den vorhergesagten Wert \\(\\hat{y}_i\\) von \\(y_i\\) anhand der Geradengleichung. Das Hütchen über \\(y_i\\) ist dabei immer das Signal dafür, das es sich um einen abgeschätzten Wert handelt. Wenn wir \\(\\beta_0\\) und \\(\\beta_1\\) anhand der Normalengleichung bestimmen, dann sind das mit großer Wahrscheinlichkeit nicht die wahren Werte aus der Population, sondern wir haben sie nur anhand der Daten abgeschätzt. Daher bekommen die berechneten Werte ebenfalls ein Hütchen \\(\\hat{\\beta}_0\\) und \\(\\hat{\\beta}_1\\). Insgesamt nimmt die lineare Geradengleichung dann die folgende Form an:\n\\[\n\\hat{y}_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot x_i\n\\]\nGraphisch sind die \\(\\hat{y}_i\\)s die Werte auf der Geraden für die gegebenen \\(x_i\\)-Werte.\n\n\n\n\n\nAbbildung 5.5: Die vorhergesaten Werte \\(\\hat{y}_i\\) auf der Gerade.\n\n\n\n\nFür den vorliegenden Fall der Weitsprungdaten erhalten wir die Werte für die Koeffizienten nach Einsetzen der beobachteten Werte in Gleichung 5.5 mit \\(\\hat{\\beta}_0 = -0.14\\) und \\(\\hat{\\beta}_1 = 0.76\\). Somit folgt für die Geradengleichung:\n\\[\n\\hat{y}_i = -0.14 + 0.76 \\cdot x_i\n\\]\nWir erhalten die graphische Darstellung der Geradengleichung indem die \\(x_i\\)-Werte eingesetzt werden und eine Gerade durch die Punkte gezogen wird. Oder auch einfacher für den größten und den kleinsten \\(x_i\\)-Wert.\n\n\n\n\n\nAbbildung 5.6: Die Regressionsgerade der Sprungdaten.\n\n\n\n\nUm uns auch zu vergewissern, dass unsere Berechnungen korrekt sind, schauen wir uns noch einmal an, wie sich \\(E\\) verhält, wenn wir unterschiedliche Kombinationen von Werten für \\(\\beta_0\\) und \\(\\beta_1\\) in die lineare Gleichung einsetzen.\n\n\n\n\n\nAbbildung 5.7: Heatmap von \\(log(E)\\) für verschiedene Werte von \\(\\beta_0\\) und \\(\\beta_1\\)\n\n\n\n\nIn Abbildung 5.7 sind verschiedene Werte für \\(E\\) in Form einer heatmap dargestellt. Die Abweichungen wurden \\(log\\)-transformiert (d.h. der Logarithmus der \\(E\\)-Werte wurde berechnet), da sonst die Unterschiede in der diagnaolen Bildrichtung zu schnell wachsen und die Unterschiede nicht mehr so einfach zu erkennen sind. Werte näher an Weiß bedeuten kleine Werte und Werte näher an Rot bedeuten größere Werte von \\(E\\). Das berechnete Paar für \\((\\hat{\\beta}_0, \\hat{\\beta}_1)\\) mit \\(\\hat{\\beta}_0 = -0.14\\) und \\(\\hat{\\beta}_1 = 0.76\\) ist schwarz eingezeichnet. Die Abbildung zeigt, dass dieses Wertepaar tatsächlich ein Minimum bezüglich der Funktion \\(E\\) ist, da in alle Richtung weg von dem schwarzen Punkt die Werte für \\(E\\) zunehmen. Da wir nur einen Ausschnitt der möglichen Werte sehen, handelt es sich zunächst um eine lokales Minimum aber es lässt sich zeigen, dass es sich dabei auch um ein globales Minimum handelt. Diese Eigenschaft hängt mit der Form der Funktion \\(E\\) zusammen. In Tabelle 5.5 sind beispielhaft ein paar Werte für \\(log(E)\\) für Paare von \\(\\beta_0\\) und \\(\\beta_1\\) angezeigt, die in Abbildung 5.7 gelb eingezeichnet sind.\n\n\n\n\nTabelle 5.5: Werte von \\(log(E)\\) für verschiedenen Kombinationen von \\(\\beta_0\\) und \\(\\beta_1\\).\n\n\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\\(log(E)\\)\n\n\n\n\n-0.48\n0.67\n70.34\n\n\n-0.44\n0.68\n51.85\n\n\n-0.38\n0.72\n22.04\n\n\n-0.30\n0.75\n6.46\n\n\n-0.22\n0.75\n3.77\n\n\n-0.14\n0.76\n2.41\n\n\n\n\n\n\n\n5.2.1 Schritt-für-Schritt Herleitung der Normalengleichungen\nUm die Herleitung der Normalengleichungen Schritt-für-Schritt nachvollziehen zu können benötigen wir zunächst einmal ein paar algebraische Tricks.\nFür den Mittelwert gilt: \\[\n\\bar{x} = \\frac{1}{n}\\sum x_i \\Leftrightarrow \\sum x_i = n \\bar{x}\n\\]\nBei Summen und konstanten \\(a\\) konstant gilt: \\[\\begin{align}\n    \\sum a &= n a \\\\\n    \\sum a x_i &= a \\sum x_i \\\\\n    \\sum (x_i + y_i) &= \\sum x_i + \\sum y_i\n\\end{align}\\]\nWenn eine Summe abgeleitet wird, kann in die Ableitung in die Summe reingezogen werden. \\[\n\\frac{d}{d x}\\sum f(x) = \\sum\\frac{d}{d x} f(x)\n\\]\nHier ein zwei Umformungen bei Summen und dem Kreuzprodukt bzw. dem Quadrat. \\[\\begin{alignat}{2}\n&& \\sum(x_i-\\bar{x})(y_i-\\bar{y}) \\\\\n\\Leftrightarrow\\mkern40mu && \\sum (x_iy_i-\\bar{x}y_i-x_i\\bar{y}+\\bar{x}\\bar{y}) \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum x_i y_i - \\sum\\bar{x}y_i - \\sum x_i \\bar{y} + \\sum \\bar{x} \\bar{y} \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu&&  \\sum x_iy_i - n\\bar{x}\\bar{y}-n\\bar{x}\\bar{y}+n\\bar{x}\\bar{y} \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum x_iy_i - n\\bar{x}\\bar{y} \\nonumber\n\\end{alignat}\\] \\[\\begin{alignat}{2}\n&& \\sum(x_i - \\bar{x})^2 \\\\\n\\Leftrightarrow\\mkern40mu && \\sum(x_i^2 - 2 x_i \\bar{x} + \\bar{x}^2) \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum x_i^2 - 2\\bar{x}\\sum x_i + \\sum\\bar{x}^2 \\nonumber\\\\\n\\Leftrightarrow\\mkern40mu && \\sum x_i^2 - 2\\bar{x}n\\bar{x} + n\\bar{x}^2 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum x_i^2 - n \\bar{x}^2 \\nonumber\n\\end{alignat}\\]\nZurück zu unserem Problem. Es gilt \\(E\\) zu minimieren:\n\\[\\begin{alignat}{2}\n&& E = \\sum e_i^2 = \\sum (y_i - \\hat{y}_i)^2 \\\\\n\\Leftrightarrow\\mkern40mu && \\sum (y_i - (\\beta_0 + \\beta_1 x_i))^2 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum (y_i - \\beta_0 - \\beta_1 x_i)^2 \\nonumber\n\\end{alignat}\\]\nDie Gleichung hängt von zwei Variablen \\(\\beta_0\\) und \\(\\beta_1\\). Um das Minimum der Gleichung zu erhalten, verfährt man wie in der Schule, indem man die Ableitung gleich Null setzt. Der vorliegenden Fall ist jedoch etwas komplizierter, da die Gleichung von zwei Variablen abhängt. Daher müssen wir die partiellen Ableitungen \\(\\frac{\\partial}{\\partial \\beta_0}\\) und \\(\\frac{\\partial}{\\partial \\beta_1}\\) verwendet. Wir erhalten dadurch ein Gleichungssystem mit zwei Gleichungen (die jeweiligen Ableitungen) in zwei Unbekannten (\\(\\beta_0\\) und \\(\\beta_1\\)). Die Lösung erfolgt, indem zuerst eine Gleichung nach der einen Unbekannten umgestellt wird und das Ergebnis dann in die andere Gleichung eingesetzt wird.\nWir beginnen mit der partiellen Ableitung nach \\(\\beta_0\\) für den y-Achsenabschnitt. (Zurück an die Schule erinnern: Äußere Ableitung mal innere Ableitung)\n\\[\\begin{alignat}{2}\n&& \\frac{\\partial \\sum (y_i - \\beta_0 - \\beta_1 x_i)^2}{\\partial \\beta_0} \\\\\n\\Leftrightarrow\\mkern40mu && \\sum\\frac{\\partial}{\\partial \\beta_0}(y_i - \\beta_0- \\beta_1 x_i)^2 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum 2(y_i - \\beta_0- \\beta_1 x_i) (-1) \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && -2 \\sum (y_i - \\beta_0- \\beta_1 x_i) \\nonumber\n\\end{alignat}\\] Zum minimieren gleich Null setzen. \\[\\begin{alignat}{2}\n&& -2 \\sum (y_i - \\beta_0- \\beta_1 x_i) = 0 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum (y_i - \\beta_0- \\beta_1 x_i) = 0 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum y_i - \\sum \\beta_0- \\sum \\beta_1 x_i = 0 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && n \\bar{y} - n \\beta_0- \\beta_1 n \\bar{x} = 0 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\bar{y} - \\beta_0- \\beta_1 \\bar{x} = 0 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\bar{y} - \\beta_1 \\bar{x} = \\beta_0\\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\beta_0= \\bar{y} - \\beta_1 \\bar{x}\n\\end{alignat}\\]\nEs folgt nach dem gleichen Prinzip die Herleitung für die Steigung \\(\\beta_1\\) und indem die Lösung für \\(\\beta_0\\) eingesetzt wird.\n\\[\\begin{alignat}{2}\n&& \\frac{\\partial \\sum (y_i - \\beta_0 - \\beta_1x_i)^2}{\\partial \\beta_1} \\\\\n\\Leftrightarrow\\mkern40mu && \\sum\\frac{\\partial}{\\partial b}(y_i - \\beta_0 - \\beta_1x_i)^2 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum2(y_i - \\beta_0 - \\beta_1x_i) -x_i \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && -2 \\sum(y_i - \\beta_0 - \\beta_1x_i)x_i\n\\end{alignat}\\] Wiederum gleich Null setzen. \\[\\begin{alignat}{2}\n&& -2 \\sum(y_i - \\beta_0 - \\beta_1x_i)x_i = 0 \\nonumber\\\\\n\\Leftrightarrow\\mkern40mu && \\sum (y_i - \\beta_0 - \\beta_1x_i)x_i = 0 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum (y_i x_i - \\beta_0 x_i - \\beta_1x_i x_i) = 0 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum y_i x_i - \\beta_0 \\sum x_i - b\\sum x_i^2 = 0 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum y_i x_i - n \\beta_0 \\bar{x} - \\beta_1\\sum x_i^2 = 0 \\nonumber\n\\end{alignat}\\] Einsetzen der Lösung für \\(\\beta_0\\) führt zu: \\[\\begin{alignat}{2}\n\\Leftrightarrow\\mkern40mu && \\sum y_i x_i - n (\\bar{y} - \\beta_1 \\bar{x}) \\bar{x} - \\beta_1\\sum x_i^2 = 0 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum y_i x_i - n\\bar{y}\\bar{x} + n \\beta_1\\bar{x}^2 - \\beta_1\\sum x_i^2 = 0 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum y_i x_i - n\\bar{y}\\bar{x} = \\beta_1 \\sum x_i^2 - \\beta_1n \\bar{x}^2 \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\sum (x_i-\\bar{x})(y_i-\\bar{y}) = \\beta_1 (\\sum x_i^2 - n\\bar{x}^2) \\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\frac{\\sum (x_i-\\bar{x})(y_i-\\bar{y})}{\\sum x_i^2 - n\\bar{x}^2} = \\beta_1\\nonumber \\\\\n\\Leftrightarrow\\mkern40mu && \\beta_1= \\frac{\\sum (x_i-\\bar{x})(y_i-\\bar{y})}{\\sum(x_i-\\bar{x})^2} \\nonumber\n\\end{alignat}\\]\nSomit erhält man die beiden Normalengleichungen der Regression.\nÜber diese beiden Gleichungen erhalten wir die gewünschten Koeffizienten \\(\\hat{\\beta_0}\\) und \\(\\hat{\\beta_1}\\). Die Methode wird als die als die Methode der kleinsten Quadrate bezeichnet oder im Englischen Root-Mean-Square (RMS)."
  },
  {
    "objectID": "slm_basics.html#was-bedeuten-die-koeffizienten",
    "href": "slm_basics.html#was-bedeuten-die-koeffizienten",
    "title": "5  Einführung",
    "section": "5.3 Was bedeuten die Koeffizienten?",
    "text": "5.3 Was bedeuten die Koeffizienten?\nGehen wir zurück nun zu unseren Ausgangsproblem der Weitspringer, was haben wir jetzt durch die Berechnung der Gerade eigentlich gewonnen? Dazu müssen wir erst einmal verstehen was die beiden Koeffizienten \\(\\hat{\\beta}_0\\) und \\(\\hat{\\beta}_1\\) bedeuten. Wenn wir zurück zu Gleichung 5.1 gehen, haben die beiden Koeffzienten den \\(y\\)-Achsenabschnitt und die Steigung der Geraden beschrieben. In unserem Beispiel haben wir anhand der Daten einen \\(y\\)-Achsenabschnitt \\(\\hat{\\beta}_0\\) von \\(-0.14\\) berechnet. D.h ein Weitspringer der mit einer Anlaufgeschwindigkeit von \\(x = 0\\) anläuft, landet \\(14\\)cm hinter der Sprunglinie. Dies macht offensichtlich nicht viel Sinn (warum?). Der Grund warum hier ein offensichtlich unrealistischere Wert berechnet wurde, werden wir später noch genauer betrachten. Wir können trotzdem zwei Eigenschaften von \\(\\hat{\\beta}_0\\) beobachten. 1) der Koeffizient hat eine Einheit, nämlich die gleiche Einheit wie die Variable \\(y\\). 2) Ob der Wert zu interpretieren ist, hängt von der Verteilung der Daten ab. Schauen wir uns nun den Steigungskoeffizienten \\(\\hat{\\beta}_0\\) an. Der Steigungskoeffizient in Gleichung 5.1 zeigt an, wie sich der \\(y\\)-Wert verändert, wenn sich der \\(x\\)-Wert um einen Einheit verändert. In unserem Fall welcher Unterschied zu erwarten ist zwischen zwei Weitspringern die sich in der Anlaufgeschwindigkeit um eine \\(m/s\\) unterscheiden. D.h. der Steigungskoeffizient ist ebenfalls in der Einheit der \\(y\\)-Variable zu interpretieren.\nUnsere Trainerin kann jetzt die berechnete Gerade dazu nehmen um zu überprüfen ob es sich lohnen würde Trainingszeit in den Anlauf zu stecken und welche Verbesserung dort zu erwarten sind. Allerdings fehlt dazu noch etwas, wir wissen nämlich noch nicht ob die berechnete Gerade auch wirklich die Daten gut wiederspiegelt. Im Beispiel erscheint dies anhand der Grafik als relativ plausibel. Das muss aber nicht immer so sein. Wir können nämlich für alle möglichen Daten eine Gerade berechnen ohne das diese Gerade die Daten wirklich auch nur annährend korrekt wiedergibt. In Gleichung 5.5 steht nirgends für welche Daten die Berechnung nur erlaubt ist.\n\n\n\n\n\nAbbildung 5.8: Gefittete Gerade durch die Daten einer Funktion \\(f(x) = x^3\\).\n\n\n\n\nIn Abbildung 5.8 sind synthetische Daten der Funktion \\(f(x) = x^3\\) abgebildet und die mittels Gleichung 5.5 berechneten Gerade eingezeichnet. Die Gerade ist zwar in der Lage die ansteigenden Werte zu modellieren aber eben nicht Schwingungen die durch die kubische Abhängigkeit zustande kommen. Aber, nichts verhindert die Anwendung der Formel auf die Daten.\nDer gleiche Effekt ist auch in Abbildung 5.9 wieder zu beobachten. Hier besteht eine sinusförmige Abhängigkeit zwischen \\(y\\) und \\(x\\). Wir können wieder Gleichung 5.5 anwenden und erhalten auch ein Ergebnis für \\(\\hat{\\beta}_0\\) und \\(\\hat{\\beta}_1\\). Allerdings repräsentiert die Gerade in keinster Weise den tatsächlichen Zusammenhang zwischen den Daten.\n\n\n\n\n\nAbbildung 5.9: Gefittete Gerade durch die Daten einer Funktion \\(f(x) = sin(x) + 3\\).\n\n\n\n\nIm nächsten Kapitel werden wir uns daher damit beschäftigen die Repräsentation der Daten näher zu betrachten und zu präzisieren.\nWir nehmen noch eine weitere Eigenschaft der Gerade mit, die zunächst nichts mit der Interpretation der Koeffizienten zu tun hat, aber später noch mal von Interesse sein wird. Die Gerade hat nämlich die Eigenschaft durch den Punkt (\\(\\bar{x}\\), \\(\\bar{y}\\)) zu gehen. Dies kann daran gesehen werden wenn in die Gleichung \\(\\bar{x}\\) für \\(x_i\\) eingesetzt wird. Anhand der Normalgleichungen kann die Geradengleichung in der Form.\n\\[\ny_i = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot x_i = \\underbrace{\\bar{y} - \\hat{\\beta}_1 \\bar{x}}_{\\text{Def. }\\hat{\\beta}_0} + \\hat{\\beta}_1 \\cdot x_i\n\\]\nWird jetzt für \\(x_i\\) der Wert \\(\\bar{x}\\) eingesetzt folgt daher.\n\\[\ny_i = \\bar{y} - \\hat{\\beta}_1 \\bar{x} + \\hat{\\beta}_1 \\bar{x} = \\bar{y}\n\\]\nD.h. für den Wert \\(\\bar{x}\\) nimmt die Geradengleichung der Wert \\(\\bar{y}\\) an. Für die Sprungdaten ist die auch noch mal in Abbildung 5.10 graphisch dargestellt.\n\n\n\n\n\nAbbildung 5.10: Regressionsgerade der Sprungdaten und der Punkt \\((\\bar{x}, \\bar{y})\\)\n\n\n\n\nEine Eigenschaft die im weiteren Verständnis immer wieder auftaucht bezieht sich auf die \\(x\\)-Werte. Bei der Regression wird im Allgemeinen davon ausgegangen, dass die beobachteten \\(x\\)-Werte fixiert sind. D.h. trotzdem die \\(x\\)-Werte bei einem Experiment zufällig sein können, werden diese in den nachfolgenden Schritten als fixiert angesehen. Daher ist in der Formel \\(Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i\\) auch nur \\(\\epsilon_i\\) die einzige zufällige Variable."
  },
  {
    "objectID": "slm_basics.html#die-einfache-regression-in-r",
    "href": "slm_basics.html#die-einfache-regression-in-r",
    "title": "5  Einführung",
    "section": "5.4 Die einfache Regression in R",
    "text": "5.4 Die einfache Regression in R\nIn R wird eine Regression mit der Funktion lm() berechnet. Die für uns zunächst wichtigsten Parameter von lm() sind der erste Parameter formula und der zweite Parameter data. Mit der Formel wird der Zusammenhang zwischen den Variablen beschrieben, dabei können die Namen bzw. Bezeichner aus dem tibble() benutzt werden, die an den zweiten Parameter data übergeben werden. D.h. die Spaltennamen aus dem tibble() werden in formula verwendet.\nIn unserem Weitsprungbeispiel konnten wir in Tabelle 5.3 sehen, das das tibble() zwei Spalten mit den Namen v_ms, den Anlaufgeschwindigkeiten, und jump_m, den Weitsprungweiten enthielt. Dementsprechend, müssen wir diese beiden Bezeichner in formula verwenden, um unser Regressionsmodell zu beschreiben. Die Form der Modellbeschreibung folgt, dabei einer bestimmten Syntax die wir uns zunächst anschauen müssen. Zentrales Element der Syntax ist das Tilde Zeichen ~ (Win: ALTGR++, MacOS: ___), welches interpretiert wird als modelliert mit. Der Term der auf der linken Seite steht bezeichnet die abhängige Variable während die Terme auf der rechten Seite der Tilde stehen die unabhängige Variablen spezifizieren. Dementsprechend kann der Satz “Y wird mittels X modelliert” in die Formelsyntax mit Y ~ X übersetzt. Die komplette Syntax orientiert sich an eine Arbeit von Wilkinson und Rogers (1973).\nWenn ein konstanter in der Syntax benötigt wird, dann wird dieser mit einer \\(1\\) bezeichnet. Also zum Beispiel wenn wir Gleichung 5.3 modellieren wollen benutzen wir die Syntax y ~ 1 + x. Die beiden Koeffizienten \\(\\beta_0\\) und \\(\\beta_1\\) brauchen wir nicht explizit anzugeben, sondern R generiert uns automatisch anhand der Bezeichner Koeffizienten, die allerdings die Namen der Bezeichner bekommen. Dazu kommt noch eine Besonderheit, dass R bei einer Regressionsgleichung automatisch davon ausgeht, dass ein konstanter Term verwendet werden soll, d.h. der Term +1 wird automatisch dazugefüht. Wenn wir ein Modell ohne einen \\(y\\)-Achsenabschnitt fitten wollen, dann müssen wir dies R explizit mitteilen, indem wir -1 der linken Seite hinzufügen, also z.B. y ~ x - 1. Die Syntax generalisiert dann später einfach, wenn zusätzliche Terme in der multiplen Regression benötigt werden, in dem weitere unabhängige Variablen durch + dazugefügt werden. Dementsprechend würde sich die Formel y ~ x_1 + x_1 übersetzen in die abhängige Variable \\(y\\) wird mittels der unabhängigen Variablen x_1 und x_2 und einem konstaten Term modelliert. In Tabelle 5.6 sind weitere Beispiele für die Struktur der Formelsyntax für lm() gezeigt.\n\n\nTabelle 5.6: Formelsyntaxbeispiele für lm() (y-Ab = y-Achsenabshnitt, StKoef = Steigungskoeffizient)\n\n\nModell\nFormel\nErklärung\n\n\n\n\n\\(y=\\beta_0\\)\ny ~ 1\ny-Ab\n\n\n\\(y=\\beta_0+\\beta x\\)\ny ~ x\ny-Ab und StKoef\n\n\n\\(y=\\beta_0+\\beta_1x_1+\\beta_2x_2\\)\ny ~ x1 + x2\ny-Ab und 2 StKoe\n\n\n\n\nWenn wir jetzt also unsere Weitsprungdaten modellieren wollen, verwenden wir die folgenden Befehle.\n\nlm(jump_m ~ v_ms, data = jump)\n\n\nCall:\nlm(formula = jump_m ~ v_ms, data = jump)\n\nCoefficients:\n(Intercept)         v_ms  \n    -0.1385       0.7611  \n\n\nPer default ist das Ergebnis von lm() nicht wirklich besonders hilfreich und es werden nur die beiden berechneten Koeffizienten ausgegeben. Dabei bezeichnet der Term (Intercept) den automatisch dazugefügten konstanten Term in der Formel, sprich den \\(y\\)-Achsenabschnitt \\(\\hat{\\beta}_0\\) und mit v_ms den Steigungskoeffizienten \\(\\hat{\\beta}_1\\). Um aus lm() mehr Informationen heraus zu bekommen, ist es sinnvoll das Ergebnis einen Variable zuzuweisen. In dem vorliegenden Arbeit wird dazu in den meisten Fällen eine Variante des Bezeichners mod benutzt, als Kurzform vom model. Diese Bezeichnung ist aber wie alle Bezeichner in R vollkommen willkürlich und entspringt nur der Tippfaulheit des Autors.\n\nmod &lt;- lm(jump_m ~ v_ms, data = jump)\n\nUm jetzt mehr Informationen aus dem gefitteten lm()-Objekt zu bekommen werden Helferfunktion verwendet. Die wichtigste Funktion ist die summary()-Funktion (?summary.lm).\n\nsummary(mod)\n\n\nCall:\nlm(formula = jump_m ~ v_ms, data = jump)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.44314 -0.22564  0.02678  0.19638  0.42148 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.13854    0.23261  -0.596    0.555    \nv_ms         0.76110    0.02479  30.702   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2369 on 43 degrees of freedom\nMultiple R-squared:  0.9564,    Adjusted R-squared:  0.9554 \nF-statistic: 942.6 on 1 and 43 DF,  p-value: &lt; 2.2e-16\n\n\nHier bekommen wir schon deutlich mehr Informationen mitgeteilt. Als erstes die Formell die wir lm() übergeben haben. Dann folgt ein Abschnitt über die Residuen, gefolgt von den Koeffzienten und im unteren Abschnitt noch weitere Statistiken. Wir konzentrieren uns zunächst einmal nur auf die Tabelle im Abschnitt Coefficients. Hier begegnen uns wieder in der ersten Spalte die Bezeichner für die beiden \\(\\beta\\)s in Form von \\(\\beta_0\\) (Intercept) und \\(\\beta_1\\) v_ms. In der zweiten Spalte daneben stehen die berechneten Koeffizienten die wir jetzt schon mehrmals gesehen haben. Die weiteren Spalten ignorieren wir hier zunächst. Im Laufe der folgenden Kapitel werden wir uns die weiteren Statistiken anschauen und deren Bedeutung verstehen.\nBei der Benutzung von lm() werden uns noch weitere Helferfunktionen begegnen, die den Umgang mit dem gefitteten Modell vereinfachen. Wollen wir zum Beispiel die beiden Koeffiziente aus dem Modell extrahieren können wir dazu die Funktion coefficients() oder auch nur kurz coef() verwenden. Koeffizienten und Standardschätzfehler\n\ncoef(mod)\n\n(Intercept)        v_ms \n -0.1385361   0.7611019 \n\n\nDie Funktion coef() gibt einen Vektor benannten Vektor zurück der entweder über die Bezeichner oder einfach über die Position der Koeffizienten angesprochen werden kann. Möchte ich zum Beispiel den Steigungskoeffizienten verwendent werwende ich:\n\ncoef(mod)[1]\n\n(Intercept) \n -0.1385361 \n\n\noder\n\ncoef(mod)['v_ms']\n\n     v_ms \n0.7611019 \n\n\nEin etwas übersichtlicher Zugang ist wieder zunächst einmal das Ergebnis von coef() einer Variablen zuweisen und diese dann weiter benutzen.\n\njump_betas &lt;- coef(mod)\njump_betas[1]\n\n(Intercept) \n -0.1385361 \n\n\nDie Koeffizienten kann ich zum Beispiel benutzen um die Regressionsgerade in ein Streudiagramm hinzuzufügen (Das tibble() mit den Sprungdaten hat den Bezeichner jump). Entweder mit dem ggplot2() Grafiksystem.\n\nggplot(jump,\n       aes(x = v_ms, y = jump_m)) +\n  geom_abline(intercept = jump_betas[1],\n              slope = jump_betas[2],\n              color = 'red') +\n  geom_point()\n\n\n\n\nOder mit den Standard R-Grafiksystem. Hier kann der Funktion abline() das gefittete lm()-Objekt direkt übergeben werden und die Koeffizienten werden automatisch extrahiert.\n\nplot(jump_m ~ v_ms, data = jump)\nabline(mod, color = 'red')\n\n\n\n\nSchauen wir uns noch mal ein ganz einfaches Beispiel, bei dem wir tatsächlich wissen welcher Zusammenhang zwischen den beiden Variablen. Wir halten das Beispiel ganz einfache und nehmen vier verschiedene \\(x\\)-Werte mit \\(x_i = i\\). Wir setzen \\(\\beta_0 = 1\\) und \\(\\beta_1 = 0.5\\). Wir generieren die vier Werte mit R, speichern diese in einem tibble() mit dem Bezeichner data und berechnen die resultierenden Koeffizienten mittels lm().\n\ndata &lt;- tibble(\n  x = 1:4,\n  y = 1 + 0.5 * x\n) \nmod &lt;- lm(y ~ x, data)\ncoef(mod)\n\n(Intercept)           x \n        1.0         0.5 \n\n\nUnd tatsächlich können wir die korrekten Koeffizienten mittels der einfachen linearen Regression wiedergewinnen. Diesen Ansatz mittels synthetisch generierten Daten die eingeführten Konzepte und Ansätze zu überprüfen werden wir im weiteren Verlauf des Skripts immer wieder anwenden, da er die Möglichkeit bietet relativ einfach und nachvollziehbar das Verhalten verschiedener Ansätze auszutesten.\nZusammenfassend lässt sich sagen, das wir jetzt gelernt haben wie wir ein einfaches Regressionmodell der Form Gleichung 5.3 an einen beliebigen Datensatz fitten können. Die Berechnung der beiden Koeffizienten \\(\\beta_0\\) und \\(\\beta_1\\) erfolgt mittels Gleichung 5.5. Dabei berechnen wir die Koeffizienten nicht von Hand sondern lassen die von R mittels der lm() durchführen. Die Berechnung ist dabei vollkommen mechanisch und die Koeffizienten per-se sagen nichts darüber aus, ob das lineare Modell die Daten tatsächlich auch widerspiegelt. Dazu müssen wir noch etwas mehr Theorie aufbauen um Aussagen darüber zu treffen ob das Modell adäquat ist. Dies gehen wir in den folgenden Abschnitten und Kapiteln an.\n\n\n\n\nWilkinson, G. N., und C. E. Rogers. 1973. „Symbolic description of factorial models for analysis of variance“. Applied Statistics 22 (3): 392–99."
  },
  {
    "objectID": "slm_inference.html#inferenz",
    "href": "slm_inference.html#inferenz",
    "title": "6  Inferenz",
    "section": "6.1 Inferenz",
    "text": "6.1 Inferenz\n\n6.1.1 Modellannahmen\n\\[\\begin{align*}\ny_i &= \\beta_0 + \\beta_1 x_i + \\epsilon_i \\quad i=1,\\ldots,N \\\\\n\\epsilon_i &\\sim N(0,\\sigma^2) \\quad \\textrm{identisch, unabhängig verteilt}\n\\end{align*}\\]"
  },
  {
    "objectID": "slm_inference.html#modellannahmen---verteilung-der-werte-für-gegebene-x-werte",
    "href": "slm_inference.html#modellannahmen---verteilung-der-werte-für-gegebene-x-werte",
    "title": "6  Inferenz",
    "section": "6.2 Modellannahmen - Verteilung der Werte für gegebene x-Werte",
    "text": "6.2 Modellannahmen - Verteilung der Werte für gegebene x-Werte"
  },
  {
    "objectID": "slm_inference.html#statistische-hypothesen",
    "href": "slm_inference.html#statistische-hypothesen",
    "title": "6  Inferenz",
    "section": "6.3 Statistische Hypothesen",
    "text": "6.3 Statistische Hypothesen\n\n6.3.1 Ungerichtet\n\\[\\begin{gather*}\nH_0: \\beta_1 = 0  \\\\\nH_1: \\beta_1 \\neq 0\n\\end{gather*}\\]\n\n\n6.3.2 Gerichtet\n\\[\\begin{gather*}\nH_0: \\beta_1 \\leq 0  \\\\\nH_1: \\beta_1 > 0\n\\end{gather*}\\]\n\n\n6.3.3 in R\n\nsigma(mod)\n\n[1] 0.2369055"
  },
  {
    "objectID": "slm_inference.html#verteilung-der-statistik-unter-der-h_0",
    "href": "slm_inference.html#verteilung-der-statistik-unter-der-h_0",
    "title": "6  Inferenz",
    "section": "6.4 Verteilung der Statistik unter der \\(H_0\\)",
    "text": "6.4 Verteilung der Statistik unter der \\(H_0\\)\nUnter den Annahmen des Regressionsmodells und der \\(H_0\\) gilt:\n\\[\n\\frac{\\beta_1}{\\sigma_{\\beta_1}} \\sim t_{N-2}\n\\]\nMittels \\(\\alpha\\) lässt sich daher wieder ein kritischer Wert bestimmen ab dem die \\(H_0\\) verworfen wird."
  },
  {
    "objectID": "slm_inference.html#verteilung-der-hatsigma-sqrtsum_i1n-e_i2n-k",
    "href": "slm_inference.html#verteilung-der-hatsigma-sqrtsum_i1n-e_i2n-k",
    "title": "6  Inferenz",
    "section": "6.5 Verteilung der \\(\\hat{\\sigma} = \\sqrt{\\sum_{i=1}^N e_i^2/(N-K)}\\)",
    "text": "6.5 Verteilung der \\(\\hat{\\sigma} = \\sqrt{\\sum_{i=1}^N e_i^2/(N-K)}\\)\n\n\n\n\n\nVerteilung von \\(\\hat{\\sigma}\\)"
  },
  {
    "objectID": "slm_inference.html#nochmal-summary",
    "href": "slm_inference.html#nochmal-summary",
    "title": "6  Inferenz",
    "section": "6.1 Nochmal summary()",
    "text": "6.1 Nochmal summary()\n\nsummary(mod)\n\n\nCall:\nlm(formula = jump_m ~ v_ms, data = jump)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.44314 -0.22564  0.02678  0.19638  0.42148 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.13854    0.23261  -0.596    0.555    \nv_ms         0.76110    0.02479  30.702   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2369 on 43 degrees of freedom\nMultiple R-squared:  0.9564,    Adjusted R-squared:  0.9554 \nF-statistic: 942.6 on 1 and 43 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "slm_inference.html#konfidenzintervalle-für-die-koeffizienten",
    "href": "slm_inference.html#konfidenzintervalle-für-die-koeffizienten",
    "title": "6  Inferenz",
    "section": "6.4 Konfidenzintervalle für die Koeffizienten",
    "text": "6.4 Konfidenzintervalle für die Koeffizienten\n\n6.4.1 Formel\n\\[\n\\hat{\\beta_j} \\pm q_{t_{\\alpha/2,df=N-2}} \\times \\hat{\\sigma}_{\\beta_j}\n\\]\n\n\n6.4.2 In R\n\nconfint(mod)\n\n                 2.5 %    97.5 %\n(Intercept) -0.6076488 0.3305767\nv_ms         0.7111082 0.8110957"
  },
  {
    "objectID": "slm_inference.html#zum-nacharbeiten",
    "href": "slm_inference.html#zum-nacharbeiten",
    "title": "6  Inferenz",
    "section": "6.5 Zum Nacharbeiten",
    "text": "6.5 Zum Nacharbeiten\nAltman und Krzywinski (2015) und Kutner u. a. (2005, p.40–48)\n\n\n\n\nAltman, Naomi, und Martin Krzywinski. 2015. „Points of Significance: Simple linear regression.“ Nature methods 12 (11).\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "slm_model_fit.html#residuen",
    "href": "slm_model_fit.html#residuen",
    "title": "7  Modellfit",
    "section": "7.1 Residuen",
    "text": "7.1 Residuen"
  },
  {
    "objectID": "slm_model_fit.html#was-sind-noch-mal-residuen-epsilon_i-bzw.-deren-schätzer-hatepsilon_i-e_i",
    "href": "slm_model_fit.html#was-sind-noch-mal-residuen-epsilon_i-bzw.-deren-schätzer-hatepsilon_i-e_i",
    "title": "7  Modellfit",
    "section": "7.2 Was sind noch mal Residuen \\(\\epsilon_i\\) bzw. deren Schätzer \\(\\hat{\\epsilon}_i = e_i\\)",
    "text": "7.2 Was sind noch mal Residuen \\(\\epsilon_i\\) bzw. deren Schätzer \\(\\hat{\\epsilon}_i = e_i\\)\n\\[\ny_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i\n\\]\n\n\n\n\n\nSpielzeugbeispiel mit Residuen \\(\\hat{\\epsilon}_i = e_i = y_i - \\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#annahme-epsilon_i-sim-mathcaln0-sigma2",
    "href": "slm_model_fit.html#annahme-epsilon_i-sim-mathcaln0-sigma2",
    "title": "7  Modellfit",
    "section": "7.3 Annahme: \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)",
    "text": "7.3 Annahme: \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)\n\n\n\n\n\nVerteilung der Werte für verschiedene x-Werte (rote Punkte) und die resultierende Regressionsgerade mit den Vorhersagewerte \\(\\hat{y}_i\\) (schwarze Punkte)"
  },
  {
    "objectID": "slm_model_fit.html#übersicht-residuen",
    "href": "slm_model_fit.html#übersicht-residuen",
    "title": "7  Modellfit",
    "section": "7.4 Übersicht Residuen",
    "text": "7.4 Übersicht Residuen\n\nÜbersicht über verschiedene Arten von Residuen1\n\n\n\n\n\n\n\nTyp\nBerechnung\nZiel\n\n\n\n\nEinfache Residuen\n\\(e_i = y_i - \\hat{y}_i\\)\nVerteilungsannahme\n\n\nStandardisierte Residuen\n\\(e_{Si} = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_i}}\\)\nVerteilungsannahme\n\n\nStudentized Residuen\n\\(e_{Ti} = \\frac{e_i}{\\hat{\\sigma}_{(-i)}\\sqrt{1-h_i}}\\)\nEinfluss auf Modell"
  },
  {
    "objectID": "slm_model_fit.html#residuen-in-r-berechnen-mit-residuals-und-freunden",
    "href": "slm_model_fit.html#residuen-in-r-berechnen-mit-residuals-und-freunden",
    "title": "7  Modellfit",
    "section": "7.5 Residuen in R berechnen mit residuals() und Freunden",
    "text": "7.5 Residuen in R berechnen mit residuals() und Freunden\n\nresiduals(mod)[1:5] # einfache Residuen\n\n         1          2          3          4          5 \n -9.300928  -9.368288 -11.217658  -5.572108  -6.363565 \n\nrstandard(mod)[1:5] # standardisierte Residuen\n\n         1          2          3          4          5 \n-1.4592936 -1.4598906 -1.7440573 -0.8724351 -0.9916310 \n\nrstudent(mod)[1:5] # studentized Residuen\n\n         1          2          3          4          5 \n-1.4814779 -1.4821191 -1.7928881 -0.8697060 -0.9914135"
  },
  {
    "objectID": "slm_model_fit.html#residuen-in-r-inspizieren",
    "href": "slm_model_fit.html#residuen-in-r-inspizieren",
    "title": "7  Modellfit",
    "section": "7.6 Residuen in R inspizieren",
    "text": "7.6 Residuen in R inspizieren\n\ny_hat <- predict(mod)\nplot(y_hat, residuals(mod))\nplot(y_hat, rstandard(mod))\nplot(y_hat, rstudent(mod))"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---einfache-residuen-hatepsilon_i-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---einfache-residuen-hatepsilon_i-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.7 Diagnoseplot - Einfache Residuen \\(\\hat{\\epsilon_i} \\sim \\hat{y_i}\\)",
    "text": "7.7 Diagnoseplot - Einfache Residuen \\(\\hat{\\epsilon_i} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der Residuen \\(\\hat{\\epsilon_i}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---standardisierte-residuen-hatepsilon_si-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---standardisierte-residuen-hatepsilon_si-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.8 Diagnoseplot - Standardisierte Residuen \\(\\hat{\\epsilon}_{Si} \\sim \\hat{y_i}\\)",
    "text": "7.8 Diagnoseplot - Standardisierte Residuen \\(\\hat{\\epsilon}_{Si} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der standardisierten Residuen \\(\\hat{\\epsilon}_{Si}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---studentized-residuen-hatepsilon_ti-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---studentized-residuen-hatepsilon_ti-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.9 Diagnoseplot - Studentized Residuen \\(\\hat{\\epsilon}_{Ti} \\sim \\hat{y_i}\\)",
    "text": "7.9 Diagnoseplot - Studentized Residuen \\(\\hat{\\epsilon}_{Ti} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der studentized Residuals \\(\\hat{\\epsilon}_{Ti}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus",
    "href": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus",
    "title": "7  Modellfit",
    "section": "7.10 Diagnoseplot - Wie sehen Probleme aus?",
    "text": "7.10 Diagnoseplot - Wie sehen Probleme aus?\n\n\n\n\n\nBeispielstreudiagramm"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus-1",
    "href": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus-1",
    "title": "7  Modellfit",
    "section": "7.11 Diagnoseplot - Wie sehen Probleme aus?",
    "text": "7.11 Diagnoseplot - Wie sehen Probleme aus?\n\n\n\n\n\nBeispielstreudiagramm"
  },
  {
    "objectID": "slm_model_fit.html#wie-kann-die-verteilung-der-residuen-überprüft-werden",
    "href": "slm_model_fit.html#wie-kann-die-verteilung-der-residuen-überprüft-werden",
    "title": "7  Modellfit",
    "section": "7.12 Wie kann die Verteilung der Residuen überprüft werden?",
    "text": "7.12 Wie kann die Verteilung der Residuen überprüft werden?\n\n\n\nSpielzeugbeispieldaten mit \\(n=5\\)\n\n\ny\n\n\n\n\n-2.0\n\n\n5.0\n\n\n-1.2\n\n\n0.1\n\n\n7.0\n\n\n\n\n\n\n\n\n\n\nDichtefunktion der Standardnormalverteilung"
  },
  {
    "objectID": "slm_model_fit.html#konstruktion-eines-qq-graphen",
    "href": "slm_model_fit.html#konstruktion-eines-qq-graphen",
    "title": "7  Modellfit",
    "section": "7.13 Konstruktion eines qq-Graphen",
    "text": "7.13 Konstruktion eines qq-Graphen\n\n\n\n\n\n\nSortierte Datenwerte\n\n\nkleinster\n2.kleinster\nmittlerer\n2.größter\ngrößter\n\n\n\n\n-2\n-1.2\n0.1\n5\n7"
  },
  {
    "objectID": "slm_model_fit.html#konstruktion-eines-qq-graphen-1",
    "href": "slm_model_fit.html#konstruktion-eines-qq-graphen-1",
    "title": "7  Modellfit",
    "section": "7.14 Konstruktion eines qq-Graphen",
    "text": "7.14 Konstruktion eines qq-Graphen\n\n\n\n\n\nStreudiagramm der empirischen Werte gegen die theoretischen Quantilen"
  },
  {
    "objectID": "slm_model_fit.html#beispiele-für-qq-graphen-mit-qqnorm-und-qqline",
    "href": "slm_model_fit.html#beispiele-für-qq-graphen-mit-qqnorm-und-qqline",
    "title": "7  Modellfit",
    "section": "7.15 Beispiele für qq-Graphen mit qqnorm() und qqline()",
    "text": "7.15 Beispiele für qq-Graphen mit qqnorm() und qqline()"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---qq-diagramm",
    "href": "slm_model_fit.html#diagnoseplot---qq-diagramm",
    "title": "7  Modellfit",
    "section": "7.16 Diagnoseplot - QQ-Diagramm",
    "text": "7.16 Diagnoseplot - QQ-Diagramm\n\n\n\n\n\nQQ-Diagramm der Residuen des ADAS-ADCS-Modells\n\n\n\n\n2"
  },
  {
    "objectID": "slm_model_fit.html#summary",
    "href": "slm_model_fit.html#summary",
    "title": "7  Modellfit",
    "section": "7.17 summary()",
    "text": "7.17 summary()\n\n\n\nCall:\nlm(formula = adcs ~ adas, data = adl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.2177  -3.8033  -0.4663   2.7950  20.9634 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  26.5445     4.3052   6.166 3.05e-07 ***\nadas         -0.2638     0.1015  -2.599   0.0131 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.516 on 39 degrees of freedom\nMultiple R-squared:  0.1477,    Adjusted R-squared:  0.1258 \nF-statistic: 6.757 on 1 and 39 DF,  p-value: 0.01312"
  },
  {
    "objectID": "slm_model_fit.html#neue-idee-zu-residuen",
    "href": "slm_model_fit.html#neue-idee-zu-residuen",
    "title": "7  Modellfit",
    "section": "7.18 Neue Idee zu Residuen",
    "text": "7.18 Neue Idee zu Residuen\n\n\n\n\n\nSpielzeugbeispiel mit Residuen \\(\\hat{\\epsilon}_i = e_i = y_i - \\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#zum-nacharbeiten",
    "href": "slm_model_fit.html#zum-nacharbeiten",
    "title": "7  Modellfit",
    "section": "7.19 Zum Nacharbeiten",
    "text": "7.19 Zum Nacharbeiten\nKutner u. a. (2005, p.100–114) Altman und Krzywinski (2016b) Fox (2011, p.285–296)"
  },
  {
    "objectID": "slm_model_fit.html#hebelwerte",
    "href": "slm_model_fit.html#hebelwerte",
    "title": "7  Modellfit",
    "section": "7.20 Hebelwerte",
    "text": "7.20 Hebelwerte\n\n\n\n\n\n\n\n\nStreudiagramm der ADCS-MCI-ADL scores gegen ADAS-cos scores\n\n\n\n\n\n\n\n\n\nHebelwerte der jeweiligen \\(x_i\\)s\n\n\n\n\n\n\n\n\n\nHebelwerte der jeweiligen Datenpunkte"
  },
  {
    "objectID": "slm_model_fit.html#dffits",
    "href": "slm_model_fit.html#dffits",
    "title": "7  Modellfit",
    "section": "7.21 DFFITS",
    "text": "7.21 DFFITS\nMit Hilfe der Hebelwerte lassen sich verschiedene Maße erstellen um den Einfluss von Datenpunkten auf das Modell zu überprüfen. Ein Maß wird als bezeichnet (siehe Gleichung 7.1)\n\\[\n(DFFITS)_i = \\frac{\\hat{y}_i - \\hat{y}_{i(i)}}{\\sqrt{\\hat{\\sigma}^2h_i}}\n\\tag{7.1}\\]\nIm Zähler kommen vin Gleichung 7.1 zweimal vorhergesagte \\(y\\)-Werte vor. \\(\\hat{y}_i\\) ist dabei der ganz normale Vorhersagewert der uns mittlerweile schon mehrfach begegnet ist. Der zweite Wert \\(\\hat{y}_{i(i)}\\) bezeichnet den vorhergesagten Wert aus dem Modell aus dem der Wert \\(y_i\\) weggelassen wurde. D.h, dass Modell ist mit einem Wert weniger gefittet worden. Daher misst die Differenz \\(\\hat{y}_i - \\hat{y}_{i(i)}\\) den Unterschied in den Vorhersagewerte zwischen zwei Modellen bei denen einmal der Wert \\(y_i\\) zum fitten verwendet wurde und einmal wenn \\(y_i\\) nicht zum fitten verwendet wurde. Umso größer der Unterschied zwischen diesen beiden Werte umso größer ist der Einfluss des Wertes \\(y_i\\) auf den Modellfit. Den Nenner von Gleichung 7.1 lassen wir mal fallen, da es sich dabei nur um einen Normierungswert handelt. Dementsprechend, wird mittels DFFITS für jeden Datenpunkt ein Wert ermittelt und umso größer dieser Wert ist umso größer ist der Einfluss des jeweiligen Datenpunktes auf den Modellfit.\nIm idealen Fall sollte alle Datenpunkt ungefähr den gleichen Einfluss haben und einzelne Datenpunkte die einen übermäßig großen Einfluss auf das Modell haben sollten noch einmal genauer inspiziert werden.\n\n\n\n\n\n\nTipp\n\n\n\nAls Daumenregel, kann für kleine bis mittlere Datensätze ein DFFITS von \\(\\approx 1\\) auf Probleme hindeuten, während bei großen Datensätzen \\(\\approx 2\\sqrt{k/N}\\) als Orientierungshilfe verwendet werden kann (k := Anzahl der Prediktoren, N := Stichprobengröße).\n\n\n\n\n\n\n\n\nWarnung\n\n\n\nWenn ein Wert außerhalb der Daumenregel liegt, heißt das nicht, dass er automatisch ausgeschlossen werden muss/soll, sondern lediglich inspiziert werden sollte und das Modell mit und ohne diesen Wert interpretiert werden sollte.\n\n\nIn R können die DFFITS werden mittels der dffits()-Funktion berechnet werden. Als Parameter erwartet dffits() das gefittete lm()-Objekt. Ähnlich wie bei den Residuen, werden die DFFITS-Werte gegen die vorhergesagten \\(y_i\\)-Werte graphisch abgetragen um die Wert zu inspizieren und Probleme in der Modellspezifikation zu identifizieren.\n\nplot(adl$y_hat, dffits(mod),\n     ylim=c(-2,2),\n     xlab=expression(hat(y)[i]),\n     ylab='DFFIT-Wert')\nabline(h=c(-1,1), col='red', lty=2)\n\n\n\n\nAbbildung 7.1: Beispiel für DFFITS gegen \\(\\hat{y}_i\\)\n\n\n\n\nIn Abbildung 7.1 sind die DFFITS-Werte gegen die vorhergesagten Werte \\(\\hat{y}_i\\) abgetragen und zusätzlich die Daumenregel \\(\\pm1\\) eingezeichnet. Hier ist ein Wert nur gerade so außerhalb des vorgeschlagenen Bereichs. Hier könnte daher sich dieser Datenpunkt noch einmal genauer angeschaut werden, ob bei Ausschluß des Wertes es zu einer qualitativ anderen Interpretation der Daten kommt oder ob bespielsweise Übertragungsfehler für diesen Wert vorliegen oder sonstige Gründe."
  },
  {
    "objectID": "slm_model_fit.html#cooks-abstand",
    "href": "slm_model_fit.html#cooks-abstand",
    "title": "7  Modellfit",
    "section": "7.22 Cooks-Abstand",
    "text": "7.22 Cooks-Abstand\nEin Maß um den Einfluss von einzelnen Datenpunkten auf die Vorhersagewerte \\(\\hat{y}_i\\) über alle Werte abzuschätzen.\n\\[\nD_i = \\frac{\\sum_{j=1}^N(\\hat{y_j} - \\hat{y}_{j(i)})}{k\\hat{\\sigma}^2}\n\\]\n\n7.22.1 Daumenregel\n\\(D_i > 1\\)\n\n\n7.22.2 In R\ncooks.distance()"
  },
  {
    "objectID": "slm_model_fit.html#cooks-abstand-plot",
    "href": "slm_model_fit.html#cooks-abstand-plot",
    "title": "7  Modellfit",
    "section": "7.23 Cooks-Abstand plot",
    "text": "7.23 Cooks-Abstand plot\n\n\n\n\n\nCook’s \\(D_i\\) gegen \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#dfbetas",
    "href": "slm_model_fit.html#dfbetas",
    "title": "7  Modellfit",
    "section": "7.24 DFBETAS",
    "text": "7.24 DFBETAS\nEin Maß für die Veränderung der \\(\\beta\\)-Koeffizienten durch einzelne Datenpunkte \\(i\\).\n\\[\n(DFBETAS)_{k(i)} = \\frac{\\hat{\\beta}_k - \\hat{\\beta}_{k(i)}}{\\sqrt{\\hat{\\sigma}^2c_{kk}}}\n\\]\n\n7.24.1 Daumenregel\nFür kleine bis mittlere Datensätze \\(\\approx 1\\)\nFür große Datensätze \\(\\approx 2/\\sqrt{N}\\)\n\n\n7.24.2 In R\ndfbeta()3"
  },
  {
    "objectID": "slm_model_fit.html#dfbetas-1",
    "href": "slm_model_fit.html#dfbetas-1",
    "title": "7  Modellfit",
    "section": "7.25 DFBETAS",
    "text": "7.25 DFBETAS\n\n\n\n\n\nDFBETA-Werte für \\(\\beta_0\\) und \\(\\beta_1\\) gegen \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#zusammenfassung",
    "href": "slm_model_fit.html#zusammenfassung",
    "title": "7  Modellfit",
    "section": "7.26 Zusammenfassung",
    "text": "7.26 Zusammenfassung\n\nÜbersicht über die verschiedene Einflussmaße zur Bewertung der Modellgüte\n\n\nTyp\nVeränderung\nDaumenregel\n\n\n\n\n\\((DFFITS)_i\\)\nVorhersagewert i\n\\(2\\sqrt{k/N}\\)\n\n\nCook\nDurchschnittliche Vorhersagewerte\n\\(>1\\)\n\n\n\\((DFBETAS)_{k(i)}\\)\nKoeffizient i\n\\(2\\sqrt{N}\\)\n\n\n\\(e_{Ti}\\)\nResiduum i\nt-Verteilung(n-k-2)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplots-in-r-mit-plotmod",
    "href": "slm_model_fit.html#diagnoseplots-in-r-mit-plotmod",
    "title": "7  Modellfit",
    "section": "7.27 Diagnoseplots in R mit plot(mod)",
    "text": "7.27 Diagnoseplots in R mit plot(mod)\n\nplot(mod)"
  },
  {
    "objectID": "slm_model_fit.html#zum-nacharbeiten-1",
    "href": "slm_model_fit.html#zum-nacharbeiten-1",
    "title": "7  Modellfit",
    "section": "7.28 Zum Nacharbeiten",
    "text": "7.28 Zum Nacharbeiten\nAltman und Krzywinski (2016a) Fox (2011, p.294–302)\n\n7.28.1 Weiterführendes\nYoung (2019)\n\n\n\n\nAltman, Naomi, und Martin Krzywinski. 2016a. „Points of significance: Analyzing outliers: influential or nuisance“. Nature Methods 13 (4): 281–82.\n\n\n———. 2016b. „Points of significance: regression diagnostics“. Nature Methods 13 (5): 385–86.\n\n\nFox, John. 2011. An R companion to applied regression. 2. Aufl. SAGE Publication Inc., Thousand Oaks.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York.\n\n\nYoung, Alwyn. 2019. „Channeling fisher: Randomization tests and the statistical insignificance of seemingly significant experimental results“. The Quarterly Journal of Economics 134 (2): 557–98."
  },
  {
    "objectID": "slm_prediction.html#vorhergesagte-werte-haty_i",
    "href": "slm_prediction.html#vorhergesagte-werte-haty_i",
    "title": "8  Vorhersage",
    "section": "8.1 Vorhergesagte Werte \\(\\hat{y}_i\\)",
    "text": "8.1 Vorhergesagte Werte \\(\\hat{y}_i\\)\n\n\n\nWenn ein einfaches lineares Modell gefittet wurde ist eine zentrale Frage welche Vorhersagen anhand des Modell getroffen werden können. Die Vorhersagen \\(\\hat{y}_i\\) liegen auf der vorhergesagten Regressionsgerade und berechnen sich nach dem Modell für einen gegeben \\(x\\)-Wert.\n\\[\n\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_0} x\n\\]\nWie schon mehrfach besprochen unterliegt die Regressionsgerade inherent der Unsicherheit bezüglich der geschätzen Modellkoeffizienten \\(\\hat{\\beta}_0\\) und \\(\\hat{\\beta}_1\\). Diese Unsicherheit überträgt sich auf die geschätzen Werte \\(\\hat{y}_i\\) und muss daher bei deren Interpretation berücksichtigt werden.\nIn Abbildung 8.1 sind die bereits behandelten Sprungdaten gegen die Anlaufgeschwindigkeiten zusammen mit der Regressionsgeraden und vorhergesagten Werten (rot) abgetragen.\n\n\n\n\n\nAbbildung 8.1: Vorhersagewerte \\(\\hat{y}_i\\) (rote Punkte) für die Sprungdaten.\n\n\n\n\nIn R können die vorhergesagten Werte des mittels lm() gefitteten Modells mit der Hilfsfunktion predict() bestimmt werden. Wenn der Funktion predict() keine weiteren Parameter außer dem lm-Objekt übergeben werden, berechnet predict() die vorhergesagten Werte \\(\\hat{y}_i\\) für alle die \\(x\\)-Werte die auch zum fitten des Modells benutzt wurden. Die Reihenfolge der Werte \\(\\hat{y}_i\\) enspricht dabei den Werten im Original-data.frame().\n\npredict(mod)[1:5] \n\n       1        2        3        4        5 \n4.523537 4.725140 4.856256 4.761778 5.416207 \n\n\nWir haben uns hier nur die ersten fünf Werte ausgeben lassen, da nur demonstriert werden soll wie die predict()-Funktion angewendet werden kann. Um eine Anwendung zu geben, so können mittels predict() die Residuen auch von Hand ohne die resid()-Funktion erhalten werden.\n\n(jump$jump_m - predict(mod))[1:5]\n\n          1           2           3           4           5 \n-0.16267721 -0.41248842 -0.29359256 -0.01047071  0.09927500 \n\nresid(mod)[1:5]\n\n          1           2           3           4           5 \n-0.16267721 -0.41248842 -0.29359256 -0.01047071  0.09927500 \n\n\nWiederum nur zur Demonstration die ersten fünf Wert um die Äquivalenz der beiden Methoden zu demonstrieren.\nMeistens liegt das Interesse jedoch weniger auf den vorhergesagten Werten \\(\\hat{y}_i\\) für die gemessenen Werte, sondern es sollen Werte vorhergesagt werden für \\(x\\)-Werte die nicht im Datensatz enthalten sind. Operational ändert sich nichts, es wird immer noch das gefittete Modell verwendetet und es müssen lediglich neue \\(x\\)-Werte übergeben werden.\nIn R kann dies mittels des zweite Parameter in predict() erreicht werden. Soll zum Beispiel die Sprungweite für eine Anlaufgeschwindigkeit von \\(v = 11.5[m/s]\\) berechnen werden, muss zunächst ein neues tibble() erstellt werden, welches den gewünschten \\(x\\)-Wert enthält. Dabei muss der Spaltenname in dem neuen tibble() demjenigen im Original-tibble() entsprechen. Ansonsten funktioniert die Anwendung von predict() nicht.\n\ndf <- tibble(v_ms = 11.5)\ndf\n\n# A tibble: 1 x 1\n   v_ms\n  <dbl>\n1  11.5\n\n\nDieses tibble() kann nun zusammen mit dem lm()-Objekt an predict() übergeben werden.\n\npredict(mod, newdata = df)\n\n       1 \n8.614136 \n\n\nD.h., bei einer Anlaufgeschwindigkeit von \\(v = 11.5[m/s]\\) ist anhand des Modells eine Sprungweite von \\(8.6m\\) zu erwarten."
  },
  {
    "objectID": "slm_prediction.html#unsicherheit-in-der-vorhersage",
    "href": "slm_prediction.html#unsicherheit-in-der-vorhersage",
    "title": "8  Vorhersage",
    "section": "8.2 Unsicherheit in der Vorhersage",
    "text": "8.2 Unsicherheit in der Vorhersage\nWie schon angesprochen ist unser Modell natürlich mit Unsicherheiten behaftet. Diese drücken sich in den Standardfehler für die beiden Koeffizienten \\(\\hat{\\beta_0}\\) und \\(\\hat{\\beta_1}\\) (siehe Tabelle 8.1).\n\n\n\n\nTabelle 8.1: Modellparameter und Standardfehler\n\n\n\nSchätzer\n\\(s_e\\)\n\n\n\n\n(Intercept)\n-0.14\n0.23\n\n\nv_ms\n0.76\n0.02\n\n\n\n\n\n\nDer vorhergesagte Wert \\(\\hat{y}\\) ist daher für sich alleine ist noch nicht brauchbar, da auch Informationen über dessen Unsicherheit notwendig sind um die Ergebnisse korrekt zu interpretieren.\nEs können zwei unterschiedliche Anwendungsfälle voneinander unterschieden werden.\n\nDer mittlere, erwartete Wert \\(\\hat{\\bar{y}}_{neu}\\)\nDie Vorhersage eines einzelnen Wertes \\(\\bar{y}_{neu}\\)\n\nIm konkreten Fall werden damit zwei unterschiedliche Fragestellungen beantwortet. Im 1. Fall lautet die Frage, ich habe eine Trainingsgruppe und möchte wissen was der mittlere Wert der Gruppe anhand des Modells ist, wenn alle eine bestimmte Anlaufgeschwindigkeit \\(v_{neu}\\) haben. Im 2. Fall lautet die Frage welche Weite eine einzelne Athletin für die Anlaufgeschwindigkeit \\(v_{neu}\\) springen sollte. In beiden Fällen werden keiner genau den Wert des Regressionsmodells treffen, aber im 1. Fall der Gruppe werden sich Streuungen nach oben bzw. nach unten gegenseitig im Schnitt ausbalancieren während im 2. Fall der einzelnen Athletin dies nicht der Fall ist. Daher hat die Vorhersage im 2. Fall eine höhere Unsicherheit. Diese Unterschied sollte sich dementsprechend in den Varianzen der beiden Vorhersagen wiederspiegeln.\nWie bereits erwähnt, der vorhergesagte Wert \\(\\hat{y}_{neu}\\) ist in beiden Fällen gleich und entsprecht der oben beschriebenen Methode anhand des Modell \\(y_{neu} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\times x_{\\text{neu}}\\).\nFür den erwarteten Mittelwert errechnet sich die Varianz nach:\n\\[\\begin{equation}\nVar(\\hat{\\bar{y}}_{neu}) = \\hat{\\sigma}^2 \\left[\\frac{1}{n} + \\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\\right] = \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}^2\n\\end{equation}\\]\nDas dazugehörige Konfidenzintervall errechnet sich danach mittels:\n\\[\\begin{equation}\n\\hat{\\bar{y}}_{neu} \\pm q_{t(1-\\alpha/2;n-2)} \\times \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}\n\\end{equation}\\]\nDie Varianz für die Vorhersage eines einzelnen Wertes errechnet sich:\n\\[\\begin{equation}\nVar(\\hat{y}_{neu}) = \\hat{\\sigma}^2 \\left[1 + \\frac{1}{n} + \\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\\right] = \\hat{\\sigma}^2 + \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}^2 = \\hat{\\sigma}_{\\hat{y}_{neu}}^2\n\\end{equation}\\]\nWas wiederum zu dem folgenden Konfidenzintervall führt:\n\\[\\begin{equation}\n\\hat{y}_{neu} \\pm q_{t(1-\\alpha/2;n-2)} \\times \\hat{\\sigma}_{\\hat{y}_{neu}}\n\\end{equation}\\]\nIn beiden Fällen ist der Term\n\\[\n\\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\n\\]\nenthalten. Anhand des Zählers kann abgeleitet werden, dass die Unsicherheit der Vorhersage mit dem Abstand vom Mittelwert der \\(x\\)-Werte zunimmt. Rein heuristisch macht dies Sinn, da davon ausgegangen werden kann, dass um den Mittelwert der \\(x\\)-Werte auch die meiste Information über \\(y\\) vorhanden ist und dementsprechend umso weiter die Werte sich vom \\(\\bar{x}\\) entfernen die Information abnimmt. Im Nenner ist wiederum wie auch beim Standardfehler \\(\\sigma_{\\beta_1}\\) des Steigungskoeffizienten \\(\\beta_1\\) zu sehen, dass die Varianz abnimmt mit der Streuung der \\(x\\)-Werte. Daher, wenn eine Vorhersage in einem bestimmten Bereich von \\(x\\)-Werten durchgeführt werden soll, dann sollte darauf geachtet werden möglichst diesen Bereich auch zu samplen um die Unsicherheit so klein wie möglich zu halten."
  },
  {
    "objectID": "slm_prediction.html#vorhersagen-in-r-mit-predict",
    "href": "slm_prediction.html#vorhersagen-in-r-mit-predict",
    "title": "8  Vorhersage",
    "section": "8.3 Vorhersagen in R mit predict()",
    "text": "8.3 Vorhersagen in R mit predict()\n\n8.3.1 Erwarteter Mittelwert\n\ndf <- data.frame(v_ms = 11.5) # oder tibble(v_ms = 11.5)\npredict(mod, newdata = df, interval = 'confidence')\n\n       fit      lwr      upr\n1 8.614136 8.482039 8.746234\n\n\n\n\n8.3.2 Individuelle Werte\n\npredict(mod, newdata = df, interval = 'prediction')\n\n       fit      lwr      upr\n1 8.614136 8.118445 9.109827"
  },
  {
    "objectID": "slm_prediction.html#konfidenzintervalle-graphisch",
    "href": "slm_prediction.html#konfidenzintervalle-graphisch",
    "title": "8  Vorhersage",
    "section": "8.4 Konfidenzintervalle graphisch",
    "text": "8.4 Konfidenzintervalle graphisch\n\n\n\n\n\nWeiterführende Literatur sind Kutner u. a. (2005)"
  },
  {
    "objectID": "slm_prediction.html#r2-und-root-mean-square",
    "href": "slm_prediction.html#r2-und-root-mean-square",
    "title": "8  Vorhersage",
    "section": "8.5 \\(R^2\\) und Root-mean-square",
    "text": "8.5 \\(R^2\\) und Root-mean-square"
  },
  {
    "objectID": "slm_prediction.html#einfaches-modell",
    "href": "slm_prediction.html#einfaches-modell",
    "title": "8  Vorhersage",
    "section": "8.6 Einfaches Modell",
    "text": "8.6 Einfaches Modell\n\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n\n\nCall:\nlm(formula = y ~ x, data = simple)\n\nResiduals:\n      1       2       3       4 \n-0.5817  0.9898 -0.2345 -0.1736 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.8414     0.7008   2.628    0.119\nx             0.4574     0.3746   1.221    0.346\n\nResidual standard error: 0.8376 on 2 degrees of freedom\nMultiple R-squared:  0.4271,    Adjusted R-squared:  0.1406 \nF-statistic: 1.491 on 1 and 2 DF,  p-value: 0.3465"
  },
  {
    "objectID": "slm_prediction.html#nochmal-abweichungen",
    "href": "slm_prediction.html#nochmal-abweichungen",
    "title": "8  Vorhersage",
    "section": "8.7 Nochmal Abweichungen",
    "text": "8.7 Nochmal Abweichungen\n\nGesamtvarianz: \\[\nSSTO := \\sum_{i=1}^N (y_i - \\bar{y})^2\n\\]\nRegressionsvarianz: \\[\nSSR :=\\sum_{i=1}^N(\\hat{y}_i - \\bar{y})^2\n\\]\nResidualvarianz: \\[\nSSE := \\sum_{i=1}^N (y_i - \\hat{y}_i)^2\n\\]\n\n\n\n\n\n\nMinimalmodell der Abweichungen"
  },
  {
    "objectID": "slm_prediction.html#verhältnis-von-ssr-zu-ssto",
    "href": "slm_prediction.html#verhältnis-von-ssr-zu-ssto",
    "title": "8  Vorhersage",
    "section": "8.8 Verhältnis von \\(SSR\\) zu \\(SSTO\\)",
    "text": "8.8 Verhältnis von \\(SSR\\) zu \\(SSTO\\)\n\n\n\n\n\nPerfekter Zusammenhang\n\n\n\n\n\\[\n\\frac{SSR}{SSTO} = 1\n\\]\n\n\n\n\n\nKein Zusammenhang\n\n\n\n\n\\[\n\\frac{SSR}{SSTO} = 0\n\\]"
  },
  {
    "objectID": "slm_prediction.html#determinationskoeffizient-r2",
    "href": "slm_prediction.html#determinationskoeffizient-r2",
    "title": "8  Vorhersage",
    "section": "8.9 Determinationskoeffizient \\(R^2\\)",
    "text": "8.9 Determinationskoeffizient \\(R^2\\)\nEs gilt: \\(SSTO = SSR + SSE\\)\n\\[\nR^2 = \\frac{SSR}{SSTO} = 1 - \\frac{SSE}{SSTO} \\in [0,1]\n\\] 1\n\n8.9.1 Korrigierter Determinationskoeffizient \\(R_a^2\\)\n\\[\nR_a^2 = 1 - \\frac{\\frac{SSE}{n-p}}{\\frac{SSTO}{n-1}} = 1 - \\frac{n-1}{n-p}\\frac{SSE}{SSTO}\n\\]\n\n\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "mlm_title.html",
    "href": "mlm_title.html",
    "title": "Multiple Regression",
    "section": "",
    "text": "Im folgenden wird das Modell der einfachen linearen Regression erweitert indem zusätzliche Terme in das Modell aufgenommen werden. Die Prinzipien bleiben dabei jedoch weitestgehendst gleich und können direkt auf den komplizierteren Fall der multiplen Regression übertragen werden. Im Laufe der Erweiterung des Modells wird sich dabei wird herausstellen, dass neben mehreren kontinuierlichen Variablen auch nominale Faktoren in das Modell intergriert werden können. Daraus entsteht ein sehr flexibler Modellapparat, der in den verschiedensten Zusammenhängen angewendet werden kann."
  },
  {
    "objectID": "mlm_basics.html#bedeutung-der-koeffizienten-bei-der-multiplen-regression",
    "href": "mlm_basics.html#bedeutung-der-koeffizienten-bei-der-multiplen-regression",
    "title": "9  Einführung",
    "section": "9.1 Bedeutung der Koeffizienten bei der multiplen Regression",
    "text": "9.1 Bedeutung der Koeffizienten bei der multiplen Regression\nUm die Bedeutung der Regressionskoeffzienten bei der multiple Regression besser zu verstehen ist es von Vorteil sich noch einmal die Bedeutung der Koeffizienten im einfachen Regressionsmodell zu vergegenwärtigen (siehe Abbildung 9.1).\n\n\n\n\n\nAbbildung 9.1: Beispiel für eine einfache Regression und der resultierenden Regressiongeraden\n\n\n\n\nBei der einfachen Regression haben mittels der Methode der kleinsten Quadrate eine Regressiongerade durch unsere Punktwolke gelegt. Dabei haben wir die Regressionsgerade so gewählt, dass die senkrechten Abstände der beobachteten Punkte von der Regressionsgerade minimiert werden bzw. die Abstände zwischen denen auf der Gerade liegenden, vorhergesagten Werte \\(\\hat{y}_i\\) und den beobachteten Wert \\(y_i\\).\nWenn wir nun den Übergang von einer Prädiktorvariablenzum nächstkomplizierteren Fall nehmen mit zwei Prädiktorvariablen \\(x_1\\) und \\(x_2\\), dann wäre eine mögliche Darstellungsform der Daten eine Punktwolke im dreidimensionalen Raum (siehe Abbildung 9.2 (a)).\n\n\n\n\n\n\n\n(a) 3D Punktwolke\n\n\n\n\n\n\n\n(b) 3D Punktwolke mit gefitteter Ebene\n\n\n\n\nAbbildung 9.2: Punktwolken bei der multiple Regression\n\n\nDa jetzt eine einzelne Gerade nicht mehr in der Lage ist die Daten zu fitten, ist die nächst Möglichkeit eine Ebene die in die Punktwolke gelegt wird (siehe Abbildung 9.2 (b)). Dies ermöglicht dann genau die gleiche Herangehensweise wie bei der einfachen linearen Regression anzuwenden. Als Zielgröße wird aus den möglichen Ebenen diejenigen gesucht deren vorhergesagten, auf der Ebene liegenden Punkte \\(\\hat{y}_i\\) die geringsten senkrechten Abstand zu den beobachteten Punkten \\(y_i\\) haben. Anders, wir suchen diejenigen Ebene durch die Punktwolke deren Summe der quadrierten Residuen \\(e_i = y_i - \\hat{y}_i\\) minimal ist.\nDiese Herangehensweise hat den Vorteil, dass sie zum einem die einfache lineare Regression als Spezialfall mit \\(K=1\\) beinhaltet und sich beliebig erweitern lässt mit der Einschränkung, dass bei \\(K>2\\) die dreidimenionale Darstellung mittels einer Grafik nicht mehr möglich ist. Das Prinzip der Minimierung der Abweichungen von \\(\\hat{y}_i\\) zu \\(y\\) bleibt aber immer erhalten. Zusammenfassend hat dieser Ansatz somit die folgenden Vorteile:\n\nDie Berechnungen bleiben alle gleich\nAbweichungen \\(\\hat{\\epsilon_i}\\) sind jetzt nicht mehr Abweichungen von einer Gerade sondern von einer \\(K\\)-dimensionalen Hyperebene. Die Eigenschaften der Residuen bleiben aber alle erhalten.\nDie Modellannahmen bleiben gleich: Unabhängige \\(y_i\\) und \\(\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\) iid\nInferenz für die Koeffizienten mittels \\(t_k = \\frac{\\hat{\\beta}_k}{s_k} \\sim t(N-K-1)\\) (Konfidenzintervall dito)\nKonzepte für die Vorhersage bleiben erhalten\nModelldiagnosetools bleiben alle erhalten\n\nAls nächster Schritt versuchen wir nun die Interpretation der Koeffizienten im multiplen Regressionsmodell besser zu verstehen."
  },
  {
    "objectID": "mlm_basics.html#einfaches-beispiel",
    "href": "mlm_basics.html#einfaches-beispiel",
    "title": "9  Einführung",
    "section": "9.2 Einfaches Beispiel",
    "text": "9.2 Einfaches Beispiel\n\\[\\begin{align*}\ny_i &= \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\epsilon_i \\\\\n\\beta_0 &= 1 ,\\beta_1 = 3, \\beta_2 = 0.7 \\\\\n\\epsilon_i &\\sim N(0,\\sigma = 0.5)\n\\end{align*}\\]\n\nN <- 50 # Anzahl Datenpunkte\nbeta_0 <- 1\nbeta_1 <- 3\nbeta_2 <- 0.7\nsigma <- 0.5\nset.seed(123)\ndf <- tibble(\n  x1 = runif(N, -2, 2),\n  x2 = runif(N, -2, 2),\n  y = beta_0 + beta_1*x1 + beta_2*x2 + \n    rnorm(N, 0, sigma)) \n\n\n\n\n\n\nEinfacher Zusammenhang y~x1\n\n\n\n\n\n\n\n\n\nEinfacher Zusammenhang y~x2"
  },
  {
    "objectID": "mlm_basics.html#wie-sieht-der-fit-aus",
    "href": "mlm_basics.html#wie-sieht-der-fit-aus",
    "title": "9  Einführung",
    "section": "9.3 Wie sieht der Fit aus?",
    "text": "9.3 Wie sieht der Fit aus?\n\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.20883 -0.26741 -0.00591  0.27315  1.01322 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.07674    0.06552   16.43  < 2e-16 ***\nx1           2.96537    0.05604   52.91  < 2e-16 ***\nx2           0.70815    0.05961   11.88 9.27e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4604 on 47 degrees of freedom\nMultiple R-squared:  0.9849,    Adjusted R-squared:  0.9842 \nF-statistic:  1529 on 2 and 47 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "mlm_basics.html#was-bedeuten-die-einzelnen-koeffizienten",
    "href": "mlm_basics.html#was-bedeuten-die-einzelnen-koeffizienten",
    "title": "9  Einführung",
    "section": "9.4 Was bedeuten die einzelnen Koeffizienten?",
    "text": "9.4 Was bedeuten die einzelnen Koeffizienten?\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n1.077\n0.066\n\n\nx1\n2.965\n0.056\n\n\nx2\n0.708\n0.060\n\n\n\n\n\nDer Unterschied in der abhängigen Variablen, wenn zwei Objekte sich in \\(x_i\\) um eine Einheit unterscheiden und die paarweise gleichen Werte in den verbleibenden \\(x_j, j \\neq i\\) annehmen."
  },
  {
    "objectID": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination",
    "href": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination",
    "title": "9  Einführung",
    "section": "9.5 Was bedeuten die Koeffizienten in Kombination?",
    "text": "9.5 Was bedeuten die Koeffizienten in Kombination?\n\n9.5.1 Full model\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n1.077\n0.066\n\n\nx1\n2.965\n0.056\n\n\nx2\n0.708\n0.060\n\n\n\n\n\n\n\n9.5.2 um x2 bereinigt\n\nmod_x1_x2 <- lm(x1 ~ x2, df)\nres_mod_x1_x2 <- resid(mod_x1_x2)\nmod_x1_res <- lm(y ~ res_mod_x1_x2, df)\n\n\n\n              Estimate Std. Error t value\n(Intercept)       1.25       0.16    7.61\nres_mod_x1_x2     2.97       0.14   20.97\n\n\n\n\n9.5.3 um x1 bereinigt\n\nmod_x2_x1 <- lm(x2 ~ x1, df)\nres_mod_x2_x1 <- resid(mod_x2_x1)\nmod_x2_res <- lm(y ~ res_mod_x2_x1, df)\n\n\n\n              Estimate Std. Error t value\n(Intercept)       1.25       0.51    2.44\nres_mod_x2_x1     0.71       0.47    1.51"
  },
  {
    "objectID": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination-1",
    "href": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination-1",
    "title": "9  Einführung",
    "section": "9.6 Was bedeuten die Koeffizienten in Kombination?",
    "text": "9.6 Was bedeuten die Koeffizienten in Kombination?\n\n\\(\\hat{\\beta}_1\\): Wenn ich \\(x_2\\) weiß, welche zusätzlichen Informationen bekomme ich durch \\(x_1\\)\n\\(\\hat{\\beta}_2\\): Wenn ich \\(x_1\\) weiß, welche zusätzlichen Informationen bekomme ich durch \\(x_2\\)\n\nIn Beispiel nicht problematisch, weil nach Konstruktion \\(x_1\\) und \\(x_2\\) unabhängig voneinander sind:\n\nround(cor(df),3)\n\n      x1    x2     y\nx1 1.000 0.078 0.969\nx2 0.078 1.000 0.289\ny  0.969 0.289 1.000"
  },
  {
    "objectID": "mlm_basics.html#added-variable-plots",
    "href": "mlm_basics.html#added-variable-plots",
    "title": "9  Einführung",
    "section": "9.7 Added-variable plots",
    "text": "9.7 Added-variable plots\n\n\n\n\n\nZusammenhang zwischen y und x2 bereinigt um den Einfluß von x1."
  },
  {
    "objectID": "mlm_basics.html#added-variable-plots-mit-caravplots",
    "href": "mlm_basics.html#added-variable-plots-mit-caravplots",
    "title": "9  Einführung",
    "section": "9.8 Added-variable plots mit car::avPlots()",
    "text": "9.8 Added-variable plots mit car::avPlots()\n\ncar::avPlots(mod, ~x2)"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-ich-einen-prädiktor-weg-lasse",
    "href": "mlm_basics.html#was-passiert-wenn-ich-einen-prädiktor-weg-lasse",
    "title": "9  Einführung",
    "section": "9.9 Was passiert wenn ich einen Prädiktor weg lasse?",
    "text": "9.9 Was passiert wenn ich einen Prädiktor weg lasse?\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n1.077\n0.066\n\n\nx1\n2.965\n0.056\n\n\nx2\n0.708\n0.060\n\n\n\n\n\n\ncoef(lm(y ~ x1, df))\n\n(Intercept)          x1 \n   1.007466    3.017589 \n\ncoef(lm(y ~ x2, df))\n\n(Intercept)          x2 \n  1.3377771   0.9555316 \n\n\nIn unserem Beispiel wieder nicht viel, da die Variablen unabhängig (orthogonal) voneinander sind."
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren",
    "title": "9  Einführung",
    "section": "9.10 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.10 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\n\n\nAusschnitt von Körperfettdaten\n\n\ntriceps\nthigh\nmidarm\nbody_fat\n\n\n\n\n19.5\n43.1\n29.1\n11.9\n\n\n24.7\n49.8\n28.2\n22.8\n\n\n30.7\n51.9\n37.0\n18.7\n\n\n29.8\n54.3\n31.1\n20.1\n\n\n19.1\n42.2\n30.9\n12.9\n\n\n25.6\n53.9\n23.7\n21.7\n\n\n\n\n\n1"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-1",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-1",
    "title": "9  Einführung",
    "section": "9.11 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.11 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\nGGally::ggpairs(bodyfat) + theme(text = element_text(size = 10))\n\n\n\n\nKorrelationsmatrize"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-2",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-2",
    "title": "9  Einführung",
    "section": "9.12 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.12 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\n# Alle drei Prädiktoren\nmod_full <- lm(body_fat ~ triceps + thigh + midarm, bodyfat)\n# ohne Arm\nmod_wo_midarm <- lm(body_fat ~ triceps + thigh, bodyfat)\n# Ohne Oberschenkel\nmod_wo_thigh <- lm(body_fat ~ triceps + midarm, bodyfat)\n# Ohne Triceps\nmod_wo_triceps <- lm(body_fat ~ thigh + midarm, bodyfat)"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-3",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-3",
    "title": "9  Einführung",
    "section": "9.13 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.13 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\n\n\nfull model\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n117.085\n99.782\n\n\ntriceps\n4.334\n3.016\n\n\nthigh\n-2.857\n2.582\n\n\nmidarm\n-2.186\n1.595\n\n\n\n\n\n\n\n\nw/o midarm\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n-19.174\n8.361\n\n\ntriceps\n0.222\n0.303\n\n\nthigh\n0.659\n0.291\n\n\n\n\n\n\n\n\nw/o thigh\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n6.792\n4.488\n\n\ntriceps\n1.001\n0.128\n\n\nmidarm\n-0.431\n0.177\n\n\n\n\n\n\n\n\nw/o triceps\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n-25.997\n6.997\n\n\nthigh\n0.851\n0.112\n\n\nmidarm\n0.096\n0.161"
  },
  {
    "objectID": "mlm_basics.html#multikollinearität",
    "href": "mlm_basics.html#multikollinearität",
    "title": "9  Einführung",
    "section": "9.14 Multikollinearität2",
    "text": "9.14 Multikollinearität2\n\nGroße Änderungen in den Koeffizienten wenn Prädiktoren ausgelassen/eingefügt werden\nKoeffizienten haben eine andere Richtung als erwartet\nHohe (einfache) Korrelationen zwischen Prädiktoren\nBreite Konfidenzintervalle für “wichtige” Prädiktoren \\(b_j\\)\n\n\\[\n\\widehat{\\text{Var}}(b_j) = \\frac{\\hat{\\sigma}^2}{(n-1)s_j^2}\\frac{1}{1-R_j^2}\n\\]\n\\(R_j^2\\) = Multipler Korrelationskoeffizient der Prädiktoren auf Prädiktorvariable \\(j\\)."
  },
  {
    "objectID": "mlm_basics.html#variance-inflation-factor-vif",
    "href": "mlm_basics.html#variance-inflation-factor-vif",
    "title": "9  Einführung",
    "section": "9.15 Variance Inflation Factor (VIF)",
    "text": "9.15 Variance Inflation Factor (VIF)\n\\[\n\\text{VIF}_j = \\frac{1}{1-R_j^2}\n\\]\n\n\n\n\n\n\nTipp\n\n\n\nWenn VIF > 10 ist, dann deutet dies auf hohe Multikollinearität hin.\n\n\n3"
  },
  {
    "objectID": "mlm_basics.html#variance-inflation-factor-vif-1",
    "href": "mlm_basics.html#variance-inflation-factor-vif-1",
    "title": "9  Einführung",
    "section": "9.16 Variance Inflation Factor (VIF)",
    "text": "9.16 Variance Inflation Factor (VIF)\n\ncar::vif(mod_full) \n\n triceps    thigh   midarm \n708.8429 564.3434 104.6060 \n\n\n4\nÜblicherweise wird der größte Wert betrachtet um die Multikollinearität zu bewerten."
  },
  {
    "objectID": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren",
    "href": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren",
    "title": "9  Einführung",
    "section": "9.17 Wenn Prädiktoren sich gegenseitig maskieren5",
    "text": "9.17 Wenn Prädiktoren sich gegenseitig maskieren5\n\n\n\n\n\nx_pos maskiert den Einfluss von x_neg"
  },
  {
    "objectID": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren-1",
    "href": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren-1",
    "title": "9  Einführung",
    "section": "9.18 Wenn Prädiktoren sich gegenseitig maskieren",
    "text": "9.18 Wenn Prädiktoren sich gegenseitig maskieren\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n0.235\n0.135\n\n\nx_pos\n0.218\n0.147\n\n\n\n\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n0.228\n0.116\n\n\nx_neg\n-0.618\n0.103\n\n\n\n\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n0.135\n0.096\n\n\nx_pos\n0.850\n0.123\n\n\nx_neg\n-0.976\n0.099"
  },
  {
    "objectID": "mlm_basics.html#multiple-regression",
    "href": "mlm_basics.html#multiple-regression",
    "title": "9  Einführung",
    "section": "9.19 Multiple Regression",
    "text": "9.19 Multiple Regression\nAus der einfachen Regression\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\n\\]\nwird\n\\[\ny_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\dots + \\beta_K x_{Ki} + \\epsilon_i\n\\]\nmit K Prädiktorvariablen und Multikollinearität."
  },
  {
    "objectID": "mlm_basics.html#zum-nacharbeiten",
    "href": "mlm_basics.html#zum-nacharbeiten",
    "title": "9  Einführung",
    "section": "9.20 Zum Nacharbeiten",
    "text": "9.20 Zum Nacharbeiten\nAltman und Krzywinski (2015) Kutner u. a. (2005, p.278–288) Fox (2011, p.325–327)\n\n\n\n\nAltman, Naomi, und Martin Krzywinski. 2015. „Points of significance: Multiple linear regression“. Nature Methods 12 (12): 1103–4.\n\n\nFox, John. 2011. An R companion to applied regression. 2. Aufl. SAGE Publication Inc., Thousand Oaks.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York.\n\n\nMcElreath, Richard. 2016. Statistical rethinking, A Bayesian Course with Examples in R and Stan. 1. Aufl. Boca Raton: CRC Press."
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten",
    "href": "mlm_interactions.html#beispieldaten",
    "title": "10  Interaktionseffekte",
    "section": "10.1 Beispieldaten1",
    "text": "10.1 Beispieldaten1\n\n\n\nBeispieldaten (synthetisch)\n\n\nVelocity[m/s]\nbody mass[kg]\narm span[cm]\n\n\n\n\n185.42\n68.71\n20.14\n\n\n184.08\n73.85\n21.29\n\n\n200.74\n89.43\n27.57\n\n\n170.34\n84.97\n19.88\n\n\n176.89\n82.40\n20.51\n\n\n200.68\n91.57\n29.22"
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten---deskriptiv",
    "href": "mlm_interactions.html#beispieldaten---deskriptiv",
    "title": "10  Interaktionseffekte",
    "section": "10.2 Beispieldaten - Deskriptiv",
    "text": "10.2 Beispieldaten - Deskriptiv\n\n\n\nDeskriptive Statistik der Handballdaten\n\n\n\nMean\nStd.Dev\nMin\nMax\n\n\n\n\narm_span\n184.3\n7.7\n169.4\n200.7\n\n\nbody_mass\n77.5\n10.3\n58.0\n101.1\n\n\nvel\n21.9\n2.3\n18.5\n29.2"
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten-1",
    "href": "mlm_interactions.html#beispieldaten-1",
    "title": "10  Interaktionseffekte",
    "section": "10.3 Beispieldaten",
    "text": "10.3 Beispieldaten\n\n\n\n\n\nGeschwindigkeit gegen Körpergewicht\n\n\n\n\n\n\n\n\n\nGeschwindigkeit gegen Armspannweite"
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten---startmodell",
    "href": "mlm_interactions.html#beispieldaten---startmodell",
    "title": "10  Interaktionseffekte",
    "section": "10.4 Beispieldaten - Startmodell",
    "text": "10.4 Beispieldaten - Startmodell\n\\[\nY_{i} = \\beta_0 + \\beta_1 \\times \\textrm{bm}_i + \\beta_2 \\times \\textrm{as}_i + \\epsilon_i\n\\]\n\nmod_1 <- lm(vel ~ body_mass + arm_span, handball)\n\n\n\n\nModell 1\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n-1.768\n7.632\n-0.232\n0.818\n\n\nbody_mass\n0.077\n0.033\n2.359\n0.024\n\n\narm_span\n0.096\n0.044\n2.192\n0.035\n\n\n\\(\\hat{\\sigma}\\)\n1.996"
  },
  {
    "objectID": "mlm_interactions.html#modellfit",
    "href": "mlm_interactions.html#modellfit",
    "title": "10  Interaktionseffekte",
    "section": "10.5 Modellfit",
    "text": "10.5 Modellfit\n\n\n\n\n\n3D Streudiagramm"
  },
  {
    "objectID": "mlm_interactions.html#zentrierung",
    "href": "mlm_interactions.html#zentrierung",
    "title": "10  Interaktionseffekte",
    "section": "10.6 Zentrierung",
    "text": "10.6 Zentrierung\n\nhandball <- dplyr::mutate(handball,\n                          body_mass_c = body_mass - mean(body_mass),\n                          arm_span_c = arm_span - mean(arm_span))\n\n\n\n\nDeskriptive Statistik\n\n\n\nMean\nStd.Dev\n\n\n\n\narm_span\n184.29\n7.72\n\n\narm_span_c\n0.00\n7.72\n\n\nbody_mass\n77.46\n10.26\n\n\nbody_mass_c\n0.00\n10.26\n\n\nvel\n21.85\n2.31"
  },
  {
    "objectID": "mlm_interactions.html#modell-mit-zentrierten-variablen",
    "href": "mlm_interactions.html#modell-mit-zentrierten-variablen",
    "title": "10  Interaktionseffekte",
    "section": "10.7 Modell mit zentrierten Variablen",
    "text": "10.7 Modell mit zentrierten Variablen\n\nmod_2 <- lm(vel ~ body_mass_c + arm_span_c, handball)\n\n\n\n\nModell 2\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n21.852\n0.316\n69.247\n<0.001\n\n\nbody_mass_c\n0.077\n0.033\n2.359\n0.024\n\n\narm_span_c\n0.096\n0.044\n2.192\n0.035\n\n\n\\(\\hat{\\sigma}\\)\n1.996"
  },
  {
    "objectID": "mlm_interactions.html#residuen-im-zentrierten-additiven-modell",
    "href": "mlm_interactions.html#residuen-im-zentrierten-additiven-modell",
    "title": "10  Interaktionseffekte",
    "section": "10.8 Residuen im zentrierten, additiven Modell",
    "text": "10.8 Residuen im zentrierten, additiven Modell\n\n\n\n\n\nResiduenplot"
  },
  {
    "objectID": "mlm_interactions.html#added-variable-plot",
    "href": "mlm_interactions.html#added-variable-plot",
    "title": "10  Interaktionseffekte",
    "section": "10.9 Added-variable plot",
    "text": "10.9 Added-variable plot\n\n\n\n\n\nAbbildung 10.1: Added-variable Graph mit car::avPlots()"
  },
  {
    "objectID": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind",
    "href": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind",
    "title": "10  Interaktionseffekte",
    "section": "10.10 Was passiert wenn die Effekte nicht mehr nur additiv sind?",
    "text": "10.10 Was passiert wenn die Effekte nicht mehr nur additiv sind?\n\n\n\n\n\nUnterteilung von Körpergewicht und Armspannweite in Kategorien"
  },
  {
    "objectID": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind-1",
    "href": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind-1",
    "title": "10  Interaktionseffekte",
    "section": "10.11 Was passiert wenn die Effekte nicht mehr nur additiv sind?",
    "text": "10.11 Was passiert wenn die Effekte nicht mehr nur additiv sind?\n\n10.11.1 Neues Modell mit Interaktionen:\n\\[\nY_{i} = \\beta_0 + \\beta_1 \\times \\textrm{bm}_i + \\beta_2 \\times \\textrm{as}_i + \\beta_3 \\times \\textrm{bm}_i \\times \\textrm{as}_i + \\epsilon_i\n\\]"
  },
  {
    "objectID": "mlm_interactions.html#modellierung",
    "href": "mlm_interactions.html#modellierung",
    "title": "10  Interaktionseffekte",
    "section": "10.12 Modellierung",
    "text": "10.12 Modellierung\n\nmod_3 <- lm(vel ~ body_mass_c * arm_span_c, handball) \n\n\n\n\nModell 3\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n21.346\n0.143\n149.296\n<0.001\n\n\nbody_mass_c\n0.119\n0.015\n8.133\n<0.001\n\n\narm_span_c\n0.083\n0.019\n4.380\n<0.001\n\n\nbody_mass_c:arm_span_c\n0.021\n0.002\n12.633\n<0.001\n\n\n\\(\\hat{\\sigma}\\)\n0.868\n\n\n\n\n\n\n\n\n2"
  },
  {
    "objectID": "mlm_interactions.html#einfache-steigungen-in-vergleich",
    "href": "mlm_interactions.html#einfache-steigungen-in-vergleich",
    "title": "10  Interaktionseffekte",
    "section": "10.13 Einfache Steigungen in Vergleich",
    "text": "10.13 Einfache Steigungen in Vergleich\n\n\n\n\n\nModell ohne Interaktionen\n\n\n\n\n\n\n\n\n\nModell mit Interaktionen"
  },
  {
    "objectID": "mlm_interactions.html#interaktionen-sind-symmetrisch",
    "href": "mlm_interactions.html#interaktionen-sind-symmetrisch",
    "title": "10  Interaktionseffekte",
    "section": "10.14 Interaktionen sind symmetrisch",
    "text": "10.14 Interaktionen sind symmetrisch\n\n\n\n\n\nVeränderung mit der Körpergewicht\n\n\n\n\n\n\n\n\n\nVeränderung mit dem Armspannweite"
  },
  {
    "objectID": "mlm_interactions.html#warum-das-model-sinn-macht",
    "href": "mlm_interactions.html#warum-das-model-sinn-macht",
    "title": "10  Interaktionseffekte",
    "section": "10.15 Warum das Model Sinn macht",
    "text": "10.15 Warum das Model Sinn macht\n\n\n\n\n\nVeränderung mit dem Körpergewicht\n\n\n\n\n\n\n\nEinfache Steigungen\n\n\narm span\\centered\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\n\n\n\n10\n22.18\n0.33\n\n\n0\n21.35\n0.12\n\n\n-10\n20.51\n-0.09"
  },
  {
    "objectID": "mlm_interactions.html#warum-das-modell-sinn-macht",
    "href": "mlm_interactions.html#warum-das-modell-sinn-macht",
    "title": "10  Interaktionseffekte",
    "section": "10.16 Warum das Modell Sinn macht",
    "text": "10.16 Warum das Modell Sinn macht\n\n\n\nEinfache Steigungen\n\n\narm span\\centered\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\n\n\n\n10\n22.18\n0.33\n\n\n0\n21.35\n0.12\n\n\n-10\n20.51\n-0.09\n\n\n\n\n\n\n\n\nModellkoeffizienten\n\n\n\nbetas\n\n\n\n\nb0\n21.35\n\n\nbm_c\n0.12\n\n\nas_c\n0.08\n\n\nbm_c:as_c\n0.02"
  },
  {
    "objectID": "mlm_interactions.html#interpretation-der-koeffizienten",
    "href": "mlm_interactions.html#interpretation-der-koeffizienten",
    "title": "10  Interaktionseffekte",
    "section": "10.17 Interpretation der Koeffizienten",
    "text": "10.17 Interpretation der Koeffizienten\n\\[\nY = b_0 + b_1 \\cdot x_1 + b_2 \\cdot x_2 + b_3 \\cdot x_1 \\cdot x_2 + \\epsilon_i\n\\]\n\n\\(b_0\\): (y-Achsenabschnitt) der Wert von \\(\\hat{Y}\\) wenn \\(x_1 = 0\\) und \\(x_2 = 0\\) gilt.\n\\(b_1\\): Der Unterschied in \\(\\hat{Y}\\) wenn zwei Objekte sich in \\(x_1\\) um eine Einheit unterscheiden und \\(x_2 = 0\\) ist.\n\\(b_2\\): Der Unterschied in \\(\\hat{Y}\\) wenn zwei Objekte sich in \\(x_2\\) um eine Einheit unterscheiden und \\(x_1 = 0\\) ist.\n\\(b_3\\): (Interaktionskoeffizient) Die Veränderung des Effekts von \\(x_1\\) auf \\(\\hat{Y}\\) wenn \\(x_2\\) um eine Einheit größer wird bzw. genau andersherum für \\(x_2\\)."
  },
  {
    "objectID": "mlm_interactions.html#aus-der-ebene-wird-eine-gekrümmte-fläche",
    "href": "mlm_interactions.html#aus-der-ebene-wird-eine-gekrümmte-fläche",
    "title": "10  Interaktionseffekte",
    "section": "10.18 Aus der Ebene wird eine gekrümmte Fläche",
    "text": "10.18 Aus der Ebene wird eine gekrümmte Fläche\n\n\n\n\n\n3D Streudiagramm des Interaktionsmodells"
  },
  {
    "objectID": "mlm_interactions.html#residuenvergleich",
    "href": "mlm_interactions.html#residuenvergleich",
    "title": "10  Interaktionseffekte",
    "section": "10.19 Residuenvergleich",
    "text": "10.19 Residuenvergleich\n\n\n\n\n\nResiduen im additiven Modell\n\n\n\n\n\n\n\n\n\nResiduen im Interaktionsmodell"
  },
  {
    "objectID": "mlm_interactions.html#residuenvergleich---qq-plot",
    "href": "mlm_interactions.html#residuenvergleich---qq-plot",
    "title": "10  Interaktionseffekte",
    "section": "10.20 Residuenvergleich - qq-Plot",
    "text": "10.20 Residuenvergleich - qq-Plot\n\n\n\n\n\nadditives Modell\n\n\n\n\n\n\n\n\n\nInteraktionsmodell"
  },
  {
    "objectID": "mlm_interactions.html#take-away",
    "href": "mlm_interactions.html#take-away",
    "title": "10  Interaktionseffekte",
    "section": "10.21 Take-away",
    "text": "10.21 Take-away\nInteraktionsmodell\n\nErhöht die Flexibilität des linearen Modells.\nBei Interaktionen hängt der Einfluss der einzelnen Variablen immer von den Werten der anderen Variablen ab.\nAchtung: Interpretation der einfachen Haupteffekte nicht mehr möglich bzw. sinnvoll!"
  },
  {
    "objectID": "mlm_interactions.html#zuschlag",
    "href": "mlm_interactions.html#zuschlag",
    "title": "10  Interaktionseffekte",
    "section": "10.22 Zuschlag",
    "text": "10.22 Zuschlag\nWas passiert im Interaktionsmodell mit den Koeffizienten wenn die \\(x_{ki}\\)s zentriert werden?\n\\[\\begin{align*}\ny_i &= \\beta_0 + \\beta_1 (x_{1i} - \\bar{x}_1) + \\beta_2 (x_{2i} - \\bar{x}_2) + \\beta_3 (x_{1i}-\\bar{x}_1)(x_{2i}-\\bar{x}_2) \\\\\n&= \\beta_0 + \\beta_1 x_{1i} - \\beta_1 \\bar{x}_1 + \\beta_2 x_{2i} - \\beta_2 \\bar{x}_2 + \\beta_3 x_{1i} x_{2i} - \\beta_3 x_{1i} \\bar{x}_2 - \\beta_3 \\bar{x}_1 x_{2i} + \\beta_3 \\bar{x}_1 \\bar{x}_2 \\\\\n&= \\beta_0 - \\beta_1 \\bar{x}_1 - \\beta_2 \\bar{x}_2 + \\beta_3 \\bar{x}_1 \\bar{x}_2 + \\beta_1 x_{1i}- \\beta_3 \\bar{x}_2 x_{1i} + \\beta_2 x_{2i} - \\beta_3 \\bar{x}_1 x_{2i} + \\beta_3 x_{1i} x_{2i} \\\\\n&= \\underbrace{\\beta_0 - \\beta_1 \\bar{x}_1 - \\beta_2 \\bar{x}_2 + \\beta_3 \\bar{x}_1 \\bar{x}_2}_{\\beta_0} + \\underbrace{(\\beta_1 - \\beta_3 \\bar{x}_2) x_{1i}}_{\\beta_1 x_{1i}} + \\underbrace{(\\beta_2 - \\beta_3 \\bar{x}_1) x_{2i}}_{\\beta_2 x_{2i}} + \\beta_3 x_{1i} x_{2i}\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_interactions.html#zum-nacharbeiten",
    "href": "mlm_interactions.html#zum-nacharbeiten",
    "title": "10  Interaktionseffekte",
    "section": "10.23 Zum Nacharbeiten",
    "text": "10.23 Zum Nacharbeiten\nKutner u. a. (2005, p.306–313)\n\n\n\n\nDebanne, Thierry, und Guillaume Laffaye. 2011. „Predicting the throwing velocity of the ball in handball with anthropometric variables and isotonic tests“. Journal of Sports Sciences 29 (7): 705–13.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "mlm_dummy_coding.html#beispiel-körpergröße-bei-frauen-und-männern",
    "href": "mlm_dummy_coding.html#beispiel-körpergröße-bei-frauen-und-männern",
    "title": "11  Integration von nominale Variablen",
    "section": "11.1 Beispiel: Körpergröße bei Frauen und Männern",
    "text": "11.1 Beispiel: Körpergröße bei Frauen und Männern\n\n\n\n\n\nSimulierte Daten: Verteilung von Körpergrößen nach Geschlecht"
  },
  {
    "objectID": "mlm_dummy_coding.html#datensatz",
    "href": "mlm_dummy_coding.html#datensatz",
    "title": "11  Integration von nominale Variablen",
    "section": "11.2 Datensatz",
    "text": "11.2 Datensatz\n\n\n\nAusschnitt aus den Daten\n\n\ncm\ngender\n\n\n\n\n174.4\nm\n\n\n177.7\nm\n\n\n195.6\nm\n\n\n171.3\nf\n\n\n164.0\nf\n\n\n176.0\nf"
  },
  {
    "objectID": "mlm_dummy_coding.html#nominale-variablen-in-r",
    "href": "mlm_dummy_coding.html#nominale-variablen-in-r",
    "title": "11  Integration von nominale Variablen",
    "section": "11.3 Nominale Variablen in R",
    "text": "11.3 Nominale Variablen in R\nNominale Variablen werden in R als factor() dargestellt.\n\ngender <- factor(c(0,0,1,1),\n                 levels = c(0,1),\n                 labels = c('m','f'))\ngender\n\n[1] m m f f\nLevels: m f\n\n\n1"
  },
  {
    "objectID": "mlm_dummy_coding.html#t-test-in-r-mit-t.test",
    "href": "mlm_dummy_coding.html#t-test-in-r-mit-t.test",
    "title": "11  Integration von nominale Variablen",
    "section": "11.4 t-Test in R mit t.test()",
    "text": "11.4 t-Test in R mit t.test()\n\nt.test(cm ~ gender, data=height, var.equal=T)\n\n\n\n\n Two Sample t-test\n\ndata: cm by gender\nt = -4.57, df = 58, p-value = <0.001\nd = -10.75, s_e = 2.35\n95 percent confidence interval\n[-15.45, -6.04]"
  },
  {
    "objectID": "mlm_dummy_coding.html#modellformulierung-beim-t-test-n_w-n_m",
    "href": "mlm_dummy_coding.html#modellformulierung-beim-t-test-n_w-n_m",
    "title": "11  Integration von nominale Variablen",
    "section": "11.5 Modellformulierung beim t-Test \\((n_w = n_m)\\)",
    "text": "11.5 Modellformulierung beim t-Test \\((n_w = n_m)\\)\n\\[\\begin{align*}\nY_{if} &= \\mu_{f} + \\epsilon_{if}, \\quad \\epsilon_{if} \\sim \\mathcal{N}(0,\\sigma^2) \\\\\nY_{im} &= \\mu_{m} + \\epsilon_{im}, \\quad \\epsilon_{im} \\sim \\mathcal{N}(0,\\sigma^2)\n\\end{align*}\\]\n\n11.5.1 Hypothesen\n\\[\\begin{align*}\nH_0&: \\delta = 0 \\\\\nH_1&: \\delta \\neq 0\n\\end{align*}\\]\n\n\n11.5.2 Teststatistik\n\\[\nt = \\frac{\\bar{y}_m - \\bar{y}_w}{\\sqrt{\\frac{s_m^2 + s_w^2}{2}}\\sqrt{\\frac{2}{n}}}\n\\]\n\n\n11.5.3 Referenzverteilung\n\\[\nt \\sim t_{df=2n-2}\n\\]\n\n\n\n\n\nt-Verteilung mit \\(df=58\\)"
  },
  {
    "objectID": "mlm_dummy_coding.html#kann-ich-aus-dem-t-test-ein-lineares-modell-machen",
    "href": "mlm_dummy_coding.html#kann-ich-aus-dem-t-test-ein-lineares-modell-machen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.6 Kann ich aus dem t-Test ein lineares Modell machen?",
    "text": "11.6 Kann ich aus dem t-Test ein lineares Modell machen?\n\n11.6.1 t-Test\n\\[\\begin{align*}\nY_{if} &= \\mu_{f} + \\epsilon_{if}, \\quad \\epsilon_{if} \\sim \\mathcal{N}(0,\\sigma^2) \\\\\nY_{im} &= \\mu_{m} + \\epsilon_{im}, \\quad \\epsilon_{im} \\sim \\mathcal{N}(0,\\sigma^2) \\\\\nt &= \\frac{\\bar{y}_m - \\bar{y}_w}{\\sqrt{\\frac{s_m^2 + s_w^2}{2}}\\sqrt{\\frac{2}{n}}} \\\\\nt &\\sim t_{df=2n-2}\n\\end{align*}\\]\n\n\n11.6.2 Lineares Modell\n\\[\\begin{align*}\nY_i &= \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i \\\\\n\\Delta_m &= \\mu_m - \\mu_f \\\\\nY_i &= \\beta_0 + \\beta_1 \\times x_{??} + \\epsilon_i \\\\\nY_i &= \\mu_f + \\Delta_{m} \\times x_{??} + \\epsilon_i\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#dummy--oder-indikatorkodierung",
    "href": "mlm_dummy_coding.html#dummy--oder-indikatorkodierung",
    "title": "11  Integration von nominale Variablen",
    "section": "11.7 Dummy- oder Indikatorkodierung",
    "text": "11.7 Dummy- oder Indikatorkodierung\n\\[\\begin{align*}\nY_i &= \\mu_f + \\Delta_{m} \\times x_{1i} + \\epsilon_i \\\\\n\\Delta_m &= \\mu_m - \\mu_f \\\\\nx_1 &=\n\\begin{cases}\n0\\text{ wenn weiblich}\\\\\n1\\text{ wenn männlich}\n\\end{cases}\n\\end{align*}\\]\nFür eine nominale Variable wird eine Indikatorvariablen (Dummyvariable) definiert. Über diese Indikatorvariable kann die Zugehörigkeit eines Messwerts \\(Y_i\\) zu einer Faktorstufe \\(k\\) bestimmt werden. Eine Faktorstufe ist dabei immer die Referenzstufe bei der die Indikatorvariable gleich \\(0\\) ist."
  },
  {
    "objectID": "mlm_dummy_coding.html#einfach-mal-stumpf-in-lm-eingeben",
    "href": "mlm_dummy_coding.html#einfach-mal-stumpf-in-lm-eingeben",
    "title": "11  Integration von nominale Variablen",
    "section": "11.8 Einfach mal stumpf in lm() eingeben",
    "text": "11.8 Einfach mal stumpf in lm() eingeben\n\nmod <- lm(cm ~ gender, height)\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n168.783\n1.663\n101.477\n<0.001\n\n\ngenderm\n10.746\n2.352\n4.568\n<0.001\n\n\n\n\n\n2"
  },
  {
    "objectID": "mlm_dummy_coding.html#vergleich-der-konfidenzintervalle",
    "href": "mlm_dummy_coding.html#vergleich-der-konfidenzintervalle",
    "title": "11  Integration von nominale Variablen",
    "section": "11.9 Vergleich der Konfidenzintervalle",
    "text": "11.9 Vergleich der Konfidenzintervalle\n\n11.9.1 Lineares Modell\n\nconfint(mod)\n\n                2.5 %    97.5 %\n(Intercept) 165.45401 172.11276\ngenderm       6.03713  15.45403\n\n\n\n\n11.9.2 t-Test\n\nt.test(cm ~ gender,\n       data = height,\n       var.equal=T)$conf\n\n[1] -15.45403  -6.03713\nattr(,\"conf.level\")\n[1] 0.95\n\n\n3"
  },
  {
    "objectID": "mlm_dummy_coding.html#auf-welchen-werten-wird-ein-lineares-modell-gerechnet",
    "href": "mlm_dummy_coding.html#auf-welchen-werten-wird-ein-lineares-modell-gerechnet",
    "title": "11  Integration von nominale Variablen",
    "section": "11.10 Auf welchen Werten wird ein lineares Modell gerechnet???",
    "text": "11.10 Auf welchen Werten wird ein lineares Modell gerechnet???\n\n\n\nRepräsentation der Faktorvariablen\n\n\ncm\ngender\n\\(x_1\\)\n\n\n\n\n174.40\nm\n1\n\n\n177.70\nm\n1\n\n\n195.59\nm\n1\n\n\n160.05\nf\n0\n\n\n164.92\nf\n0\n\n\n154.35\nf\n0"
  },
  {
    "objectID": "mlm_dummy_coding.html#residuen",
    "href": "mlm_dummy_coding.html#residuen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.11 Residuen",
    "text": "11.11 Residuen\n\n\n\n\n\nResiduen"
  },
  {
    "objectID": "mlm_dummy_coding.html#wens-interessiert---t-wert",
    "href": "mlm_dummy_coding.html#wens-interessiert---t-wert",
    "title": "11  Integration von nominale Variablen",
    "section": "11.12 Wen’s interessiert - t-Wert",
    "text": "11.12 Wen’s interessiert - t-Wert\nSeien beide Gruppen gleich groß (\\(n\\)) mit \\(N = n_m + n_w = 2 \\times n\\). Der t-Wert für \\(\\beta_1\\) berechnet sich aus \\(t = \\frac{b_1}{s_b}\\) mit:\n\\[\ns_b = \\sqrt{\\frac{\\sum_{i=1}^N (y_i - \\bar{y})^2}{N-2}\\frac{1}{\\sum_{i=1}^N(x_i-\\bar{x})^2}}\n\\] Dadurch, das die \\(x_i\\) entweder gleich \\(0\\) oder \\(1\\) sind, ist \\(\\bar{x}=0.5\\) und die Abweichungsquadrate im zweiten Term sind alle gleich \\(\\frac{1}{4}\\).\n\\[\n\\sum_{i=1}^N(x_i - \\bar{x})^2=\\sum_{i=1}^N\\left(x_i - \\frac{1}{2}\\right)^2 = \\sum_{i=1}^N\\frac{1}{4}=\\frac{N}{4}=\\frac{2n}{4}=\\frac{n}{2}\n\\]\nDer ersten Term kann mit etwas Algebra und der Definition für die Stichprobenvarianz \\(s^2\\) auf die gewünschte Form gebracht werden.\n\\[\n\\frac{\\sum_{i=1}^N(y_i-\\hat{y})^2}{N-2}=\\frac{\\sum_{i=1}^n(\\overbrace{y_{im} - \\bar{y}_m}^{Männer})^2+\\sum_{i=1}^n(\\overbrace{y_{iw}-\\bar{y}_w}^{Frauen})^2}{2(n-1)}=\\frac{(n-1)s_m^2+(n-1)s_w^2}{2(n-1)}=\\frac{s_m^2+s_w^2}{2}\n\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#wens-interessiert---beta_1-mu_w---mu_m",
    "href": "mlm_dummy_coding.html#wens-interessiert---beta_1-mu_w---mu_m",
    "title": "11  Integration von nominale Variablen",
    "section": "11.13 Wen’s interessiert - \\(\\beta_1 = \\mu_w - \\mu_m\\)",
    "text": "11.13 Wen’s interessiert - \\(\\beta_1 = \\mu_w - \\mu_m\\)\nMit \\(s_x^2 = \\frac{N\\frac{1}{4}}{N-1} = \\frac{N}{4(N-1)}\\) \\[\\begin{align*}\n    b_1 &= \\frac{cov(x,y)}{s_x^2} \\\\\n    &= \\frac{\\sum_{i=1}^N(y_i - \\bar{y})(x_i - \\bar{x})}{N-1} \\frac{4(N-1)}{N} \\\\\n    &= 4\\frac{\\sum_{i=1}^n(y_{im}-\\bar{y})\\frac{-1}{2}+\\sum(y_{iw}-\\bar{y})\\frac{1}{2}}{N} \\\\\n    &= \\frac{4}{2}\\frac{\\sum_{i=1}^n(y_{iw}-\\bar{y}) - \\sum_{i=1}^n(y_{im}-\\bar{y})}{2n} \\\\\n    &= \\frac{\\sum_{i=1}^n y_{iw}}{n} - \\frac{n\\bar{y}}{n} - \\frac{\\sum_{i=1}^n y_{im}}{n} + \\frac{n\\bar{y}}{n} \\\\\n    &= \\bar{y}_w - \\bar{y}_m = \\Delta\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#wens-interessiert---beta_0-mu_m",
    "href": "mlm_dummy_coding.html#wens-interessiert---beta_0-mu_m",
    "title": "11  Integration von nominale Variablen",
    "section": "11.14 Wen’s interessiert - \\(\\beta_0 = \\mu_m\\)",
    "text": "11.14 Wen’s interessiert - \\(\\beta_0 = \\mu_m\\)\nMit \\(b_1 = \\Delta = \\bar{y}_w - \\bar{y}_m\\): \\[\\begin{align*}\nb_0 &= \\bar{y} - \\Delta \\times \\bar{x} \\\\\n&= \\frac{\\sum_{i=1}^N y_i}{N} - \\Delta \\times \\frac{1}{2} \\\\\n&= \\frac{\\sum_{i=1}^n y_{im} + \\sum_{i=1}^n y_{iw}}{2n} - \\frac{1}{2}(\\bar{y}_w - \\bar{y}_m)  \\\\\n&= \\frac{1}{2}\\frac{\\sum_{i=1}^ny_{im}}{n} + \\frac{1}{2}\\frac{\\sum_{i=1}^ny_{iw}}{n} - \\frac{1}{2}\\bar{y}_w + \\frac{1}{2}\\bar{y}_m \\\\\n&= \\frac{1}{2}\\bar{y}_m + \\frac{1}{2}\\bar{y}_w - \\frac{1}{2}\\bar{y}_w + \\frac{1}{2}\\bar{y}_m \\\\\n&= \\bar{y}_m\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#können-auch-mehr-als-zwei-stufen-verwendet-werden",
    "href": "mlm_dummy_coding.html#können-auch-mehr-als-zwei-stufen-verwendet-werden",
    "title": "11  Integration von nominale Variablen",
    "section": "11.15 Können auch mehr als zwei Stufen verwendet werden?",
    "text": "11.15 Können auch mehr als zwei Stufen verwendet werden?\n\n\n\n\n\nEin Reaktionszeitexperiment mit vier Stufen A, B, C und D"
  },
  {
    "objectID": "mlm_dummy_coding.html#deskriptive-daten",
    "href": "mlm_dummy_coding.html#deskriptive-daten",
    "title": "11  Integration von nominale Variablen",
    "section": "11.16 Deskriptive Daten",
    "text": "11.16 Deskriptive Daten"
  },
  {
    "objectID": "mlm_dummy_coding.html#reaktionszeitexperiment-als-lineares-modell",
    "href": "mlm_dummy_coding.html#reaktionszeitexperiment-als-lineares-modell",
    "title": "11  Integration von nominale Variablen",
    "section": "11.17 Reaktionszeitexperiment als lineares Modell",
    "text": "11.17 Reaktionszeitexperiment als lineares Modell\n\n11.17.1 Modell\n\\[\ny_i = \\mu_A + \\Delta_{B-A} x_1 + \\Delta_{C-A} x_2 + \\Delta_{D-A} x_3 + \\epsilon_i\n\\]\n\n\n11.17.2 Dummyvariablen"
  },
  {
    "objectID": "mlm_dummy_coding.html#nochmal-allgemeiner",
    "href": "mlm_dummy_coding.html#nochmal-allgemeiner",
    "title": "11  Integration von nominale Variablen",
    "section": "11.18 Nochmal allgemeiner",
    "text": "11.18 Nochmal allgemeiner\nMit \\(K\\) Faktorstufen werden (K-1) Dummyvariablen \\(x_1, x_2, \\ldots, x_{K-1}\\) benötigt. Eine Stufe wird als Referenz definiert. Die \\(x_1\\) bis \\(x_{K-1}\\) kodieren die Abweichungen der anderen Stufen von dieser Stufe.4"
  },
  {
    "objectID": "mlm_dummy_coding.html#reaktionszeitexperiment-mit-lm",
    "href": "mlm_dummy_coding.html#reaktionszeitexperiment-mit-lm",
    "title": "11  Integration von nominale Variablen",
    "section": "11.19 Reaktionszeitexperiment mit lm()",
    "text": "11.19 Reaktionszeitexperiment mit lm()\n\nmod <- lm(rt ~ group, data)\n\n\n\n\n\nModellfit\n \n  \n      \n    $\\hat{\\beta}$ \n    $s_e$ \n    t \n    p \n  \n \n\n  \n    (Intercept) \n    509.526 \n    10.235 \n    49.784 \n    <0.001 \n  \n  \n    groupB \n    90.150 \n    14.474 \n    6.228 \n    <0.001 \n  \n  \n    groupC \n    197.414 \n    14.474 \n    13.639 \n    <0.001 \n  \n  \n    groupD \n    295.561 \n    14.474 \n    20.420 \n    <0.001"
  },
  {
    "objectID": "mlm_dummy_coding.html#ausblick",
    "href": "mlm_dummy_coding.html#ausblick",
    "title": "11  Integration von nominale Variablen",
    "section": "11.20 Ausblick",
    "text": "11.20 Ausblick\n\nanova(mod)\n\n\n\n\n\nANOVA-Tabelle\n \n  \n     \n    Df \n    SSQ \n    MSQ \n    F \n    p \n  \n \n\n  \n    group \n    3 \n    988935.1 \n    329645.04 \n    157.35 \n    <0.001 \n  \n  \n    Residuals \n    76 \n    159221.0 \n    2095.01"
  },
  {
    "objectID": "mlm_dummy_coding.html#kombination-von-kontinuierlichen-und-nominalen-variablen",
    "href": "mlm_dummy_coding.html#kombination-von-kontinuierlichen-und-nominalen-variablen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.21 Kombination von kontinuierlichen und nominalen Variablen",
    "text": "11.21 Kombination von kontinuierlichen und nominalen Variablen\n\n\n\n\n\nHypothetische Leistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#modellansatz",
    "href": "mlm_dummy_coding.html#modellansatz",
    "title": "11  Integration von nominale Variablen",
    "section": "11.22 Modellansatz",
    "text": "11.22 Modellansatz\n\nAus gender (K = 2) wird eine Dummyvariable\nFrauen werden (zufällig) als Referenz genommen\n\n\\[\\begin{align*}\nY_i &= \\beta_{ta = 0,x_1=0} + \\Delta_m \\times x_1 + \\beta_{ta} \\times ta + \\epsilon_i \\\\\nx_1 &=\n\\begin{cases}\n0\\text{ wenn weiblich}\\\\\n1\\text{ wenn männlich}\n\\end{cases} \\\\\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#modellieren-mit-lm",
    "href": "mlm_dummy_coding.html#modellieren-mit-lm",
    "title": "11  Integration von nominale Variablen",
    "section": "11.23 Modellieren mit lm()",
    "text": "11.23 Modellieren mit lm()\n\nmod <- lm(perf ~ gender_f + ta, lew)\n\n\n\n\n\nModellfit\n \n  \n      \n    $\\hat{\\beta}$ \n    $s_e$ \n  \n \n\n  \n    (Intercept) \n    41.181 \n    1.083 \n  \n  \n    gender\\_fm \n    -10.877 \n    0.805 \n  \n  \n    ta \n    1.927 \n    0.145 \n  \n  \n    $\\hat{\\sigma}$ \n    2.845"
  },
  {
    "objectID": "mlm_dummy_coding.html#die-resultierenden-graden",
    "href": "mlm_dummy_coding.html#die-resultierenden-graden",
    "title": "11  Integration von nominale Variablen",
    "section": "11.24 Die resultierenden Graden",
    "text": "11.24 Die resultierenden Graden\n\n\n\n\n\nLeistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#interaktion-zwischen-kontinuierlichen-und-nominalen-variablen",
    "href": "mlm_dummy_coding.html#interaktion-zwischen-kontinuierlichen-und-nominalen-variablen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.25 Interaktion zwischen kontinuierlichen und nominalen Variablen",
    "text": "11.25 Interaktion zwischen kontinuierlichen und nominalen Variablen\n\n\n\n\n\nLeistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#ansatz-für-ein-interaktionsmodell",
    "href": "mlm_dummy_coding.html#ansatz-für-ein-interaktionsmodell",
    "title": "11  Integration von nominale Variablen",
    "section": "11.26 Ansatz für ein Interaktionsmodell",
    "text": "11.26 Ansatz für ein Interaktionsmodell\nDas vorhergehendes Modell wird um einen Interaktionsterm erweitert.\n\\[\ny_i = \\beta_{ta=0,x_1=0} + \\Delta_m \\times x_1 + \\beta_{ta} \\times ta + \\beta_{ta \\times gender} \\times x_1 \\times ta + \\epsilon_i\n\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#interaktionsmodell-mit-lm",
    "href": "mlm_dummy_coding.html#interaktionsmodell-mit-lm",
    "title": "11  Integration von nominale Variablen",
    "section": "11.27 Interaktionsmodell mit lm()",
    "text": "11.27 Interaktionsmodell mit lm()\n\nmod <- lm(perf ~ gender_f * ta, lew)\n\n\n\n\n\nModellfit\n \n  \n      \n    $\\hat{\\beta}$ \n    $s_e$ \n  \n \n\n  \n    (Intercept) \n    31.354 \n    1.370 \n  \n  \n    gender\\_fm \n    8.575 \n    2.010 \n  \n  \n    ta \n    1.763 \n    0.195 \n  \n  \n    gender\\_fm:ta \n    2.362 \n    0.290 \n  \n  \n    $\\hat{\\sigma}$ \n    2.828"
  },
  {
    "objectID": "mlm_dummy_coding.html#regressionsgeraden",
    "href": "mlm_dummy_coding.html#regressionsgeraden",
    "title": "11  Integration von nominale Variablen",
    "section": "11.28 Regressionsgeraden",
    "text": "11.28 Regressionsgeraden\n\n\n\n\n\nLeistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#zum-nacharbeiten",
    "href": "mlm_dummy_coding.html#zum-nacharbeiten",
    "title": "11  Integration von nominale Variablen",
    "section": "11.29 Zum Nacharbeiten",
    "text": "11.29 Zum Nacharbeiten\nKutner u. a. (2005, p.313–319) \n\n\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "mlm_hierarchies.html#einfaches-modell",
    "href": "mlm_hierarchies.html#einfaches-modell",
    "title": "12  Modellhierarchien",
    "section": "12.1 Einfaches Modell",
    "text": "12.1 Einfaches Modell\n\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n\n\nCall:\nlm(formula = y ~ x, data = simple)\n\nResiduals:\n      1       2       3       4 \n-0.5817  0.9898 -0.2345 -0.1736 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.8414     0.7008   2.628    0.119\nx             0.4574     0.3746   1.221    0.346\n\nResidual standard error: 0.8376 on 2 degrees of freedom\nMultiple R-squared:  0.4271,    Adjusted R-squared:  0.1406 \nF-statistic: 1.491 on 1 and 2 DF,  p-value: 0.3465"
  },
  {
    "objectID": "mlm_hierarchies.html#einfaches-modell-1",
    "href": "mlm_hierarchies.html#einfaches-modell-1",
    "title": "12  Modellhierarchien",
    "section": "12.2 Einfaches Modell",
    "text": "12.2 Einfaches Modell\n\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n\n\nCall:\nlm(formula = y ~ x, data = simple)\n\nResiduals:\n      1       2       3       4 \n-0.5817  0.9898 -0.2345 -0.1736 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.8414     0.7008   2.628    0.119\nx             0.4574     0.3746   1.221    0.346\n\nResidual standard error: 0.8376 on 2 degrees of freedom\nMultiple R-squared:  0.4271,    Adjusted R-squared:  0.1406 \nF-statistic: 1.491 on 1 and 2 DF,  p-value: 0.3465"
  },
  {
    "objectID": "mlm_hierarchies.html#abweichungen-noch-mal",
    "href": "mlm_hierarchies.html#abweichungen-noch-mal",
    "title": "12  Modellhierarchien",
    "section": "12.3 Abweichungen … noch mal",
    "text": "12.3 Abweichungen … noch mal\n\n12.3.1 Sum of squares of error\n\\[\nSSE = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n\\]\nTypischerweise beinhaltet ein Modell zum berechnen der \\(\\hat{y}_i\\) verschiedene Parameter. Bei der einfachen Regression zum Beispiel \\(\\beta_0\\) und \\(\\beta_1\\) (#Modellparameter \\(p\\) = 2) .\n\n\n12.3.2 Freiheitsgrade (degrees of freedom) von SSE\n\\[\ndfE := n - p\n\\]\nDie effektive Anzahl der Beobachtungen um die Varianz \\(\\sigma^2\\) abzuschätzen."
  },
  {
    "objectID": "mlm_hierarchies.html#mse-als-schätzer-für-sigma2",
    "href": "mlm_hierarchies.html#mse-als-schätzer-für-sigma2",
    "title": "12  Modellhierarchien",
    "section": "12.4 MSE als Schätzer für \\(\\sigma^2\\)",
    "text": "12.4 MSE als Schätzer für \\(\\sigma^2\\)\n\n12.4.1 Mean squared error MSE\n\\[\nMSE = \\frac{SSE}{dfE} = \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{n-p}\n\\]\nAls Schätzer \\(\\hat{\\sigma}^2\\) für \\(\\sigma^2\\) aus \\(\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\)\n\n\n12.4.2 Parallel zur Berechnung der Stichprobenvarianz\n\\[\n\\hat{\\sigma}^2 = s^2 = \\frac{1}{n-1}\\sum_{i=1}^2(y_i - \\bar{y})^2\n\\]\nwo \\(s^2\\) ein Schätzer für die Varianz von \\(y\\) ist."
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz",
    "title": "12  Modellhierarchien",
    "section": "12.5 Genereller Linearer Modell Testansatz1",
    "text": "12.5 Genereller Linearer Modell Testansatz1\n\n12.5.1 Idee\nWir bauen uns eine Teststatistik die die Verbesserung in der Vorhersage (\\(=\\) Reduktion der Fehlervarianz) als Metrik verwendet. Modelle werden in eine Hierarchie gesetzt mit einfacheren Modellen untergeordnet zu komplexeren Modellen.\n\n\n12.5.2 Leitfrage:\nBringt mir die Aufnahme Modellparameter eine in der Vorhersage von Y bzw. bezüglich der Aufklärung der Varianz in Y?"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---full-model",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---full-model",
    "title": "12  Modellhierarchien",
    "section": "12.6 Genereller Linearer Modell Testansatz - Full model",
    "text": "12.6 Genereller Linearer Modell Testansatz - Full model\nBeispiel einfache lineare Regression\n\n12.6.1 Volles Modell\n\\[\nY_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\n\\]\n\n\n12.6.2 Residualvarianz SSE(F)\n\\[\n\\textrm{SSE(F)}  = \\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = \\sum_{i=1}^n [y_i - (\\beta_0 + \\beta_1 x_i)]^2\n\\]\nmit \\(p = 2, dfE(F) = n - 2\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---reduced-model",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---reduced-model",
    "title": "12  Modellhierarchien",
    "section": "12.7 Genereller Linearer Modell Testansatz - Reduced model",
    "text": "12.7 Genereller Linearer Modell Testansatz - Reduced model\n\n12.7.1 Reduziertes Modell\n\\[\nY_i = \\beta_0 + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\n\\]\n\n\n12.7.2 Residualvarianz SSE(R)\n\\[\n\\textrm{SSE(R)} = \\sum_{i=1}^n (y_i - \\beta_0)^2 = \\sum_{i=1}^n(y_i - \\bar{y})^2 = \\textrm{SSTO}\n\\]\nmit \\(p = 1, dfE(R) = n - 1\\)\nIm Allgemeinen gilt: \\(SSE(F) \\leq SSE(R)\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#link-reduziertes-modell-und-stichprobenvarianz",
    "href": "mlm_hierarchies.html#link-reduziertes-modell-und-stichprobenvarianz",
    "title": "12  Modellhierarchien",
    "section": "12.8 Link: Reduziertes Modell und Stichprobenvarianz",
    "text": "12.8 Link: Reduziertes Modell und Stichprobenvarianz\n\\[\\begin{align*}\nSSE &= \\sum_{i=1}^n(y_i - \\beta_0)^2 = \\sum_{i=1}^n (y_i^2 - 2y_i\\beta_0 + \\beta_0^2) \\\\\n0 &= \\frac{\\mathrm{d}}{\\mathrm{d} \\beta_0}\\sum_{i=1}^n (y_i^2 - 2y_i\\beta_0 + \\beta_0^2) \\\\\n0 &= \\sum_{i=1}^n (-2y_i + 2 \\beta_0) = -2\\sum_{i=1}^n y_i + 2\\sum_{i=1}^n \\beta_0\\\\\nn\\beta_0 &= \\sum_{i=1}^n y_i \\\\\n\\beta_0 &= \\frac{\\sum_{i=1}^n y_i}{n} = \\bar{y} \\rightarrow \\frac{SSE}{n-1} = \\hat{\\sigma}^2 = s^2\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz-1",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz-1",
    "title": "12  Modellhierarchien",
    "section": "12.9 Genereller Linearer Modell Testansatz",
    "text": "12.9 Genereller Linearer Modell Testansatz\nAnnahme: Das reduzierte Modell ist korrekt. Dann sollte \\[\n\\textrm{SSE(R)} - \\textrm{SSE(F)}\n\\] eher klein sein (Beide Modelle haben einen gleich guten fit).\nAnnahme: Das reduzierte Modell ist falsch: Dann sollte \\[\n\\textrm{SSE(R)} - \\textrm{SSE(F)}\n\\] eher groß sein (Das reduzierte Modell kann die Daten nicht so gut fitten wie das komplizierte Modell)"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---teststatistik",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---teststatistik",
    "title": "12  Modellhierarchien",
    "section": "12.10 Genereller Linearer Modell Testansatz - Teststatistik",
    "text": "12.10 Genereller Linearer Modell Testansatz - Teststatistik\nWenn das reduzierte Modell korrekt ist, dann lässt sich zeigen, dass: \\[\nMS_{\\textrm{test}} = \\frac{\\textrm{SSE(R)} - \\textrm{SSE(F)}}{\\textrm{dfE(R)} - \\textrm{dfE(F)}}\n\\] ein Schätzer für die Varianz \\(\\sigma^2\\) (\\(\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\)) ist.\nWenn das reduzierte Modell korrekt ist, dann ist auch das volle Modell korrekt. Daher ist dann:\n\\[\n\\textrm{MSE(F)} = \\frac{\\textrm{SSE(F)}}{\\textrm{dfE(F)}}\n\\] auch ein Schätzer für \\(\\sigma^2\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#f-wert-als-teststatistik",
    "href": "mlm_hierarchies.html#f-wert-als-teststatistik",
    "title": "12  Modellhierarchien",
    "section": "12.11 F-Wert als Teststatistik",
    "text": "12.11 F-Wert als Teststatistik\n\\[\nF = \\frac{MS_{\\textrm{test}}}{MSE(F)}= \\frac{\\frac{\\textrm{SSE(R)} - \\textrm{SSE(F)}}{\\textrm{dfE(R)} - \\textrm{dfE(F)}}}{ \\frac{\\textrm{SSE(F)}}{\\textrm{dfE(F)}}}\n\\]"
  },
  {
    "objectID": "mlm_hierarchies.html#verteilung-der-f-statistik",
    "href": "mlm_hierarchies.html#verteilung-der-f-statistik",
    "title": "12  Modellhierarchien",
    "section": "12.12 Verteilung der F-Statistik",
    "text": "12.12 Verteilung der F-Statistik\n\\[\nF = \\frac{MS_{\\textrm{test}}}{MSE(F)}  \\sim F(\\textrm{dfE(R)}-\\textrm{dfE(F)},\\textrm{dfE(F)})\n\\]\n\n\n\n\n\nBeispiele für die F-Verteilung mit verschiedenen Freiheitsgraden \\(df_1, df_2\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#hypothesentest-mit-f-wert",
    "href": "mlm_hierarchies.html#hypothesentest-mit-f-wert",
    "title": "12  Modellhierarchien",
    "section": "12.13 Hypothesentest mit F-Wert",
    "text": "12.13 Hypothesentest mit F-Wert\n\n\n\n\n\nF-Verteilung mit \\(df_1 = 5, df_2 = 10\\) und kritischem Wert bei \\(\\alpha=0.05\\)\n\n\n\n\n2"
  },
  {
    "objectID": "mlm_hierarchies.html#teilziel",
    "href": "mlm_hierarchies.html#teilziel",
    "title": "12  Modellhierarchien",
    "section": "12.14 Teilziel",
    "text": "12.14 Teilziel\n\nDurch den Vergleich von Modellen kann die Verbesserung/Verschlechterung der Modellvorhersage statistisch Überprüft werden\nAlternativ: Brauchen ich zusätzliche Parameter oder reicht mir das einfache Modell?"
  },
  {
    "objectID": "mlm_hierarchies.html#beispiel-candy-problem",
    "href": "mlm_hierarchies.html#beispiel-candy-problem",
    "title": "12  Modellhierarchien",
    "section": "12.15 Beispiel: Candy-Problem",
    "text": "12.15 Beispiel: Candy-Problem\n\n\n\n\n\nZusammenhang zwischen der Präferenz für ein Bonbon und dem Süßgrad für verschiedene Weichheitsgrade"
  },
  {
    "objectID": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen",
    "href": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen",
    "title": "12  Modellhierarchien",
    "section": "12.16 Modelle als Hierarchien auffassen",
    "text": "12.16 Modelle als Hierarchien auffassen\n\n12.16.1 Full model\n\\[\ny_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i}x_{2i} + \\epsilon_i\n\\]\n\n\n12.16.2 Hierarchie\n\\[\\begin{align*}\nm_0&: y_i = \\beta_0 + \\epsilon_i \\\\\nm_1&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i \\\\\nm_2&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i \\\\\nm_3&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i}x_{2i} + \\epsilon_i\n\\end{align*}\\]\nEs gilt: \\(m_0 \\subseteq m_1 \\subseteq m_2 \\subseteq m_3\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen-in-r",
    "href": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen-in-r",
    "title": "12  Modellhierarchien",
    "section": "12.17 Modelle als Hierarchien auffassen in R",
    "text": "12.17 Modelle als Hierarchien auffassen in R\nIn R:\n\nmod_0 <- lm(like ~ 1, candy)\nmod_1 <- lm(like ~ sweetness, candy)\nmod_2 <- lm(like ~ sweetness + moisture, candy)\nmod_3 <- lm(like ~ sweetness * moisture, candy)"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-m_0-gegen-m_1",
    "href": "mlm_hierarchies.html#vergleich-m_0-gegen-m_1",
    "title": "12  Modellhierarchien",
    "section": "12.18 Vergleich \\(m_0\\) gegen \\(m_1\\)",
    "text": "12.18 Vergleich \\(m_0\\) gegen \\(m_1\\)\n\\[\\begin{align*}\nm_0: y_i &= \\beta_0 + \\epsilon_i \\\\\nm_1: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_0, mod_1)\n\n\n\n\nVergleich der Modellfits\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ 1\n77\n\n\n\n\n\n\nModel 2: like ~ sweetness\n76\n1\n18871.5\n36.63\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-m_1-gegen-m_2",
    "href": "mlm_hierarchies.html#vergleich-m_1-gegen-m_2",
    "title": "12  Modellhierarchien",
    "section": "12.19 Vergleich \\(m_1\\) gegen \\(m_2\\)",
    "text": "12.19 Vergleich \\(m_1\\) gegen \\(m_2\\)\n\\[\\begin{align*}\nm_1: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i \\\\\nm_2: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_1, mod_2)\n\n\n\n\nVergleich der Modellfits\n\n\n\n\n\n\n\n\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ sweetness\n76\n\n\n\n\n\n\nModel 2: like ~ sweetness + moisture\n75\n1\n29720.3\n236.28\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-m_2-gegen-full-model-m_3",
    "href": "mlm_hierarchies.html#vergleich-m_2-gegen-full-model-m_3",
    "title": "12  Modellhierarchien",
    "section": "12.20 Vergleich \\(m_2\\) gegen full model \\(m_3\\)",
    "text": "12.20 Vergleich \\(m_2\\) gegen full model \\(m_3\\)\n\\[\\begin{align*}\nm_2: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i  \\\\\nm_3: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i} x_{2i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_2, mod_3)\n\n\n\n\nVergleich der Modellfits\n\n\n\n\n\n\n\n\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ sweetness + moisture\n75\n\n\n\n\n\n\nModel 2: like ~ sweetness * moisture\n74\n1\n9223.32\n3244.88\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-full-model-m_3-gegen-minmales-modell-m_0",
    "href": "mlm_hierarchies.html#vergleich-full-model-m_3-gegen-minmales-modell-m_0",
    "title": "12  Modellhierarchien",
    "section": "12.21 Vergleich full model \\(m_3\\) gegen minmales Modell \\(m_0\\)",
    "text": "12.21 Vergleich full model \\(m_3\\) gegen minmales Modell \\(m_0\\)\n\\[\\begin{align*}\nm_0: y_i &= \\beta_0 + \\epsilon_i  \\\\\nm_3: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i} x_{2i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_0, mod_3)\n\n\n\n\nVergleich der Modellfits\n\n\n\n\n\n\n\n\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ 1\n77\n\n\n\n\n\n\nModel 2: like ~ sweetness * moisture\n74\n3\n57815.11\n6780.02\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#in-summary-m_3-gegen-m_0",
    "href": "mlm_hierarchies.html#in-summary-m_3-gegen-m_0",
    "title": "12  Modellhierarchien",
    "section": "12.22 In summary() \\(m_3\\) gegen \\(m_0\\)",
    "text": "12.22 In summary() \\(m_3\\) gegen \\(m_0\\)\n\n\n\nCall:\nlm(formula = like ~ sweetness * moisture, data = candy)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.7039 -1.1896  0.0072  1.1910  3.6822 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         2.588066   0.668791   3.870 0.000233 ***\nsweetness          -0.015015   0.036327  -0.413 0.680568    \nmoisture           -0.040123   0.055030  -0.729 0.468240    \nsweetness:moisture  0.166812   0.002928  56.964  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.686 on 74 degrees of freedom\nMultiple R-squared:  0.9964,    Adjusted R-squared:  0.9962 \nF-statistic:  6780 on 3 and 74 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "mlm_hierarchies.html#eine-nominale-variable-mit-vier-stufen",
    "href": "mlm_hierarchies.html#eine-nominale-variable-mit-vier-stufen",
    "title": "12  Modellhierarchien",
    "section": "12.23 Eine nominale Variable mit vier Stufen",
    "text": "12.23 Eine nominale Variable mit vier Stufen\n\n\n\n\n\nEin Reaktionszeitexperiment mit vier Stufen A, B, C und D"
  },
  {
    "objectID": "mlm_hierarchies.html#früher---analysis-of-variance-anova-bzw.-aov",
    "href": "mlm_hierarchies.html#früher---analysis-of-variance-anova-bzw.-aov",
    "title": "12  Modellhierarchien",
    "section": "12.24 Früher - Analysis of Variance (ANOVA bzw. AOV)",
    "text": "12.24 Früher - Analysis of Variance (ANOVA bzw. AOV)\n\\[\\begin{align*}\ns_{zwischen}^2 &= \\frac{1}{K-1}\\sum_{j=1}^K N_j (\\bar{x}_{j.}-\\bar{x})^2 \\\\\ns_{innerhalb}^2 &= \\frac{1}{N-K}\\sum_{j=1}^K\\sum_{i=1}^{N_j}(x_{ji}-\\bar{x}_{j.})^2 = \\frac{1}{N-K}\\sum_{j=1}^K(N_j-1)s_j^2 \\\\\nF &= \\frac{\\hat{\\sigma}_{zwischen}^2} {\\hat{\\sigma}_{innerhalb}^2} \\sim F(K-1,N-K)\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_hierarchies.html#anova-in-r",
    "href": "mlm_hierarchies.html#anova-in-r",
    "title": "12  Modellhierarchien",
    "section": "12.25 ANOVA in R",
    "text": "12.25 ANOVA in R\n\nmod_aov <- aov(rt ~ group, rt_tbl)\nsummary(mod_aov)\n\n\n\n\nAusgabe mit aov()\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\ngroup\n3\n988935.1\n329645\n157.3\n0\n\n\nResiduals\n76\n159221.0\n2095"
  },
  {
    "objectID": "mlm_hierarchies.html#ansatz-mittels-modellhierarchien",
    "href": "mlm_hierarchies.html#ansatz-mittels-modellhierarchien",
    "title": "12  Modellhierarchien",
    "section": "12.26 Ansatz mittels Modellhierarchien",
    "text": "12.26 Ansatz mittels Modellhierarchien\n\n12.26.1 Full model\n\\[\ny_i = \\beta_0 + \\beta_{\\Delta_{B-A}} x_1 + \\beta_{\\Delta_{C-A}} x_2 + \\beta_{\\Delta_{D-A}} x_3 + \\epsilon_i\n\\]\n\n\n12.26.2 Reduced model\n\\[\ny_i = \\beta_0 + \\epsilon_i\n\\]\nWenn das reduced model die Daten gleich gut fittet wie das full model \\(\\Rightarrow\\) Information über das Treatment verbessert meine Vorhersage von \\(y_i\\) nicht."
  },
  {
    "objectID": "mlm_hierarchies.html#model-fit---full-model",
    "href": "mlm_hierarchies.html#model-fit---full-model",
    "title": "12  Modellhierarchien",
    "section": "12.27 Model fit - Full model",
    "text": "12.27 Model fit - Full model\n\nmod <- lm(rt ~ group, rt_tbl)\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n509.526\n10.235\n49.784\n<0.001\n\n\ngroupB\n90.150\n14.474\n6.228\n<0.001\n\n\ngroupC\n197.414\n14.474\n13.639\n<0.001\n\n\ngroupD\n295.561\n14.474\n20.420\n<0.001"
  },
  {
    "objectID": "mlm_hierarchies.html#anova-mit-nur-einem-modell",
    "href": "mlm_hierarchies.html#anova-mit-nur-einem-modell",
    "title": "12  Modellhierarchien",
    "section": "12.28 anova() mit nur einem Modell",
    "text": "12.28 anova() mit nur einem Modell\n\nanova(mod)\n\n\n\n\nÄquivalent zum Vergleich full gegen reduced model\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\ngroup\n3\n988935.1\n329645\n157.3\n0\n\n\nResiduals\n76\n159221.0\n2095"
  },
  {
    "objectID": "mlm_hierarchies.html#zum-nacharbeiten",
    "href": "mlm_hierarchies.html#zum-nacharbeiten",
    "title": "12  Modellhierarchien",
    "section": "12.29 Zum Nacharbeiten",
    "text": "12.29 Zum Nacharbeiten\nChristensen (2018, p.57–64) \n\n\n\n\nChristensen, Ronald. 2018. Analysis of variance, design, and regression: Linear modeling for unbalanced data. CRC Press.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Altman, Douglas G, and J Martin Bland. 1995. “Statistics Notes:\nAbsence of Evidence Is Not Evidence of Absence.” Bmj 311\n(7003): 485.\n\n\nAltman, Naomi, and Martin Krzywinski. 2015a. “Points of\nSignificance: Multiple Linear Regression.” Nature\nMethods 12 (12): 1103–4.\n\n\n———. 2015b. “Points of Significance: Simple Linear\nRegression.” Nature Methods 12 (11).\n\n\n———. 2016a. “Points of Significance: Analyzing Outliers:\nInfluential or Nuisance.” Nature Methods 13 (4): 281–82.\n\n\n———. 2016b. “Points of Significance: Regression\nDiagnostics.” Nature Methods 13 (5): 385–86.\n\n\nChristensen, Ronald. 2018. Analysis of Variance, Design, and\nRegression: Linear Modeling for Unbalanced Data. CRC Press.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. 2nd ed. Routledge.\n\n\nCumming, Geoff. 2013. Understanding the New Statistics: Effect\nSizes, Confidence Intervals, and Meta-Analysis. Routledge.\n\n\nDebanne, Thierry, and Guillaume Laffaye. 2011. “Predicting the\nThrowing Velocity of the Ball in Handball with Anthropometric Variables\nand Isotonic Tests.” Journal of Sports Sciences 29 (7):\n705–13.\n\n\nFox, John. 2011. An r Companion to Applied Regression. 2nd ed.\nSAGE Publication Inc., Thousand Oaks.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, and William Li.\n2005. Applied Linear Statistical Models. 5th ed. McGraw-Hill\nIrwin New York.\n\n\nMcElreath, Richard. 2016. Statistical Rethinking, a Bayesian Course\nwith Examples in r and Stan. 1st ed. Boca Raton: CRC Press.\n\n\nSpiegelhalter, David. 2019. The Art of Statistics: Learning from\nData. Penguin UK.\n\n\nWasserstein, Ronald L, and Nicole A Lazar. 2016. “The ASA\nStatement on p-Values: Context, Process, and Purpose.” Taylor\n& Francis.\n\n\nWild, Christopher J, and Georg AF Seber. 2000. Chance Encounters: A\nFirst Course in Data Analysis and Inference. Wiley Press.\n\n\nWilkinson, G. N., and C. E. Rogers. 1973. “Symbolic Description of\nFactorial Models for Analysis of Variance.” Applied\nStatistics 22 (3): 392–99.\n\n\nYoung, Alwyn. 2019. “Channeling Fisher: Randomization Tests and\nthe Statistical Insignificance of Seemingly Significant Experimental\nResults.” The Quarterly Journal of Economics 134 (2):\n557–98."
  },
  {
    "objectID": "slm_inference.html#herleitung-der-eigenschaften-von-hatbeta_1",
    "href": "slm_inference.html#herleitung-der-eigenschaften-von-hatbeta_1",
    "title": "6  Inferenz",
    "section": "6.2 Herleitung der Eigenschaften von \\(\\hat{\\beta}_1\\)",
    "text": "6.2 Herleitung der Eigenschaften von \\(\\hat{\\beta}_1\\)\nUm den Schätzer \\(\\hat{\\beta}_1\\) für \\(\\beta_1\\) formal herzuleiten. Beginnen wir zunächst mit der folgenden Formel, wobei wir im folgenden den Schätzer mit \\(b_1\\) bezeichnen.\n\\[\nb_1 = \\sum k_i Y_i\n\\tag{6.7}\\]\nD.h. wir zeigen zunächst, dass \\(b_1\\) durch eine lineare Kombination der \\(Y_i\\)-Werte berechnet werden kann. Die Koeffizienten \\(k_i\\) der Summe sind dabei wie folgt definiert:\n\\[\nk_i = \\frac{X_i - \\bar{X}}{\\sum(X_i - \\bar{X})^2}\n\\tag{6.8}\\]\nDer Grund für diese zunächst etwas uneinsichtige Definition wird im weiteren klarer werden. Zunächst haben die \\(k_i\\) verschieldene Eigenschaften die wir uns im Späteren zunutze machen wollen. Zunächst erst einmal noch ein paar Identitäten die wir später auch noch verwenden.\nDie erste Identität bezieht sich auf das Kreuzprodukt der Abweichungen von \\(X_i\\) und \\(Y_i\\) von ihren jeweiligen Mittelwerten.\n\\[\\begin{align*}\n\\sum(X_i-\\bar{X})(Y_i-\\bar{Y}) &= \\sum(X_i - \\bar{X})Y_i  -\\underbrace{\\sum(X_i - \\bar{X})}_{=0}\\bar{Y}  \\\\\n&= \\sum(X_i - \\bar{X})Y_i\n\\end{align*}\\]\nWenn wir in der Formel \\((Y_i-\\bar{Y})\\) durch \\((X_i-\\bar{X})\\) austauschen, folgt noch eine weitere nützliche Identität:\n\\[\n\\sum(X_i-\\bar{X})^2 = \\sum(X_i - \\bar{X})X_i\n\\]\nWerden die jeweiligen \\(k_i\\) mit den dazugehörigen \\(X_i\\) multipliziert und die Definition der \\(k_i\\) (siehe Gleichung 6.8) beachten, erhalten wir:\n\\[\n\\sum k_i X_i = \\frac{\\sum(X_i - \\bar{X})X_i}{\\sum(X_i-\\bar{X})^2} = \\frac{\\sum(X_i-\\bar{X})^2}{\\sum(X_i-\\bar{X})^2} = 1\n\\]\nD.h. Die Summe der \\(k_i X_i\\) ist gleich \\(1\\). Aus der Definition Gleichung 6.8 folgt weiterhin.\n\\[\n\\sum k_i = \\sum \\left(\\frac{X_i-\\bar{X}}{\\sum(X_i-\\bar{X})^2}\\right)= \\frac{\\sum(X_i-\\bar{X})}{\\sum(X_i-\\bar{X})^2} = \\frac{0}{\\sum(X_i-\\bar{X})^2} = 0\n\\]\nD.h. die Summe der \\(k_i\\) ist gleich Null.\nWenn wir jetzt wieder die Definition unseres Schätzer für \\(\\beta_1\\) verwenden (siehe Gleichung 5.5). Dann erhalten unter der Verwendung der Identität der Kreuzprodukte den gewünschten Zusammenhang zwischen \\(b_1\\) und \\(Y_i\\).\n\\[\\begin{align*}\nb_1 &= \\frac{\\sum(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum(X_i - \\bar{X})^2} \\\\\n&= \\frac{\\sum(X_i - \\bar{X})Y_i}{\\sum(X_i - \\bar{X})^2} = \\sum k_i Y_i\\\\\n\\end{align*}\\]\nWenden wir jetzt den Erwartungswert auf \\(Y_i\\) an, dann werden die \\(k_i\\) als konstant angesehen und nur die \\(Y_i\\) sind Zufallsvariablen. Da aber \\(Y_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i\\) gilt und in dieser Formel wiederum nur \\(\\epsilon_i\\) eine Zufallsvariable mit \\(\\beta_0\\) und \\(\\beta_1 X_i\\) konstant ist und zudem die \\(\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)\\) also \\(E[\\epsilon_i] = 0\\) laut der Annahme gilt, folgt:\n\\[\\begin{align*}\n    E[b_1] &= E\\left[\\sum k_i Y_i\\right] = \\sum k_i E[Y_i] = \\sum k_i (\\beta_0 + \\beta_1 X_i) \\\\\n    &= \\beta_0 \\sum k_i + \\beta_1 \\sum k_i X_i = \\beta_1\n\\end{align*}\\]\nD.h. Gleichung 5.5 ist ein erwartungstreuer Schätzer für \\(\\beta_1\\).\nLeiten wir noch eine weitere Identität über die Summe der \\(k_i^2\\) her:\n\\[\n\\sum k_i^2 = \\sum \\left[\\frac{X_i-\\bar{X}}{\\sum(X_i-\\bar{X})^2}\\right]^2 = \\frac{\\sum(X_i-\\bar{X})^2}{\\left[\\sum(X_i-\\bar{X})^2\\right]^2} = \\frac{1}{\\sum(X_i-\\bar{X})^2}\n\\] Können wir auch noch die Varianz bzw. den Standardfehler unseres Schätzers für \\(\\beta_1\\) herleiten. Es gilt nämlich:\n\\[\\begin{align*}\n    \\sigma^2[b_1] &= \\sigma^2\\left[\\sum k_i Y_i\\right] = \\sum k_i^2 \\sigma^2[Y_i] \\\\\n    &= \\sum k_i^2 \\sigma^2 = \\sigma^2 \\sum k_i^2 \\\\\n    &= \\sigma^2 \\frac{1}{\\sum(X_i-\\bar{X})^2}\n\\end{align*}\\]\nWir erhalten die bereits eingeführte Formel. Wiederum eine Einsicht aus der Herleitung der Formel folgt, dass die Varianz \\(\\sigma^2\\) als konstant angesehen wird, d.h. \\(\\sigma_i^2 = \\sigma^2\\). Dies hat uns erlaubt im zweiten Schritt \\(\\sigma^2\\) aus der Summe heraus zu ziehen. Wenn die Varianz \\(\\sigma^2\\) nicht konstant ist, dann ist der berechnete Standardfehler für \\(\\hat{\\beta}_1 = b_1\\) nicht korrekt."
  },
  {
    "objectID": "slm_inference.html#statistische-überprüfung-von-beta_1-und-beta_0",
    "href": "slm_inference.html#statistische-überprüfung-von-beta_1-und-beta_0",
    "title": "6  Inferenz",
    "section": "6.1 Statistische Überprüfung von \\(\\beta_1\\) und \\(\\beta_0\\)",
    "text": "6.1 Statistische Überprüfung von \\(\\beta_1\\) und \\(\\beta_0\\)\nDer erste Schritt um eine Verteilung zu bekommen ist allerdings, dass wir zunächst einmal eine Zufallsvariable benötigen. Bisher haben wir den Zusammenhang zwischen Variablen über die Formel\n\\[\ny_i = \\beta_0 + \\beta_1 \\cdot x_i\n\\]\nbeschrieben. In dieser Form ist allerdings noch kein zufälliges Element vorhanden. Für ein gegebenes \\(x_i\\) bekommen wir ein genau spezifiziertes \\(y_i\\). Allerdings haben wir bei der Herleitung gesehen, dass die Daten in den seltensten Fällen genau auf der Gerade liegen, sondern wir die Parameter \\(\\hat{\\beta}_0\\) und \\(\\hat{beta}_1\\) so gewählt haben, dass die quadrierten Abweichungen, die Residuen \\(\\epsilon_i\\) minimal werden. Dies Residuen verwenden wir jetzt um eine zufälliges Element in unsere Regression rein zu bekommen. Ein mögliche Annahme ist, das die Residuen beispielsweise Normalverteilt sind.\nWarum könnte dies Sinn machen. In dem vorhergehenden Weitsprungbeispiel haben wir informell hergeleitet, dass die Weitsprungleistung von unzähligen weiteren Faktoren beeinflusst werden kann, welche dazu führen, dass für eine gegebene Anlaufgeschwindigkeit nicht immer die gleiche Weitsprungweite erzielt wird. Generell, ist diese Art der Begründung bei biologischen System meistens plausibel. In vorhergehenden Abschnitt haben wir dazu aber auch noch gesehen, dass die Normalverteilung eben gut geeignet ist, um solche Prozesse, bei denen viele kleine additive Effekt auftreten. Dieser Argumentation folgend ist es plausibel diese Einflüsse auch beim Regressionsfall mittels einer Normalverteilung zu modellieren. Dazu führen wir noch eine weitere Annahme an, nämlich dass diese Einflüsse im Mittel in gleichen Maßen die Werte nach nach oben wie auch nach unten ablenken. D.h. die Werte nach oben und unten von der Regressionsgerade abweichen. Dies erlaubt uns jetzt die Annahme genau zu spezifizieren.\n\\[\n\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\n\\]\nD.h also, wir gehen davon aus, dass die Residuen normalverteilt sind, mit einem Mittelwert von \\(\\mu = 0\\) und einer noch näher zu spezifizierenden Varianz \\(\\sigma^2\\). Das führt dann zu der folgenden Formulierung des Regressionsmodells.\n\\[\nY_i = \\beta_0 + \\beta_1 \\cdot x_i + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\n\\tag{6.1}\\]\n\\(Y\\) wird jetzt groß geschrieben, da es sich um eine Zufallsvariable handelt. Dies führt jetzt dazu, das das Regressionsmodell in zwei Teile unterschieden werden kann. Einmal eine deterministischen Teil \\(\\beta_0 + \\beta_1 \\cdot x\\) und einen stochastischen Teil \\(\\epsilon_i\\). Dies führt dazu, dass \\(Y_i\\) ebenfalls stochastisch ist und zu einer Zufallsvariable wird.\nSchauen wir uns weiter an, wie sich \\(Y_i\\) verhält, wenn wir \\(x_i\\) als Konstante \\(x\\) mit ein bestimmten Wert annehmen. Dann wird aus Gleichung 6.1 \\(Y_i = \\beta_0 + \\beta_i \\cdot x + \\epsilon_i\\). Folglich bleibt der deterministische Teil immer gleich, wird zu einer Konstante. Da \\(\\epsilon_i\\) normalverteilt ist ist \\(Y_i\\) ebenfalls normalverteilt. Der Mittelwert der Normalverteilung von \\(Y_i\\) \\(\\mu_{Y_i}\\) ist allerdings nicht gleich Null, sondern die Normalverteilung von \\(\\epsilon_i\\) wird um die Konstante \\(\\beta_0 + \\beta_1 \\cdot x\\) verschoben (siehe Abbildung 6.1). Das führt dazu, dass \\(Y_i\\) der Verteilung \\(\\mathcal{N}(\\beta_0 + \\beta_1 x)\\) folgt.\n\n\n\n\n\n\n\n(a) Verteilung von \\(\\epsilon_i\\)\n\n\n\n\n\n\n\n(b) Verteilung von \\(Y_i\\)\n\n\n\n\nAbbildung 6.1: Relation der Lageparameter von \\(e_i\\) und \\(Y_i\\)\n\n\nDaraus folgt jetzt aber zusätzlich, dass für jedes gegebenes \\(X\\) die \\(Y\\)-Werte einer Normalverteilung folgen. Lediglich die Verschiebung des Mittelwert der jeweiligen \\(Y\\)-Normalverteilung hängt von \\(X\\) über die Formel \\(\\beta_0 + \\beta_1 \\cdot X\\) zusammen. Formal:\n\\[\nY|X \\sim N(\\beta_0+ \\beta_1 X,\\sigma^2)\n\\]\nDie Schreibweise \\(|X\\) wird übersetzt für gegenbenes \\(X\\) und sagt aus, dass die Verteilung von \\(Y\\) von \\(X\\) abhängt. Es handelt sich dabei um eine bedingte Wahrscheinlichkeit. Die Varianz der jeweiligen \\(Y\\)-Werte ist dabei die zuvor angenommen Varianz der \\(\\epsilon_i\\) also \\(\\sigma^2\\). Eine wichtige Annahme die noch mal betont werden sollte, wir gehen davon aus, dass die einzelnen Punkte unabhängig voneinander sind. Im Weitsprungbeispiel würde dies bedeuten, dass jeder Sprung von einem anderen Athleten kommen muss.\nWenn wir die Verteilungen von \\(Y\\) graphisch führ beispielweise drei verschiedene \\(X\\)-Wert darstellen, dann folgt daraus die folgende Abbildung (siehe Abbildung 6.2). D.h. für jeden \\(X\\)-Wert werden mehrere \\(Y\\)-Werte beobachtet, die jeweils einer Normalverteilung folgen.\n\n\n\n\n\nAbbildung 6.2: Verteilung der Daten für verschiedene \\(x\\)-Werte\n\n\n\n\nIn Abbildung 6.2 ist klar zu sehen, wie für jeden der drei Punkte von \\(X\\) die beobachteten \\(Y\\)-Werte einer Normalverteilung. Die Breite der Verteilung ist an jedem Punkte gleich, nämlich \\(=\\sigma^2\\) während der Mittelwert der Gleichung \\(\\beta_0 + \\beta_1 X\\) folgend entlang der Regressionsgerade verschoben ist.\nWenn wir uns zurück an die Ausführungen zur statistischen Signifikanz erinnern, dann haben wir in dem Zusammenhang vom einem datengenerierenden Prozess gesprochen (Definition 2.1) (DGP). In unserem jetzigen Modell können wir dementsprechend zwei Komponenten als Teile des DGP identizifieren. Entsprechend Gleichung 6.1 besteht der DGP aus dem deterministischen Teil \\(\\beta_0 + \\beta_1 X\\) und dem stochastischen Teil \\(\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\). Diese Einsicht können wir verwenden um die Eigenschaften dieses Modells bezüglich Aussagen über statistische Signifikanz zu untersuchen.\nWir fokussieren uns jetzt auf ein vereinfachtes Modell bei dem wir zusätzlich noch \\(\\beta_0 = 0\\) setzen, und wir uns erst mal nur für die Eigenschaften von \\(\\beta_1\\) interessieren. Gehen wir nun davon aus, dass zwischen \\(X\\) und \\(Y\\) der Zusammenhang \\(\\beta_1 = 1\\) besteht. D.h. wenn \\(X\\) um eine Einheit vergrößert wird, dann wird \\(Y\\) ebenfalls um eine Einheit größer.\n\\[\nY = 0 + 1 \\cdot X + \\epsilon, \\quad \\epsilon\\sim\\mathcal{N}(0,\\sigma^2)\n\\tag{6.2}\\]\nJetzt müssen wir noch einen Wert für \\(\\sigma^2\\) festlegen. Sei dieser einfach einmal \\(\\sigma = \\frac{1}{2}\\). Jetzt können wir R benutzen um Experimente, also Beobachtungen, anhand dieses DGP zu simulieren. Der Einfachheit halber legen wir ein übersichtliches \\(N = 12\\) fest und nehmen uns jeweils drei \\(X\\)-Werte z.B. mit \\(X \\in \\{-1, 0, 1\\}\\), d.h. wir ziehen für jeden \\(X\\)-Wert vier \\(Y\\)-Werte.\n\nN &lt;- 12\nbeta_0 &lt;- 0\nbeta_1 &lt;- 1\nsigma &lt;- 1/2\ndat_sim_1 &lt;- tibble(\n  x_i = rep(-1:1, each=4),\n  y_i = beta_0 + beta_1 * x_i + rnorm(N, mean = 0, sd = sigma)\n)\n\nWenn wir uns die generierten Daten anschauen, dann sehen wir wenig überraschend 12 verschiedene Werte für \\(y_i\\) und jeweils \\(3 \\times 4\\) verschiedene Werte für \\(x_i\\) (siehe Tabelle 6.1).\n\n\n\n\nTabelle 6.1: Eine Simulation des Modells Gleichung 6.2\n\n\nx_i\ny_i\n\n\n\n\n-1\n-0.93\n\n\n-1\n-0.53\n\n\n-1\n-0.67\n\n\n-1\n-0.67\n\n\n0\n-0.18\n\n\n0\n0.09\n\n\n0\n-0.50\n\n\n0\n0.66\n\n\n1\n0.46\n\n\n1\n0.72\n\n\n1\n0.82\n\n\n1\n0.62\n\n\n\n\n\n\nWenn wir die Daten graphisch darstellen erhalten wir (Abbildung 6.3):\n\nggplot(dat_sim_1, aes(x_i, y_i)) + \n  geom_point()\n\n\n\n\nAbbildung 6.3: Streudiagramm der Daten aus Tabelle 6.1\n\n\n\n\nEbenfalls wenig überraschend, die Punkte sind auf den \\(x\\)-Werten \\(-1, 0\\) und \\(1\\) zentriert und liegen nicht alle aufeinander, da sie einer Zufallsstichprobe aus \\(\\mathcal{N}(0, \\frac{1}{4})\\) entspringen.\nJetzt kann ich natürlich für diese Daten unsere Normalengleichungen anwenden und Werte für \\(\\hat{\\beta}_0\\) und \\(\\hat{\\beta}_1\\) berechnen. Oder eben direkt in R.\n\nmod_sim_1 &lt;- lm(y_i ~ x_i, dat_sim_1)\ncoef(mod_sim_1)\n\n (Intercept)          x_i \n-0.008845957  0.678696054 \n\n\nWir sehen, dass die berechneten Werte für \\(\\beta_0\\) und \\(\\beta_1\\) schon in der Nähe der tatsächlichen Werte liegen (siehe ?eq-slm-inf-mod-1), aber auf Grund der Stichprobenvariabilität eben nicht genau auf diesen Werten. Was passiert denn jetzt, wenn ich das Ganze noch einmal durchlaufen lassen?\n\ndat_sim_2 &lt;- tibble(\n  x_i = rep(-1:1, each=4),\n  y_i = beta_0 + beta_1 * x_i + rnorm(N, mean = 0, sd = sigma)\n)\nmod_sim_2 &lt;- lm(y_i ~ x_i, dat_sim_2)\ncoef(mod_sim_2)\n\n(Intercept)         x_i \n-0.08740939  1.13324316 \n\n\nWieder wenig überraschend, da jedes Mal wenn ich rnom() eine neue Ziehung aus der Normalverteilung generiert wird, erhalte ich neue Werte für \\(y_i\\) und dementsprechend andere Werte für \\(\\hat{\\beta}_0\\) und \\(\\hat{\\beta}_1\\). Nochmal, warum? Stichprobenvariabilität! Jetzt sind wir wieder bei dem gleichen Prinzip, das wir im Rahmen der kleinen Welt ausgiebig behandelt haben. Schauen wir uns jetzt doch einfach mal was passiert wenn wir die Simulation nicht \\(2\\times\\) sondern z.B. \\(1000\\times\\) durchführen.\n\nN_sim &lt;- 1000\nbeta_1_s &lt;- numeric(N_sim)\nx_i &lt;- rep(-1:1, each=4)\nfor (i in 1:N_sim) {\n  daten_temporaer &lt;- tibble(x_i,\n                            y_i = beta_0 + beta_1 * x_i + rnorm(N, mean = 0, sd = sigma))\n  model_temporaer &lt;- lm(y_i ~ x_i, daten_temporaer)\n  beta_1_s[i] &lt;- coef(model_temporaer)[2]\n}\n\nWir erhalten jetzt einen Vektor beta_1_s mit \\(1000\\) beobachteten \\(\\hat{\\beta}_1\\). Da das etwas viele Werte sind um die uns einzeln anzuschauen, erstellen ein Histogramm der \\(\\hat{\\beta}_1\\)s. (Abbildung 6.4).\n\nhist(beta_1_s, xlab = expression(hat(beta)[1]), main='')\nabline(v = beta_1, col='red', lty=2)\n\n\n\n\nAbbildung 6.4: Histogram der auf den simulierten Daten berechneten \\(\\hat{\\beta}_1\\). Wahrer Wert von \\(\\beta_1\\) rot eingezeichnet.\n\n\n\n\nIn Abbildung 6.4 begegnet uns zunächst einmal wieder unsere altbekannte Glockenkurve. Schön ist, dass deren Mittelwert im Bereich des wahren Werts von \\(\\beta_1\\) liegt und Werte mit größer werdender Abweichung vom wahren Wert in ihrer Häufigkeit abnehmen. Aber die Häufigkeit ist nicht Null, sondern eben nur geringer. Werte in der Nähe von \\(\\beta_1\\) weisen dagegen eine größere Häufigkeit aufweisen. Das sollte uns jetzt auch irgendwie zufrieden stimmen, denn dies bedeutet, dass wir in der Lage sind mit unserem Regressionsmodell im Mittel tatsächlich den korrekten Wert abzuschätzen. Allerdings, wie immer, bei einer einzelnen Durchführung des Experiments können wir alles von perfekt spot-on bis komplett danebenliegen und würden es nicht wissen.\nWir können jetzt aber auch wieder ganz parallel zu unseren Herleitungen in der kleinen Welt einen Entscheidungsprozess spezifizieren. Wenn Abbildung 6.4 den DGP beschreibt und das die Verteilung der zu erwartenden \\(\\hat{\\beta}_1\\) unter dem Modell sind. Bei der Dürchführung eines neuen Experiments, dann würden wir sagen, dass wenn unserer beobachteter Wert in den Rändern der Verteilung von Abbildung 6.4 liegt, das wir eher nicht davon ausgehen, dass unserer neues Experiment den gleichen DGP zugrundeliegen hat. D.h wir definieren uns jetzt Grenzen am oberen und am unteren Rand der Verteilung. Wenn jetzt ein neuer beobachteter Wert entweder unterhalb der unteren Grenze oder oberhalb der oberen Grenze liegt, dann sagen wir: Wir sind jetzt aber sehr überrascht diesen Wert zu sehen, wenn der dem gleichen datengenerierenden Prozess entstammen soll. Daher glauben wir nicht, dass dieses Experiment den gleichen DGP besitzt.\nUm diese Entscheidung treffen zu können, müssen wir also Grenzen definieren. Dazu können wir zunächst einmal einfach die Quantilen der Verteilung nehmen und schneiden z.B. unten \\(2.5\\%\\) und oben \\(2.5\\%\\) ab. So kommen wir dann insgesamt auf \\(5\\%\\), um auf die übliche Irrtumswahrscheinlichkeit von \\(\\alpha = 0.05\\) zu kommen. Dazu benutzen wir R und zwar quantile()-Funktion^[Im folgenden Snippet werden die Werte auf zwei Kommastellen mit round() der besseren Darstellung wegen gerundet).\n\n\n 2.5% 97.5% \n 0.65  1.35 \n\n\nMittels dieser Werte können wir zwei disjunkte Wertmenge definieren, einmal die Werte innerhalb von \\(\\hat{\\beta}_1 \\in [0.65,1.35]\\) bei denen wir nicht überrascht sind, und die unter der Annahme \\(\\beta_1 = 1\\) erwartbar sind und die Werte \\(\\hat{\\beta}_1 \\notin [0.65,1.35]\\) diejenigen Werte die uns überraschen würden unter der Annahme. Ins Histogramm übertragen (siehe Abbildung 6.5).\n\n\n\n\n\nAbbildung 6.5: Histogram der auf den simulierten Daten berechneten \\(\\hat{\\beta}_1\\). Wahrer Wert von \\(\\beta_1\\) rot eingezeichnet und kritische Werte grün.\n\n\n\n\nFühren wir nun ein Experiment noch einmal durch. Wir beobachten einen Wert für \\(\\hat{\\beta}_1\\) von \\(1.46\\). Dieser Wert liegt außerhalb unseres definierten Intervalls \\([0.65, 1.35]\\), daher sehen wir diesen Wert als derart unwahrscheinlich unter dem angenommenen DGP, das wir sagen: Wir glauben nicht, dass diesem Experiment nicht der angenommene DGP zugrunde liegt. Graphisch wieder dargestellt (siehe Abbildung 6.6).\n\n\n\n\n\nAbbildung 6.6: Histogram der auf den simulierten Daten berechneten \\(\\hat{\\beta}_1\\). Wahrer Wert von \\(\\beta_1\\) rot eingezeichnet und kritische Werte grün und der beobachtete Wert als roter Punkt.\n\n\n\n\nDaher würden wir diesen Wert als statisisch signifikant bezeichnen und würden unsere Annahme ablehnen.\nJetzt sind wir aber etwas hin und her zwischen Experiment, Annahmen und Schlussfolgerungen gesprungen. Normalerweise kennen wir die Stichprobenverteilung nicht vor dem Experiment, sondern, wir sind am dem Wert \\(\\beta_1\\) interessiert. Wenn wir den Wert schon wissen würden, dann müssten wir ja gar kein Experiment mehr durchführen. D.h. wir haben eigentlich noch keinen klaren Vorkenntnisse. Mit welcher Annahme gehen wir dann in das Experiment rein? Nun, wir schon bei kleinen Welt Beispiel, starten wir mit der Annahme das zwischen den beiden Variablen kein Zusammenhang besteht. Übertragen auf die Modellparameter also, dass kein linearer Zusammenhang zwischen den beiden Variablen besteht.\n\\[\\begin{align*}\nH_0: \\beta_1 &= 0 \\\\\nH_1: \\beta_1 &\\neq 0\n\\end{align*}\\]\nUm die Stichprobenverteilung unter der \\(H_0\\) formal Herleitung zu können, ist der Erwartungswert von \\(\\hat{\\beta}_1\\) und dessen Standardfehler notwendig. Es lässt sich zeigen, dass die folgenden Zusammenhänge unter den gesetzten Annahmen bestehen:\n\\[\nE[\\hat{\\beta}_0] = \\beta_0\n\\]\nAlso der Schätzer von \\(\\beta_1\\) ist erwartungstreu (biased) und der Standardfehler des Schätzer lässt sich wie folgt bestimmen.\n\\[\n\\sigma_{\\beta_1} = \\sqrt{\\frac{\\sigma^2}{\\sum{(X_i - \\bar{X})^2}}}\n\\tag{6.3}\\]\nHier taucht jetzt zum ersten Mal der Parameter \\(\\sigma^2\\) formal auf. Wo kommt diese Variance her? Sie gehört zu unserer Annahme der Verteilung der \\(\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\). Bisher haben wir aber noch gar keine Möglichkeit kennen gelerntm, diese abzuschätzen. Wieder nach etwas motivierten Starren auf die verschiedenen Formeln, könnte heuristisch plausibel sein, dass die Varianz, also die Streuung der \\(\\epsilon_i\\) mit der Streuung unserer Werte um die Regressionsgerade zusammenhängen könnten. Formal hatten wir diese als Residuen bezeichnet und mit \\(e_i = \\hat{y}_i - y_i\\) bezeichnet. Vormals hatten wir diese Abweichungen als Fehler bezeichnet, aber unter den jetzt eingeführten Annahmen, handelt es sich nicht wirklich um Fehler, sondern die Abweichungen sind eine Folge davon, dass \\(Y_i\\) für jeden Wert von \\(X_i\\) nicht nur einen einzigen Wert hat, sondern eben einer Verteilung folgt \\(Y_i|X_i \\sim \\mathcal{N}(\\beta_0 + beta_1, \\sigma^2)\\) deren Form über die \\(\\epsilon_i\\) bestimmt wird.\nDie \\(e_i\\) sind tatsächlich die Schätzer für die wahren \\(\\epsilon_i\\) also \\(e_i = \\hat{\\epsilon_i} = \\hat{y}_i - y_i\\). Es lässt sich nun wieder zeigen, dass mittels dieser \\(e_i\\) ein erwartungstreuer Schätzer für \\(\\sigma^2\\) erzeugen lässt. Nämlich die mittleren quadrierten Abweichungen (MSE).\n\\[\n\\hat{\\sigma} = \\frac{\\sqrt{\\sum_{i=1}^N e_i^2}}{N-2} = \\frac{\\text{SSE}}{N-2} = \\text{MSE}\n\\tag{6.4}\\]\nDa das später immer wieder auftauchen wird, hier auch noch mal in die zwei Komponenten zerlegt. Der Zähler wird als Summe der quadrierten Abweichungen (SSE) bezeichnet und durch den Term \\(N-2\\), der als Freiheitsgerade bezeichnet wird, geteilt. Dann mit die Formel und deren Bezeichnung mittlere Abweichung zusammenpasst, wäre es schöner wenn die Summe durch die Anzahl \\(N\\) der Terme geteilt wird, allerdings verhält sich das in diesem Fall ähnlich wie bei der Varianz einer Stichprobe wo die Summe auch durch \\(N-1\\) geteilt wird (zur Erinnerung \\(s = \\frac{\\sum_{i=1}^N (x_i - \\bar{x})^2}{N-1}\\)). Jetzt wird dementsprechend nicht durch \\(N-1\\) sondern durch \\(N-2\\) geteilt.\nFür unser Problem der Stichprobenverteilung ist jetzt aber wichtiger, dass wir mittels Gleichung 6.4 den Standardfehler von \\(\\hat{\\beta}_1\\) bestimmen können, indem wir für \\(\\sigma^2\\) das mittels der Daten ermittelte \\(\\hat{\\sigma}^2\\) einsetzen.\n\\[\n\\hat{\\sigma}_{\\beta_1} = \\sqrt{\\frac{\\hat{\\sigma}^2}{\\sum{(X_i - \\bar{X})^2}}}\n\\tag{6.5}\\]\nDies erlaubt uns jetzt nach unserem bereits bekannten Muster eine Teststatistik für die \\(H_0\\) herzuleiten:\n\\[\nt = \\frac{\\hat{\\beta}_1 - \\beta_1}{\\hat{\\sigma}_{\\beta_1}}\n\\]\nUnter der \\(H_0\\) mit \\(\\beta_1 = 0\\) wird daraus\n\\[\nt = \\frac{\\hat{\\beta}_1}{\\hat{\\sigma}_{\\beta_1}}\n\\tag{6.6}\\]\nDiese Teststatistik folgt einer t-Verteilung mit \\(N-2\\) Freiheitsgeraden. Da diese Formel wieder etwas aus der Luft gegriffen erscheint, hier noch mal eine Simulation zusammen mit der theoretischen Testverteilung.\n\nN &lt;- 45\nn_sim &lt;- 1000\nx &lt;- runif(N, -1, 1)\nsigma &lt;- 1\nexperiment &lt;- function() {\n  y &lt;- rnorm(N, mean = 0, sd = sigma)\n  mod &lt;- lm(y~x)\n  b &lt;- coef(mod)[2]\n  c(beta_0 = coef(mod)[1],\n    beta_1 = coef(mod)[2],\n    sigma = sigma(mod))\n}\nbetas &lt;- t(replicate(n_sim, experiment()))\nbetas &lt;- tibble(beta_0 = betas[,1],\n                beta_1 = betas[,2],\n                sigma = betas[,3]) |&gt; \n  mutate(\n   s_e_beta_1 = sqrt(sigma**2/sum( (x - mean(x))**2)),\n   t = beta_1 / s_e_beta_1)\nt_theoretical &lt;- tibble(\n  t = seq(-3, 3, length.out = 150),\n  p = dt(t, N - 2)\n)\n\nggplot(betas, aes(t)) +\n  geom_histogram(aes(y = ..density..), bins = 20) +\n  geom_line(data = t_theoretical, aes(t, p), color = 'red') +\n  labs(x = \"t\", y = 'Relative Häufigkeit') \n\n\n\n\nAbbildung 6.7: Verteilung von t bei 1000 Simulationen unter der Annahme der \\(H_0\\) und die theoretische Verteilung von t (rot).\n\n\n\n\nIn Abbildung 6.7 können wir sehen, dass die theoretische Verteilung in rot die beobachtete Verteilung sehr gut abschätzt.\nIn R kann der Wert \\(\\hat{\\sigma}^2\\) über die Funktion sigma() aus dem gefitteten lm()-Modell extrahiert werden.\n\nsigma(mod)\n\n[1] 0.2369055\n\n\nSchauen wir uns die Stichprobenverteilung von \\(\\hat{\\sigma}^2\\) anhand unserer Simulation an. Es ist wieder zu beobachten, das im Mittel der korrekte, im Modell definierte, Wert von \\(\\sigma = 1\\) beobachtet wird (siehe Abbildung 6.8).\n\n\n\n\n\nAbbildung 6.8: Verteilung von \\(\\hat{\\sigma}\\) in der Simulation und der wahre Wert in rot eingezeichnet\n\n\n\n\nAber wie immer, leider steht uns bei einem realen Experiment diese Information nicht zur Verfügung und wir haben nur einen einzelnen Wert, der alles von komplett daneben bis ziemlich perfekt sein kann.\nSchauen wir uns noch einmal die Ausgabe zu unserem Weitsprungmodell mittels summary() an. Unter Residual Standard Error sehen wir, dass hier \\(\\hat{\\sigma}\\) angegeben wird. Dieser Wert wird auch als mittlerer Schätzfehler bezeichnet und kann als Maß verwendet werden, welche Abweichung das Modell im Mittel hat. Die Einheit sind wieder in den Einheiten der abhängigen Variable, so kann auch schon abgeschätzt werden mit welcher Präzision das Modell die Daten fittet.\n\nsummary(mod)\n\n\nCall:\nlm(formula = jump_m ~ v_ms, data = jump)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.44314 -0.22564  0.02678  0.19638  0.42148 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.13854    0.23261  -0.596    0.555    \nv_ms         0.76110    0.02479  30.702   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2369 on 43 degrees of freedom\nMultiple R-squared:  0.9564,    Adjusted R-squared:  0.9554 \nF-statistic: 942.6 on 1 and 43 DF,  p-value: &lt; 2.2e-16\n\n\nIn unserem Fall beobachten wir \\(0.24m\\). Diesen Wert muss jetzt unsere Trainerin im Sinne der Weitsprungleistung der deren Varianz interpretieren und ein Abschätzung treffen zu können.\nNach der Herleitung der Teststatistik für \\(\\beta_1\\), können wir jetzt auch weitere Teil der Ausgabe von summary() interpretieren. In der Tabelle stehen entsprechend die Standardfehler für \\(\\hat{\\beta}_1\\) und \\(\\hat{\\beta}_0\\). Für \\(\\beta_0\\) wird genau die gleiche Vorgehensweise wie auch bei _1$ angewendet. Die Nullhypothese \\(H_0\\) ist hier ebenfalls das der Parameter standardmäßig als Null angesetzt wird.\n\\[\\begin{align*}\nH_0: \\beta_0 &= 0 \\\\\nH_1: \\beta_0 &neq 0\n\\end{align*}\\]\nDementsprechend überprüft die Hypothesentestung ob der \\(y\\)-Achsenabschnitt gleich Null ist. Hier sollte berücksichtigt werden, dass diese Hypothese in den seltensten Fällen tatsächlich auch von Interesse ist und lediglich besagt, dass entweder der \\(y\\)-Achsenabschnitt durch den Nullpunkt geht, oder dass wenn tatsächlich \\(\\beta_1 = 0\\) gilt, der Mittelwert von \\(y\\) gleich Null ist, was ebenfalls in den seltensten Fällen von Interesse ist.\nDie Spalten 3 und 4 in summary() unter Coefficients: können jetzt interpretiert werden, da es sich hierbei um die \\(t\\)-Teststatistik handelt und den entsprechenden p-Wert unter der jeweiligen \\(H_0\\). Die Hypothesen sind ungerichtet."
  },
  {
    "objectID": "slm_inference.html#maximum-likelihood-methode-bei-der-einfachen-linearen-regression",
    "href": "slm_inference.html#maximum-likelihood-methode-bei-der-einfachen-linearen-regression",
    "title": "6  Inferenz",
    "section": "6.3 Maximum-likelihood Methode bei der einfachen linearen Regression",
    "text": "6.3 Maximum-likelihood Methode bei der einfachen linearen Regression\nEin anderer Herleitung für \\(\\beta_0\\) und \\(\\beta_1\\) kann über die sogenannten Maximum Likelihood durchgeführt werden. Dabei gehen direkt die Verteilungsannahmen direkt ein.\nFür eine gegebene Zufallsvariable die jeweilige Dichte eines gegebenen Wertes über die Dichtefunktion berechnet werden. Wenn ein Zufallsvariable \\(X\\) einer Normalverteilung folgt, dann wird die Verteilung von \\(X\\) nach der bereits kennengelernte Dichtefunktion der Normalverteilung beschrieben.\n\\[\nf(X|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2}\\frac{(X - \\mu)^2}{\\sigma^2}\\right)\n\\]\nHier wird die Dichte von \\(X\\) als eine Funktion von \\(\\mu\\) und \\(\\sigma^2\\) aufgefasst. Es ist aber auch möglich, die Zufallsvariable \\(X\\) als gegeben anzusehen und die Dichte für verschiedene Werte von \\(\\mu\\) und \\(\\sigma^2\\) abzutragen. Der Einfachheit halber gehen wir davon aus, dass \\(\\sigma^2\\) gegeben sei und wir \\(\\mu\\) nicht kennen. Eine mögliche Fragestellung ist jetzt, für einen beobachteten Wert \\(x\\), welcher Wert von \\(\\mu\\) ist am plausibelsten?\nTragen wir dazu verschiedene Dichtewerte für ein gegebenes \\(x\\) in Abhängigkeit von verschiedenen \\(\\mu\\) ab.\nD.h. wir interpretieren die Funktion als:\n\\[\nf(\\mu|x,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} \\exp\\left(-\\frac{1}{2}\\frac{(X - \\mu)^2}{\\sigma^2}\\right)\n\\]\nDiese Funktion wird als die likelihood-Funktion bezeichnet. Das Maximum dieser Funktion kann als derjenige Wert interpretiert werden bei dem derjenige Wert von \\(\\mu\\) die maximal mögliche Dichte einnimmt.\nDie Likelihood-Funktion ist eine Funktion, die die Wahrscheinlichkeit beschreibt, mit der eine gegebene Stichprobe, in Abhängikeit von den Parametern aus einer bestimmten Verteilung stammt. Die Likelihood-Funktion gibt also an, wie gut die beobachteten Daten zu einem bestimmten Satz von Parametern passen.\nFormal wird die Likelihood-Funktion als die gemeinsame Wahrscheinlichkeitsdichte der Stichprobe beschrieben, betrachtet als Funktion der Parameter. Dabei werden die beobachteten Werte als festgelegt und die Parameter als Variablen betrachtet. Die Likelihood-Funktion ist also eine Funktion der Parameter, die die Wahrscheinlichkeit der beobachteten Daten als Funktion dieser Parameter beschreibt. Die Likelihood-Funktion ist dabei keine Dichtefunktion und beschreibt somit keine Wahrscheinlichkeiten. Dementsprechend ist gilt für das Integral der Likelihood-Funktion \\(\\int L(\\mu|X,\\sigma^2) d\\mu \\neq 1\\) bzw. ist \\(=1\\) per Zufall.\nIn unserem Regressionsfall nimmt die Likelihood-Funktion für einen einzelnen Wert die folgende Form an:\n\\[\nL(\\beta_0, \\beta_1, \\sigma^2|y_i) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2\\sigma^2}\\right)\n\\]\nBei unserer Regressionsanalyse haben wir jedoch nicht nur einen einzigen beobachteten Wert \\((y_i, x_i)\\) sondern \\(N\\) beobachtete Werte. Da die Werte unabhängig voneinander sind (laut der Annahmen), werden die jeweiligen likelihoods miteinander multipliziert. Die resultierende Likelihood-Funktion nimmt dann die folgenden Form an:\n\\[\\begin{align*}\nL(\\beta_0, \\beta_1, \\sigma^2) &= \\prod_{i=1}^{N} f(y_i | x_i; \\beta_0, \\beta_1, \\sigma^2) \\\\\n&= \\prod_{i=1}^{N} \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2\\sigma^2}\\right) \\\\\n&= \\left(\\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\right)^N \\exp\\left(\\sum_{i=1}^N \\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2 \\sigma^2}\\right) \\\\\n&= \\left(\\frac{1}{2\\pi \\sigma^2}\\right)^{N/2} \\exp\\left(\\sum_{i=1}^N \\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2 \\sigma^2}\\right) \\\\\n\\end{align*}\\]\nDie Idee ist jetzt wieder die Gleiche. Wir versuchen das Maximum dieser Funktion zu finden, da die Werte \\(\\beta_0, \\beta_1\\) und \\(\\sigma^2\\) dann so gewählt sind, dass sie die höchste likelihood haben. Der Ansatz erfolgt wieder mechanisch ,indem wie bei der Herleitung der Normalengleichungen, die partiellen Ableitungen berechnet werden, diese gleich Null gesetzt werden und das resultierende Gleichungssystem gelöst wird. Zu beachten hierbei, wir haben in jedem Produktterm die gleichen Parameter \\(\\beta_0, \\beta-1\\) und \\(\\sigma^2\\) und die jeweiligen beobachteten \\((y_i, x_i)\\) Tuple werden als gegeben angesehen.\nUm die Berechnungn zu vereinfachen, bietet sich bei der Likelihoo-Funktion ein Trick an. Es wird nicht Likelihood-Funktion abgeleitet, sondern der Logarithmus der Likelihood-Funktion. D.h. die Funktion wird transformiert. Bei der Logarithmus-Funktion handelt es sich um eine sogenannte bijektive Funktion. Eine bijektive Funktion ist eine Funktion die jedem Element in der Ursprungsmenge genau ein Element in der Zielmenge zuordnet und ebenfalls umgekehrt. Dadurch kommt es zu keinen Kollisionen oder Auslassungen. Einfach gesagt, wenn die Funktion \\(y = f(x) = log(x)\\) ist, dann wird jedem \\(x\\) genau ein \\(y\\) zugeordnet. Bzw. anders herum, wenn ich \\(y\\) kenne, dann kenne ich auch den Wert von \\(x\\) mit \\(f(x) = y\\) bzw. \\(x = f^{-1}(y) = \\exp(y)\\). Dadurch, das die Logarithmus-Funktion bijektiv ist, führt dies dazu, dass das Maximum der ursprünglichen Funktion \\(L(\\beta_0, \\beta_1, \\sigma^2)\\) an der gleichen Stelle auftritt wie bei der transformierten Funktion \\(\\ln L(\\beta_0, \\beta_1, \\sigma^2)\\).\nWenn jetzt die Eigenschaften der Logarithmusfunktion, speziell des natürlichen Logarithmus, beachtet werden, dann wird auch klar, warum es Sinn machen könnte die Likelihood-Funktion mit dem Logarithmus zu transformieren, da aus den Produkten Summen werden mit denen einfacher umgegangen werden kann:\n\\[\\begin{align*}\n\\log(xy) &= \\log(x) + \\log(y) \\\\\n\\log\\left(\\frac{x}{y}\\right) &= \\log(x) - \\log(y) \\\\\n\\log(x^n) &= n\\log(x) \\\\\n\\log(\\exp(x)) &= x \\\\\n\\log(1) &= 0\n\\end{align*}\\]\nDer Logarithmus angewendet auf \\(L(\\beta_0, \\beta_1, \\sigma^2)\\) resultiert dann in der folgenden Funktion:\n\\[\\begin{align*}\n\\ell(\\beta_0, \\beta_1, \\sigma^2) &= \\ln L(\\beta_0, \\beta_1, \\sigma^2) \\\\\n&= \\ln \\left[\\left(\\frac{1}{2\\pi \\sigma^2}\\right)^{N/2} \\exp\\left(-\\sum_{i=1}^N \\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2 \\sigma^2}\\right)\\right] \\\\\n&= \\ln \\left[\\left(\\frac{1}{2\\pi \\sigma^2}\\right)^{N/2} \\right] + \\ln \\left[\\exp\\left(-\\sum_{i=1}^N \\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2 \\sigma^2}\\right)\\right] \\\\\n&= \\frac{N}{2} \\ln \\left[\\left(\\frac{1}{2\\pi \\sigma^2}\\right) \\right] -\\sum_{i=1}^N \\frac{(y_i - \\beta_0 - \\beta_1 x_i)^2}{2 \\sigma^2} \\\\\n&= -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln(\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{N}(y_i - \\beta_0 - \\beta_1 x_i)^2\n\\end{align*}\\]\nWir die Funktion \\(\\ell(\\beta_0, \\beta_1, \\sigma^2)\\) wieder partiell nach \\(\\beta_0\\) und \\(\\beta_1\\) abgeleitet und gleich Null gesetzt erhalten wir das gleiche Gleichungssystem wie bei den vorhergehenden Herleitungen über die Abweichungen von der Regressionsgeraden. z.B.\n\\[\\begin{align*}\n\\frac{\\partial \\ell(\\beta_0, \\beta_1, \\sigma^2)}{\\partial \\beta_0} &= \\frac{\\partial}{\\partial \\beta_0} -\\frac{n}{2}\\ln(2\\pi) - \\frac{n}{2}\\ln(\\sigma^2) - \\frac{1}{2\\sigma^2}\\sum_{i=1}^{N}(y_i - \\beta_0 - \\beta_1 x_i)^2 \\\\\n&= \\frac{2}{2\\sigma^2}\\sum_{i=1}^N (y_i - \\beta_0 - \\beta_1 x_i)\n\\end{align*}\\] Wenn dieser Ausdruck gleich Null gesetzt erhalten wir den gleichen Ausdruck wie unter"
  },
  {
    "objectID": "stats_significance.html#footnotes",
    "href": "stats_significance.html#footnotes",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "",
    "text": "auch Skalenparameter↩︎\nDer Standardfehler schätzt die Reliabilität der Statistik ab (Cohen (1988))↩︎\nStrictly speaking, a 95% confidence interval does not mean there is a 95% probability that this particular interval contains the true value […]↩︎"
  },
  {
    "objectID": "stats_hypotheses.html#rechenregeln-zum-erwartungswert-und-der-varianz",
    "href": "stats_hypotheses.html#rechenregeln-zum-erwartungswert-und-der-varianz",
    "title": "4  Hypothesen testen",
    "section": "4.2 Rechenregeln zum Erwartungswert und der Varianz",
    "text": "4.2 Rechenregeln zum Erwartungswert und der Varianz\n\n4.2.1 Erwartungwert\nFür eine diskrete Zufallsvariable \\(X\\) auf einer endlichen Menge \\(\\{x_i, i = 1, \\ldots, n\\}\\) mit \\(n\\) Elementen ist der Erwartungswert definiert mit:\n\\[\nE[X] = \\sum_{i=1}^n x_i P(x_i)\n\\]\nD.h. jedes mögliche Ereignis wird mit seiner Wahrscheinlichkeit multipliziert und die Summe über alle diese Möglichkeiten wird gebildet.\nWird eine Zufallsvariable mit einer Konstanten \\(a\\) multipliziert, dann ist der Erwartungswert:\n\\[\nE[aX] = \\sum_{i=1}^n a x_i P(x_i) = a \\sum_{i=1}^n x_i P(x_i) = a E[X]\n\\]\nWerden zwei unabhängige Zufallsvariablen \\(X\\) und \\(Y\\) auf den Ereignismengen \\(\\{x_i, i = 1, \\ldots, n\\}\\) und \\(\\{y_j, j = 1, \\ldots, m\\}\\) addiert, dann berechnet sich der Erwartungswert von \\(E[X + Y]\\) mittels:\n\\[\nE[X + Y] = \\sum_{i=1}^n x_i P(x_i) + \\sum_{j=1}^m y_j P(x_j) = E[X] + E[Y]\n\\]\nDiese Formel generalisiert für unabhängige \\(X_i, i = 1, \\ldots, n\\) zu:\n\\[\nE[X_1 + X_2 + \\ldots + X_n] = E[X_1] + E[X_2] + \\ldots + E[X_n]\n\\]\nIn Kombination mit der Regel für konstante Terme mit den Konstanten \\(a_1, a_2, \\ldots, a_n\\) folgt:\n\\[\nE[a_1 X_1 + a_2 X_2 + \\ldots + a_n X_n] = a_1 E[X_1] + a_2 E[X_2] + \\ldots + a_n E[X_n]\n\\]\n\nBeispiele\nNehmen wir zur Veranschaulichung ein einfaches Beispiel mit einer Zufallsvariable \\(x\\) welche die folgende Verteilung hat (siehe Tabelle 4.1):\n\n\nTabelle 4.1: Verteilung der Zufallsvariablen \\(X\\)\n\n\nx\n0\n1\n2\n3\n\n\n\n\n\\(P(x)\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{5}{8}\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{1}{8}\\)\n\n\n\n\nDaher folgt für den Erwartungswert \\(E[X]\\):\n\\[\nE[X] = \\sum_{i=1}^4 x_i P(x_i) = \\frac{1}{8} \\cdot 0 + \\frac{1}{8}\\cdot 1 + \\frac{5}{8}\\cdot2 + \\frac{1}{8}\\cdot3 = 1.25\n\\]\nHaben wir eine zweite Zufallsvariable \\(Y\\) mit der Verteilung (siehe Tabelle 4.2)\n\n\nTabelle 4.2: Verteilung der Zufallsvariablen \\(X\\)\n\n\ny\n0\n1\n2\n3\n\n\n\n\n\\(P(y)\\)\n\\(\\frac{2}{8}\\)\n\\(\\frac{2}{8}\\)\n\\(\\frac{1}{8}\\)\n\\(\\frac{3}{8}\\)\n\n\n\n\nMit \\(E[Y]\\):\n\\[\nE[Y] = \\sum_{i=1}^4 y_i P(y_i) = \\frac{2}{8} \\cdot 0 + \\frac{2}{8}\\cdot 1 + \\frac{1}{8}\\cdot2 + \\frac{3}{8}\\cdot3 = 1.625\n\\]\nDann folgt für den Erwarungswert von \\(E[X + Y]\\):\n\\[\nE[X + Y] = E[X] + E[Y] = 1.25 + 1.625 = 2.875\n\\]\nDefinieren wir eine neue Zufallsvariable \\(Z\\) mit \\(Z := a \\cdot X\\) mit der Konstanten \\(a := 2\\). Dann folgt für den Erwartungswert von \\(E[Z]\\):\n\\[\nE[Z] = E[aX] = aE[X] = 2 \\cdot 1.25 = 2.5\n\\]\n\n\n\n4.2.2 Varianz"
  }
]