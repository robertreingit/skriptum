# Interaktionseffekte 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```

```{r defs_mult_reg_inter}
lm_coef_ex <- function(mod, max_co=3) round(summary(mod)$coefficients[,1:max_co],2)
n <- 40
set.seed(123)
foo <- MASS::mvrnorm(n, mu = c(184,77),
              Sigma=matrix(c(72,37,37,125),nr=2))
handball <- tibble::tibble(
  arm_span = foo[,1],
  body_mass = foo[,2],
  vel = 1 + 0.12*body_mass + 0.06*arm_span + 0.02*(body_mass-77)*(arm_span-184) + rnorm(n)
)
ncol_text <- theme(text = element_text(size=20))
```

Bisher haben wir uns additive Effekte angeschaut. D.h. in unserer Modellspezifikation sind die Prädiktorvariablen $x_i$ immer nur mit einem $+$ in die Formel eingegangen. Im folgenden werden wir sehen, das das lineare Modell nicht nur auf solche Effekt beschränkt ist, sondern Prädiktorvariablen $x_i$ auch multiplikativ in die Formel eingehen können.

## Ein Handballbeispiel

Fangen wir mit einem hypothetischen Datensatz zum Handball an. Wir haben drei Datenspalten zur Wurfgeschwindigkeit, der Körpermasse und der Armspannweite und unser Ziel ist es, die Wurfgeschwindigkeit anhand der Körpermasse und der Armspanweite vorherzusagen. Die Fragestellung ist angelehnt an @debanne2011. Schauen wir uns zunächst die deskriptiven Daten (siehe @tbl-mlm-inter-handball-01).

```{r}
#| label: tbl-mlm-inter-handball-01
#| tbl-cap: "Deskriptive Statistiken der Handballdaten"
#| output: asis

handball |> 
  dplyr::rename(c('Armspannweite[cm]'=arm_span, 'Körpermasse[kg]'=body_mass, 'Wurfgeschwindigkeit[m/s]'=vel)) |> 
  summarytools::descr(
  stats = c('mean','sd','min','max'),
  transpose = T,
  style = 'rmarkdown',
  heading = F) #|>
```

In @tbl-mlm-inter-handball-01 ist zunächst einmal nichts auffallendes zu sehen. Vielleicht sind die Wurfgeschwindigkeiten etwas niedring für Hochleistungshandballer, aber das soll uns nun nicht weiter stören. Schauen wir uns die Daten als Streudiagramme an.

```{r}
#| label: fig-mlm-inter-handball-01
#| fig-height: 5
#| layout-ncol: 2
#| fig-cap: "Streudiagramme der Handballdaten."
#| fig-subcap:
#|   - "Geschwindigkeit gegen Körpergewicht"
#|   - "Geschwindigkeit gegen Armspannweite"

ggplot(handball, aes(body_mass, vel)) +
  geom_point(size=3) +
  labs(x = 'Köpergewicht [kg]', y = 'Geschwindigkeit [m/s]') +
  ncol_text

ggplot(handball, aes(arm_span, vel)) +
  geom_point(size=3) +
  labs(x = 'Armspannweite [cm]', y = 'Geschwindigkeit [m/s]') +
  ncol_text
```

In beiden Graphen ist mit etwas gutem Willen ein positiver Zusammenhang zwischen den jeweiligen Prädiktorvariablen und der Wurfgeschwindigkeit zu identifzieren. Für das Körpergewicht in @fig-mlm-inter-handball-01-1 vielleicht etwas mehr als für die Armspannweite in @fig-mlm-inter-handball-01-2.

Versuchen wir nun die Daten mittels eines linearen Modells zu modellieren.

\begin{equation*}
Y_{i} = \beta_0 + \beta_1 \times \textrm{bm}_i + \beta_2 \times \textrm{as}_i + \epsilon_i
\end{equation*}

Übersetzt in `R` und `lm()` bedeutet dies:

```{r}
#| echo: true
mod_1 <- lm(vel ~ body_mass + arm_span, handball)
```

Wenn wir uns die Parameter des Modells ansehen (siehe @tbl-mlm-inter-handball-mod1), dann sehen wir dass die Steigungskoeffizienten zwar knapp statistisch signifikant sind, aber in Bezug auf die Residualvarianz bzw. den Standardfehler $\hat{\sigma}$ wir eine ziemlich hohe Restunsicherheit haben, die letztendlich Vorhersagen des Modell unbrauchbar macht.

```{r}
#| label: tbl-mlm-inter-handball-mod1
#| tbl-cap: "Modellfit der Handballdaten aus Model 1"
 
mod_1 |> lm_tbl_knitr(caption = "Modell 1", long = T, add_sigma = T)
```

Der y-Achsenabschnitt $\beta_0$ im Modell macht auch keinen Sinn, da er verbal übersetzt ausdrücken würde, dass ein Handballer mit $0$cm Spannweite und einer Körpermasse von $0$ Kg eine Wurfgeschwindigkeit von $v = `r round(coef(mod_1)[1],1)`$m/s erreichen würde.

Zentrieren wir die Daten damit die Koeffizienten besser interpretierbar werden. Das ändert zwar nichts an dem Modellfit, aber der y-Achsenabschnitt bekommt dadurch einen sinnvollen Wert. Wie immer beim Zentrieren, ziehen wir von den Prädiktorvariablen den jeweiligen Mittelwert der Variablen ab.

```{r}
#| echo: true

handball <- dplyr::mutate(handball,
                          body_mass_c = body_mass - mean(body_mass),
                          arm_span_c = arm_span - mean(arm_span))
```

Fitten wir die Daten nun mittels der zentrierten Variablen.

```{r}
#| echo: true

mod_2 <- lm(vel ~ body_mass_c + arm_span_c, handball)
```

Wie erwartet ändert dies nichts an den Werten, bis auf den y-Achsenabschnitt. Der Wert von $21.8$ ist jetzt so zu interpretieren, dass ein Handballer mit einer Armspannweite von $184$cm und einer Körpermasse von $77$Kg eine Wurfgeschwindigkeit von $21.9$m/s erreichen sollte (siehe @tbl-mlm-inter-handball-01 und @tbl-mlm-inter-handball-mod2).

```{r}
#| label: tbl-mlm-inter-handball-mod2
#| tbl-cap: "Modellfit der Handballdaten aus Model 2"

mod_2 |> lm_tbl_knitr(caption = "Modell 2", long = T, add_sigma = T)
```

Schauen wir uns als nächstes die Residuen $e_i$ im zentrierten, additiven Modell (Model 2) an (siehe @fig-mlm-inter-handball-02).

```{r}
#| label: fig-mlm-inter-handball-02
#| fig-cap: "Residuenplot unter Modell 2"

handball <- handball |> 
  dplyr::mutate(res_2 = resid(mod_2),
                y_hat_2 = predict(mod_2))
p_resid_2 <- ggplot(handball, aes(y_hat_2, res_2)) +
  geom_point() +
  geom_hline(yintercept = 0, col = 'red', linetype = 'dashed') +
  labs(x = expression(paste('Vorhergesagte Werte ', hat(y)[i])),
       y = expression(paste('Residuen ', hat(e)[i]))) 
print(p_resid_2)
```

Da die Werte für kleine und große vorhergesagte Werte $\hat{y}_i$ ganz klar ein Muster anzeigen, können wir davon ausgehen, dass unser Modell eine Struktur der Daten nicht modelliert. Untersuchen wir noch einmal eingehender den Einfluss der Prädiktorvariablen auf die Wurfgeschwindigkeit.

Schauen wir uns einmal an, was passiert, wenn wir eine künstliche Unterteilung der Armspannweiten und Körpermassen in drei verschiedene Kategorien durchführen. D.h. wir unterteilen die Armspannweite in kurze, mittlere und lange Spannweiten und das Gleiche für die Körpermasse in leicht, mittel und schwer. Wir benutzen dazu die `cut_number()`-Funktion (siehe [Doku](https://ggplot2.tidyverse.org/reference/cut_interval.html)).

```{r}
#| echo: true

hb_quick <- handball |>
  dplyr::mutate(
    as_f = cut_number(arm_span_c, 3, labels=c('kurz','mittel','lang')),
    bm_f = cut_number(body_mass_c, 3, labels=c('leicht','mittel','schwer'))
  ) 
```

Schauen wir uns die Daten nun wieder mittels eines Graphen an (siehe @fig-mlm-inter-handball-03).

```{r}
#| label: fig-mlm-inter-handball-03
#| fig-cap: "Mittlere Wurfgeschwindigkeiten ($\\pm$SD) für die Unterteilung nach Körpergewicht und Armspannweite in Kategorien"

hb_quick |>
  dplyr::group_by(as_f, bm_f) |> 
  dplyr::summarize(m = mean(vel), sd = sd(vel)) |> 
  ggplot(aes(as_f, m, color=bm_f, group=bm_f)) +
  geom_pointrange(aes(ymin = m - sd, ymax = m + sd)) +
  geom_line() +
  labs(x = 'Armspannweite', y = 'Geschwindigkeit') 
```

Hier zeigt sich ein interessantes Muster. Für mittel und schwere Handballer nimmt die Wurfgeschwindigkeit mit der Armspannweite zu. Dagegen zeigt sich der gegensätzliche Trend für leichte Handballer. D.h. der Einfluss der Armspannweite hängt davon ab wie schwer der Handballer ist. Der Einfluss ist in der anderen Richtung genause, der Einfluss der Körpermasse hängt von der Armspanweite ab. Wenn sich die Effekte zweier Prädiktorvariablen gegenseitig beeinflussen, dann wird dies als Interaktionseffekts bezeichnet.

## Interaktion zwischen zwei Effekten

::: {#def-interaction}
## Interaktionseffekt\index{Interaktion}

Wenn der Effekt einer unabhängigen Variable auf die abhängige Variable davon abhängt welche Ausprägung eine weitere unabhängige Variable hat, dann wird dies als ein Interaktionseffekt bezeichnet.
:::

Im Rahmen eines linearen Modells, wird ein solcher Interaktionseffekt durch einen multiplikativen Term zwischen den beiden Variablen modelliert.

\begin{equation*}
Y_{i} = \beta_0 + \beta_1 \times \textrm{bm}_i + \beta_2 \times \textrm{as}_i + \beta_3 \times \textrm{bm}_i \times \textrm{as}_i + \epsilon_i
\end{equation*}

Warum die Multiplikation sinnvoll ist, werden wir etwas später genauer betrachten. In `R` spezifieren wir Interaktionseffekte mittels eines `:`.

```{r}
#| echo: true
mod_3 <- lm(vel ~ body_mass_c + arm_span_c + body_mass_c:arm_span_c, handball) 
```

Wir können auch die Kurzform mittels eines `*` benutzen. 
```{r}
#| echo: true

mod_3 <- lm(vel ~ body_mass_c * arm_span_c, handball) 
```

Die Funktion `lm()` multipliziert Terme der Form `A*B` in `A + B + A:B` aus. Schauen wir uns jetzt den Fit von Modell 3 an (siehe @tbl-mlm-inter-handball-mod3)

```{r}
#| label: tbl-mlm-inter-handball-mod3
#| tbl-cap: "Modellfit der Handballdaten unter Momdell 3"

handball <- handball |> 
  dplyr::mutate(res_3 = resid(mod_3),
                y_hat_3 = predict(mod_3))
mod_3 |> lm_tbl_knitr(caption = "Modell 3", long = T, add_sigma = T)
```

Als erstes sehen wir, dass sich die Residualvarianz $\hat{\sigma}$ mehr als halbiert hat. D.h unser Modell ist schon einmal deutlich präziser geworden. Auch die Standardfehler der beiden Steigungskoeffizienten für die Haupteffekte haben sich deutlich verringert (vgl. @tbl-mlm-inter-handball-mod2). Dementsprechend sind beide Koeffizienten statistisch signifikant. Der neu dazugekommene Koeffizient für den Interaktionseffekt ist ebenfalls statistisch signifikant mit einem sehr kleinen Standardfehler. Jetzt müssen wir nur noch verstehen was die Koeffizienten und insbesondere $\beta_3$ eigentlich bedeuten.

Schauen wir dazu zunächst die Vorhersagen $\hat{y}_i$ unter den beiden Modellen Modell 2 und Modell 3 an. Zur Erinnerung, beide Modell arbeiten mit zentrierten Prädiktorvariablen. Um einen besseren Überblick über die Vorhersagen zu bekommen, vereinfachen wir die Daten und nehmen nur drei verschiedene Werte für die Armspannweite $as = \{-10,0,10\}$ cm. D.h. einen hypothetischen Handballer mit der Durchschnittsspannweite, sowie jeweils einen mit $10$ cm kürzerer bzw. $10$ cm längerer Spannweite. Wir kombinieren diese drei Werte mit drei verschiedenen Körpermassen $bm = \{-2,0,2\}$ Kg. D.h. eine durchschnittliche Körpermasse und jeweils $2$ und $2$ Kg darüber und darunter. Das führt dann insgesamt zu dieser Kombination von Prädiktorvariablen (siehe @tbl-mlm-inter-handball-xpred).

```{r}
#| label: tbl-mlm-inter-handball-xpred
#| tbl-cap: "Alle Kombinationen von Prädiktorvariablen."
  
expand.grid(as = c(-10,0,10), bm = c(-2,0,2)) |> 
  knitr::kable(booktabs = T,
               col.names = c('Armspannweite','Körpermasse'))
```

Berechnen wir jetzt die vorhergesagten Wert $\hat{y}_i$ für die beiden Modelle (siehe @fig-mlm-inter-simple).

```{r}
#| label: fig-mlm-inter-simple
#| fig-height: 5
#| layout-ncol: 2
#| fig-cap: "Vergleich der Modellvorhersagen für Modell 2 und Modell 3."
#| fig-subcap:
#|   - "Vorhersage unter Modell 2"
#|   - "Vorhersage unter Modell 3"

hb_new <- tibble::tibble(
  arm_span_c = rep(c(-10,0,10),3),
  body_mass_c = rep(c(-2,0,2), each=3),
  bm_f = factor(body_mass_c)
)
hb_new_1 <- hb_new |> 
  dplyr::mutate(vel = predict(mod_2, newdata = hb_new))
ggplot(hb_new_1, aes(arm_span_c, vel, group=bm_f)) +
  geom_point() +
  geom_line(aes(linetype=bm_f)) +
  scale_linetype_discrete("Level von\nbody mass\ncentered", guide = guide_legend(reverse=T)) +
  scale_x_continuous("Armspannweite zentriert[cm]", breaks = c(-10,0,10)) +
  labs(y = 'Ballgeschwindigkeit[m/s]') +
  ncol_text

hb_new_2 <- hb_new |>  dplyr::mutate(vel = predict(mod_3, newdata = hb_new))
p_inter_1 <- ggplot(hb_new_2, aes(arm_span_c, vel, group=bm_f)) +
  geom_point() +
  geom_line(aes(linetype=bm_f)) +
  scale_linetype_discrete("Level von\nbody mass\ncentered",
                          guide = guide_legend(reverse=T)) +
  scale_x_continuous("Armspannweite zentriert[cm]", breaks = c(-10,0,10)) +
  labs(y = 'Ballgeschwindigkeit[m/s]') 
print(p_inter_1 + ncol_text)
```

In @fig-mlm-inter-simple-1 sehen wir, dass die vorhergesagten Werte $\hat{y}_i$ für verschiedene Körpermassen jeweils nur parallel verschoben sind. Da die Unterschiede zwischen den Körpermassen sich um jeweils $2$ Kg unterscheiden sind für einen gegebenen Wert der Armspannweite die Abstände zwischen den Linien konstant um den Faktor $\beta_{\text{body mass}} \times 2$. D.h. egal welchen Wert die Armspannweite einnimmt, der Zusammenhang der Körpermasse mit der Wurfgeschwindigkeit bleibt gleich. Diese Zusammenhänge zwischen einer Prädiktorvariable und der abhängigen Variable während die andere Variable konstant gehalten wird, werden als einfache Steigungen bezeichnet.

Dagegen sehen die einfachen Steigung anders unter Modell 3 aus (siehe @fig-mlm-inter-simple-2). Hier können wir sehen, dass die Unterschiede zwischen den verschiedenen Armspannweiten davon abhängen wie schwer ein Handballer ist. Während bei kleinen Armspannweiten die Unterschiede eher gering sind, werden die Unterschiede zwischen den Gewichtskategorien umso größer je größer die Armspannweite wird. Es handelt sich um einen Interkationseffekt. Wir sehen weiter, dass bei einer Armspannweite von $-5$ cm es sogar zum schneiden der einfachen Steigungen kommt und entsprechend die Anordnung der Wurfweiten in Abhängigkeit von der Körpermasse sich umkehrt.

Ein Interaktionseffekt ist dabei symmetrisch und hängt nicht davon ab, welche Variable als $x$-Variable in dem Graphen verwendet wird. In @fig-mlm-inter-simple-02 sind beide Möglichkeiten einmal nebeneinander dargestellt.

```{r}
#| label: fig-mlm-inter-simple-02
#| fig-height: 5
#| layout-ncol: 2
#| fig-cap: "Vergleich der Modellvorhersagen für Modell 2 und Modell 3."
#| fig-subcap:
#|   - "Vorhersage unter Modell 3 mit Körpermasse auf der $x$-Achse"
#|   - "Vorhersage unter Modell 3 mit Armspannweite auf der $x$-Achse"


hb_new_3 <- tibble::tibble(
  arm_span_c = rep(seq(-10,10,by=5), each=2),
  body_mass_c = rep(c(-.5,.5), 5),
  arm_f = factor(arm_span_c)
)
hb_new_3 <- hb_new_3 |> 
  dplyr::mutate(vel = predict(mod_3, newdata = hb_new_3))
p_inter_2 <- ggplot(hb_new_3, aes(body_mass_c, vel, group=arm_f)) +
  geom_point() +
  geom_line(aes(linetype=arm_f)) +
  scale_linetype_discrete("Level von\narm span\ncentered",
                          guide = guide_legend(reverse=T)) +
  scale_x_continuous("Bodymass zentriert[kg]", breaks = c(-.5,0,.5)) +
  labs(y = 'Ballgeschwindigkeit[m/s]') +
  theme(text = element_text(size=12))
print(p_inter_2 + ncol_text)

print(p_inter_1 + ncol_text)
```

In beiden Fällen beobachten wir den Interaktionseffekt, wobei sich die einfachen Steigungen auf Grund der unterschiedlichen Varianz der Variablen unterscheidet bzw. von deren Einheiten abhängt.

## Koeffizienten im Interaktionsmodell verstehen

Als nächstes Versuchen wir zu verstehen warum die Multiplikation im Model Sinn macht und was die Koeffizienten in @tbl-mlm-inter-handball-mod3 bedeuten. In @fig-mlm-inter-mod3-coefs-1 sind noch einmal die Steigungen für die Körpermasse in Abhängigkeit von der Armspannweite abgebildet. 

```{r}
#| label: fig-mlm-inter-mod3-coefs-1
#| fig-cap: "Einfache Steigungen für die Körpermasse"

hb_new_3 |> filter(arm_span_c %in% c(-10,0,10)) |>  
ggplot(aes(body_mass_c, vel, group=arm_f)) +
  geom_point() +
  geom_vline(xintercept = 0, color = 'green', linetype = 'dashed') +
  geom_line(aes(linetype=arm_f)) +
  scale_linetype_discrete("Level von\narm span\ncentered",
                          guide = guide_legend(reverse=T)) +
  scale_x_continuous("Bodymass zentriert[kg]", breaks = c(-.5,0,.5)) +
  labs(y = 'Ballgeschwindigkeit[m/s]') +
  theme(text = element_text(size=12))
```

Nochmal, wir sehen anhand des Graphen, dass der Zusammenhang zwischen der Wurfgeschwindigkeit und der Körpermasse von der Armspannweite abhängt. In @tbl-mlm-inter-mod3-coefs-1 sind die dazugehörenden Steigungskoeffizienten für die einfachen Steigungen abgebildet. $\beta_0$ ist der $y$-Achsenabschnitt für die jeweiligen Armspannweiten und $\beta_1$ die jeweiligen Steigungen. 

```{r}
#| label: tbl-mlm-inter-mod3-coefs-1
#| layout-ncol: 2
#| tbl-cap: "Einfache Steigungen und Modellkoeffizienten"
#| tbl-subcap:
#|   - "Steigungskoeffizienten für die einfachen Steigungen."
#|   - "Modellkoeffizienten unter Modell 3" 

tbl_simple <- hb_new_3 |>
  dplyr::filter(arm_span_c %in% c(10,0,-10)) |> 
  dplyr::group_by(arm_span_c) |>
  dplyr::summarize(b_0 = coef(lm(vel ~ body_mass_c))[1],
            b_1 = coef(lm(vel ~ body_mass_c))[2],
            arm_f = arm_f[1]) |> 
  dplyr::select(-1) |> dplyr::relocate(arm_f) |> 
  dplyr::arrange(dplyr::desc(arm_f)) |> 
  knitr::kable(booktabs = T,
               col.names = c('Armspannweite (zentriert)',
                             '$\\beta_0$','$\\beta_1$'),
               digits = 3, escape = F)
tbl_simple

mod_3_cs <- coef(mod_3) 
names(mod_3_cs) <- c('b0','bm_c','as_c','bm_c:as_c')
knitr::kable(mod_3_cs, booktabs = T, col.names = 'betas',
             digits = 3, caption='Modellkoeffizienten', escape=T)
```

Fangen wir erst einmal einfach an und setzten die Körpermasse auf $bm = 0$. D.h. in @fig-mlm-inter-mod3-coefs-1 bewegen wir uns auf der grünen Linie. Wenn ein Handballer auch eine durchschnittliche Armspannweite hat, also $as = 0$ dann wird eine Wurfgeschwindigkeit von $v = 21.346$ vorhergesagt. D.h. $bm = 0$ und $as = 0$ also genau der $y$-Achsenabschnitt in Modell 3. Nehmen wir jetzt einen Handballer mit durschnittlicher Körpermasse aber einer Armspannweite von $+10$ cm also $cm = 10$ dann gehen wir in @fig-mlm-inter-mod3-coefs-1 entlang der grünen Linie nach oben. In Modellkoeffizienten gesprochen bedeutet dies:

\begin{align*}
\hat{y} &= 21.346 + 0.119 \cdot 0 + 0.083 \cdot 10 + 0.021 \cdot 0 \cdot 10 \\
&= 21.346 + 0.83 = 22.175
\end{align*}

Das ist bis auf ein paar Rundungsfehler der Steigungskoeffizient in @tbl-mlm-inter-mod3-coefs-1-1 unter $\beta_0$ und Armspannweite $=10$. Das gleiche Wenn wir die Armspannweite um $10$ cm verkürzen.

\begin{align*}
\hat{y} &= 21.346 + 0.119 \cdot 0 + 0.083 \cdot -10 + 0.021 \cdot 0 \cdot 10 \\
&= 21.346 - 0.83 = 20.516
\end{align*}

Schauen wir uns nun die Steigungskoeffizienten in @tbl-mlm-inter-mod3-coefs-1-1 an. Wenn wir einen Handballer mit einer Armspannweite von $as = 0$ nehmen, dann haben wir direkt den Koeffizienten in @tbl-mlm-inter-mod3-coefs-1-2. Die Wurfgeschwindigkeit verändert sich somit mit der Körpermasse über den Koeffizienten $\beta_{\text{bm_c}} = 0.119. Denn eingesetzt in die Modellgleichung erhalten wir:

\begin{align*}
\hat{y} &= 21.346 + 0.119 \cdot bm_c + 0.083 \cdot 0 + 0.021 \cdot bm_c \cdot 0 \\
&= 21.346 + 0.119 \cdot b_mc
\end{align*}

Was passiert nun, wenn beide Prädiktorvariablen $as\neq 0$ und $bm\neq 0$ sind. Sei zum Beispiel $as = 10$. Wie verändert sich der vorhergesagte Wert $\hat{y}_i$ mit der Körpermasse $bm_c$. Wir lassen $bm_c$ jetzt offen als Variable um die Steigungsgleichung zu bestimmen. Wieder eingesetzt in das Modell ergibt dies:

\begin{align*}
\hat{y} &= 21.346 + 0.119 \cdot bm_c + 0.083 \cdot 10 + 0.021 \cdot bm_c \cdot 10 \\
&= 21.346 + 0.83 + 0.119 \cdot bm_c + 0.21 \cdot bm_c \\
&= 22.175 + (0.119 + 0.21) \cdot bm_c \\
&= 22.175 + 0.329 \cdot bm_c
\end{align*}

D.h. wir erhalten, bis auf ein paar Rundungsfehler, die Steigungskoeffizienten der Geradengleichung in @tbl-mlm-inter-mod3-coefs-1-1.

::: {#exr-interaction-coeffs}
Versuche anhand der Koeffizienten in @tbl-mlm-inter-mod3-coefs-1-2 die einfache Steigungsgleichung für $as_c = -10$ zu erhalten.
::: 

### Zusammenfassung

Zusammenfassend lässt sich die folgende Interpretation der Koeffizienten in einem Interaktionsmodell formulieren.

\begin{equation*}
Y = b_0 + b_1 \cdot x_1 + b_2 \cdot x_2 + b_3 \cdot x_1 \cdot x_2 + \epsilon_i
\end{equation*}

- $b_0$: (y-Achsenabschnitt) der Wert von $\hat{Y}$ wenn $x_1 = 0$ und $x_2 = 0$ gilt.
- $b_1$: Der Unterschied in $\hat{Y}$ wenn zwei Objekte sich in $x_1$ um eine Einheit unterscheiden und $x_2 = 0$ ist.
- $b_2$: Der Unterschied in $\hat{Y}$ wenn zwei Objekte sich in $x_2$ um eine Einheit unterscheiden und $x_1 = 0$ ist.
- $b_3$: (Interaktionskoeffizient) Die Veränderung des Effekts von $x_1$ auf $\hat{Y}$ wenn $x_2$ um eine Einheit größer wird bzw. genau andersherum für $x_2$.


## Vergleich additives Modell mit dem Interaktionsmodell

Schauen wir nun noch einmal an, wie sich die gefitteten Flächen der beiden Modell voneinander unterscheiden. In @fig-mlm-inter-resid-plane sind die gefitten Flächen und die Residuen unter den beiden Modell abgebildet.

```{r}
#| label: fig-mlm-inter-resid-plane
#| fig-height: 5
#| layout-ncol: 2
#| fig-cap: "Vergleich der gefitteten Ebenen in den beiden Modellen." 
#| fig-subcap:
#|   - "3D Streudiagramm des Interaktionsmodells und gefittet Ebene unter Model 1"
#|   - "3D Streudiagramm des Interaktionsmodells und gefittet Fläche unter Model 2"

par(mar=c(1,1,1,1), cex.axis = 0.5)
# x, y, z variables
x <- handball$body_mass
y <- handball$arm_span
z <- handball$vel
# Compute the linear regression (z = ax + by + d)
fit <- lm(z ~ x + y)
# predict values on regular xy grid
grid.lines = 26
x.pred <- seq(min(x), max(x), length.out = grid.lines)
y.pred <- seq(min(y), max(y), length.out = grid.lines)
xy <- expand.grid( x = x.pred, y = y.pred)
z.pred <- matrix(predict(fit, newdata = xy), 
                 nrow = grid.lines, ncol = grid.lines)
# fitted points for droplines to surface
fitpoints <- predict(fit)
# scatter plot with regression plane
plot3D::scatter3D(x, y, z, col='black', pch=16, cex=1.2,
    theta = 20, phi = 20, ticktype = "detailed",
    xlab = "body mass[kg]", ylab = "arm span[cm]", zlab = "ball velocity[m/s]",  
    surf = list(x = x.pred, y = y.pred, z = z.pred,  
    facets = NA, fit = fitpoints, col='red'), main = "", bty="b2",
    colkey=F, d = 4)


par(mar=c(1,1,1,1), cex.axis = 0.5)
# x, y, z variables
x <- handball$body_mass_c
y <- handball$arm_span_c
z <- handball$vel
# Compute the linear regression (z = ax + by + d)
fit <- lm(z ~ x + y)
# predict values on regular xy grid
grid.lines = 26
x.pred <- seq(min(x), max(x), length.out = grid.lines)
y.pred <- seq(min(y), max(y), length.out = grid.lines)
xy <- expand.grid( body_mass_c = x.pred, arm_span_c = y.pred)
z.pred <- matrix(predict(mod_3, newdata = xy), 
                 nrow = grid.lines, ncol = grid.lines)
# fitted points for droplines to surface
fitpoints <- predict(mod_3)
# scatter plot with regression plane
plot3D::scatter3D(x, y, z, col='black', pch=16, cex=1.2,
    theta = -20, phi = 20, ticktype = "detailed",
    xlab = "body mass[kg]", ylab = "arm span[cm]", zlab = "ball velocity[m/s]",  
    surf = list(x = x.pred, y = y.pred, z = z.pred,  
    facets = NA, fit = fitpoints, col='red'), main = "", bty="b2",
    colkey=F, d = 4)
```

Die gefitte Oberfläche ist jetzt keine Ebene mehr, sondern die Hinzunahme des Interaktionseffekts hat dazu geführt, dass die Oberfläche jetzt eher einem Sattel ähnelt. D.h. durch die Interaktionseffekte können wir deutlich komplizierte Zusammenhänge zwischen den Prädiktorvariablen und der abhängigen Variable modellieren. Die Komplexität erhöht sich entsprechend mit der Zahl der Prädiktorvariablen und den möglichen Interaktion zwischen diesen.

Zurückkommend auf unser Ausgangsbeispiel. Wie hat sich die Hinzunahme des Interaktionseffekts eigentlich auf den Modellfit ausgewirkt. Vergleichen wir die beiden Residuenplots dazu (siehe @fig-mlm-inter-resid-comparison).

```{r}
#| label: fig-mlm-inter-resid-comparison
#| layout-ncol: 2
#| fig-height: 5
#| fig-cap: "Vergleich der Residuen zwischen Modell 2 und Modell 3."
#| fig-subcap:
#|   - "Residuen im additiven Modell"
#|   - "Residuen im Interaktionsmodell"

print(p_resid_2 + ncol_text)
ggplot(handball, aes(y_hat_3, res_3)) +
  geom_point() +
  geom_hline(yintercept = 0, col = 'red', linetype = 'dashed') +
  labs(x = expression(paste('Vorhergesagte Werte ', hat(y)[i])),
       y = expression(paste('Residuen ', hat(e)[i]))) +
  ncol_text
```

Wir sehen in @fig-mlm-inter-resid-comparison-2 das die Struktur, die wir im additiven Modell in @fig-mlm-inter-resid-comparison-1 in den Residuen beobachtet haben, nun nicht mehr vorhanden ist. Ähnlich verhält sich auch der Vergleich für die die qq-Plots der Residuen (siehe @fig-mlm-inter-qq-comparison).

```{r}
#| label: fig-mlm-inter-qq-comparison
#| layout-ncol: 2
#| fig-height: 5
#| fig-cap: "Vergleich der Residuen zwischen Modell 2 und Modell 3."
#| fig-subcap:
#|   - "qq-Plot für das additive Modell"
#|   - "qq-Plot für das Interaktionsmodell"

ggplot(handball, aes(sample = res_2)) +
  geom_qq() +
  stat_qq_line() +
  labs(x = 'Theoretisch', y = 'Empirisch') +
  ncol_text
ggplot(handball, aes(sample = res_3)) +
  geom_qq() +
  stat_qq_line() +
  labs(x = 'Theoretisch', y = 'Empirisch') +
  ncol_text
```

Schauen wir uns noch die verbleibenden Performanceparameter an.

```{r}
#| label: tbl-stats-int-model-performance
#| tbl-cap: "Vergleich der Modellperformance zwischen Model 2 und Model 3"

performance::compare_performance(mod_2, mod_3, metrics = c('R2','R2_adj','RMSE','SIGMA')) |> 
  knitr::kable(booktabs = TRUE, digits = 3)
```


Insgesamt sind durch die Hinzunahme des Interaktionseffekt nicht nur die Standardfehler und der Residualfehler verringert worden, sondern das Modell fittet die Daten auch deutlich besser als das additive Modell. Dies ist natürlich nicht immer der Fall, sondern hängt eng mit den jeweiligen Daten zusammen.

## Take-away

Das Interaktionsmodell:

- Erhöht die Flexibilität des linearen Modells.
- Bei Interaktionen hängt der Einfluss der einzelnen Variablen immer von den Werten der anderen Variablen ab. 
- Achtung: Interpretation der einfachen Haupteffekte oft nicht mehr möglich bzw. sinnvoll!

### Zuschlag^*^

Schauen wir uns noch zum Abschluss noch an, was algebraisch mit dem Koeffizienten im Interaktionsmodell passiert wenn die Prädiktorvariablen $x_{ki}$s zentriert werden.

\begin{align*}
y_i &= \beta_0 + \beta_1 (x_{1i} - \bar{x}_1) + \beta_2 (x_{2i} - \bar{x}_2) + \beta_3 (x_{1i}-\bar{x}_1)(x_{2i}-\bar{x}_2) \\
 &= \beta_0 + \beta_1 x_{1i} - \beta_1 \bar{x}_1 + \beta_2 x_{2i} - \beta_2 \bar{x}_2 + \beta_3 x_{1i} x_{2i} - \beta_3 x_{1i} \bar{x}_2 - \beta_3 \bar{x}_1 x_{2i} + \beta_3 \bar{x}_1 \bar{x}_2 \\ 
 &= \beta_0 - \beta_1 \bar{x}_1 - \beta_2 \bar{x}_2 + \beta_3 \bar{x}_1 \bar{x}_2 + \beta_1 x_{1i}- \beta_3 \bar{x}_2 x_{1i} + \beta_2 x_{2i} - \beta_3 \bar{x}_1 x_{2i} + \beta_3 x_{1i} x_{2i} \\
 &= \underbrace{\beta_0 - \beta_1 \bar{x}_1 - \beta_2 \bar{x}_2 + \beta_3 \bar{x}_1 \bar{x}_2}_{\beta_0} + \underbrace{(\beta_1 - \beta_3 \bar{x}_2) x_{1i}}_{\beta_1 x_{1i}} + \underbrace{(\beta_2 - \beta_3 \bar{x}_1) x_{2i}}_{\beta_2 x_{2i}} + \beta_3 x_{1i} x_{2i} 
\end{align*}

Wir sehen, dass der Interaktionsterm tatsächlich gleich ist unter beiden Modellen. Dagegen unterscheiden sich die Koeffizienten der Haupteffekte deutlich voneinander. Der Übergang vom zentrierten zum unzentrierten Modell ist dabei nicht immer gleich, sondern hängt von den jeweiligen Werten dern Daten ab.

## Zum Nacharbeiten

@kutner2005 [p.306-313]
