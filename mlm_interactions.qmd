# Interaktionseffekte 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```

```{r defs_mult_reg_inter}
lm_coef_ex <- function(mod, max_co=3) round(summary(mod)$coefficients[,1:max_co],2)
n <- 40
set.seed(123)
foo <- MASS::mvrnorm(n, mu = c(184,77),
              Sigma=matrix(c(72,37,37,125),nr=2))
handball <- tibble::tibble(
  arm_span = foo[,1],
  body_mass = foo[,2],
  vel = 1 + 0.12*body_mass + 0.06*arm_span + 0.02*(body_mass-77)*(arm_span-184) + rnorm(n)
)
```

Bisher sind die Variablen in das multiple Regressionsmodell nur *additiv* eingegangen. D.h. in der Modellspezifikation sind die Prädiktorvariablen $x_i$ immer nur mit einem $+$ in die Formel eingegangen. Im folgenden soll nun untersucht werden, was passiert wenn die Prädiktorvariablen auch multiplikativ in das Modell eingehen. Dies führt dann zu sogenannten *Interaktionseffekten*.

## Ein Handballbeispiel

Ausgangspunkt sei ein hypothetischen Datensatz aus dem Handball angelehnt an die Übung. Es sei ein Datensatz mit drei Datenspalten gegeben. Die Variablen sind die Wurfgeschwindigkeit, die Körpermasse und die Armspannweite. Ziel ist es, die Wurfgeschwindigkeit anhand der Körpermasse und der Armspanweite zu modellieren angelehnt an @debanne2011. Zunächst, wie immer, eine Betrachtung der deskriptiven Daten (siehe @tbl-mlm-inter-handball-01).

```{r}
#| label: tbl-mlm-inter-handball-01
#| tbl-cap: "Deskriptive Statistiken der Handballdaten"
#| output: asis

handball |> 
  dplyr::rename(c('Armspannweite[cm]'=arm_span, 'Körpermasse[kg]'=body_mass, 'Wurfgeschwindigkeit[m/s]'=vel)) |> 
  summarytools::descr(
  stats = c('mean','sd','min','max'),
  transpose = T,
  style = 'rmarkdown',
  heading = F) #|>
```

In @tbl-mlm-inter-handball-01 ist zunächst einmal nichts auffallendes zu sehen. Vielleicht sind die Wurfgeschwindigkeiten etwas zu niedrig für Hochleistungshandballer, aber das stört die weitere Analyse der Daten. Als nächstes erfolgt eine Betrachtung der Daten mittels von Streudiagrammen.

```{r}
#| label: fig-mlm-inter-handball-01
#| fig-height: 5
#| layout-ncol: 2
#| fig-cap: "Streudiagramme der Handballdaten."
#| fig-subcap:
#|   - "Geschwindigkeit gegen Körpergewicht"
#|   - "Geschwindigkeit gegen Armspannweite"

ggplot(handball, aes(body_mass, vel)) +
  geom_point(size=3) +
  labs(x = 'Köpergewicht [kg]', y = 'Geschwindigkeit [m/s]') +
  ncol_text

ggplot(handball, aes(arm_span, vel)) +
  geom_point(size=3) +
  labs(x = 'Armspannweite [cm]', y = 'Geschwindigkeit [m/s]') +
  ncol_text
```

In beiden Graphen ist mit etwas gutem Willen ein positiver Zusammenhang zwischen den jeweiligen Prädiktorvariablen und der Wurfgeschwindigkeit zu identifizieren. Für das Körpergewicht in @fig-mlm-inter-handball-01-1 vielleicht etwas mehr als für die Armspannweite in @fig-mlm-inter-handball-01-2.

Nun sollen die Daten mittels eines linearen Modells modelliert werden.

\begin{equation*}
Y_{i} = \beta_0 + \beta_1 \times \textrm{bm}_i + \beta_2 \times \textrm{as}_i + \epsilon_i
\end{equation*}

Mit `lm()` in `R` Code übersetzt:

```{r}
#| echo: true

mod_1 <- lm(vel ~ body_mass + arm_span, handball)
```

Bei Betrachtung der Modellparameter (siehe @tbl-mlm-inter-handball-mod1) ist zu erkennen, dass die Steigungskoeffizienten zwar knapp statistisch signifikant sind, aber in Bezug auf die Residualvarianz bzw. den Standardfehler $\hat{\sigma}$ eine ziemlich hohe Restunsicherheit $\hat{\sigma} = `r sigma(mod_1) |> round(4)`$ aufweisen. Dies macht die Vorhersage letztendlich unbrauchbar.

```{r}
#| label: tbl-mlm-inter-handball-mod1
#| tbl-cap: "Modellfit der Handballdaten aus Model 1"
 
mod_1 |> lm_tbl_knitr(caption = "Modell 1", long = T, add_sigma = T)
```

Der $y$-Achsenabschnitt $\beta_0$ im Modell macht auch ebenfalls keinen Sinn, da er, verbal übersetzt ausdrückt, dass ein Handballer mit einer Spannweite von $0$cm und einer Körpermasse von $0$ Kg eine Wurfgeschwindigkeit von $v = `r round(coef(mod_1)[1],1)`$m/s erreichen würde. Um den $y$-Achsenabschnitt interpretierbar zu machen, ist damit wie schon so oft sinnvoll die Daten zu zentrieren. Dies ändert wieder nichts an dem Modellfit, aber der $y$-Achsenabschnitt bekommt dadurch einen sinnvollen Wert. Wie immer beim Zentrieren, werden von den Prädiktorvariablen die jeweiligen Mittelwert abgezogen. Übersetzt in `R`-Code mittels der Funktion `mutate()`.

```{r}
#| echo: true

handball <- dplyr::mutate(handball,
                          body_mass_c = body_mass - mean(body_mass),
                          arm_span_c = arm_span - mean(arm_span))
```

Nun wird wieder da gleiche Modell angepasst, wobei die zentrierten Variablen als Prädiktorvariablen verwendet werden.

```{r}
#| echo: true

mod_2 <- lm(vel ~ body_mass_c + arm_span_c, handball)
```

Wie erwartet ändert dies nichts an den Modellwerten, bis auf den $y$-Achsenabschnitt. Der Wert von $21.8$ ist jetzt dahingehend zu interpretieren, dass ein Handballer mit einer Armspannweite von $184$cm und einer Körpermasse von $77$Kg eine Wurfgeschwindigkeit von $21.9$m/s erreichen sollte (siehe @tbl-mlm-inter-handball-01 und @tbl-mlm-inter-handball-mod2).

```{r}
#| label: tbl-mlm-inter-handball-mod2
#| tbl-cap: "Modellfit der Handballdaten aus Model 2"

mod_2 |> lm_tbl_knitr(caption = "Modell 2", long = T, add_sigma = T)
```

Nun erfolgt wie immer eine Betrachtung der Residuen $e_i$ im zentrierten, additiven Modell (Model 2) (siehe @fig-mlm-inter-handball-02).

```{r}
#| label: fig-mlm-inter-handball-02
#| fig-cap: "Residuenplot unter Modell 2"

handball <- handball |> 
  dplyr::mutate(res_2 = resid(mod_2),
                y_hat_2 = predict(mod_2))
p_resid_2 <- ggplot(handball, aes(y_hat_2, res_2)) +
  geom_point() +
  geom_hline(yintercept = 0, col = 'red', linetype = 'dashed') +
  labs(x = expression(paste('Vorhergesagte Werte ', hat(y)[i])),
       y = expression(paste('Residuen ', hat(e)[i]))) 
print(p_resid_2)
```

Da die Werte für kleine und große vorhergesagte Werte $\hat{y}_i$ ganz klar ein Muster aufweisen, kann davon ausgegangen werden, das das Modell eine in den Daten vorhandene *Struktur* nicht zu modellieren im Stande ist. Dazu wird nun noch einmal der Einfluss der Prädiktorvariablen auf die Wurfgeschwindigkeit genauer untersucht.

Um den Zusammenhang der beiden Variablen zusammen zu untersuchen werden nun Hilfsvariablen definiert. Dazu wird eine künstliche Unterteilung der Armspannweiten und Körpermassen in drei verschiedene Kategorien vorgenommen. D.h. die Armspannweite wird in kurze, mittlere und lange Spannweiten und die Körpermasse wird in leicht, mittel und schwer unterteilt. 

```{r}
#| label: tbl-mlm-inter-cut
#| tbl-cap: "Ausschnitt der Handballdaten."
hb_quick <- handball |>
  dplyr::mutate(
    as_f = cut_number(arm_span_c, 3, labels=c('kurz','mittel','lang')),
    bm_f = cut_number(body_mass_c, 3, labels=c('leicht','mittel','schwer'))
  ) 
hb_quick |> select(arm_span_c, as_f, body_mass_c, bm_f) |> 
  head() |> 
  knitr::kable(digits=2)
```

In @tbl-mlm-inter-cut ist ein Ausschnitt der Daten zu sehen. Hier sind die beiden neuen Spalten die die kontinuierlichen Variablen Körpermasse und Armspannweite jeweils in eine nominale Variable abbilden abgetragen. Hier ist zu erkennen, dass größere positive Werte jeweils als `lang` bzw. `schwer` kategorisiert werden und entsprechend kleine absolute Wert als `mittel` und kleine negative Werte als `kurz` bzw. `leicht`. Die Geschwindigkeitsdaten können nun in einem Graphen abgebildet werden, bei dem nicht mehr die originalen, kontinuierlichen Daten, sondern nun die beiden nominalen Variablen verwendet werden (siehe @fig-mlm-inter-handball-03).

```{r}
#| label: fig-mlm-inter-handball-03
#| fig-cap: "Mittlere Wurfgeschwindigkeiten ($\\pm$SD) für die Unterteilung nach Körpergewicht und Armspannweite in Kategorien"

hb_quick |>
  dplyr::group_by(as_f, bm_f) |> 
  dplyr::summarize(m = mean(vel), sd = sd(vel)) |> 
  ggplot(aes(as_f, m, color=bm_f, group=bm_f)) +
  geom_pointrange(aes(ymin = m - sd, ymax = m + sd)) +
  geom_line() +
  labs(x = 'Armspannweite', y = 'Geschwindigkeit') 
```

In dem Graphen zeigt sich ein interessantes Muster. Für mittel und schwere Handballer nimmt die Wurfgeschwindigkeit mit der Armspannweite zu. Dagegen ist der Trend gegensätzliche für leichte Handballer. D.h. der Einfluss der Armspannweite hängt davon ab wie schwer der Handballer ist. Der Einfluss ist in der anderen Richtung genauso, der Einfluss der Körpermasse hängt von der Armspannweite ab. Wenn sich die Effekte zweier Prädiktorvariablen gegenseitig beeinflussen, dann wird dies als **Interaktionseffekts** bezeichnet.

### Kontinierlichen zu nominaler Variable in `R`

Um die Unterteilung einer kontinuierlichen Variablen in eine nominale Variable durchzuführen, kann in `R` die `cut_number()`-Funktion aus dem `tidyverse` verwendet werden. Die Parameter der Funktion sind die kontinuierliche Variable und die Anzahl der gewünschten Kategorien. Über den Parameter `labels` können die Bezeichnungen angepasst werden. 

```{r}
#| echo: true
#| eval: false

hb_quick <- handball |>
  dplyr::mutate(
    as_f = cut_number(arm_span_c, 3, labels=c('kurz','mittel','lang')),
    bm_f = cut_number(body_mass_c, 3, labels=c('leicht','mittel','schwer'))
  ) 
```

`cut_number()` unterteilt den Wertebereich der Variablen so, dass die Anzahl der Datenpunkte pro Kategorie ungefähr gleich sind. Eine verwandte Funktion ist `cut_interval()` die die Kategoriengrenzen so bestimmt, dass die Intervall ungefähr gleich groß sind, unabhängig davon wie viele Datenpunkte in den jeweiligen Kategorien sind.

## Interaktion zwischen zwei Effekten

::: {#def-interaction}
## Interaktionseffekt\index{Interaktionseffekt}

Wenn der Effekt einer unabhängigen Variable auf die abhängige Variable davon abhängt welche Ausprägung eine weitere unabhängige Variable hat, dann wird dies als ein Interaktionseffekt bezeichnet.
:::

In Abgrenzung zu Interaktionseffekte werden die *normalen* Effekte als Haupteffekte bezeichnet.

::: {#def-maineffect}
## Haupteffekte \index{Haupteffekt}

Haupteffekte beschreiben den **isolierten Einfluss** einer unabhängigen Variable auf die abhängige Variable, unabhängig von anderen Variablen im Modell.  
:::

Im Rahmen eines linearen Modells, wird ein solcher Interaktionseffekt durch einen *multiplikativen* Term zwischen den beiden Variablen modelliert.

\begin{equation}
Y_{i} = \beta_0 + \beta_1 \times \textrm{bodymass}_i + \beta_2 \times \textrm{armspan}_i + \beta_3 \times \textrm{bodymass}_i \times \textrm{armspan}_i + \epsilon_i
\label{mlm-inter-model-ex}
\end{equation}

In der Formel \eqref{mlm-inter-model-ex} ist neben den beiden Mdeollkoeffizienten $\beta_1$ und $\beta_2$ jetzt ein weitere Koeffizienten $\beta_3$ der den Interaktionseffekt abbildet. Die $X$-Werte die diesem Modellkoeffizienten zugeordnet sind, berechnen sich aus Produkt aus den beiden beteiligten Prädiktorvariablen. In dem vorliegenden Handballbeispiel aus dem Produkt aus Armspannweite und Körpergewicht `body_mass` $\times$ `arm_span`. Dies ist der Interaktionseffekt.

Warum die Multiplikation zwischen den Prädiktorvariablen sinnvoll ist, wird etwas später genauer betrachtet. 

### Interaktionseffekte in `lm()`

In `R` wird ein Interaktionseffekt in der Formel mittels eines `:` spezifiziert.

```{r}
#| echo: true
mod_3 <- lm(vel ~ body_mass_c + arm_span_c + body_mass_c:arm_span_c, handball) 
```

Um sich etwas Tipparbeit zu sparen, kann auch die Kurzform `*` benutzet werden. Hier multipliziert `R` die beiden beteiligten Variablen selbst *aus*.

```{r}
#| echo: true

mod_3 <- lm(vel ~ body_mass_c * arm_span_c, handball) 
```

D.h. die Funktion `lm()` multipliziert Terme der Form `A*B` in `A + B + A:B` aus.

Angewendet auf das Handballbeispiel folgt daraus die folgende Modellanpassung (siehe @tbl-mlm-inter-handball-mod3)

```{r}
#| label: tbl-mlm-inter-handball-mod3
#| tbl-cap: "Modellfit der Handballdaten unter Momdell 3"

handball <- handball |> 
  dplyr::mutate(res_3 = resid(mod_3),
                y_hat_3 = predict(mod_3))
mod_3 |> lm_tbl_knitr(caption = "Modell 3", long = T, add_sigma = T)
```

Bei Betrachtung der Residualvarianz $\hat{\sigma}$ ist zu beobachten, dass sich der halbiert hat. D.h das Interaktionsmodell scheint deutlich präziser den Zusammenhang zwischen den Prädiktorvariablen und der abhängigen Variablen abbilden zu können, als dies bei dem rein additiven Modell der Fall war. Zusätzlich haben sich die Standardfehler der beiden Steigungskoeffizienten für die **Haupteffekte** deutlich verringert (vgl. @tbl-mlm-inter-handball-mod2). Beide Koeffizienten sind nun statistisch signifikant geworden. Der neu dazugekommene Koeffizient für den Interaktionseffekt ist ebenfalls statistisch signifikant mit einem sehr kleinen Standardfehler. D.h die Hinzunahme des Interaktionseffekts hat in dem vorliegenden Beispiel dazu geführt, dass der Modellfit deutlich verbessert wurde. Im nächsten Schritt soll nun die Wirkung des Interaktionseffekt noch einmal deutlicher herausgearbeitet werden.

## Koeffizienten im Interaktionsmodell verstehen

Im weiteren wird genauer betrachtet wie die Modellkoeffizienten und insbesondere der Interaktionseffekt $\beta_3$ interpretiert werden kann. Dazu werden zunächst die Vorhersagen $\hat{y}_i$ unter den beiden Modellen Modell 2, dem additiven Modell, und Modell 3, dem Interaktionsmodell, miteinander verglichen. Zur Erinnerung, beide Modell arbeiten mit zentrierten Prädiktorvariablen.

Um einen besseren Überblick über die Vorhersagen zu bekommen, ist es hilfreich die Daten zu vereinfachen indem nur drei verschiedene Werte für die Armspannweite $as = \{-10,0,10\}$ cm. D.h. einen hypothetischen Handballer mit der Durchschnittsspannweite, sowie jeweils einen mit $10$ cm kürzerer bzw. $10$ cm längerer Spannweite. Der gleiche Ansatz wird auf für die Körpermasse gewählt, indem hier ebenfalls drei verschiedenen Körpermassen $bm = \{-2,0,2\}$ Kg verwendet werden. D.h. eine Person mit durchschnittlicher Körpermasse und jeweils eine Person mit $-2$ und $2$ Kg leichter bzw. schwerer. Dies führt zu der folgenden Kombination von Prädiktorvariablen (siehe @tbl-mlm-inter-handball-xpred).

```{r}
#| label: tbl-mlm-inter-handball-xpred
#| tbl-cap: "Alle Kombinationen von Prädiktorvariablen."
  
expand.grid(as = c(-10,0,10), bm = c(-2,0,2)) |> 
  knitr::kable(booktabs = T,
               col.names = c('Armspannweite','Körpermasse'))
```

Für diese Daten wird nun die vorhergesagten Wert $\hat{y}_i$ unter beiden Modellen berechnet und graphisch dargestellt (siehe @fig-mlm-inter-simple). Diese Art der Darstellung des Zusammenhangs zwischen **einer** Prädiktorvariable und der abhängigen Variable während weitere Prädiktorvariablen konstant gehalten werden, wird als *einfache Steigungen* bezeichnet.

```{r}
#| label: fig-mlm-inter-simple
#| fig-height: 5
#| layout-ncol: 2
#| fig-cap: "Vergleich der Modellvorhersagen für Modell 2 und Modell 3."
#| fig-subcap:
#|   - "Vorhersage unter Modell 2"
#|   - "Vorhersage unter Modell 3"

hb_new <- tibble::tibble(
  arm_span_c = rep(c(-10,0,10),3),
  body_mass_c = rep(c(-2,0,2), each=3),
  bm_f = factor(body_mass_c)
)
hb_new_1 <- hb_new |> 
  dplyr::mutate(vel = predict(mod_2, newdata = hb_new))
ggplot(hb_new_1, aes(arm_span_c, vel, group=bm_f)) +
  geom_point() +
  geom_line(aes(linetype=bm_f)) +
  scale_linetype_discrete("Level von\nbody mass\ncentered", guide = guide_legend(reverse=T)) +
  scale_x_continuous("Armspannweite zentriert[cm]", breaks = c(-10,0,10)) +
  labs(y = 'Ballgeschwindigkeit[m/s]') +
  ncol_text

hb_new_2 <- hb_new |>  dplyr::mutate(vel = predict(mod_3, newdata = hb_new))
p_inter_1 <- ggplot(hb_new_2, aes(arm_span_c, vel, group=bm_f)) +
  geom_point() +
  geom_line(aes(linetype=bm_f)) +
  scale_linetype_discrete("Level von\nbody mass\ncentered",
                          guide = guide_legend(reverse=T)) +
  scale_x_continuous("Armspannweite zentriert[cm]", breaks = c(-10,0,10)) +
  labs(y = 'Ballgeschwindigkeit[m/s]') 
print(p_inter_1 + ncol_text)
```

In @fig-mlm-inter-simple-1 ist zu sehen, dass die vorhergesagten Werte $\hat{y}_i$ für verschiedene Körpermassen jeweils nur parallel gegeneinander verschoben sind. Da die Unterschiede zwischen den Körpermassen sich um jeweils $2$ Kg unterscheiden, sind für einen gegebenen Wert der Armspannweite die Abstände zwischen den Linien konstant um den Faktor $\beta_{\text{body mass}} \times 2$. D.h. egal welchen Wert die Armspannweite einnimmt, der Zusammenhang der Körpermasse mit der Wurfgeschwindigkeit bleibt gleich. 

Unter Modell 3 fallen die einfachen Steigung dagegen vollkommen anders aus (siehe @fig-mlm-inter-simple-2). Hier kann beobachtet werden, dass die Unterschiede zwischen den verschiedenen Armspannweiten davon abhängen wie schwer ein Handballer ist. Während bei kleinen Armspannweiten die Unterschiede eher gering ausfallen, werden die Unterschiede zwischen den drei gewählten Gewichtskategorien umso größer je größer die Armspannweite wird. Es handelt sich eben um einen Interaktionseffekt. Es ist weiter sehen, dass bei einer Armspannweite von $-5$ cm es sogar zum schneiden der einfachen Steigungen kommt. In diesem Fall führt dies dazu, dass sich die Anordnung der Wurfgeschwindigkeiten in Abhängigkeit von der Körpermasse umkehrt. Während bei Armspannweite von $-10$cm eine leichtere Person die höchste Wurfgeschwindigkeit produziert, ist dies bei einer Armspannweite von $+10$cm ein schwerere Person (in diesem Vergleich immer in Bezug auf die gewählten Wertebereiche).

Generell ist ein Interaktionseffekt dabei immer symmetrisch und hängt nicht davon ab, welche Variable als $X$-Variable in dem Graphen verwendet wird. Wenn die Änderung der einen Variable $A$ davon abhängt welchen Wert die andere Variable $B$ hat, dann gilt dies auch anderes herum für die Veränderung von Variable $B$ in Abhängigkeit vom Wert der Variablen $A$. Um diese *Symmetrie* zu verdeutlichen sind in @fig-mlm-inter-simple-02 beide Möglichkeiten der Darstellung der einfachen Effekte nebeneinander dargestellt.

```{r}
#| label: fig-mlm-inter-simple-02
#| fig-height: 5
#| layout-ncol: 2
#| fig-cap: "Vergleich der Modellvorhersagen für Modell 2 und Modell 3."
#| fig-subcap:
#|   - "Vorhersage unter Modell 3 mit Körpermasse auf der $x$-Achse"
#|   - "Vorhersage unter Modell 3 mit Armspannweite auf der $x$-Achse"


hb_new_3 <- tibble::tibble(
  arm_span_c = rep(seq(-10,10,by=5), each=2),
  body_mass_c = rep(c(-.5,.5), 5),
  arm_f = factor(arm_span_c)
)
hb_new_3 <- hb_new_3 |> 
  dplyr::mutate(vel = predict(mod_3, newdata = hb_new_3))
p_inter_2 <- ggplot(hb_new_3, aes(body_mass_c, vel, group=arm_f)) +
  geom_point() +
  geom_line(aes(linetype=arm_f)) +
  scale_linetype_discrete("Level von\narm span\ncentered",
                          guide = guide_legend(reverse=T)) +
  scale_x_continuous("Bodymass zentriert[kg]", breaks = c(-.5,0,.5)) +
  labs(y = 'Ballgeschwindigkeit[m/s]') 
print(p_inter_2 + ncol_text)

print(p_inter_1 + ncol_text)
```

In beiden Fällen ist ein Interaktionseffekt zu beobachten. Die genau Ausprägung der einfachen Steigungen ist dabei abhängig von Varianzen der Prädiktorvariablen, d.h. wie stark die Werte streuen, bzw. von de gewählten Einheiten.

### Interaktionseffekte deep-dive

Als nächstes Versuchen soll untersucht werden, warum die Multiplikation der an der Interaktion beteiligten Prädiktorvariablen sinnvoll ist um die Interpretation der Koeffizienten in @tbl-mlm-inter-handball-mod3 numerisch besser bedeuten zu können. In @fig-mlm-inter-mod3-coefs-1 sind noch einmal die einfachen Steigungen für die Körpermasse in Abhängigkeit von der Armspannweite dargestellt. 

```{r}
#| label: fig-mlm-inter-mod3-coefs-1
#| fig-cap: "Einfache Steigungen für die Körpermasse"

hb_new_3 |> filter(arm_span_c %in% c(-10,0,10)) |>  
ggplot(aes(body_mass_c, vel, group=arm_f)) +
  geom_point() +
  geom_vline(xintercept = 0, color = 'green', linetype = 'dashed') +
  geom_line(aes(linetype=arm_f)) +
  scale_linetype_discrete("Level von\narm span\ncentered",
                          guide = guide_legend(reverse=T)) +
  scale_x_continuous("Bodymass zentriert[kg]", breaks = c(-.5,0,.5)) +
  labs(y = 'Ballgeschwindigkeit[m/s]') +
  theme(text = element_text(size=12))
```

Wie bereits beschrieben, es ist zu beobachten, dass der Zusammenhang zwischen der Wurfgeschwindigkeit und der Körpermasse von der gewählten Armspannweite abhängt. Um die Bedeutung der Koeffizienten in einen Interaktionsmodell besser zu verstehen, werden nun die einfachen Steiungen für die drei abgebildeten Graphen berechnet. D.h. es wird dreimal eine einfache lineare Regression berechnet. In @tbl-mlm-inter-mod3-coefs-1 sind die dazugehörenden Steigungskoeffizienten für die einfachen Steigungen abgebildet. $\beta_0$ ist der $y$-Achsenabschnitt für die jeweiligen Armspannweiten und $\beta_1$ die jeweiligen Steigungen. 

```{r}
#| label: tbl-mlm-inter-mod3-coefs-1
#| layout-ncol: 2
#| tbl-cap: "Einfache Steigungen und Modellkoeffizienten"
#| tbl-subcap:
#|   - "Steigungskoeffizienten für die einfachen Steigungen."
#|   - "Modellkoeffizienten unter Modell 3" 

tbl_simple <- hb_new_3 |>
  dplyr::filter(arm_span_c %in% c(10,0,-10)) |> 
  dplyr::group_by(arm_span_c) |>
  dplyr::summarize(b_0 = coef(lm(vel ~ body_mass_c))[1],
            b_1 = coef(lm(vel ~ body_mass_c))[2],
            arm_f = arm_f[1]) |> 
  dplyr::select(-1) |> dplyr::relocate(arm_f) |> 
  dplyr::arrange(dplyr::desc(arm_f)) |> 
  knitr::kable(booktabs = T,
               col.names = c('Armspannweite (zentriert)',
                             '$\\beta_0$','$\\beta_1$'),
               digits = 3, escape = F)
tbl_simple

mod_3_cs <- coef(mod_3) 
names(mod_3_cs) <- c('`(Intercept)`','`bm_c`','`as_c`','`bm_c:as_c`')
knitr::kable(mod_3_cs, booktabs = T, col.names = '$\\beta$',
             digits = 3, caption='Modellkoeffizienten', escape=T)
```

Entsprechend den Graphen in @fig-mlm-inter-mod3-coefs-1 ist der Steigungskoeffizient für $\beta_1$ für die Armspannweiten $0$ und $10$ positive, während er bei der Armspannweite $-10$ negativ ist. Ein Vergleich dieser Wert mit denjenigen aus dem Interaktionsmodell in @tbl-mlm-inter-mod3-coefs-1-2 zeigt, dass die Werte unterschiedlich sind. Um nun nachzuvollziehen, dass die Werte in @tbl-mlm-inter-mod3-coefs-1-1 aus denjenigen in @tbl-mlm-inter-mod3-coefs-1-2 resultieren sind ein paar Vereinfachungen notwendig.

Sei zunächst einmal die zentrierte Körpermasse auf $\text{bodymass} = 0$. D.h. in @fig-mlm-inter-mod3-coefs-1 bewegen wir uns entlang der eingezeichneten, grünen Linie. Wenn ein Handballer nun ebenfalls eine durchschnittliche Armspannweite hat, also $\text{armspan} = 0$ dann wird eine Wurfgeschwindigkeit von $v = 21.346$ vorhergesagt. D.h. $\text{bodymass} = 0$ und $\text{armspan} = 0$ also genau der $Y$-Achsenabschnitt in Modell 3. Sei nun ein Handballer mit durschnittlicher Körpermasse aber einer Armspannweite von $+10$ cm also $cm = 10$ gegeben. In @fig-mlm-inter-mod3-coefs-1 würde das einer vertikalen Beweung entlang der grünen Linie nach oben entsprechen. In Modellkoeffizienten gesprochen bedeutet dies:

\begin{align*}
\hat{y} &= 21.346 + 0.119 \cdot 0 + 0.083 \cdot 10 + 0.021 \cdot 0 \cdot 10 \\
&= 21.346 + 0.83 = 22.175
\end{align*}

Der Wert ist, bis auf ein paar Rundungsfehler, dem $Y$-Achsenabschnitt $\beta_0$ in @tbl-mlm-inter-mod3-coefs-1-1 unter Armspannweite $=10$ gleich, $22.175 \approx 22.178$. Das gleiche Prinzip kann ebenfalls angewendet werden, wenn die Armspannweite um $10$cm verkürzt wird. D.h. in @fig-mlm-inter-mod3-coefs-1 entlang der grünen Linie nach unten. In Modellkoeffizienten resultiert dies in:

\begin{align*}
\hat{y} &= 21.346 + 0.119 \cdot 0 + 0.083 \cdot -10 + 0.021 \cdot 0 \cdot 10 \\
&= 21.346 - 0.83 = 20.516
\end{align*}

Dies entspricht wieder, bis auf Rundungsfehler, dem $Y$-Achsenabschnitt in @tbl-mlm-inter-mod3-coefs-1-1 unter dem Eintrag für Armspannweite $-10$ ($20.516 \approx 20.514$).

Sei nun ein Handballer mit einer Armspannweite von $as = 0$ gegeben. Dann können die Koeffizienten in @tbl-mlm-inter-mod3-coefs-1-2 direkt abgelesen werden. Die Wurfgeschwindigkeit verändert sich somit mit der Körpermasse über den Koeffizienten $\beta_{bm_c} = 0.119$. Eingesetzt in die Modellgleichung führt dies zu:

\begin{align*}
\hat{y} &= 21.346 + 0.119 \cdot bm_c + 0.083 \cdot 0 + 0.021 \cdot bm_c \cdot 0 \\
&= 21.346 + 0.119 \cdot bm_c
\end{align*}

Als nächstes wird der Fall betrachtet, wenn beide Prädiktorvariablen $as\neq 0$ und $bm\neq 0$ sind. Sei zum Beispiel $as = 10$. Wie verändert sich der vorhergesagte Wert $\hat{y}_i$ mit der Körpermasse $bm_c$. $bm_c$ bleibt offen um die Steigungsgleichung zu bestimmen. Wieder eingesetzt in das Modell ergibt dies:

\begin{align*}
\hat{y} &= 21.346 + 0.119 \cdot bm_c + 0.083 \cdot 10 + 0.021 \cdot bm_c \cdot 10 \\
&= 21.346 + 0.83 + 0.119 \cdot bm_c + 0.21 \cdot bm_c \\
&= 22.175 + (0.119 + 0.21) \cdot bm_c \\
&= 22.175 + 0.329 \cdot bm_c
\end{align*}

Bis auf ein paar Rundungsfehler, werden die Steigungskoeffizienten der Geradengleichung in @tbl-mlm-inter-mod3-coefs-1-1 für den Eintrag `as = 10` erhalten. 

In Bezug auf die Interpretation der Modellkoeffizienten ergibt sich somit das folgende Bild. Der Modellkoeffizient $\beta_0$ beschreibt den $y$-Achsenabschnitt wenn alle Prädiktorvariablen den Wert $0$ annehmen. Wenn einer der beiden Prädiktorvariablen $0$ ist, dann beschreibt der andere  Modellkoeffizient die Verschiebung des $Y$-Achsenabschnitts der *einfachen* Gerade deren Steigung durch den Modellkoeffizienten beschrieben wird. Wenn beide Prädiktorvariablen $neq 0$ sind, dann kommt erst der Interaktionskoeffizient ins Spiel und führt zu einer Veränderung der einfachen Steigung in Abhängigkeit von der Kombination der Prädiktorvariablen.

::: {#exr-interaction-coeffs}
Versuche anhand der Koeffizienten in @tbl-mlm-inter-mod3-coefs-1-2 die einfache Steigungsgleichung für $as_c = -10$ zu erhalten.
::: 

Zusammenfassend lässt sich die folgende Interpretation der Koeffizienten in einem Interaktionsmodell mit zwei Prädiktorvariablen formulieren.

\begin{equation*}
Y = b_0 + b_1 \cdot x_1 + b_2 \cdot x_2 + b_3 \cdot x_1 \cdot x_2 + \epsilon_i
\end{equation*}

- $b_0$: (y-Achsenabschnitt) der Wert von $\hat{Y}$ wenn $x_1 = 0$ und $x_2 = 0$ gilt.
- $b_1$: Der Unterschied in $\hat{Y}$ wenn zwei Objekte sich in $x_1$ um eine Einheit unterscheiden und $x_2 = 0$ ist (Haupteffekt).
- $b_2$: Der Unterschied in $\hat{Y}$ wenn zwei Objekte sich in $x_2$ um eine Einheit unterscheiden und $x_1 = 0$ ist (Haupteffekt).
- $b_3$: (Interaktionskoeffizient) Die Veränderung des Effekts von $x_1$ auf $\hat{Y}$ wenn $x_2$ um eine Einheit größer wird bzw. genau andersherum für $x_2$.

## Die Form der Modellfläche unter dem additiven und der Interaktionsmodell

Abschließend nun eine Betrachtung der resultierenden Flächen unter additiven und dem Interaktionsmodell. In @fig-mlm-inter-resid-plane sind die gefitteten Flächen und die Residuen unter den beiden Modellen abgebildet.

```{r}
#| label: fig-mlm-inter-resid-plane
#| fig-height: 5
#| layout-ncol: 2
#| fig-cap: "Vergleich der gefitteten Ebenen in den beiden Modellen." 
#| fig-subcap:
#|   - "3D Streudiagramm des Interaktionsmodells und gefittet Ebene unter Model 1"
#|   - "3D Streudiagramm des Interaktionsmodells und gefittet Fläche unter Model 2"

par(mar=c(1,1,1,1), cex.axis = 0.5)
# x, y, z variables
x <- handball$body_mass
y <- handball$arm_span
z <- handball$vel
# Compute the linear regression (z = ax + by + d)
fit <- lm(z ~ x + y)
# predict values on regular xy grid
grid.lines = 26
x.pred <- seq(min(x), max(x), length.out = grid.lines)
y.pred <- seq(min(y), max(y), length.out = grid.lines)
xy <- expand.grid( x = x.pred, y = y.pred)
z.pred <- matrix(predict(fit, newdata = xy), 
                 nrow = grid.lines, ncol = grid.lines)
# fitted points for droplines to surface
fitpoints <- predict(fit)
# scatter plot with regression plane
plot3D::scatter3D(x, y, z, col='black', pch=16, cex=1.2,
    theta = 20, phi = 20, ticktype = "detailed",
    xlab = "body mass[kg]", ylab = "arm span[cm]", zlab = "ball velocity[m/s]",  
    surf = list(x = x.pred, y = y.pred, z = z.pred,  
    facets = NA, fit = fitpoints, col='red'), main = "", bty="b2",
    colkey=F, d = 4)


par(mar=c(1,1,1,1), cex.axis = 0.5)
# x, y, z variables
x <- handball$body_mass_c
y <- handball$arm_span_c
z <- handball$vel
# Compute the linear regression (z = ax + by + d)
fit <- lm(z ~ x + y)
# predict values on regular xy grid
grid.lines = 26
x.pred <- seq(min(x), max(x), length.out = grid.lines)
y.pred <- seq(min(y), max(y), length.out = grid.lines)
xy <- expand.grid( body_mass_c = x.pred, arm_span_c = y.pred)
z.pred <- matrix(predict(mod_3, newdata = xy), 
                 nrow = grid.lines, ncol = grid.lines)
# fitted points for droplines to surface
fitpoints <- predict(mod_3)
# scatter plot with regression plane
plot3D::scatter3D(x, y, z, col='black', pch=16, cex=1.2,
    theta = -20, phi = 20, ticktype = "detailed",
    xlab = "body mass[kg]", ylab = "arm span[cm]", zlab = "ball velocity[m/s]",  
    surf = list(x = x.pred, y = y.pred, z = z.pred,  
    facets = NA, fit = fitpoints, col='red'), main = "", bty="b2",
    colkey=F, d = 4)
```

Unter dem Interaktionsmodell ist die gefittete Fläche keine einfache Ebene mehr, sondern durch die Hinzunahme des Interaktionseffekts ähnelt die Fläche nun eher einem Sattel. D.h. durch die Integration von Interaktionseffekte zwischen den Prädiktorvariablen können deutlich komplizierte Zusammenhänge zwischen den Prädiktorvariablen und der abhängigen Variable modellieren werden. Die Komplexität erhöht sich entsprechend mit der Zahl der Prädiktorvariablen und den möglichen Interaktion zwischen diesen.

Zurückkommend auf unser Ausgangsbeispiel mit den Handballdaten, kann entsprechend die Auswirkung auf den die Modellanpassung analysiert werden. Dazu ein Vergleich der beiden Residuenplots (siehe @fig-mlm-inter-resid-comparison).

```{r}
#| label: fig-mlm-inter-resid-comparison
#| layout-ncol: 2
#| fig-height: 5
#| fig-cap: "Vergleich der Residuen zwischen Modell 2 und Modell 3."
#| fig-subcap:
#|   - "Residuen im additiven Modell"
#|   - "Residuen im Interaktionsmodell"

print(p_resid_2 + ncol_text)
ggplot(handball, aes(y_hat_3, res_3)) +
  geom_point() +
  geom_hline(yintercept = 0, col = 'red', linetype = 'dashed') +
  labs(x = expression(paste('Vorhergesagte Werte ', hat(y)[i])),
       y = expression(paste('Residuen ', hat(e)[i]))) +
  ncol_text
```

Es ist zu beobachten, dass in @fig-mlm-inter-resid-comparison-2 die Struktur, die im additiven Modell in @fig-mlm-inter-resid-comparison-1 für die Residuen , nun nicht mehr vorhanden ist. Ähnlich verhält sich auch der Vergleich für die die qq-Plots der Residuen (siehe @fig-mlm-inter-qq-comparison).

```{r}
#| label: fig-mlm-inter-qq-comparison
#| layout-ncol: 2
#| fig-height: 5
#| fig-cap: "Vergleich der Residuen zwischen Modell 2 und Modell 3."
#| fig-subcap:
#|   - "qq-Plot für das additive Modell"
#|   - "qq-Plot für das Interaktionsmodell"

ggplot(handball, aes(sample = res_2)) +
  geom_qq() +
  stat_qq_line() +
  labs(x = 'Theoretisch', y = 'Empirisch') +
  ncol_text
ggplot(handball, aes(sample = res_3)) +
  geom_qq() +
  stat_qq_line() +
  labs(x = 'Theoretisch', y = 'Empirisch') +
  ncol_text
```

Dazu nun ein Vergleich der weiteren Performanceparameter.

```{r}
#| label: tbl-stats-int-model-performance
#| tbl-cap: "Vergleich der Modellperformance zwischen Model 2 und Model 3"

performance::compare_performance(mod_2, mod_3, metrics = c('R2','R2_adj','RMSE','SIGMA')) |> 
  knitr::kable(booktabs = TRUE, digits = 3)
```

Insgesamt sind durch die Hinzunahme des Interaktionseffekt nicht nur die Standardfehler und der Residualfehler verringert worden, sondern das Modell fittet die Daten auch deutlich besser als das additive Modell. Dies ist natürlich nicht immer der Fall, sondern hängt eng mit den jeweiligen Daten zusammen.

## Modelmatrix in `R` unter dem Interaktionsmodell

Um die Modellmatrix bei Interaktionsmodell sei wieder der einfache Datensatz aus dem letzten Kapitel genommen.

```{r}
#| echo: true

df <- tibble(
  y = c(1,3,2.5,7),
  x_1 = 1:4,
  x_2= c(11,11,14,13) 
)
```

Die Anwendung der Funktion `model.matrix()` mit einem Interaktionsterm zwischen `x_1` und `x_2` führt zu folgender Darstellung.

```{r}
#| echo: true

model.matrix(~x_1 + x_2 + x_1:x_2, df)
```

Es ist zu beobachten, dass eine weitere Spalte für den Interaktionsterm zur Modellmatrize hinzugefügt wurde. Die Werte sind dabei genau das Ergebnis der Multiplikation zwischen den Werten von `x_1` und `x_2`.

Wie oben schon erwähnt führt `~x_1 * x_2` zum gleichem Ergebnis.

```{r}
#| echo: true

model.matrix(~x_1 * x_2, df)
```


## Take-away

Das Interaktionsmodell:

- Erhöht die Flexibilität des linearen Modells.
- Bei Interaktionen hängt der Einfluss der einzelnen Variablen immer von den Werten der anderen Variablen ab. 
- Achtung: Interpretation der einfachen Haupteffekte oft nicht mehr möglich bzw. sinnvoll!

## Einfluss der Zentrierung auf die Koeffizienten im Interaktionsmodell (advanced)

Schauen wir uns noch zum Abschluss noch an, was algebraisch mit dem Koeffizienten im Interaktionsmodell passiert wenn die Prädiktorvariablen $x_{ki}$s zentriert werden.

\begin{align*}
y_i &= \beta_0 + \beta_1 (x_{1i} - \bar{x}_1) + \beta_2 (x_{2i} - \bar{x}_2) + \beta_3 (x_{1i}-\bar{x}_1)(x_{2i}-\bar{x}_2) \\
 &= \beta_0 + \beta_1 x_{1i} - \beta_1 \bar{x}_1 + \beta_2 x_{2i} - \beta_2 \bar{x}_2 + \beta_3 x_{1i} x_{2i} - \beta_3 x_{1i} \bar{x}_2 - \beta_3 \bar{x}_1 x_{2i} + \beta_3 \bar{x}_1 \bar{x}_2 \\ 
 &= \beta_0 - \beta_1 \bar{x}_1 - \beta_2 \bar{x}_2 + \beta_3 \bar{x}_1 \bar{x}_2 + \beta_1 x_{1i}- \beta_3 \bar{x}_2 x_{1i} + \beta_2 x_{2i} - \beta_3 \bar{x}_1 x_{2i} + \beta_3 x_{1i} x_{2i} \\
 &= \underbrace{\beta_0 - \beta_1 \bar{x}_1 - \beta_2 \bar{x}_2 + \beta_3 \bar{x}_1 \bar{x}_2}_{\beta_0} + \underbrace{(\beta_1 - \beta_3 \bar{x}_2) x_{1i}}_{\beta_1 x_{1i}} + \underbrace{(\beta_2 - \beta_3 \bar{x}_1) x_{2i}}_{\beta_2 x_{2i}} + \beta_3 x_{1i} x_{2i} 
\end{align*}

Wir sehen, dass der Interaktionsterm tatsächlich gleich ist unter beiden Modellen. Dagegen unterscheiden sich die Koeffizienten der Haupteffekte deutlich voneinander. Der Übergang vom zentrierten zum unzentrierten Modell ist dabei nicht immer gleich, sondern hängt von den jeweiligen Werten dern Daten ab.

## Zum Nacharbeiten

@kutner2005 [p.306-313]
