# Completely Randomized Block Design 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```

```{r defs_aov_blocking}
#source(filep('/resources/nice_format_helper_fcn.R'))
# Datensatz für t-test
set.seed(123)
n <- 6
df_dep <- tibble::tibble(
  id = rep(paste0('P',1:n), each=2),
  y = rep(sample(runif(n, 10,15)), each=2) +
    rep(c(0,3), n) + rnorm(2*n),
  condition = rep(c('A','B'), n) 
)
# Resting metabolic rate
rmr <- readr::read_delim(
  "subject;protocol;rate\n1;1;7131\n1;2;6846\n1;3;7095\n2;1;8062\n2;2;8573\n2;3;8685\n3;1;6921\n3;2;7287\n3;3;7132\n4;1;7249\n4;2;7554\n4;3;7471\n5;1;9551\n5;2;8866\n5;3;8840\n6;1;7046\n6;2;7681\n6;3;6939\n7;1;7715\n7;2;7535\n7;3;7831\n8;1;9862\n8;2;10087\n8;3;9711\n9;1;7812\n9;2;7708\n9;3;8179\n",
  delim = ';', col_types = 'ddd'
)
rmr <- rmr |> dplyr::mutate(subject = paste0('P',subject),
                             protocol = factor(protocol, levels=1:3,
                                               labels=c('A','B','C')))
```

Nachdem wir CRD and die Verallgemeinerung die CRFD kennengelernt haben um den Einfluss von Variablen auf eine abhängige Variable für die wir uns interessieren zu untersuchen gab uns der Ansatz der ANCOVA eine Möglichkeit Varianz in der abhängigen Variablen mittels einer Kovariaten aus dem Modell rauszurechnen. Der Einfluss der Kovariaten ist für uns dabei per-se nicht von Interesse, sondern wir sehen die Kovariate vor allem als Möglichkeit an um Varianz zu kontrollieren. Diesen Ansatz werden in dem vorliegenden Kapitel weiter ausbauen und uns anschauen wie wir mittels sogenannter Blockfaktoren weitere Varianz aus der abhänigen Variable isolieren können. Dies hilft uns wieder dabei den Einfluss derjenigen unabhängigen Variablen für die wir uns primär interessieren genauer zu schätzen.

Fangen wir mit einem Beispiel an, das zunächst einmal nichts mit sportlicher Leistung zu tun hat. In einem Experiment wollen wir vier verschiedene Backmischung für Brötchen hinsichtlich ihrer Eigenschaften untersuchen. Bezeichnen wir diese Backmischung mit $I, II, III$ und $IV$. Nun haben wir nur einen Ofen zur Verfügung und wir wollen in einem Backgang natürlich so viele Brötchen wie möglich backen. In den Ofen können wir vier Bleche gleichzeitig backen (siehe @fig-ed-crdb-oven). Wie sollten wir die Brötchen auf diese vier Backbleche verteilen? 

```{r}
#| fig-cap: "Untersuchung verschiedener Teigmischungen."
#| label: fig-ed-crdb-oven

include_graphics('pics/oven.png')
```

Wir könnten mit einer einfachen Randomisierung anfangen. Wir nummerieren die Plätze auf allen Backblechen der Reihe nach durch und weisen die Teigmischungen zufällig den Platznummern zu. Nun, da wir alle ständig Backsendungen schauen, wissen wir, dass die Höhe der Blechs im Ofen einen Einfluss auf die Temperatur hat. Darauf folgt, dass alle Brötchen die auf einem Blech angeordnet sind, alle wenn nicht der Gleiche dann doch einer sehr ähnliche Temperatur ausgesetzt sind. Dabei werden die Temperaturvariationen innerhalb eines Bleches geringer als zwischen den Blechen sein. Wenn nun der Fall eintritt, dass alle Brötchen der Teigmischung $I$ auf dem tiefsten Blech sind, alle Brötchen $II$ auf dem Zweitniedrigsten uns so weiter, dann bekommen wir ein Problem. Wenn wir Unterschiede zwischen den Backmischungen finden dann können wir nicht ausschließen das die Unterschiede auf die Bleche anstatt die Backmischungen zurück zu führen sind. Der Effekt des Blechs und der Effekt der Backmischung sind miteinander konfundiert (engl. confounder \index{confounder}). Letztendlich hat das Problem dadurch eine ähnliche Struktur wie wir das in der ANCOVA kennengelernt haben. Wir sind nicht an den Unterschieden zwischen den Blechen interessiert und wollen für deren Einfluss kontrollieren. Wie könnten wir in diesem Fall vorgehen? Eine direkte Möglichkeit ist, dass wir jeweils die gleich Anzahl an Backmischungen jedem Blech zuweisen. Danach weisen wir die Position der Backmischungen auf dem Blech dann wieder randomisiert. Die Bleche werden unter dieser Perspektive als Blöcke bezeichnet. Durch die nachfolgende Randomisierung erklärt sich auch der Begriff completely randomized block design (CRBD). 

::: {#def-ed-crbd-block}
## Blöcke \index{Block}

In einem statistischen Design, wir als ein Block eine Gruppe von experimentellen Einheiten bezeichnet, die sich hinsichtlich bestimmter Merkmale ähneln. Diese Merkmale können äußere Einflüsse sein, die die Ergebnisse des Experiments beeinflussen könnten.
:::

Das Ziel des Blockens ist es also, Einflussfaktoren, die nicht von Interesse sind, zu kontrollieren und so ähnlich wie bei der ANCOVA die Genauigkeit und Präzision des Experiments zu erhöhen. Durch das Blocken werden die Einheiten innerhalb eines Blocks homogenisiert, während Unterschiede zwischen den Blöcken kontrolliert und gemessen werden können. So können Blockeffekte isoliert und statistisch berücksichtigt werden. Zusammengefasst können wir die Varianz in der abhängigen Variable $\sigma_{Y}^2$ somit in vier verschiedene Komponenten unterteilen:

1. Systematische Varianz auf Grund des Treatments
2. Varianz auf Grund von **Kovariaten**
3. Varianz auf Grund von **Blockeffekten**
4. Unsystematische oder Residualvarianz $\epsilon$ 

Umformuliert als Pseudogleichung erhalten wir:

\begin{equation*}
\sigma_{Y}^2 = \sigma_{\text{Effekt(e)}}^2 + \sigma_{\text{Kovariate}}^2 + \sigma_{\text{Block}}^2 + \sigma_{\epsilon}^2
\end{equation*}


Tatsächlich ist das Konzept eines Blockfaktors nichts Neues sondern das haben wir wahrscheinlich schon im Zusammenhang mit dem abhängigen t-Test kennengelernt. Schauen wir uns ein hypothetisches Beispiel mit $N = 6$ Personen an, die wir unter zwei Konditionen $A$ und $B$ beobachtet haben. Der Datensatz ist in @fig-ed-crbd-ttest abgebildet.

```{r}
#| fig-cap: "Hypothetisches Experiment mit zwei Konditionen und $n = 6$"
#| label: fig-ed-crbd-ttest

ggplot(df_dep, aes(condition,y,group=id)) +
  geom_point(size=4) +
  geom_line(size=1.3) +
  labs(x = 'Kondition', y = 'Messwert') +
  geom_label(data = df_dep |> dplyr::filter(condition == 'A'),
              aes(label = id), alpha = 0.8, nudge_x = -0.2, size = 2) +
  scale_y_continuous(breaks=NULL, limits=c(5,20)) 
```

Standardmäßig würden wir dieses Design mit einem abhängigen t-Test analysieren. In `R` könnte das zu folgendem Code führen (Daten in `df_dep`).

```{r}
#| echo: true

mod_ttest <- t.test(y ~ condition, data = df_dep, paired=T)
mod_ttest
```

Wir sehen, dass wir ein statistisch signifikantes Ergebnis für den Unterschied zwischen den beiden Konditionen erhalten haben. Konzeptionell können wir die Personen als Blöcke ansehen. Wir betrachten jede Person unter beiden Konditionen. Dabei gehen wir davon aus, dass es Unterschiede zwischen den Personen gibt, die uns aber gar nicht interessieren. Dadurch das wir beide Konditionen in den gleichen Personen beobachten, können wir diese Unterschied raus nehmen und können den Effekt der Konditionen isolieren. Hätten wir unterschiedliche Personen für die beiden Gruppen genommen, dann hätten wir zu dem potentiellen Unterschieden zwischen den Personen auch noch die Unterschiede zwischen den Personen. Dadurch, dass wir eine Blockstruktur nehmen sind wir also wieder in der Lage Varianzkomponenten zu isolieren.

Schauen wir uns als nächstes an, ob wir den abhängigen t-Test auch in die Form eines linearen Modells bekommen. Wenn wir parallel zum Ansatz in der ANCOVA vorgehen, dann sehen wir Unterschiede zwischen den Personen als Störvariable respektive Kovariate an. D.h. wir möchten die Unterschiede zwischen den Personen modellieren. Eine direkte Möglichkeit ist daher die Personen `id` als eine nominale Variable zu identifizieren und Dummy-Variablen für die Personen in das Modell zu integrieren. Als `lm`-Modell formuliert erhalten wir den folgenden Code:

```{r}
#| echo: true

mod_lm <- lm(y ~id + condition, df_dep)
summary(mod_lm)$coefficients
```

Wir sehen, dass `P1` als Referenzstufe modelliert wurde und die $\beta$s für die `id` jeweils die Abweichung der Personen von `P1` darstellen. Als letzten Koeffizienten haben wir den Effekt der Kondition, bzw. den Unterschied zwischen von Kondition $B$ zu Kondition $A$. Wenn wir die Werte mit denjenigen im abhängigen t-Test vergleichen, dann sehen das exakt die gleichen Werte geschätzt wurden. Lediglich das Vorzeichen ist anders herum auf Grund der Wahl von `R` für die Referenzstufe. Schauen wir uns die Konfidenzintervalle für die $\beta$s an.

```{r}
#| echo: true

confint(mod_lm)
```

Wieder erhalten wir exakt die gleichen Werte für den für uns relevanten Effekt der Kondition. Insgesamt sehen wir, dass wir wieder ein zunächst als getrennt behandeltes Verfahren, der abhängige t-Test, in das allgemeine lineare Modell integriert werden kann. Weiterhin kann der Ansatz Varianz in der abhängigen Variable mit Hilfe von Blockeffekten zu erklären auf direkte und uns schon bekannte Art und Weise in das Modell integriert werden. Wir gewinnen dadurch wiederum Flexibilität bei der Erstellung und Analyse von Experimenten. Letztendlich können wir, wie auch bei der ANCOVA, durch die geschickte Wahl von Blöcken, die Power unseres Untersuchungsdesigns erhöhen.

## Varianten von Blockdesigns

| B = Anzahl der Blöcke 
| M = Anzahl der Messungen in einem Block (block size) 
| K = Anzahl der Treatments 
| n = Anzahl der Repetitionen

- Randomized complete block design (RCBD) $M = K$
- General complete block design (GCBD) $M = n \times K$
- Incomplete block design (IBD) $M < K$

### Layout 

::: {#col-panel layout-ncol=3}
+------+----+----+----+
|B     | A1 | A2 | A3 |
+======+:==:+:==:+:==:+
| I    | X  | X  | X  |
+------+----+----+----+
| II   | X  | X  | X  |
+------+----+----+----+
| III  | X  | X  | X  |
+------+----+----+----+

: CRBD

+------+----+----+-----+
|B     | A1 | A2 | A3  |
+======+:==:+:==:+:===:+
| I    | XX | XX | XX  |
+------+----+----+-----+
| II   | XX | XX | XX  |
+------+----+----+-----+
| III  | XX | XX | XX  |
+------+----+----+-----+

: GCBD

+------+----+----+----+
|B     | A1 | A2 | A3 |
+======+:==:+:==:+:==:+
| I    | X  | X  |    |
+------+----+----+----+
| II   | X  |    | X  |
+------+----+----+----+
| III  |    | X  | X  |
+------+----+----+----+

: IBD

:::


Modell mit einem Blockfaktor $\theta$

$$
Y_{hi} = \mu + \theta_h + \tau_i + \epsilon_{hi}
$$

| $\mu$ = Gesamtmittelwert
| $\theta_h$ = Blockeffekt der $h$-ten Stufe, $h = 1, \ldots, B$
| $\tau_i$ = Faktoreffekt der $i$-ten Stufe, $i = 1, \ldots, K$
| $e_{hi} \sim \mathcal{N}(0,\sigma^2)$, paarweise unabhängig

Statistisches Modell

Full model
$$
Y_{hi} = \mu + \theta_h + \tau_i + \epsilon_{hi}
$$

Reduced models
\begin{align*}
Y_{hi} &= \mu + \epsilon_{hi} \\
Y_{hi} &= \mu + \theta_h + \epsilon_{hi}
\end{align*}

Hypothesen
\begin{align*}
H_0 &: \tau_1 = \tau_2 = \ldots = \tau_v = 0 \\
H_1 &: \tau_i \neq \tau_j, i \neq j
\end{align*}

$F$-Tabelle

| Term | $df$ | $SS$ | $MS$ | Test |
| --- | ----- | ----- | --- | -- |
| Block | $B-1$ | $ss\theta$| $\frac{ss\theta}{B-1}$ | - |
| Treatment | $K-1$ | $ssT$| $\frac{ssT}{K-1}$ | $\frac{msT}{msE}$ |
| Error | $KB-B-K+1$ | $ssE$ | $\frac{ssE}{KB-B-K+1}$ |
| Total | $KB-1$ | $sstot$|  |  |

: Varianzanalyse beim CRBD

| $ss\theta = K\sum_h \bar{y}_{h.}^2-KB\bar{y}_{..}^2$ 
| $ssT = B\sum_i \bar{y}_{.i}^2-KB\bar{y}_{..}^2$
| $ssE = sstot - ssB - ssT$
| $sstot = \sum_h\sum_i y_{hi}^2-KB\bar{y}_{..}^2$ 
 
::: {#exm-ed-crbd-rmr}
Beispiel - Resting metabolic rate experiment (@dean1999)

```{r}
#| tbl-cap: "Beispieldaten aus Dean et al. (1999) zum Ruheumsatz wenn Patienten im Krankenhaus geschlafen und gefrühstückt haben (A), zu Hause gegessen haben und im Krankenhaus gefrühstückt haben (B) oder beides zu Hause gemacht haben (C)."

rmr |> pivot_wider(id_cols = subject, values_from = rate, names_from =protocol) |> 
  knitr::kable(booktabs = T, linesep='')
```

| A = in house meal and sleep
| B = in house meal and sleep out
| C = meal and sleep out


```{r}
#| fig-cap: "Boxplot der Ruheumsatzdaten"
#| label: fig-ed-crbd-rmr

rmr_m <- rmr |> group_by(protocol) |> summarize(rate = mean(rate)) |> 
  mutate(subject = 'P10')
ggplot(rmr, aes(protocol, rate)) + 
  geom_point() +
  geom_point(data = rmr_m,
             color = 'red', size = 4) +
  geom_line(data = rmr_m, aes(group = subject), color = 'red', linewidth=2) +
  geom_line(aes(group = subject)) +
  labs(x = 'Protocol', y = 'RMR') 
```
:::

## Analyse eines RCBD in `R`

mit `lm()`

```{r}
#| echo: true

mod_full <- lm(rate ~ subject + protocol, rmr)
mod_reduced <- lm(rate ~ subject, rmr)
anova(mod_reduced,mod_full)
```

RCBD in `R`  mit `aov()`

```{r}
#| echo: true

mod_aov_1 <- aov(rate ~ subject + protocol, data = rmr)
summary(mod_aov_1)
```


RCBD in `R`  mit `aov()` und `Error()`

```{r}
#| echo: true

mod_aov_2 <- aov(rate ~ protocol + Error(subject), data = rmr)
summary(mod_aov_2)
```

### Modell mit Interaktionen

$$
Y_{hi} = \mu + \theta_h + \tau_i + (\theta\tau)_{hi} + \epsilon_{hi}
$$

```{r}
#| echo: true

mod_2 <- lm(rate ~ subject*protocol, data = rmr)
anova(mod_2)
```

## Effektstärken $\omega^2$ und $f$ beim CRBD

\begin{align*}
\omega^2 &= \frac{df_{\mathrm{effect}} \times (MS_{\mathrm{effect}} - MS_{\mathrm{error}})}{SS_{\mathrm{total}} + MS_{\mathrm{subjects}}} \\
f^2 &=\frac{\omega^2}{1-\omega^2}
\end{align*}

\begin{table}[]
\centering
\caption{Einordnung}
\begin{tabular}{lll}
\toprule
 & $f$ & $\omega^2$ \\
\midrule
 klein & 0.1 & 0.01  \\
 mittel & 0.25 & 0.06 \\
 groß & 0.40 & 0.14 \\
\bottomrule
\end{tabular}
\end{table}

### $\omega^2$ im Beispiel


```{r}
omega_sqr = 2 * (17947 - 77218) / (2889683 + 17974 + 77218 + 2889683)
```

$$
\omega^2 = \frac{2 \times (17974 - 77219)}{\underbrace{23117462 + 35949 + 1235483}_{SS_{\mathrm{total}}} + 2889683} = `r round(omega_sqr,2)` \approx 0
$$

Effektstärke CRBD in `R`

### General complete block design GCBD

```{r}
include_graphics('pics/golf_driver_1.jpg')
```

```{r}
#| tbl-cap: "adaptiert nach (Lawson, 2014, S. 140)"
data('rcb', package='daewr')
golf <- rcb |> mutate(id = paste0('G',id),
                      teehgt = factor(teehgt, levels=1:3,
                                      labels = c('low','normal','high'))) |> 
  as_tibble()
with(golf, table(id, teehgt))[-c(7:9),] |> kable(booktabs = T)
```

### Model

\begin{equation}
y_{hij} = \mu + \theta_{h} + \tau_i + (\theta\tau)_{hi} + \epsilon_{hij}
\end{equation}

Abfolge der Abschlaghöhen ist randomisiert innerhalb eines Golfers (Blocks)

| B = 9 Golfer 
| M = 5 Repetitions (block size) 
| K = 3 different factor levels

### Analyse GCBD in `R`

```{r}
#| echo: true

mod_gcbd <- aov(cdistance ~ teehgt + Error(id/teehgt), golf)
summary(mod_gcbd)
```

### Mehrfachvergleiche in CRBD

Allgemein Kontraste

\begin{equation}
\hat{\psi} = \sum_{i=1}^Kc_i \hat{\tau_i} = \sum_{i=1}^K \bar{Y}_{.i}
\end{equation}

und Standardfehler 

\begin{equation*}
s_{\psi} = MSE\sum_{i=1}^K c_i^2/B
\end{equation*}


Kritische Werte $w$
\begin{align*}
w_{\text{Bonferroni}} &= t_{KV-B-K+1,\alpha/(2m)} \\
w_{\text{Scheffé}} &= \sqrt{(K-1)F_{K-1,KB-B-K+1,\alpha}} \\
w_{\text{Tukey}} &= q_{K,BV-B-V+1,\alpha}/\sqrt{2} \\
\end{align*}

### z.B. Paarvergleiche Tukey

$$
(\bar{y}_{.i} - \bar{y}_{.j}) \pm w_T \sqrt{MS_{\mathrm{error}}\times2/b}
$$


$w_T = q_{\alpha/\sqrt{2},v, bv-b-v+1}$ = Quantile der Studentized Range Distribution. In `R` mit `qtukey(alpha/sqrt(2), v, b*v-b-b+1)`.

## Mehrfachvergleiche in `R`

\small
```{r}
#| echo: true
#| eval: false

y_bars <- emmeans::emmeans(mod_aov_1, ~protocol)
pairs(y_bars, infer=T)
```
```{r}
y_bars <- emmeans::emmeans(mod_aov_1, ~protocol)
pairs(y_bars, infer=c(T,T)) %>% as_tibble() %>% 
  knitr::kable(booktabs = T, digits=2,
               caption="Post-hoc Ergebnisse") %>% 
  kableExtra::footnote(general="Tukey adjusted at $\\\\alpha=0.95$",
                       escape=F)
```


## Bestimung der Anzahl der Blöcke a-priori 

Direkt über den $F$-Test per trial-and-error

Nichtzentralitätsparameter $\lambda$
\begin{equation*}
\lambda = \frac{B}{\sigma^2}\sum_{i=1}^K \tau_i^2
\end{equation*}

| $\text{df}_1 = K - 1$
| $\text{df}_2 = (B-1)(K-1)$
| $\alpha$

### Beispiel RMR
```{r}
K <- 3
alpha <- 0.05
css <- 35949
MSE <- 77217.7
rmr_pow <- tibble(
  B = seq(20,24,1),
  df_1 = K - 1,
  df_2 = (B-1)*(K-1),
  lambda = B/MSE*css,
  q_H0 = qf(1-alpha, df_1, df_2),
  p_H1 = 1-pf(q_H0, df_1, df_2, lambda)
)
```

| $\hat{\sigma}^2 = `r round(MSE,2)`$
| $\sum_{i=1}^K \tau_i^2 = `r round(css, 2)`$
| $df_1 = K-1 = 3$
| $df_2 = (B-1)(K-1)$ 

```{r}
#| tbl-cap: "Powertabelle"

rmr_pow |> kable(booktabs=T, digits=2, linesep='',
                 col.names=c('B','$df_1$','$df_2$','$\\lambda$',
                             '$q_{H_0}$', 'power'),
                 escape=F)
```

## Balanced incomplete block design (IBD)

:::: {.columns}
::: {.column}
| $K$ = Anzahl der Faktorstufen
| $B$ = Anzahl der Blöcke
| $k$ = Größe der Blöcke 
| $r$ = Anzahl der Replikationen

Beim IBD $k < K$.
:::
::: {.column}
+------+----+----+----+
|B     | A1 | A2 | A3 |
+======+:==:+:==:+:==:+
| I    | X  | X  |    |
+------+----+----+----+
| II   | X  |    | X  |
+------+----+----+----+
| III  |    | X  | X  |
+------+----+----+----+

: IBD
:::
::::

### Beispiel incomplete block design mit $B=8,k=3,K=8,r=3$

```{r}
#| label: bibd_01
#| tbl-cap: "Beispiel IBD" 

de_1 <- tibble(
  Block = as.character(as.roman(1:8)),
  s_1 = 1:8,
  s_2 = c(3:8,1:2),
  s_3 = c(8,1:7)
)
de_1 |> knitr::kable(
  booktabs = TRUE,
  col.names = c('Block', '', '', ''),
  linesep = '',
  label = 'bibd_01',
)
```

### Welche Paarvergleiche können geschätzt werden?

:::: {.columns}
::: {.column}
\begin{figure}
    \centering
    \begin{tikzpicture}
        \tikzstyle{every node} = [circle, fill=gray!30]
        \node (a) at (0, 0) {1};
        \node (b) at (1, 1) {2};
        \node (c) at (2, 0) {3};
        \node (d) at (0,-1) {6};
        \node (e) at (1,-2) {5};
        \node (f) at (2,-1) {4};
        \foreach \from/\to in {a/b, b/c, c/a, d/e, e/f, f/d}
            \draw (\from) -- (\to);
    \end{tikzpicture}
    \caption{Disconnected design}
    \label{fig:network_01}
\end{figure}
:::
::: {.column}
\begin{figure}
    \centering
    \begin{tikzpicture}
        \tikzstyle{every node} = [circle, fill=gray!30]
        \node (a) at (0, 0) {1};
        \node (b) at (1, 1) {2};
        \node (c) at (2, 0) {3};
        \node (d) at (0,-1) {6};
        \node (e) at (1,-2) {5};
        \node (f) at (2,-1) {4};
        \foreach \from/\to in {a/b, b/c, c/a, d/e, e/f, f/d,
        a/d, a/e, e/f, b/d, b/e, b/f, c/d, c/e, c/f}
            \draw (\from) -- (\to);
    \end{tikzpicture}
    \caption{Connected design}
    \label{fig:network_02}
\end{figure}
:::
::::

### Balanced incomplete block design (BIBD)

\begin{align*}
B &\geq K \\
Kr &= Bk \\
\lambda(K-1) &= r(k-1)
\end{align*}

^[$\lambda$ =  Anzahl der paarweisen Vergleiche der Stufen. Für alle gleich!]

- Alle paarweisen Vergleiche haben den gleichen Standardfehler
- Power für die Detektion von Paarunterschieden ist für alle Paare gleich

### Design erstellen mittels Optimierung

```{r}
#| echo: true
K <- 6
B <- 8 
k <- 3
bib_des <- AlgDesign::optBlock(~.,
                               withinData = factor(1:K),
                               blocksize = rep(k,B))
```

Alternativen: `ibd`, `agricolae`


```{r}
#| tbl-cap: "Beispiel IBD, $K=6,B=8,k=3$"

des_02 <- t(table(bib_des$rows, rep(1:B,each=3)))
row.names(des_02) <- as.character(as.roman(1:B))
des_02 |> knitr::kable(
  booktabs = TRUE,
  col.names = LETTERS[1:K],
  linesep=''
)
```

Modell

\begin{gather*}
Y_{hi} = \mu + \theta_h + \tau_i + \epsilon_{hi} \\
\epsilon_{hi} \sim \mathcal{N}(0,\sigma^2) \\
h = i, \ldots, b; i = 1,\ldots,t; (h,i) \text{ in the design}
\end{gather*}

Achtung - Treatmentmittelwerte sind biased

\begin{equation*}
E[\tau_i - \tau_j] \neq \bar{Y}_{.i} - \bar{Y}_{.j}
\end{equation*}

```{r}
#| tbl-cap: "Beispiel der Vermischung von Block- und Treatmenteffekten, $\\Delta_{B-A}=2, \\Delta_{C-A}=3, \\Delta_{D-A}=5$"

foo <- function(x) mean(x, na.rm=T)
mat <- addmargins(matrix(
  c(25,27,NA,NA,
    10,NA,13,NA,
    NA,35,36,NA,
    NA,NA,10,12),byrow=T, nrow=4, ncol=4
),1:2, foo, quiet=T) 
rownames(mat) <- c(as.character(as.roman(1:4)),"$\\bar{Y}_{.i}$")
knitr::kable(mat,
  booktabs=T,
  col.names=c(LETTERS[1:4],"$\\bar{Y}_{h.}$"),
  linesep="",
  digits=1,
  escape=F
)
```

### Beispiel IBD-Daten

```{r}
#| tbl-cap: "Taste Experiment adaptiert nach Lawson (2015) von Moskowitz (1988). Werte sind scores zum Geschmack verschiedener Rezepte."

taste <- readr::read_delim("id;recipe;score\n1;A;5\n2;A;7\n3;A;5\n4;B;6\n5;B;6\n6;C;8\n7;A;6\n8;A;5\n9;A;4\n10;B;7\n11;B;6\n12;C;7\n1;B;5\n2;C;6\n3;D;4\n4;C;7\n5;D;4\n6;D;6\n7;B;7\n8;C;8\n9;D;5\n10;C;7\n11;D;5\n12;D;4\n", delim=';')
taste <- taste |> dplyr::mutate(id = factor(id))

taste |> tidyr::pivot_wider(id, names_from=recipe, values_from=score) |> 
  knitr::kable(
    booktabs=T,
    col.names=c("Person", "A", "B", "C", "D"),
    linesep = ''
  )
```

Beispiel - Modellfit mit `lm()`

```{r}
#| echo: true
#| eval: false

mod <- lm(score ~ id + recipe, data = taste)
anova(mod) 
```
```{r}
#| tbl-cap: "ANOVA der Geschmacksdaten" 
mod <- lm(score ~ id + recipe, data = taste)
anova(mod) |> broom::tidy() |> 
  knitr::kable(
    booktabs = TRUE,
    linesep = '',
    col.names = c('Term', 'df', 'SSQ', 'MSQ', 'F-Wert', 'p-Wert'),
    digits = 3,
  )
```

Beispiel - Mehrfachvergleiche 

\tiny
```{r, echo=T}
emmeans::emmeans(mod, pairwise ~ recipe)
```

## Feste versus zufällige Effekte

## Zum Nachlesen

@pos_blocking
