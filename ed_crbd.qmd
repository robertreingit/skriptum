# Block Design 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```

```{r defs_aov_blocking}
#source(filep('/resources/nice_format_helper_fcn.R'))
# Datensatz für t-test
set.seed(123)
n <- 6
df_dep <- tibble::tibble(
  id = rep(paste0('P',1:n), each=2),
  y = rep(sample(runif(n, 10,15)), each=2) +
    rep(c(0,3), n) + rnorm(2*n),
  condition = rep(c('A','B'), n) 
)
# Resting metabolic rate
rmr <- readr::read_delim(
  "subject;protocol;rate\n1;1;7131\n1;2;6846\n1;3;7095\n2;1;8062\n2;2;8573\n2;3;8685\n3;1;6921\n3;2;7287\n3;3;7132\n4;1;7249\n4;2;7554\n4;3;7471\n5;1;9551\n5;2;8866\n5;3;8840\n6;1;7046\n6;2;7681\n6;3;6939\n7;1;7715\n7;2;7535\n7;3;7831\n8;1;9862\n8;2;10087\n8;3;9711\n9;1;7812\n9;2;7708\n9;3;8179\n",
  delim = ';', col_types = 'ddd'
)
rmr <- rmr |> dplyr::mutate(subject = paste0('P',subject),
                             protocol = factor(protocol, levels=1:3,
                                               labels=c('A','B','C')))
```

Nachdem wir CRD and die Verallgemeinerung die CRFD kennengelernt haben um den Einfluss von Variablen auf eine abhängige Variable für die wir uns interessieren zu untersuchen gab uns der Ansatz der ANCOVA eine Möglichkeit Varianz in der abhängigen Variablen mittels einer Kovariaten aus dem Modell rauszurechnen. Der Einfluss der Kovariaten ist für uns dabei per-se nicht von Interesse, sondern wir sehen die Kovariate vor allem als Möglichkeit an um Varianz zu kontrollieren. Diesen Ansatz werden in dem vorliegenden Kapitel weiter ausbauen und uns anschauen wie wir mittels sogenannter Blockfaktoren weitere Varianz aus der abhänigen Variable isolieren können. Dies hilft uns wieder dabei den Einfluss derjenigen unabhängigen Variablen für die wir uns primär interessieren genauer zu schätzen.

Fangen wir mit einem Beispiel an, das zunächst einmal nichts mit sportlicher Leistung zu tun hat. In einem Experiment wollen wir vier verschiedene Backmischung für Brötchen hinsichtlich ihrer Eigenschaften untersuchen. Bezeichnen wir diese Backmischung mit $I, II, III$ und $IV$. Nun haben wir nur einen Ofen zur Verfügung und wir wollen in einem Backgang natürlich so viele Brötchen wie möglich backen. In den Ofen können wir vier Bleche gleichzeitig backen (siehe @fig-ed-crdb-oven). Wie sollten wir die Brötchen auf diese vier Backbleche verteilen? 

```{r}
#| fig-cap: "Untersuchung verschiedener Teigmischungen."
#| label: fig-ed-crdb-oven
#| fig-height: 2 

include_graphics('pics/oven.png')
```

Wir könnten mit einer einfachen Randomisierung anfangen. Wir nummerieren die Plätze auf allen Backblechen der Reihe nach durch und weisen die Teigmischungen zufällig den Platznummern zu. Nun, da wir alle ständig Backsendungen schauen, wissen wir, dass die Höhe der Blechs im Ofen einen Einfluss auf die Temperatur hat. Darauf folgt, dass alle Brötchen die auf einem Blech angeordnet sind, alle wenn nicht der Gleiche dann doch einer sehr ähnliche Temperatur ausgesetzt sind. Dabei werden die Temperaturvariationen innerhalb eines Bleches geringer als zwischen den Blechen sein. Wenn nun der Fall eintritt, dass alle Brötchen der Teigmischung $I$ auf dem tiefsten Blech sind, alle Brötchen $II$ auf dem Zweitniedrigsten uns so weiter, dann bekommen wir ein Problem. Wenn wir Unterschiede zwischen den Backmischungen finden dann können wir nicht ausschließen das die Unterschiede auf die Bleche anstatt die Backmischungen zurück zu führen sind. Der Effekt des Blechs und der Effekt der Backmischung sind miteinander konfundiert (engl. confounder \index{confounder}). Letztendlich hat das Problem dadurch eine ähnliche Struktur wie wir das in der ANCOVA kennengelernt haben. Wir sind nicht an den Unterschieden zwischen den Blechen interessiert und wollen für deren Einfluss kontrollieren. Wie könnten wir in diesem Fall vorgehen? Eine direkte Möglichkeit ist, dass wir jeweils die gleich Anzahl an Backmischungen jedem Blech zuweisen. Danach weisen wir die Position der Backmischungen auf dem Blech dann wieder randomisiert. Die Bleche werden unter dieser Perspektive als Blöcke bezeichnet. Durch die nachfolgende Randomisierung erklärt sich auch der Begriff completely randomized block design (CRBD). 

::: {#def-ed-crbd-block}
## Blockdesign \index{Blockdesign}

In einem statistischen Design, wir als ein Block eine Gruppe von experimentellen Einheiten bezeichnet, die sich hinsichtlich bestimmter Merkmale ähneln. Diese Merkmale können äußere Einflüsse sein, die die Ergebnisse des Experiments beeinflussen könnten.
:::

Das Ziel des Blockens ist es also, Einflussfaktoren, die nicht von Interesse sind, zu kontrollieren und so ähnlich wie bei der ANCOVA die Genauigkeit und Präzision des Experiments zu erhöhen. Durch das Blocken werden die Einheiten innerhalb eines Blocks homogenisiert, während Unterschiede zwischen den Blöcken kontrolliert und gemessen werden können. So können Blockeffekte isoliert und statistisch berücksichtigt werden. Zusammengefasst können wir die Varianz in der abhängigen Variable $\sigma_{Y}^2$ somit in vier verschiedene Komponenten unterteilen:

1. Systematische Varianz auf Grund des Treatments
2. Varianz auf Grund von **Kovariaten**
3. Varianz auf Grund von **Blockeffekten**
4. Unsystematische oder Residualvarianz $\epsilon$ 

Umformuliert als Pseudogleichung erhalten wir:

\begin{equation*}
\sigma_{Y}^2 = \sigma_{\text{Effekt(e)}}^2 + \sigma_{\text{Kovariate}}^2 + \sigma_{\text{Block}}^2 + \sigma_{\epsilon}^2
\end{equation*}

## Der abhängige t-Test als Blockdesign

Tatsächlich ist das Konzept eines Blockfaktors nichts Neues sondern wir haben Prinzip wahrscheinlich schon früher einmal im Zusammenhang mit dem abhängigen t-Test kennengelernt. Schauen wir uns ein hypothetisches Beispiel mit $N = 6$ Personen an, die wir unter zwei Konditionen $A$ und $B$ beobachtet haben. Der Datensatz ist in @fig-ed-crbd-ttest abgebildet.

```{r}
#| fig-cap: "Hypothetisches Experiment mit zwei Konditionen und $n = 6$"
#| label: fig-ed-crbd-ttest

ggplot(df_dep, aes(condition,y,group=id)) +
  geom_point(size=4) +
  geom_line(size=1.3) +
  labs(x = 'Kondition', y = 'Messwert') +
  geom_label(data = df_dep |> dplyr::filter(condition == 'A'),
              aes(label = id), alpha = 0.8, nudge_x = -0.2, size = 2) +
  scale_y_continuous(breaks=NULL, limits=c(5,20)) 
```

Standardmäßig würden wir dieses Design mit einem abhängigen t-Test analysieren. In `R` würde dies beispielsweise zu folgendem Code führen (Daten in `df_dep`).

```{r}
#| echo: true

mod_ttest <- t.test(y ~ condition, data = df_dep, paired=T)
mod_ttest
```

Wir sehen, dass wir ein statistisch signifikantes Ergebnis für den Unterschied zwischen den beiden Konditionen erhalten haben. Konzeptionell können wir die Personen als Blöcke ansehen. Wir betrachten jede Person unter beiden Konditionen. Dabei gehen wir davon aus, dass es Unterschiede zwischen den Personen gibt, die uns aber nicht wirklich interessieren. Dadurch das wir beide Konditionen in den gleichen Personen beobachten, können wir diese Unterschiede von dem Effekt der Konditionen isolieren. Hätten wir unterschiedliche Personen für die beiden Gruppen genommen, dann hätten wir zu dem potentiellen Unterschieden zwischen den Konditionen auch noch die Unterschiede zwischen den Personen. Dadurch, dass wir eine Blockstruktur nehmen sind wir also wieder in der Lage Varianzkomponenten zu isolieren.

Schauen wir uns als nächstes an, ob wir den abhängigen t-Test auch in die Form eines linearen Modells bekommen. Wenn wir parallel zum Ansatz in der ANCOVA vorgehen, dann sehen wir Unterschiede zwischen den Personen als Störvariable respektive Kovariate an. D.h. wir möchten die Unterschiede zwischen den Personen modellieren. Eine direkte Möglichkeit ist daher die Personen `id` als eine nominale Variable zu identifizieren und Dummy-Variablen für die Personen in das Modell zu integrieren. Als `lm`-Modell formuliert erhalten wir den folgenden Code:

```{r}
#| echo: true

mod_lm <- lm(y ~id + condition, df_dep)
summary(mod_lm)$coefficients
```

Wir sehen, dass `P1` als Referenzstufe modelliert wurde und die $\beta$s für die `id` jeweils die Abweichung der Personen von `P1` darstellen. Als letzten Koeffizienten haben wir den Effekt der Kondition, bzw. den Unterschied zwischen von Kondition $B$ zu Kondition $A$. Wenn wir die Werte mit denjenigen im abhängigen t-Test vergleichen, dann sehen das exakt die gleichen Werte geschätzt wurden. Lediglich das Vorzeichen ist anders herum auf Grund der Wahl von `R` für die Referenzstufe. Schauen wir uns die Konfidenzintervalle für die $\beta$s an.

```{r}
#| echo: true

confint(mod_lm)
```

Wieder erhalten wir exakt die gleichen Werte für den für uns relevanten Effekt der Kondition. Insgesamt sehen wir, dass wir wieder ein zunächst als getrennt behandeltes Verfahren, der abhängige t-Test, in das allgemeine lineare Modell integriert werden kann. Weiterhin kann der Ansatz Varianz in der abhängigen Variable mit Hilfe von Blockeffekten zu erklären auf direkte und uns schon bekannte Art und Weise in das Modell integriert werden. Wir gewinnen dadurch wiederum Flexibilität bei der Erstellung und Analyse von Experimenten. Letztendlich können wir, wie auch bei der ANCOVA, durch die geschickte Wahl von Blöcken, die Power unseres Untersuchungsdesigns erhöhen.

Bezogen auf die Designstruktur stellen die einzelnen Personen die EUs. Die Randomisierung findet in diesem Fall auf der Ebene der Blöcke statt. Innerhalb jeder Person wir die Abfolge der Konditionen randomisiert.

## Varianten von Blockdesigns

Im Rahmen des Skripts unterscheiden wir drei grundsätzliche Designs. Führen wir aber zunächst einmal erst wieder etwas Terminologie ein:

| B = Anzahl der Blöcke 
| M = Anzahl der Messungen in einem Block (block size) 
| K = Anzahl der Treatments 
| n = Anzahl der Repetitionen

Ausgehend auf dem Verhältnis von der Anzahl der Messungen in einem Block $M$ und der Anzahl der Treatments $K$ ergeben sich unter anderem die folgenden drei Blockdesigns (siehe @tbl-ed-crbd-overview}:

- Randomized complete block design (RCBD) $M = K$ 
- General complete block design (GCBD) $M = n \times K$ \index{General complete block design}
- Incomplete block design (IBD) $M < K$ \index{Incomplete block design}

### Layout 

::: {#tbl-ed-crbd-overview layout-ncol=3}
+------+----+----+----+
|B     | A1 | A2 | A3 |
+======+:==:+:==:+:==:+
| I    | X  | X  | X  |
+------+----+----+----+
| II   | X  | X  | X  |
+------+----+----+----+
| III  | X  | X  | X  |
+------+----+----+----+

: CRBD {#tbl-ed-crbd-crbd}

+------+----+----+-----+
|B     | A1 | A2 | A3  |
+======+:==:+:==:+:===:+
| I    | XX | XX | XX  |
+------+----+----+-----+
| II   | XX | XX | XX  |
+------+----+----+-----+
| III  | XX | XX | XX  |
+------+----+----+-----+

: GCBD {#tbl-ed-crbd-gcbd}

+------+----+----+----+
|B     | A1 | A2 | A3 |
+======+:==:+:==:+:==:+
| I    | X  | X  |    |
+------+----+----+----+
| II   | X  |    | X  |
+------+----+----+----+
| III  |    | X  | X  |
+------+----+----+----+

: IBD {#tbl-ed-crbd-ibd}

Übersicht über verschiedene Blockdesigns (X: Beobachtung)
:::

Die Unterschiede zwischen den drei Designs beziehen sich hauptsächlich darauf wie oft das Treatment mit dem Block gekreuzt ist. Im CRBD haben wir pro Block jede Treatmentkondition genau einmal, während beim GCBD jede Treatmentkondition mehrmals pro Block beobachtet wird. Im Gegensatz dazu werden beim IBD nicht alle Treatmentkondition in jedem Block beobachtet.

Beginnen wir mit einem CRBD.

## Completely Randomized Block Design

Beim Completely Randomized Block Design \index{Blockdesign!Randomized complete block design} wird jede Treatmentkondition genau einmal pro Block beobachtet. D.h. die Anzahl der Messungen pro Block $M$ sind gleich der Anzahl der Treatmentkonditionen $K$. Da die Blöcke vom Prinzip her genauso wie andere nominale Faktoren zu behandeln sind, entspricht das dazugehörige Modell einer zweifaktoriellen CRFD ohne Interaktionseffekte. Entsprechend erhalten wir ein Modell mit einem Blockfaktor $\theta_h$ mit $h = 1,2,\ldots,M$ und einem Effekt $\alpha_i, i=1,2,\ldots,K$ für die $K$ Treatmentkonditionen. Das entsprechende Modell können wir folgt formulieren (siehe Formel \eqref{eq-ed-crbd-crbd}):

\begin{equation}
Y_{hi} = \mu + \theta_h + \tau_i + \epsilon_{hi}
\label{eq-ed-crbd-crbd}
\end{equation}

| $\mu$ = Gesamtmittelwert
| $\theta_h$ = Blockeffekt der $h$-ten Stufe, $h = 1, \ldots, B$
| $\tau_i$ = Faktoreffekt der $i$-ten Stufe, $i = 1, \ldots, K$
| $e_{hi} \sim \mathcal{N}(0,\sigma^2)$, paarweise unabhängig

Da wir nur eine Kombination von Treatmentfaktor und Blockfaktor haben, können wir keine Interaktionseffekte zwischen $\theta$ und $\alpha_i$ bestimmen, da diese mit den Residualfaktoren konfundiert sind. Daraus folgt, wir mit unserem Modellvergleichansatz das volle Modell mit beiden Faktoren mit einem reduzierten Modell mit nur den Blockfaktoren vergleichen, bzw. wenn es gewollt ist den Blockeffekt zu überprüfen entsprechend ein weiteres reduziertes Modell mit nur einen $y$-Achsenabschnitt.

\begin{align*}
Y_{hi} &= \mu + \theta_h + \tau_i + \epsilon_{hi} & \text{full} \\
Y_{hi} &= \mu + \theta_h + \epsilon_{hi} & \text{reduced 1} \\
Y_{hi} &= \mu + \epsilon_{hi}  & \text{reduced 2}
\end{align*}


Dementsprechend bezieht sich die Haupthypothese auf den Effekt des Treatmentfaktors.

\begin{align*}
H_0 &: \tau_1 = \tau_2 = \ldots = \tau_v = 0 \\
H_1 &: \tau_i \neq \tau_j, i \neq j
\end{align*}

Wie immer können die Ergebnisse auch mittels einer ANOVA-Tabelle dokumentiert werden (siehe @tbl-ed-crbd-crbd}.

$F$-Tabelle

| Term | $df$ | $SS$ | $MS$ | Test |
| --- | ----- | ----- | --- | -- |
| Block | $B-1$ | $ss\theta$| $\frac{ss\theta}{B-1}$ | - |
| Treatment | $K-1$ | $ssT$| $\frac{ssT}{K-1}$ | $\frac{msT}{msE}$ |
| Error | $KB-B-K+1$ | $ssE$ | $\frac{ssE}{KB-B-K+1}$ |
| Total | $KB-1$ | $sstot$|  |  |

: Varianzanalyse beim CRBD {#tbl-ed-crbd-crbd}

| $ss\theta = K\sum_h \bar{y}_{h.}^2-KB\bar{y}_{..}^2$ 
| $ssT = B\sum_i \bar{y}_{.i}^2-KB\bar{y}_{..}^2$
| $ssE = sstot - ssB - ssT$
| $sstot = \sum_h\sum_i y_{hi}^2-KB\bar{y}_{..}^2$ 

Schauen wir uns dazu ein Beispiel @dean1999 an.
 
::: {#exm-ed-crbd-rmr}
Bei $N = 9$ Patienten wurde der Ruheumsatz am Morgen in Abhängigkeit von drei verschiedenen Konditionen untersucht. Unter Kondition $A$ haben die Patienten im Krankhaus übernachtet und gefrühstückt, unter Kondition $B$ zu Hause geschlafen und im Krankenhaus gefrühstückt und unter Kondition $C$ beides zu Hause durchgeführt. Die Reihenfolge der Konditionen wurde zwischen den Patienten randomisiert. In @fig-ed-crbd-rmr sind die Rohdaten abgebildet.

```{r}
#| fig-cap: "Liniendiagramm der Ruheumsatzdaten am Morgen. A: Im Krankenhaus geschlafen und gefrühstück, B: zu Hause geschlafen und im Krankenhaus gefrühstückt, C: beides zu Hause durchgeführt. (rot: Mittelwert)"
#| label: fig-ed-crbd-rmr

rmr_m <- rmr |> group_by(protocol) |> summarize(rate = mean(rate)) |> 
  mutate(subject = 'P10')
ggplot(rmr, aes(protocol, rate)) + 
  geom_point() +
  geom_point(data = rmr_m,
             color = 'red', size = 4) +
  geom_line(data = rmr_m, aes(group = subject), color = 'red', linewidth=2) +
  geom_line(aes(group = subject)) +
  labs(x = 'Protocol', y = 'RMR') 
```
In @fig-ed-crbd-rmr ist kein klarer Trend zu erkennen, was bei $N=9$ auch nicht weiter verwunderlich ist. Dargestellt als ANOVA-Tabelle ergibt sich das folgende Ergebnis.

```{r}
lm(rate ~ subject + protocol, rmr) |> 
  anova() |> 
  broom::tidy() |> 
  kable(
    booktabs=TRUE,
    col.names=c("Term","df","SS","MS","F","p-value"),
    digits = 3)
```
D.h. wir finden keinen Einfluss des Treatments auf den Ruheumsatz basierend auf der vorliegenden Stichprobe.
:::

### CRBD in `R`

Wir haben verschiedene Ansätze um die Analyse durchzuführen. Zunächst mittels Modelverlgeichen mit `lm()`

```{r}
#| echo: true

mod_full <- lm(rate ~ subject + protocol, rmr)
mod_reduced <- lm(rate ~ subject, rmr)
anova(mod_reduced,mod_full)
```

Alternativ können wir auch wieder `aov()` verwenden.

```{r}
#| echo: true

mod_aov_1 <- aov(rate ~ subject + protocol, data = rmr)
summary(mod_aov_1)
```

Als weitere Alternative mit `aov()` und der Zusatzfunktion `Error()`

```{r}
#| echo: true

mod_aov_2 <- aov(rate ~ protocol + Error(subject), data = rmr)
summary(mod_aov_2)
```

Dies führt zu der Unterteilung der Effekte in zwei Strata wie sie bei Repeated Measures ANOVA verwendet werden. Einmal in die Zwischenblockeffekte die allerdings mangels Fehlerterm nicht analysisert werden und die Innerblockeffekte. Die Innerblockeffekte sind gleich dem in SPSS üblichen Ansatz mit Innersubjekteffekten.

### Feste versus zufällige Effekte

Für die weiteren Ausführung bei Blockeffekten müssen wir zunächst ein neues Konzept kennenlernen: den Unterschied zwischen festen und zufälligen Effekten. Wir beschränken uns zunächst auf nominale Faktoren die Verallgemeinerung folgt dann aber auf natürliche Weise. Bei einem festen Effekte sind wir im Rahmen der Untersuchung nur an denen im Experiment verwendeten Faktorstufen interessiert. D.h wir möchten keine  Rückschlüsse über Faktorstufen ziehen die über diejenigen im Experiment verwendeten Stufen hinaus gehen. Dies bedeutet auch, dass bei einer Wiederholung des Experiments die genau gleichen Stufen verwendet werden. Im Gegensatz zu festen Effekten werden die Stufen bei einem zufälligen Effekt als eine Stichprobe aus einer größeren Grundgesamtheit von Faktorstufen angesehen. In diesem Fall sind wir nicht an denen im Experiment konkrete beobachteten Faktorstufen interessiert, sondern wollen einen Rückschluss über die Grundgesamtheit des Faktorstufen ziehen.

In Bezug auf das vorhergehende Beispiel lässt sich unter diesem Aspekt der Blockeffekt der Probanden betrachten. Wollen wir die beobachteten Effekte nur auf die in der Stichprobe vorkommenden Menge von Personen beziehen, dann werden die Blockeffekte (Personen) als feste Effekte interpretiert. Sehen wir dagegen, was in den meisten Fällen zutreffen wird, die Probanden als eine *Stichprobe* aus einer größeren Population von Probanden an, dann stellt der Personeneffekt der Blöcke einen Zufallseffekt dar.

Eine weitere Interpretation von festen Effekten im Gegensatz zufälligen Effekten bezieht sich auf die Präzision der Variable. Kann eine Variable ohne Fehler gemessen werden kann, dann stellt Sie einen festen Effekt dar. Bezogen auf das Beispiel der Probandenstichprobe trifft diese Bedingung allerdings zu, wir können die Identität der Person perfekt bestimmen, trotzdem wird der Personeneffekt üblicherweise als Zufallseffekt interpretiert. Ein weiteres Beispiel könnten die Trainingsintensität bei einem RCT sein. Seien eine Kontrollgruppe und eine Interventionsgruppe gegeben. Die Trainingsintensität zeichnet wir in der Studie als zweimal 30 Minuten pro Woche definiert. Da die Trainingsintensität nur eine einzige Ausprägung hat, ist es nicht möglich auf eine mögliche Population von Trainingsintensität zurück zu schließen. D.h. die Studie kann nicht über die verabreichte Intensität hinaus generalisieren. Daher wird die Intensität als fester Effekt modelliert. Andererseits könnte aber auch eine Population von Trainingsintensitäten angenommen werden und Probanden bekommen randomisiert unterschiedliche Intensitäten verabreicht. Bei einer Wiederholung des Experiments würden dann nicht die gleichen Trainingsintensitäten verabreicht werdend und die Trainingsintensität könnte als Zufallseffekt modelliert werden. Tatsächlich gibt es immer wieder Grenzfälle bei denen nicht eindeutig klar ist, wie ein Effekt modelliert werden soll und beide Ansätze sind möglich bzw. plausibel.

::: {#def-fixed-effects}
### Feste Effekte

Feste Effekte\index{Feste Effekte} (engl. fixed effects \index{fixed effects}) beziehen sich auf Variablen, deren Einflüsse bestimmter bekannter und interessierender Faktoren auf die abhängige Variable modellieren. Die Faktoren stammen aus einer endlichen Menge von möglichen Faktoren und die Effekte sind konstant für alle Beobachtungen. Bei einer Wiederholung des Experiments werden die gleichen Faktoren wiederverwendet und die spezifischen Stufen werden verwendet wiel sie von Interesse für die Studie sind. Feste Effekte erlauben keine Generalisierung über die verwendeten Stufen hinweg.
:::

::: {#def-random-effects}
### Zufallseffekte

Zufallseffekte\index{Zufallseffekte} (engl. random effects\index{random effects}) beziehen sich auf Variablen, deren Einflüsse als zufällig angesehen werden und die aus einer größeren Population von (meistens endlich vielen) möglichen Werten stammen. Die Population ist oft hypothetisch. Zufallseffekte erlauben es, die Variabilität zu modellieren, die durch zufälligen Unterschiede zwischen den Einheiten in der Studie eingeführt wird. Bei einer Wiederholung des Experiments kommen nicht die gleichen Stufen zum Einsatz. Zufallseffekte erlauben eine Generalisierung über die beobachteten Stufen hinaus.
:::

Eine weitere vereinfachte Arbeitsdefinition von [@casella2008,p.99, übersetzt] liest sich:

::: {def-random-fixed-working}
Ein Faktor ist ein fester Faktor, wenn alle interessierenden Faktorstufen im Experiment enthalten sind. Ein Faktor ist ein Zufallsfaktor, wenn nicht alle interessierenden Faktorstufen in den Versuch einbezogen werden und diejenigen, die einbezogen werden, als zufällig aus allen interessierenden Faktorstufen ausgewählt werden.
:::

Durch die Kombination von Modellen können nun verschiedene Arten von Modell identifziert werden: Modelle mit festen Effekten (engl. fixed effects model) \index{fixed effects model}, Modelle mit Zufallseffekten (engl. random effects model) \index{random effects model} und gemischte Modelle mit beiden Effekten (engl. mixed effects model) \index{mixed effects model} [@dean1999].

### Effektstärken $\omega^2$ und $f$ beim CRBD

\begin{align*}
\omega^2 &= \frac{df_{\mathrm{effect}} \times (MS_{\mathrm{effect}} - MS_{\mathrm{error}})}{SS_{\mathrm{total}} + MS_{\mathrm{subjects}}} \\
f^2 &=\frac{\omega^2}{1-\omega^2}
\end{align*}

\begin{table}[]
\centering
\caption{Einordnung}
\begin{tabular}{lll}
\toprule
 & $f$ & $\omega^2$ \\
\midrule
 klein & 0.1 & 0.01  \\
 mittel & 0.25 & 0.06 \\
 groß & 0.40 & 0.14 \\
\bottomrule
\end{tabular}
\end{table}

### $\omega^2$ im Beispiel


```{r}
omega_sqr = 2 * (17947 - 77218) / (2889683 + 17974 + 77218 + 2889683)
```

$$
\omega^2 = \frac{2 \times (17974 - 77219)}{\underbrace{23117462 + 35949 + 1235483}_{SS_{\mathrm{total}}} + 2889683} = `r round(omega_sqr,2)` \approx 0
$$

Effektstärke CRBD in `R`

## General complete block design GCBD

```{r}
include_graphics('pics/golf_driver_1.jpg')
```

```{r}
#| tbl-cap: "adaptiert nach (Lawson, 2014, S. 140)"
data('rcb', package='daewr')
golf <- rcb |> mutate(id = paste0('G',id),
                      teehgt = factor(teehgt, levels=1:3,
                                      labels = c('low','normal','high'))) |> 
  as_tibble()
with(golf, table(id, teehgt))[-c(7:9),] |> kable(booktabs = T)
```

### Model

\begin{equation}
y_{hij} = \mu + \theta_{h} + \tau_i + (\theta\tau)_{hi} + \epsilon_{hij}
\end{equation}

Abfolge der Abschlaghöhen ist randomisiert innerhalb eines Golfers (Blocks)

| B = 9 Golfer 
| M = 5 Repetitions (block size) 
| K = 3 different factor levels

### Analyse GCBD in `R`

```{r}
#| echo: true

mod_gcbd <- aov(cdistance ~ teehgt + Error(id/teehgt), golf)
summary(mod_gcbd)
```

### Mehrfachvergleiche in CRBD

Allgemein Kontraste

\begin{equation}
\hat{\psi} = \sum_{i=1}^Kc_i \hat{\tau_i} = \sum_{i=1}^K \bar{Y}_{.i}
\end{equation}

und Standardfehler 

\begin{equation*}
s_{\psi} = MSE\sum_{i=1}^K c_i^2/B
\end{equation*}


Kritische Werte $w$
\begin{align*}
w_{\text{Bonferroni}} &= t_{KV-B-K+1,\alpha/(2m)} \\
w_{\text{Scheffé}} &= \sqrt{(K-1)F_{K-1,KB-B-K+1,\alpha}} \\
w_{\text{Tukey}} &= q_{K,BV-B-V+1,\alpha}/\sqrt{2} \\
\end{align*}

### z.B. Paarvergleiche Tukey

$$
(\bar{y}_{.i} - \bar{y}_{.j}) \pm w_T \sqrt{MS_{\mathrm{error}}\times2/b}
$$


$w_T = q_{\alpha/\sqrt{2},v, bv-b-v+1}$ = Quantile der Studentized Range Distribution. In `R` mit `qtukey(alpha/sqrt(2), v, b*v-b-b+1)`.

### Mehrfachvergleiche in `R`

```{r}
#| echo: true
#| eval: false

y_bars <- emmeans::emmeans(mod_aov_1, ~protocol)
pairs(y_bars, infer=T)
```
```{r}
y_bars <- emmeans::emmeans(mod_aov_1, ~protocol)
pairs(y_bars, infer=c(T,T)) %>% as_tibble() %>% 
  knitr::kable(booktabs = T, digits=2,
               caption="Post-hoc Ergebnisse") %>% 
  kableExtra::footnote(general="Tukey adjusted at $\\\\alpha=0.95$",
                       escape=F)
```


### Bestimung der Anzahl der Blöcke a-priori 

Direkt über den $F$-Test per trial-and-error

Nichtzentralitätsparameter $\lambda$
\begin{equation*}
\lambda = \frac{B}{\sigma^2}\sum_{i=1}^K \tau_i^2
\end{equation*}

| $\text{df}_1 = K - 1$
| $\text{df}_2 = (B-1)(K-1)$
| $\alpha$

### Beispiel RMR
```{r}
K <- 3
alpha <- 0.05
css <- 35949
MSE <- 77217.7
rmr_pow <- tibble(
  B = seq(20,24,1),
  df_1 = K - 1,
  df_2 = (B-1)*(K-1),
  lambda = B/MSE*css,
  q_H0 = qf(1-alpha, df_1, df_2),
  p_H1 = 1-pf(q_H0, df_1, df_2, lambda)
)
```

| $\hat{\sigma}^2 = `r round(MSE,2)`$
| $\sum_{i=1}^K \tau_i^2 = `r round(css, 2)`$
| $df_1 = K-1 = 3$
| $df_2 = (B-1)(K-1)$ 

```{r}
#| tbl-cap: "Powertabelle"

rmr_pow |> kable(booktabs=T, digits=2, linesep='',
                 col.names=c('B','$df_1$','$df_2$','$\\lambda$',
                             '$q_{H_0}$', 'power'),
                 escape=F)
```


## Zum Nachlesen

@pos_blocking

Feste Effekte und Zufallseffekte @searle1992
