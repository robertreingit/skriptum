{"title":"Modellhierarchien","markdown":{"headingText":"Modellhierarchien","containsRefs":false,"markdown":"\n```{r}\n#| echo: false\n#| warning: false\n#| message: false\nsource('_common.R')\n```\n\n\n```{r defs_modell_hierarchy}\nsource('../resources/nice_format_helper_fcn.R')\nN <- 78\nbeta <- c(10,.5,.7,1.2)\nsigma <- 2\nmax_val <- sum(beta*c(1,30,20,20*30))\ncandy <- tibble(\n  sweetness = sample(30, N, T),\n  moisture = sample(c(0,5,10,15,20), N, T),\n  moisture_f = as.factor(moisture),\n  like = round((beta[1] + beta[2] * sweetness + beta[3] * moisture +\n            beta[4]*sweetness*moisture)/max_val*100 + rnorm(N, 0, 2))\n)\nmod_full <- lm(like ~ sweetness*moisture, candy)\nmod_res <- lm(like ~ sweetness + moisture, candy)\nset.seed(12)\nn <- 4\nsimple <- tibble(x = 0:(n-1),\n                 y = 2 + 0.5 * x + rnorm(n,0,.5))\nmod0 <- lm(y ~ x, simple)\nsimple$y_hat <- predict(mod0)\nsimple$epsilon <- paste0('epsilon[',1:n,']')\nsimple$ys <- paste0('list(x[',1:n,'],y[',1:n,'])')\nsimple$yshat <- paste('hat(y)[',1:n,']')\nN <- 20\nK <- 4\nset.seed(1)\nrt_tbl <- tibble::tibble(\n  group = gl(K, N, labels = c('A','B','C','D')),\n  rt = rnorm(K * N, mean = rep(seq(500,800,100), each=N), sd = 50)\n)\n```\n\n## Einfaches Modell\n\n\\scriptsize\n```{r, echo=T}\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n```\n\n\n\n## Einfaches Modell\n\n```{r}\n#| echo: true\n\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n```\n\n## Abweichungen ... noch mal\n\n### Sum of squares of error\n\n$$\nSSE = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n$$\n\nTypischerweise beinhaltet ein Modell zum berechnen der $\\hat{y}_i$ verschiedene Parameter. Bei der einfachen Regression zum Beispiel $\\beta_0$ und $\\beta_1$ (#Modellparameter $p$ = 2) .\n\n### Freiheitsgrade (degrees of freedom) von SSE\n\n$$\ndfE := n - p\n$$\n\nDie *effektive* Anzahl der Beobachtungen um die Varianz $\\sigma^2$ abzuschätzen.\n\n## MSE als Schätzer für $\\sigma^2$\n\n### Mean squared error MSE\n\n$$\nMSE = \\frac{SSE}{dfE} = \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{n-p}\n$$\n\nAls Schätzer $\\hat{\\sigma}^2$ für $\\sigma^2$ aus $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$\n\n### Parallel zur Berechnung der Stichprobenvarianz\n\n$$\n\\hat{\\sigma}^2 = s^2 = \\frac{1}{n-1}\\sum_{i=1}^2(y_i - \\bar{y})^2\n$$\n\nwo $s^2$ ein Schätzer für die Varianz von $y$ ist.\n\n## Genereller Linearer Modell Testansatz^[@kutner2005, p.72]\n### Idee\n\nWir bauen uns eine Teststatistik die die Verbesserung in der Vorhersage ($=$ Reduktion der Fehlervarianz) als Metrik verwendet. Modelle werden in eine Hierarchie gesetzt mit einfacheren Modellen untergeordnet zu komplexeren Modellen.\n\n### Leitfrage:\n\n*Bringt mir die Aufnahme \\underline{zusätzlicher} Modellparameter eine \\underline{Verbesserung} in der Vorhersage von Y bzw. bezüglich der Aufklärung der Varianz in Y?*\n\n\n## Genereller Linearer Modell Testansatz - Full model\n\nBeispiel einfache lineare Regression\n\n### Volles Modell\n$$\nY_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\n$$\n\n### Residualvarianz SSE(F)\n\n$$\n\\textrm{SSE(F)}  = \\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = \\sum_{i=1}^n [y_i - (\\beta_0 + \\beta_1 x_i)]^2\n$$\n\nmit $p = 2, dfE(F) = n - 2$\n\n\n## Genereller Linearer Modell Testansatz - Reduced model\n\n### Reduziertes Modell\n$$\nY_i = \\beta_0 + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\n$$\n\n### Residualvarianz SSE(R)\n\n$$\n\\textrm{SSE(R)} = \\sum_{i=1}^n (y_i - \\beta_0)^2 = \\sum_{i=1}^n(y_i - \\bar{y})^2 = \\textrm{SSTO}\n$$\n\nmit $p = 1, dfE(R) = n - 1$\n\n\nIm Allgemeinen gilt: $SSE(F) \\leq SSE(R)$\n\n## Link: Reduziertes Modell und Stichprobenvarianz\n\n\\begin{align*}\nSSE &= \\sum_{i=1}^n(y_i - \\beta_0)^2 = \\sum_{i=1}^n (y_i^2 - 2y_i\\beta_0 + \\beta_0^2) \\\\\n0 &= \\frac{\\mathrm{d}}{\\mathrm{d} \\beta_0}\\sum_{i=1}^n (y_i^2 - 2y_i\\beta_0 + \\beta_0^2) \\\\\n0 &= \\sum_{i=1}^n (-2y_i + 2 \\beta_0) = -2\\sum_{i=1}^n y_i + 2\\sum_{i=1}^n \\beta_0\\\\\nn\\beta_0 &= \\sum_{i=1}^n y_i \\\\\n\\beta_0 &= \\frac{\\sum_{i=1}^n y_i}{n} = \\bar{y} \\rightarrow \\frac{SSE}{n-1} = \\hat{\\sigma}^2 = s^2\n\\end{align*}\n\n\n## Genereller Linearer Modell Testansatz \n\nAnnahme: Das reduzierte Modell ist korrekt. Dann sollte\n$$\n\\textrm{SSE(R)} - \\textrm{SSE(F)}\n$$\neher klein sein (Beide Modelle haben einen gleich guten fit).\n\nAnnahme: Das reduzierte Modell ist falsch: Dann sollte\n$$\n\\textrm{SSE(R)} - \\textrm{SSE(F)}\n$$\neher groß sein (Das reduzierte Modell kann die Daten nicht so gut fitten wie das komplizierte Modell)\n\n## Genereller Linearer Modell Testansatz - Teststatistik\n\nWenn das reduzierte Modell korrekt ist, dann lässt sich zeigen, dass:\n$$\nMS_{\\textrm{test}} = \\frac{\\textrm{SSE(R)} - \\textrm{SSE(F)}}{\\textrm{dfE(R)} - \\textrm{dfE(F)}}\n$$\nein Schätzer für die Varianz $\\sigma^2$ ($\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$) ist.\n\nWenn das reduzierte Modell korrekt ist, dann ist auch das volle Modell korrekt. Daher ist dann:\n\n$$\n\\textrm{MSE(F)} = \\frac{\\textrm{SSE(F)}}{\\textrm{dfE(F)}}\n$$\nauch ein Schätzer für $\\sigma^2$\n\n## F-Wert als Teststatistik\n\n$$\nF = \\frac{MS_{\\textrm{test}}}{MSE(F)}= \\frac{\\frac{\\textrm{SSE(R)} - \\textrm{SSE(F)}}{\\textrm{dfE(R)} - \\textrm{dfE(F)}}}{ \\frac{\\textrm{SSE(F)}}{\\textrm{dfE(F)}}}\n$$\n\n\n## Verteilung der F-Statistik\n\n$$\nF = \\frac{MS_{\\textrm{test}}}{MSE(F)}  \\sim F(\\textrm{dfE(R)}-\\textrm{dfE(F)},\\textrm{dfE(F)})\n$$\n\n```{r}\n#| fig.cap: \"Beispiele für die F-Verteilung mit verschiedenen Freiheitsgraden $df_1, df_2$\"\n\ndff <- tibble::tibble(\n  F = seq(0.01,5,length.out=100),\n  f1 = df(F, 1, 1),\n  f2 = df(F, 1, 5),\n  f3 = df(F, 5, 10)\n) %>% tidyr::pivot_longer(-1, names_to = 'dist', values_to = 'd')\nggplot(dff, aes(F, d, color=dist)) + \n  geom_line(size=1.3) +\n  scale_color_discrete(\"Verteilung\",\n                       labels = c(\n                         expression(F['1,1']),\n                         expression(F['1,5']),\n                         expression(F['5,10'])\n                       )) +\n  labs(x = 'F-Wert', y = 'Dichte') \n```\n\n## Hypothesentest mit F-Wert\n\n```{r}\n#| fig.cap: \"F-Verteilung mit $df_1 = 5, df_2 = 10$ und kritischem Wert bei $\\\\alpha=0.05$\"\n\nk_w <- qf(0.95, 5, 10)\nggplot(dff %>% dplyr::filter(dist == 'f3'), aes(F, d)) +\n  geom_line(size=1.3) +\n  geom_vline(xintercept = k_w, color='red', linetype = 'dashed') +\n  geom_ribbon(data = tibble::tibble(F = seq(k_w, 5, length.out=30),\n                                    d = df(F, 5, 10)),\n              aes(ymin = 0, ymax = d), fill='red', alpha=0.5) +\n  labs(x = 'F-Wert', y = 'Dichte') \n```\n^[In `R`: `df(), pf(), qf(), rf()`]\n\n## Teilziel\n\n- Durch den Vergleich von Modellen kann die Verbesserung/Verschlechterung der Modellvorhersage statistisch Überprüft werden\n- Alternativ: Brauchen ich zusätzliche Parameter oder reicht mir das einfache Modell?\n\n## Beispiel: Candy-Problem\n\n```{r}\n#| fig.cap: \"Zusammenhang zwischen der Präferenz für ein Bonbon und dem Süßgrad für verschiedene Weichheitsgrade\"\n\nggplot(candy, aes(sweetness, like)) + geom_point(size=3) +\n  facet_grid(~moisture) +\n  theme(text = element_text(size=12))\n```\n\n## Modelle als Hierarchien auffassen\n\n### Full model\n$$\ny_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i}x_{2i} + \\epsilon_i\n$$\n\n### Hierarchie\n\n\\begin{align*}\nm_0&: y_i = \\beta_0 + \\epsilon_i \\\\\nm_1&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i \\\\\nm_2&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i \\\\\nm_3&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i}x_{2i} + \\epsilon_i\n\\end{align*}\n\nEs gilt: $m_0 \\subseteq m_1 \\subseteq m_2 \\subseteq m_3$\n\n## Modelle als Hierarchien auffassen in `R`\n\nIn R:\n\n```{r}\n#| echo: true\n\nmod_0 <- lm(like ~ 1, candy)\nmod_1 <- lm(like ~ sweetness, candy)\nmod_2 <- lm(like ~ sweetness + moisture, candy)\nmod_3 <- lm(like ~ sweetness * moisture, candy)\n```\n\n\n## Vergleich $m_0$ gegen $m_1$\n\n\\begin{align*}\nm_0: y_i &= \\beta_0 + \\epsilon_i \\\\\nm_1: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i\n\\end{align*}\n\n```{r}\n#| eval: false\n#| echo: true\n\nanova(mod_0, mod_1)\n```\n\n```{r}\nss1 <- anova(mod_0, mod_1)\nanova_tbl_knitr(ss1)\n```\n\n## Vergleich $m_1$ gegen $m_2$\n\n\\begin{align*}\nm_1: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i \\\\\nm_2: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i \n\\end{align*}\n\n```{r}\n#| echo: true\n#| eval: false\n\nanova(mod_1, mod_2)\n```\n\n```{r}\nss2 <- anova(mod_1, mod_2)\nanova_tbl_knitr(ss2)\n```\n\n## Vergleich $m_2$ gegen full model $m_3$\n\n\\begin{align*}\nm_2: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i  \\\\\nm_3: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i} x_{2i} + \\epsilon_i \n\\end{align*}\n\n```{r}\n#| echo: true\n#| eval: false\n\nanova(mod_2, mod_3)\n```\n\n```{r}\nss3 <- anova(mod_2, mod_3)\nanova_tbl_knitr(ss3)\n```\n\n## Vergleich full model $m_3$ gegen minmales Modell $m_0$\n\n\\begin{align*}\nm_0: y_i &= \\beta_0 + \\epsilon_i  \\\\\nm_3: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i} x_{2i} + \\epsilon_i \n\\end{align*}\n\n```{r}\n#| echo: true\n#| eval: false\n\nanova(mod_0, mod_3)\n```\n\n```{r}\nss4 <- anova(mod_0, mod_3)\nanova_tbl_knitr(ss4)\n```\n\n## In `summary()` $m_3$ gegen $m_0$\n\n```{r}\nsummary(mod_3)\n```\n\n## Eine nominale Variable mit vier Stufen \n\n```{r}\n#| fig.cap: \"Ein Reaktionszeitexperiment mit vier Stufen A, B, C und D\"\nggplot(rt_tbl, aes(group, rt)) + geom_boxplot() +\n  geom_point(alpha=.1, col='red') +\n  labs(x = 'Treatment', y = 'Reaktionszeit') \n```\n\n## Früher - Analysis of Variance (ANOVA bzw. AOV)\n\n\\begin{align*}\ns_{zwischen}^2 &= \\frac{1}{K-1}\\sum_{j=1}^K N_j (\\bar{x}_{j.}-\\bar{x})^2 \\\\\ns_{innerhalb}^2 &= \\frac{1}{N-K}\\sum_{j=1}^K\\sum_{i=1}^{N_j}(x_{ji}-\\bar{x}_{j.})^2 = \\frac{1}{N-K}\\sum_{j=1}^K(N_j-1)s_j^2 \\\\\nF &= \\frac{\\hat{\\sigma}_{zwischen}^2} {\\hat{\\sigma}_{innerhalb}^2} \\sim F(K-1,N-K)\n\\end{align*}\n\n## ANOVA in R \n\n```{r}\n#| echo: true\n#| eval: false\n\nmod_aov <- aov(rt ~ group, rt_tbl)\nsummary(mod_aov)\n```\n```{r}\nmod_aov <- aov(rt ~ group, rt_tbl)\nbroom::tidy(mod_aov) |> \n  knitr::kable(caption = 'Ausgabe mit aov()',\n               booktabs = T,\n               digits = 1)\n```\n\n## Ansatz mittels Modellhierarchien \n\n### Full model\n\n$$\ny_i = \\beta_0 + \\beta_{\\Delta_{B-A}} x_1 + \\beta_{\\Delta_{C-A}} x_2 + \\beta_{\\Delta_{D-A}} x_3 + \\epsilon_i\n$$\n\n### Reduced model\n$$\ny_i = \\beta_0 + \\epsilon_i\n$$\n\nWenn das reduced model die Daten gleich gut fittet wie das full model $\\Rightarrow$ Information über das Treatment verbessert meine Vorhersage von $y_i$ nicht.\n\n## Model fit - Full model\n\n```{r}\n#| echo: true\n#| eval: false\n\nmod <- lm(rt ~ group, rt_tbl)\n```\n\n```{r}\nmod <- lm(rt ~ group, rt_tbl)\nlm_tbl_knitr(mod)\n```\n\n## `anova()` mit nur einem Modell \n\n```{r}\n#| echo: true\n#| eval: false\n\nanova(mod)\n```\n\n```{r}\nbroom::tidy(anova(mod)) |> \n  knitr::kable(caption = 'Äquivalent zum Vergleich full gegen reduced model',\n               booktabs = T,\n               digits = 1)\n```\n\n\n## Zum Nacharbeiten \n\n@christensen2018[p.57-64] \\newline\n\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":3,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"mlm_hierarchies.html"},"language":{},"metadata":{"lang":"de","fig-responsive":true,"quarto-version":"1.2.258","bibliography":["bibliography.bib"],"theme":"cosmo","callout-icon":true},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":4,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","include-in-header":{"text":"\\usepackage{makeidx,multirow}\n\\makeindex\n"},"include-after-body":{"text":"\\printindex\n"},"output-file":"mlm_hierarchies.pdf"},"language":{},"metadata":{"block-headings":true,"bibliography":["bibliography.bib"],"documentclass":"scrreprt"},"extensions":{"book":{}}}}}