{
  "hash": "e293cd0350378d947b38ebb0532cad03",
  "result": {
    "markdown": "# Inferenz\n\n\n::: {.cell}\n\n:::\n\n\nNachdem das Modell gefittet wurde stellt sich die Frage ob tatsächlich ein Zusammenhang zwischen der Prädiktorvariable und der abhängigen Variable besteht. Da das einfache lineare Modelle zwei Parameter $\\beta_0$ und $\\beta_1$ beinhaltet (streng genommen ist $\\sigma^2$ ein dritter Parameter) kann diese Frage auf beide Koeffizienten angewendet werden.\n\nEine kurze Überlegung zeigt, dass wenn zwischen der Prädiktorvariablen und $y$ kein Zusammenhang besteht, dann sollte der Steigungskoeffizient $\\beta_1$ gleich Null sein bzw. auf Grund von Stichprobenvariabilität in der Nähe von Null sein. Daher ist eine plausible Hypothese die sich statistisch Überprüfung lässt:\n\n$$\nH_0: \\beta_1 = 0\n$$\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Inferenz\n\n### Modellannahmen\n\n\\begin{align*}\ny_i &= \\beta_0 + \\beta_1 x_i + \\epsilon_i \\quad i=1,\\ldots,N \\\\\n\\epsilon_i &\\sim N(0,\\sigma^2) \\quad \\textrm{identisch, unabhängig verteilt}\n\\end{align*}\n\n## Modellannahmen - Verteilung der Werte für gegebene x-Werte\n\n$$\nY|X \\sim N(\\beta_0+ \\beta_1 X,\\sigma^2)\n$$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Verteilung der Daten für verschiedene $x$-Werte](pics/Stats_Figures.png){width=2.67in}\n:::\n:::\n\n\n\n## Statistische Hypothesen\n\n### Ungerichtet\n\n\\begin{gather*}\nH_0: \\beta_1 = 0  \\\\\nH_1: \\beta_1 \\neq 0\n\\end{gather*}\n\n### Gerichtet\n\n\\begin{gather*}\nH_0: \\beta_1 \\leq 0  \\\\\nH_1: \\beta_1 > 0\n\\end{gather*}\n\n## Teststatistik informell herleiten\n\n### Simulation unter der $H_0$\n\n\\begin{align*}\nN &= 45 \\\\\nx &\\sim \\mathcal{U}(-1,1) \\\\\ny &\\sim \\mathcal{N}(0,\\sigma) \\\\\n\\sigma &= 1 \\\\\nH_0: & \\beta_1 = 0\n\\end{align*}\n\n## Teststatistik informell herleiten\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Acht Zufallsziehung unter der $H_0$](slm_inference_files/figure-pdf/unnamed-chunk-3-1.pdf)\n:::\n:::\n\n\n## Stichprobenverteilung von $\\beta_1$ unter der Annahme $\\beta_1 = 0$ \n\n\n::: {.cell}\n::: {.cell-output-display}\n![Verteilung der $\\beta_1$s - 1000 Simulationen unter der Annahme der $H_0$.](slm_inference_files/figure-pdf/unnamed-chunk-4-1.pdf)\n:::\n:::\n\n\n## Verteilung der Statistik unter der $H_0$\n\n\n:::: columns\n::: column\n\n#### Standardfehler von $\\beta_1$ \n$$ \\sigma_{\\beta_1} = \\sqrt{\\frac{\\sigma^2}{\\sum{(X_i - \\bar{X})^2}}}$$\n\n$\\sigma$ lässt sich abschätzen mit:\n\n$$\n\\hat{\\sigma} = \\sqrt{\\sum_{i=1}^N e_i^2/(N-K)}\n$$\n:::\n::: column\n\n### in `R`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsigma(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2369055\n```\n:::\n:::\n\n\n\n:::\n::::\n\n## Verteilung der Statistik unter der $H_0$\n\nUnter den Annahmen des Regressionsmodells und der $H_0$ gilt:\n\n$$\n\\frac{\\beta_1}{\\sigma_{\\beta_1}} \\sim t_{N-2}\n$$\n\nMittels $\\alpha$ lässt sich daher wieder ein kritischer Wert bestimmen ab dem die $H_0$ verworfen wird.\n\n\n\n## Teststatistik\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Verteilung von $\\frac{\\beta_1}{s_{\\beta_1}}$,Dichtefunktion der t-Verteilung (rot) mit $df = n - 2$](slm_inference_files/figure-pdf/unnamed-chunk-6-1.pdf)\n:::\n:::\n\n\n## Verteilung der $\\hat{\\sigma} = \\sqrt{\\sum_{i=1}^N e_i^2/(N-K)}$\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Verteilung von $\\hat{\\sigma}$](slm_inference_files/figure-pdf/unnamed-chunk-7-1.pdf)\n:::\n:::\n\n\n\n## Nochmal `summary()`\n\\tiny\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = jump_m ~ v_ms, data = jump)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.44314 -0.22564  0.02678  0.19638  0.42148 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.13854    0.23261  -0.596    0.555    \nv_ms         0.76110    0.02479  30.702   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2369 on 43 degrees of freedom\nMultiple R-squared:  0.9564,\tAdjusted R-squared:  0.9554 \nF-statistic: 942.6 on 1 and 43 DF,  p-value: < 2.2e-16\n```\n:::\n:::\n\n\n## Konfidenzintervalle für die Koeffizienten\n\n### Formel\n\n$$\n\\hat{\\beta_j} \\pm q_{t_{\\alpha/2,df=N-2}} \\times \\hat{\\sigma}_{\\beta_j}\n$$\n\n### In R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nconfint(mod)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                 2.5 %    97.5 %\n(Intercept) -0.6076488 0.3305767\nv_ms         0.7111082 0.8110957\n```\n:::\n:::\n\n\n## Zum Nacharbeiten\n\n@pos_simple_regression und @kutner2005 [p.40-48]\n\n",
    "supporting": [
      "slm_inference_files\\figure-pdf"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}