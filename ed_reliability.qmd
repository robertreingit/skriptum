# Reliabilität

Diese Kapitel beschäftigt sich mit der Güte von Messinstrumenten. Trotzdem eigentlich ein zentrales Thema bei der Erhebung von Messdaten wird es in den meisten Fällen gar nicht betrachtet.

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```


```{r}
```

```{r reliability_defs}
lil <- readr::read_delim('data/lilquist_2021_tbl_05.txt',
                         delim = ' ')
lil_w <- lil |> tidyr::pivot_longer(-Subject,
                                    names_to = 'day',
                                    values_to = 'emg')
```

## Genauigkeit versus Präzision

Die ersten beiden wichtigen Eigenschaften eines Messinstruments sind die Genauigkeit und die Präzision. Beide sind Eigenschaften sind zentrale zur Beurteilung der Qualität eines Messinstruments. **Genauigkeit** beschreibt, wie nahe eine Messung am tatsächlichen oder wahren Wert liegt. Ein Messinstrument mit hoher Genauigkeit liefert Werte, die nur eine geringe Abweichung vom *realen Wert* aufweisen. **Präzision** hingegen bezieht sich auf die Wiederholbarkeit von Messungen: Ein präzises Instrument liefert bei mehrfacher Messung ähnliche oder identische Werte, unabhängig davon, ob diese dem wahren Wert nahekommen. Ein Messinstrument kann also präzise, aber ungenau sein, wenn die Werte zwar eng beieinanderliegen, jedoch systematisch vom tatsächlichen Wert abweichen. Idealerweise sollte ein Messinstrument sowohl genau als auch präzise sein, um verlässliche Ergebnisse zu liefern.

In @fig-ed-rel-precision sind Präzision und Genauigkeit anhang einer Zielscheibe noch einmal verdeutlicht.

```{r}
#| fig-cap: "Genauigkeit versus Präzision"
#| label: fig-ed-rel-precision

plot_precision_accuracy <- function() {
  bull <- function(x=0,y=0,r=1,n=100,n_rings=3) {
    theta <- seq(0, 2*pi, length.out=n)
    tibble(
      x = x + sin(theta) * rep(seq(1, r/(n_rings+1), length.out=3), each=n),
      y = y + cos(theta) * rep(seq(1, r/(n_rings+1), length.out=3), each=n),
      g = rep(1:n_rings, each=n)
    )
  }
  pts <- function(x=0,y=0,s=0.1,n=10) {
    tibble(
      x = rnorm(n,x,s),
      y = rnorm(n,y,s)
    )
  }
  set.seed(1)
  ggplot() +
    geom_path(data = bull(), aes(x,y,group=g)) +
    geom_path(data = bull(0,3), aes(x,y,group=g)) +
    geom_path(data = bull(3,0), aes(x,y,group=g)) +
    geom_path(data = bull(3,3), aes(x,y,group=g)) +
    geom_point(data = pts(0,3), aes(x,y), size=2, color='red') +
    geom_point(data = pts(3.5,3.5), aes(x,y), size=2, color='red') +
    geom_point(data = pts(0,0,.3), aes(x,y), size=2, color='red') +
    geom_point(data = pts(3.5,0.5,.3), aes(x,y), size=2, color='red') +
    geom_text(data = tibble(x = c(-1,-1,2,2),y = c(4,1,4,1)+0.3,
                             label=c('genau und präzise','genau und unpräzise',
                                     'ungenau und präzise','ungenau und unpräzise')), 
              aes(x,y,label=label), hjust='left') +
    coord_equal(xlim=c(-1,5)) +
    theme_void()
}
plot_precision_accuracy()
```

Bevor eine Messung durchgeführt werden soll, ist es daher notwendig über die Genauigkeit und die Präzision eines Messgeräts Bescheid zu wissen. In manchen Fällen kann beispielsweise eine geringere Genauigkeit eines Messgeräts weniger problematisch sein als eine geringere Präzision. Wenn zum Beispiel nur Unterschiede gemessen werden sollen, dann ist in bestimmten Fällen die absolute Genauigkeit weniger von Bedeutung da die Abweichungen vom *realen* Wert durch den Vergleich subtrahiert werden. Wird zum Beispiel eine Waage verwendet um die Veränderungen im Gewicht an Untersuchungspersonen über die Zeit verglichen werden sollen. Die Waage sei aber nicht korrekt geeicht und zeigt immer $2$ kg zu viel an. Dadurch ist der absolute, angezeigte Wert verfälscht. Werden aber die beobachteten Gewichte über die Messzeitpunkte voneinander abgezogen, dann ist der *Unterschied* zwischen den Messzeitpunkten dennoch korrekt. Die Annahme dabei ist allerdings, dass sich die Genauigkeit über den Beobachtungszeitung nicht verändert. Diese Eigenschaft kann mit Hilfe der **Reliabilität** untersucht werden.

## Reliabilität

In @tbl-ed-rel-emg sind ein Ausschnitt von EMG-Daten aus @liljequist2019 abgetragen.

```{r}
#| tbl-cap: "Beispieldaten von Lijequist (2019), EMG Median Frequenz (Hz), linke lumbale Rückenmuskulator über drei Tage"
#| label: tbl-ed-rel-emg

lil |> head() |> knitr::kable(
             linesep = '',
             col.names = c('Subject','Day 1', 'Day 2', 'Day 3'))
```

Insgesamt wurde bei $N = 10$ Personen die Muskelaktivierung in der Rückenmuskulatur über drei Tagen jeweils an der gleichen Stelle gemessen. Ziel war ein Abzuschätzen zu erhalten, wie stabil bzw. ähnlich die EMG-Messungen über die verschiedenen Tage sind. In @fig-ed-rel-emg sind die Daten noch einmal graphisch dargestellt.

```{r}
#| fig-cap: "EMG Daten nach Liljequist et al. (2019). Die roten Punkte sind die Mittelwerte mit Standardabweichungen, schwarze gestrichtelte Linien sind die einzelnen Personen."
#| label: fig-ed-rel-emg

lil_hat <- lil_w |> dplyr::group_by(day) |> 
  dplyr::summarize(m = mean(emg),
            s = sd(emg),
            Subject = 11)
ggplot(lil_w, aes(day, emg, group=Subject)) +
  geom_pointrange(data = lil_hat,
                  aes(y = m, ymin = m - s, ymax = m + s),
                  size = 1.4, col = 'red') +
  geom_line(position = position_jitter(seed = 123, width=.05), linetype='dashed') +
  geom_point(position = position_jitter(seed = 123, width=.05), size=3) +
  scale_x_discrete('Messzeitpunkt', labels = paste('Tag', 1:3)) +
  labs(y = 'Median EMG Frequenz') 
```

Wie in @fig-ed-rel-emg zu sehen ist, schwanken die Werte über die drei Messzeitpunkte. Einmal sind innerhalb der Personen Unterschiede zu erkennen, aber auch die Mittelwerte für die Messtage über die zehn Personen hinweg verändern sich über die Messzeitpunkte. D.h. die gewählte Messmethodik weist selbst Schwankungen auf. Die Höhe der Schwankungen müssen aber bei der Erstellung eines Untersuchungsdesigns berücksichtigt werden. Sollen beispielsweise Unterschiede zwischen zwei Gruppen mit Hilfe dieser Messmethodik untersucht werden, aber wenn sich die zu erwartenden Unterschiede zwischen den Gruppen in der Größenordnung der Schwankungen oder möglicherweise sogar darunter, dann wird es sehr schwierig bis unmöglich werden diese Unterschiede in einem Experiment nachweisen zu können. Diese ungewollten Schwankungen sind einer Funktion der *Reliabilität* der Messmethodik. Ohne eine Kenntnis der Reliabilität einer Methodik ist tatsächlich die Durchführung einer experimentellen Untersuchung immer ein Stück weit Kaffeesatzlesen.

### Modell 

Um sich der Reliabilität inhaltlich zu nähern ist zunächst die Erstellung eines theoretischen Modells erforderlich. Soll ein *Wert* bestimmt werden, der die Eigenschaft eines Objekts beschreibt, dann ist eine plausible Annahme das es einen *wahren* Wert gibt. Zum Beispiel ist direkt einsichtig, dass ein gegebener Holzstab eine bestimmte Länge hat. Oder eine Hantelscheibe hat ein bestimmtes Gewicht. Solange keine Manipulation an der Scheibe durchgeführt wird, sollte sich dieses Gewicht nicht ändern. Diesen Wert soll nun als *true-score* bezeichnet werden und er erhält das Zeichen $\tau$. Während $\tau$ für eine Hantelscheibe noch relativ direkt einsichtig ist, ist dies nicht mehr ganz so einfach sobald biologische Objekte ins Spiel kommen. Soll beispielsweise die Körpergröße einer Person bestimmt werden, dann ist klar das die Körpergröße keine feststehende Größe ist, sondern im Verlauf eines Tages einer Schwankung unterliegt [@tyrrell1985]. In @fig-ed-rel-height ist beispielsweise die Veränderung der Körperhöhe im Verlauf eines Tages abgetragen.

```{r}
#| fig-cap: "Veränderung der Körpergröße über den Tag (adaptiert nach Tyrrell et al. (1985))."
#| label: fig-ed-rel-height

height <- tibble(
  time = c(0, 3.2, 7, 8, 9, 10, 12, 15.5, 20, 24),
  height = c(3.5, 16.8, 22, 13.9, 11.6, 8.6, 5.86, 4.4, 3.94, 3.9)
)
ggplot(height, aes(time,height)) +
  geom_line() + 
  geom_point() +
  scale_x_continuous('Zeit nach Mitternacht [Stunden]', breaks=seq(0,24,2)) +
  scale_y_continuous('Höhenveränderung\nzu Mitternacht [mm]')
```

Es soll nun aber davon ausgegangen werden das der wahre Wert $\tau$ wohldefiniert ist. Dann besteht aber nach wie vor das Problem, selbst bei der Hantelscheibe, dass dieser Wert mit Hilfe eines Messmethodik bestimmt werden muss. Zum Beispiel im Fall der Hantelscheibe muss eine Waage verändert werden um das Gewicht zu bestimmen. Diese Waage ist aber selbst unweigerlich mit *Messfehlern* behaftet. Vielleicht ist bei der Eichung was schief gegangen, vielleicht ist die Feder mit Zeit ausgeleiert, oder die Umgebungstemperatur entspricht nicht den Vorgaben usw. und sofort. Das führt dazu, dass der *gemessene* Wert nicht gleich dem wahren Wert $\tau$ entspricht. Um den gemessenen Wert vom wahren Wert zu unterscheiden wird ein weiteres Symbol $Y$ verwendet. $Y$ ist dementsprechend der *beobachtete* Wert. Die Messfehler werden weiterhin mit dem Symbol $\epsilon$ bezeichnet. Dies führt insgesamt zu folgendem Modell:

\begin{equation}
Y = \tau + \epsilon
\label{eq-ed-reliability-model}
\end{equation}

D.h. der beobachtete Wert $Y$ setzt sich zusammen aus dem wahren Wert $\tau$ und dem Messfehler $\epsilon$. Der Messfehler geht additiv ein. Eine weitere Annahme soll nun dahin gehend bestehen, dass die Messfehler zufällig sind und bei wiederholter Messung im *Mittel* gleich $0$ sind. Formal ist der Erwartungswert $E[\epsilon_0] = 0$. Weiterhin besteht keine Zusammenhang zwischen der Größe des Messfehlers und der Größe von $\tau$. Beispielsweise bei der Messung der Körpergröße verändert sich die Größe des Messfehlers nicht mit der Größer der Probandinnen sondern bleibt konstant. Formal führt dies zu $\text{Cov}(\epsilon,\tau) = 0$.

Werden nun mehrere bzw. $N$ Messungen durchgeführt, dann wird entsprechend nicht nur ein wiederholter, konstanter Wert beobachtet sondern eine Menge von Werten. Um diese zu unterscheiden wird entsprechend ein Index $i$ eingeführt.

\begin{equation}
Y_i = \tau_i + \epsilon_i, \quad i \in [1,\ldots,N]
\end{equation}

Sobald nun mehrere Werte zur Verfügung stehen, kann für diese beobachteten Wert $Y_i$ eine Varianz berechnet werden und, zumindest theoretisch, auch eine Varianz für die $\tau_i$s berechnet werden. Dies ermöglicht nun eine formale Definition der Reliabilität unter dem gegebenen Modell.

::: {#def-reliability}
## Reliabilität - Definition 

Die Reliabilität ist definiert als das Verhältnis der Varianz der *True-Score-Variablen* $\sigma_{\tau}$ zur *Gesamtvarianz* der Testvariablen $\sigma_{Y}$. [@moosbrugger2020, p.282]

\begin{equation}
\text{Rel} = \frac{\sigma_{\tau}^2}{\sigma_{Y}^2} = \frac{\sigma_{\tau}^2}{\sigma_{\tau}^2+\sigma_{\epsilon}^2}
\end{equation}

Der Wertebereich der Reliabilität liegt in $\text{Rel} \in [0,1]$ wobei eine Wert $0$ gar keine Reliabilität anzeigt, während ein Wert von $\text{Rel} = 1$ auf eine perfekte Reliabilität hindeutet.
:::

Veranschaulicht, wenn der Messfehler gleich Null ist, also $\sigma_{\epsilon}^2 = 0$ gilt, dann ist $\text{Rel} = 1$, während der Messfehler sehr groß im Verhältnis zu $\sigma_{\tau}^2$, dann geht der $\text{Rel}$ gegen Null. Für die Interpretation der Reliabilität hat sich in der Literatur eine Kategorisierung entlang der Werte in @tbl-ed-rel-interpretation etabliert.

| Bereich | Interpretation |
| --- | --- |
| $<0.5$ | poor |
| $0.5-0.75$ | moderate |
| $0.75-0.9$ | good |
| $>0.9$ | excellent |

: Interpretation der Reliablität nach @koo2016 {#tbl-ed-rel-interpretation}

### Terminologie

@baumgartner1989[p.46]

### Relative reliability (Consistency)

Degree to which people maintain their position (rank)

- internal consistency reliability: within day
- stability reliability: between days
- rater reliability (objectivity): between raters

### Absolute reliability (Agreement)

Degree to which people's score do not change in magnitude or value

## Intraclass correlation coefficient

\begin{equation*}
ICC = \frac{\text{variance of interest}}{\text{variance of interest} + \text{unwanted variance}}
\end{equation*}

### Datenmodell

| Subject  | Judge 1 | Judge 2 | $\cdots$ | Judge k | Mean |
| --- | --- | --- | --- | --- | --- |
| 1 | $x_{11}$ | $x_{12}$ | $\cdots$ | $x_{1k}$ | $S_1$ |
| 2 | $x_{21}$ | $x_{22}$ | $\cdots$ | $x_{2k}$ | $S_1$ |
| $\vdots$ |$\vdots$ |$\vdots$ | |$\vdots$ |$\vdots$ |
| n | $x_{n1}$ | $x_{n2}$ | $\cdots$ | $x_{nk}$ |  $S_n$ |
| Mean | $M_1$ | $M_2$ | $\cdots$ | $M_k$ | $\bar{x}$ |

### Varianzkomponenten

Ansatz: Die Gesamtvarianz in verschiedene Komponenten aufspalten (ANOVA)

Modell:
\begin{align*}
x_{ij} &= \mu + r_i + c_j + e_{ij} \\
r_i &\sim \mathcal{N}(0,\sigma_r) \\
c_j &\sim \mathcal{N}(0,\sigma_c) \\
e_{ij} &\sim \mathcal{N}(0,\sigma_e)
\end{align*}


### Berechnung der Varianzkomponenten

Terminologie nach @liljequist2019

| SSQ  | Bezeichnung | Berechnung |  MSQ |
| -- | ---- | ---- | -- | 
| SST | Total | $\sum_{i=1}^n\sum_{j=1}^k (x_{ij} - \bar{x})^2$ | $\frac{SST}{n\cdot k-1}$ |
| SSBS | Between Subject | $\sum_{i=1}^n\sum_{j=1}^k (S_i - \bar{x})^2$ | $\frac{SSBS}{n-1}$ |
| SSBM | Between Measurement | $\sum_{i=1}^n\sum_{j=1}^k (M_j - \bar{x})^2$ | $\frac{SSBM}{k-1}$ |
| SSWS | Within Subject | $\sum_{i=1}^n\sum_{j=1}^k (x_{ij} - S_i)^2$ | $\frac{SSWS}{n\cdot(k-1)}$ |
| SSWM | Within Measurements | $\sum_{i=1}^n\sum_{j=1}^k (x_{ij} - M_j)^2$ | $\frac{SST}{k\cdot (n-1)}$ |

$SSE = SST - SSBS - SSBM$ Error $MSE = \frac{SSE}{(n-1)\cdot (k-1)}$

### Intraclass Correlation - Modelle

```{r}
#| fig-cap: Modell 1

knitr::include_graphics('pics/reliability_model_1.png')
```

```{r}
#| fig-cap: Modell 2

knitr::include_graphics('pics/reliability_model_2.png')
```


| Bezeichnung | Modell | Expected Mean Squares |
| --- | -------- | ----- |
| Model 1 | $x_{ij} = \mu + \underbrace{r_i + e_{ij}}_{\text{zufällig}}$|  $MSBM \approx \sigma_e^2$ |
| Model 2 | $x_{ij} = \mu + \underbrace{r_i + \overbrace{c_j}^{bias} + e_{ij}}_{\text{zufällig}}$  | $MSBM \approx n\cdot \sigma_c^2 + \sigma_e^2$ |
| Model 3 | $x_{ij} = \mu + \underbrace{r_i}_{\text{zufällig}} + \overbrace{c_j}^{\text{fixed}} + \underbrace{e_{ij}}_{\text{zufällig}}$ | $MSBM \approx n\cdot \theta_c^2 + \sigma_e^2$ | 

: Übersicht über die Modelle

### Intraclass Correlation $\rho_1$

### Model 1 ICC(1)
\begin{equation*}
\rho_1 = \frac{\sigma_r^2}{\sigma_r^2+\sigma_e^2} 
\end{equation*}

\begin{equation*}
ICC(1) = \frac{MSBS - MSWS}{MSBS + (k-1)MSWS}
\end{equation*}

### Intraclass Correlation $\rho_2$ Modell 2

### Model 2 ICC(A,1) Absolute
\begin{align*}
\rho_{2A} &= \frac{\sigma_r^2}{\sigma_r^2+\sigma_c^2 + \sigma_e^2}  \\
ICC(A,1) &= \frac{MSBS - MSE}{MSBS + (k-1)MSE + \frac{k}{n}(MSBM-MSE)}
\end{align*}

### Model 2 ICC(C,1) Consistency
\begin{align*}
\rho_{2C} &= \frac{\sigma_r^2}{\sigma_r^2 + \sigma_e^2} \\
ICC(C,1) &= \frac{MSBS - MSE}{MSBS + (k-1)MSE}
\end{align*}

### Intraclass Correlation $\rho_3$ Model 3 

### ICC(A,1) Absolute
\begin{align*}
\rho_{3A} &= \frac{\sigma_r^2}{\sigma_r^2 + \theta_c^2 + \sigma_e^2}  \\
ICC(A,1) &= \frac{MSBS - MSE}{MSBS + (k-1)MSE + \frac{k}{n}(MSBM-MSE)}
\end{align*}

### ICC(C,1) Consistency
\begin{align*}
\rho_{3C} &= \frac{\sigma_r^2}{\sigma_r^2 + \sigma_e^2} \\
ICC(C,1) &= \frac{MSBS - MSE}{MSBS + (k-1)MSE}
\end{align*}

### Übersicht

```{r}
#| out-width: "80%"
#| fig-cap: "Adaptiert nach Liljequist et al. (2019)"

knitr::include_graphics('pics/liljequist_2019.png')
```


### Intraclass Correlation in `R`

```{r}
#| echo: true
icc_hat <- psych::ICC(lil[,-1])
icc_hat
```

siehe @liljequist2019, @qin2019

## Spearman-Brown prophecy formula

$$
\rho_{xx'}^* = \frac{K \cdot \rho_{xx'}}{1 + (K-1) \cdot \rho_{xx'}}
$$

```{r}
#| fig-cap: "Einfluss der Wiederholungen auf die Reliabilität für verschiedene $\\rho_{xx'}$"

foo <- function(K,r) { K*r/(1+((K-1)*r)) }
K_r <- tidyr::expand_grid(K = 1:10, r = seq(0.1, 0.9, 0.1)) |> 
  dplyr::mutate(r_star = foo(K,r), r_f = ordered(r))
ggplot(K_r, aes(K,r_star, group=r_f)) +
  geom_line() +
  geom_label(data = K_r |> dplyr::filter(K == 1), aes(label = r), size=2) +
  scale_x_continuous('Anzahl der Wiederholungen K', breaks = 1:10) +
  scale_y_continuous(expression(rho[xx*minute]^"*")) +
  scale_color_discrete(expression(rho[xx*minute])) 
```

## Beispiel aus @guyatt1987 

```{r}
#| tbl-cap: "Messwerte für acht Patienten"
guyatt_1 <- readxl::read_xlsx('data/reliability_01.xlsx',
                              sheet='Instrument AB')
knitr::kable(guyatt_1,
             booktabs = TRUE,
             linesep = "") |> 
  kableExtra::kable_styling(font_size = 7)
```

## Agreement versus Reliability @devet2006

### Agreement 

How close are repeated measurements?

### Reliability

How good can patients be distinguished?

```{r}
#| fig-height: .8 

df <- tibble(
  x = c(0.9,1,1.1, 1.9,2.0,2.1,2.05,2.15,2.25),
  y = 1,
  id = rep(c('A','B','C'), each=3)
)
ggplot(df, aes(x,y,color=id)) +
  geom_point(size=4) +
  scale_x_continuous("", labels=NULL)  +
  scale_y_continuous("", breaks=NULL) +
  theme_minimal() +
  theme(legend.position = 'none')
```


## Standard Error of Measurement 

\begin{align*}
SEM &= \sqrt{\sigma_{error}} \\
SEM_1 &= s_y \sqrt{1 - ICC} \\
SEM_H   &= \frac{s_{d_i}}{\sqrt{2}} 
\end{align*}^[$SEM_H$ = nach @hopkins2000, $s_y$ = Standardabweichung der Messung]



## Limits of Agreement

$\text{loa} = \bar{d}\pm 1.96\ s_d$

```{r}
#| fig-cap: "Bland-Altman Plot der EMG-Frequenzdaten"

lil <- lil |> dplyr::mutate(d = Day_1 - Day_2, m = (Day_1+Day_2)/2)
lil_loa <- dplyr::summarize(lil, d_hat = mean(d), s_d = sd(d), n = dplyr::n(),
                            loa_u = d_hat + 1.96 * s_d,
                            loa_l = d_hat - 1.96 * s_d)
p_loa <- ggplot(lil, aes(m,d)) + 
  geom_point() +
  geom_hline(yintercept = 0, color = 'gray') +
  geom_hline(yintercept = lil_loa$d_hat, linetype = 'dashed') + 
  geom_hline(yintercept = c(lil_loa$loa_u, lil_loa$loa_l),
            linetype = 'dotted') +
  labs(x = 'Mittlere Median EMG Frequenz\n(Day 1 + Day 2)/2',
       y = 'Differenz\nDay 1 - Day 2\nder EMG Frequenzen') 
print(p_loa)
```

### Konfidenzintervalle Limits of agreement 

#### Konfidenzintervall bias

$$
CI95\%_{\text{bias}} = \bar{d} \pm 1.96\frac{s_d}{\sqrt{n}}
$$

#### Konfidenzintervall loa
\begin{align*}
\text{loa} &= \bar{d}\pm 1.96\ s_d \\
Var(\bar{d}\pm1.96\ s_d) &= \left(\frac{1}{n}+\frac{1.96^2}{2(n-1)}\right)s_d^2\approx1.71^2\frac{s_d^2}{n} \\
CI95\%_{\text{loa}} &= \text{loa}\pm q_{t,\alpha,df=n-1}\times 1.71\frac{s_d}{\sqrt{n}}
\end{align*}
^[$s_d$ = Standard deviation of differences]

### Konfidenzintervalle Limits of agreement 

```{r}
#| fig-cap: "Bland-Altman Plot mit Konfidenzintervallen (bias:rot, loa:grün)"

lil_loa <- lil_loa |> dplyr::mutate(bias_c = 1.96*s_d/sqrt(n),
                         loa_c = qt(0.975, n-1)*1.71*s_d/sqrt(n))
with(lil_loa, 
p_loa + 
  geom_ribbon(aes(ymin=d_hat - bias_c, ymax=d_hat + bias_c),
              alpha=0.1, col = 'red', fill='red') +
  geom_ribbon(aes(ymin=loa_u - loa_c, ymax=loa_u + loa_c),
              alpha=0.1, col = 'green', fill='green') +
  geom_ribbon(aes(ymin=loa_l - loa_c, ymax=loa_l + loa_c),
              alpha=0.1, col = 'green', fill='green'))
```


## Smallest Worthwhile Change (SWC)

```{r}
#| fig-cap: "Pre-Pre-Post Design um Limits of Agreement zu bestimmen."

{
s_1 <- 123
set.seed(s_1)
n <- 30
mu_s <- c(10, 10, 11)
R <- matrix(c(1,0.5,0.5,0.5,1,0.5,0.5,0.5,1), nr=3)
S <- diag(rep(0.5,3))
sigma <- S %*% R %*% S
y_i <- MASS::mvrnorm(n, mu_s, sigma)
sigma[3,1] <- sigma[1,3] <- 8;
dat <- tibble::tibble(
  time = rep(1:3, each=n),
  y = c(y_i[,1], y_i[,2], y_i[,3]),
  id = rep(paste('S',1:n), 3)
) |> dplyr::arrange(id)

loa_dat <- dat |> dplyr::filter(time != 3) |> dplyr::group_by(id) |> 
  dplyr::summarize(d_i = diff(y)) |> 
  dplyr::summarize(s_d = sd(d_i), d_hat = mean(d_i))
y_hat_pre_1 <- dat |> dplyr::filter(time == 1) |> dplyr::summarize(m = mean(y))
loa_l <- y_hat_pre_1$m - 1.96 * loa_dat$s_d
loa_u <- y_hat_pre_1$m + 1.96 * loa_dat$s_d
loa_tibl <- tibble::tibble(time = 2:3,
                           ymin = c(loa_l, loa_l),
                           ymax = c(loa_u, loa_u),
                           y = 0)
pos <- position_jitter(seed = s_1, width=.1)
ggplot(dat, aes(time, y)) +
  geom_boxplot(aes(group=time)) +
  geom_ribbon(data = loa_tibl, aes(ymin = ymin, ymax = ymax),
              alpha = 0.1, col = 'red', fill = 'red') +
  geom_point(aes(group=id), position = pos) +
  geom_line(aes(group=id), position=pos, linetype='dotted') + 
  scale_x_continuous('Zeit', breaks=1:3, label=c('Pre_0','Pre','Post')) +
  scale_y_continuous('Abhängige Variable', labels=NULL) 
}
```

## Analytical goal

## Zum Nachlesen 

| Übersicht: @atkinson1998, @baumgartner1989
| Limits of agreement: @bland1999, @atkinson2000
| Analytical goal: @brown2007, @atkinson1998, @fraser1990
| SEM: @denegar1993

