# Reliabilität

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```


```{r}
```

```{r reliability_defs}
lil <- readr::read_delim('data/lilquist_2021_tbl_05.txt',
                         delim = ' ')
lil_w <- lil |> tidyr::pivot_longer(-Subject,
                                    names_to = 'day',
                                    values_to = 'emg')
```

## Accuracy vs. Precision

```{r}
#| fig-cap: "Genauigkeit vs. Präzision"

knitr::include_graphics('pics/accuracy_precision.png')
```

## Woher Reliabilität?

In @tbl-ed-rel-emg sind EMG-Daten aus @lijequist2019 abgetragen.

```{r}
#| tbl-cap: "Beispieldaten von Lijequist (2019), EMG Median Frequenz (Hz), linke lumbale Rückenmuskulator über drei Tage"
#| label: tbl-ed-rel-emg

lil |> knitr::kable(
             linesep = '',
             col.names = c('Subject','Day 1', 'Day 2', 'Day 3'))
```

Es wurden insgesamt $N = 10$ Personen an drei Tagen jeweils an der gleichen Stelle an der Rückenmuskulatur gemessen um abzuschätzen wie ähnlich die Messungen sind. In @fig-ed-rel-emg sind die Daten graphisch dargestellt.

```{r}
#| fig-cap: "EMG Daten nach Liljequist et al. (2019). Die roten Punkte sind die Mittelwerte mit Standardabweichungen, schwarze gestrichtelte Linien sind die einzelnen Personen."
#| label: fig-ed-rel-emg

lil_hat <- lil_w |> dplyr::group_by(day) |> 
  dplyr::summarize(m = mean(emg),
            s = sd(emg),
            Subject = 11)
ggplot(lil_w, aes(day, emg, group=Subject)) +
  geom_pointrange(data = lil_hat,
                  aes(y = m, ymin = m - s, ymax = m + s),
                  size = 1.4, col = 'red') +
  geom_line(position = position_jitter(seed = 123, width=.05), linetype='dashed') +
  geom_point(position = position_jitter(seed = 123, width=.05), size=3) +
  scale_x_discrete('Messzeitpunkt', labels = paste('Tag', 1:3)) +
  labs(y = 'Median EMG Frequenz') 
```

Wie in @fig-ed-rel-emg zu sehen ist, schwanken die Werte über die drei Messzeitpunkte. Einmal innerhalb der Personen sind Unterschied zu erkennen, aber auch die Mittelwerte verändern sich über die Messzeitpunkte. D.h. die gewählte Messmethodik weist selbst schon Schwankungen auf. Die Schwankungen müssen aber bei der Erstellung eines Untersuchungsdesigns berücksichtigt werden. Sollen beispielsweise Unterschiede zwischen zwei Gruppen mit Hilfe dieser Messmethodik untersucht werden, die zu erwartenden Unterschiede bewegen sich in der Größenordnung der Schwankungen oder liegen vielleicht sogar darunter, dann wird es sehr schwierig bis unmöglich diese Unterschiede im Experiment nachweisen zu können. Diese ungewollten Schwankungen sind einer Funktion der *Reliabilität* der Messmethodik. Ohne eine Kenntnis der Reliabilität einer Methodik ist tatsächlich die Durchführung einer experimentellen Untersuchung immer ein Stück weit Kaffeesatzlesen.

## Reliabilität - Modell 

Um sich der Reliabilität inhaltlich zu nähern ist zunächst die Erstellung eines theoretischen Modells erforderlich. Soll ein *Wert* bestimmt werden, der die Eigenschaft eines Objekts beschreibt, dann ist eine plausible Annahme das es einen *wahren* Wert gibt. Zum Beispiel ist direkt einsichtig, dass ein gegebener Holzstab eine bestimmte Länge hat. Oder eine Hantelscheibe hat ein bestimmtes Gewicht. Solange keine Manipulation an der Scheibe durchgeführt wird, sollte sich dieses Gewicht nicht ändern. Diesen Wert soll nun als *true-score* bezeichnet werden und er erhält das Zeichen $\tau$. Während $\tau$ für eine Hantelscheibe noch relativ direkt einsichtig ist, ist dies nicht mehr ganz so einfach sobald biologische Objekte ins Spiel kommen. Soll beispielsweise die Körpergröße einer Person bestimmt werden, dann ist klar das die Körpergröße keine feststehende Größe ist, sondern im Verlauf eines Tages einer Schwankung unterliegt [@tyrrell1985]. In @fig-ed-rel-height ist beispielsweise die Veränderung über einen Tag abgetragen.

```{r}
#| fig-cap: "Veränderung der Körpergröße über den Tag (adaptiert nach Tyrrell et al. (1985))."
#| label: fig-ed-rel-height

height <- tibble(
  time = c(0, 3.2, 7, 8, 9, 10, 12, 15.5, 20, 24),
  height = c(3.5, 16.8, 22, 13.9, 11.6, 8.6, 5.86, 4.4, 3.94, 3.9)
)
ggplot(height, aes(time,height)) +
  geom_line() + 
  geom_point() +
  scale_x_continuous('Zeit nach Mitternacht [Stunden]', breaks=seq(0,24,2)) +
  scale_y_continuous('Höhenveränderung\nzu Mitternacht [mm]')
```

Es soll nun aber davon ausgegangen werden das der wahre Wert $\tau$ wohldefiniert ist. Dann besteht aber nach wie vor das Problem, selbst bei der Hantelscheibe, dass dieser Wert mit Hilfe eines Messmethodik bestimmt werden muss. Zum Beispiel im Fall der Hantelscheibe muss eine Waage verändert werden um das Gewicht zu bestimmen. Diese Waage ist aber selbst unweigerlich mit *Messfehlern* behaftet. Vielleicht ist bei der Eichung was schief gegangen, vielleicht ist die Feder mit Zeit ausgeleiert, oder die Umgebungstemperatur entspricht nicht den Vorgaben usw. und sofort. Das führt dazu, dass der *gemessene* Wert nicht gleich dem wahren Wert $\tau$ entspricht. Um den gemessenen Wert vom wahren Wert zu unterscheiden wird ein weiteres Symbol $Y$ verwendet. $Y$ ist dementsprechend der *beobachtete* Wert. Die Messfehler werden weiterhin mit dem Symbol $\epsilon$ bezeichnet. Dies führt insgesamt zu folgendem Modell:

\begin{equation}
Y = \tau + \epsilon
\end{equation}

D.h. der beobachtete Wert $Y$ setzt sich zusammen aus dem wahren Wert $\tau$ und dem Messfehler $\epsilon$ der additiv wirkt. Eine weitere Annahme soll nun dahin gehend bestehen, die Messfehler zufällig sind und bei wiederholter Messung im *Mittel* gleich $0$ sind. Formal ist der Erwartungswert $E[\epsilon_0] = 0$ und es besteht keine Zusammenhang zwischen der Größe des Messfehlers und der Größe von $\tau$. Beispielsweise bei der Messung der Körpergröße verändert sich die Größe des Messfehlers nicht mit der Größer der Probandinnen sondern bleibt konstant. Formal führt dies zu $\text{Cov}(\epsilon,\tau) = 0$.

Werden nun mehrere bzw. $N$ Messungen durchgeführt dann wird entsprechend nur ein einzelner Wert beobachtet sondern eine Menge von Werten. Um diese zu unterschieden wird entsprechend ein Index $i$ eingeführt.

\begin{equation}
Y_i = \tau_i + \epsilon_i, \quad i \in [1,\ldots,N]
\end{equation}

Sobald nun mehrere Werte zur Verfügung stehen, kann für diese beobachteten Wert $Y_i$ eine Varianz berechnet werden und, zumindest theoretisch, auch eine Varianz für die $\tau_i$s berechnet werden. Dies ermöglicht nun eine formale Definition der Reliabilität zu erhalten.

::: {#def-reliability}
## Reliabilität - Definition 

Die Reliabilität ist definiert als das Verhältnis der Varianz der *True-Score-Variablen* $\sigma_{\tau}$ zur *Gesamtvarianz* der Testvariablen $\sigma_{Y}$. [@moosbrugger2020, p.282]

\begin{equation}
\text{Rel} = \frac{\sigma_{\tau}^2}{\sigma_{Y}^2} = \frac{\sigma_{\tau}^2}{\sigma_{\tau}^2+\sigma_{\epsilon}^2}
\end{equation}

Der Wertebereich der Reliabilität liegt in $\text{Rel} \in [0,1]$ wobei eine Wert $0$ gar keine Reliabilität anzeigt, während ein Wert von $\text{Rel} = 1$ auf eine perfekte Reliabilität hindeutet.
:::

Für die Interpretation der Reliabilität hat sich in der Literatur eine Kategorisierung entlang der Wert in @tbl-ed-rel-interpretation etabliert.

| Bereich | Interpretation |
| --- | --- |
| $<0.5$ | poor |
| $0.5-0.75$ | moderate |
| $0.75-0.9$ | good |
| $>0.9$ | excellent |

: Interpretation der Reliablität nach @koo2016 {#tbl-ed-rel-interpretation}

## Reliabilität - Terminologie^[@baumgartner1989[p.46]]{.t}

### Relative reliability (Consistency)

Degree to which people maintain their position (rank)

- internal consistency reliability: within day
- stability reliability: between days
- rater reliability (objectivity): between raters

### Absolute reliability (Agreement)

Degree to which people's score do not change in magnitude or value

## Intraclass correlation coefficient

\begin{equation*}
ICC = \frac{\text{variance of interest}}{\text{variance of interest} + \text{unwanted variance}}
\end{equation*}

## Data model

| Subject  | Judge 1 | Judge 2 | $\cdots$ | Judge k | Mean |
| --- | --- | --- | --- | --- | --- |
| 1 | $x_{11}$ | $x_{12}$ | $\cdots$ | $x_{1k}$ | $S_1$ |
| 2 | $x_{21}$ | $x_{22}$ | $\cdots$ | $x_{2k}$ | $S_1$ |
| $\vdots$ |$\vdots$ |$\vdots$ | |$\vdots$ |$\vdots$ |
| n | $x_{n1}$ | $x_{n2}$ | $\cdots$ | $x_{nk}$ |  $S_n$ |
| Mean | $M_1$ | $M_2$ | $\cdots$ | $M_k$ | $\bar{x}$ |

## Varianzkomponenten

Ansatz: Die Gesamtvarianz in verschiedene Komponenten aufspalten (ANOVA)

Modell:
\begin{align*}
x_{ij} &= \mu + r_i + c_j + e_{ij} \\
r_i &\sim \mathcal{N}(0,\sigma_r) \\
c_j &\sim \mathcal{N}(0,\sigma_c) \\
e_{ij} &\sim \mathcal{N}(0,\sigma_e)
\end{align*}


## Berechnung der Varianzkomponenten^[Terminologie nach @liljequist2019]
\small
| SSQ  | Bezeichnung | Berechnung |  MSQ |
| -- | ---- | ---- | -- | 
| SST | Total | $\sum_{i=1}^n\sum_{j=1}^k (x_{ij} - \bar{x})^2$ | $\frac{SST}{n\cdot k-1}$ |
| SSBS | Between Subject | $\sum_{i=1}^n\sum_{j=1}^k (S_i - \bar{x})^2$ | $\frac{SSBS}{n-1}$ |
| SSBM | Between Measurement | $\sum_{i=1}^n\sum_{j=1}^k (M_j - \bar{x})^2$ | $\frac{SSBM}{k-1}$ |
| SSWS | Within Subject | $\sum_{i=1}^n\sum_{j=1}^k (x_{ij} - S_i)^2$ | $\frac{SSWS}{n\cdot(k-1)}$ |
| SSWM | Within Measurements | $\sum_{i=1}^n\sum_{j=1}^k (x_{ij} - M_j)^2$ | $\frac{SST}{k\cdot (n-1)}$ |

$SSE = SST - SSBS - SSBM$ Error $MSE = \frac{SSE}{(n-1)\cdot (k-1)}$

## Intraclass Correlation - Modelle

:::: {.columns}
::: {.column}
```{r}
#| fig-cap: Modell 1

knitr::include_graphics('pics/reliability_model_1.png')
```

:::
::: {.column}
```{r}
#| fig-cap: Modell 2

knitr::include_graphics('pics/reliability_model_2.png')
```

:::
::::

## Intraclass Correlation - Modelle

| Bezeichnung | Modell | Expected Mean Squares |
| --- | -------- | ----- |
| Model 1 | $x_{ij} = \mu + \underbrace{r_i + e_{ij}}_{\text{zufällig}}$|  $MSBM \approx \sigma_e^2$ |
| Model 2 | $x_{ij} = \mu + \underbrace{r_i + \overbrace{c_j}^{bias} + e_{ij}}_{\text{zufällig}}$  | $MSBM \approx n\cdot \sigma_c^2 + \sigma_e^2$ |
| Model 3 | $x_{ij} = \mu + \underbrace{r_i}_{\text{zufällig}} + \overbrace{c_j}^{\text{fixed}} + \underbrace{e_{ij}}_{\text{zufällig}}$ | $MSBM \approx n\cdot \theta_c^2 + \sigma_e^2$ | 

: Übersicht über die Modelle

## Intraclass Correlation $\rho_1$

### Model 1 ICC(1)
\begin{equation*}
\rho_1 = \frac{\sigma_r^2}{\sigma_r^2+\sigma_e^2} 
\end{equation*}

\begin{equation*}
ICC(1) = \frac{MSBS - MSWS}{MSBS + (k-1)MSWS}
\end{equation*}

## Intraclass Correlation $\rho_2$ Modell 2

\small
### Model 2 ICC(A,1) Absolute
\begin{align*}
\rho_{2A} &= \frac{\sigma_r^2}{\sigma_r^2+\sigma_c^2 + \sigma_e^2}  \\
ICC(A,1) &= \frac{MSBS - MSE}{MSBS + (k-1)MSE + \frac{k}{n}(MSBM-MSE)}
\end{align*}

### Model 2 ICC(C,1) Consistency
\begin{align*}
\rho_{2C} &= \frac{\sigma_r^2}{\sigma_r^2 + \sigma_e^2} \\
ICC(C,1) &= \frac{MSBS - MSE}{MSBS + (k-1)MSE}
\end{align*}

## Intraclass Correlation $\rho_3$ Model 3 
\small
### ICC(A,1) Absolute
\begin{align*}
\rho_{3A} &= \frac{\sigma_r^2}{\sigma_r^2 + \theta_c^2 + \sigma_e^2}  \\
ICC(A,1) &= \frac{MSBS - MSE}{MSBS + (k-1)MSE + \frac{k}{n}(MSBM-MSE)}
\end{align*}

### ICC(C,1) Consistency
\begin{align*}
\rho_{3C} &= \frac{\sigma_r^2}{\sigma_r^2 + \sigma_e^2} \\
ICC(C,1) &= \frac{MSBS - MSE}{MSBS + (k-1)MSE}
\end{align*}

## ICC - Übersicht

```{r}
#| out-width: "80%"
#| fig-cap: "Adaptiert nach Liljequist et al. (2019)"

knitr::include_graphics('pics/liljequist_2019.png')
```


## Intraclass Correlation in `R`
\tiny
```{r}
#| echo: true
icc_hat <- psych::ICC(lil[,-1])
icc_hat
```

^[siehe @liljequist2019, @qin2019]

## Spearman-Brown prophecy formula

$$
\rho_{xx'}^* = \frac{K \cdot \rho_{xx'}}{1 + (K-1) \cdot \rho_{xx'}}
$$

```{r}
#| fig.cap="Einfluss der Wiederholungen auf die Reliabilität für verschiedene $\\rho_{xx'}$",
#| fig.height=2

foo <- function(K,r) { K*r/(1+((K-1)*r)) }
K_r <- tidyr::expand_grid(K = 1:10, r = seq(0.1, 0.9, 0.1)) |> 
  dplyr::mutate(r_star = foo(K,r), r_f = ordered(r))
ggplot(K_r, aes(K,r_star, group=r_f)) +
  geom_line() +
  geom_label(data = K_r |> dplyr::filter(K == 1), aes(label = r), size=2) +
  scale_x_continuous('Anzahl der Wiederholungen K', breaks = 1:10) +
  scale_y_continuous(expression(rho[xx*minute]^"*")) +
  scale_color_discrete(expression(rho[xx*minute])) 
```

## Beispiel aus @guyatt1987 

```{r}
#| tbl-cap: "Messwerte für acht Patienten"
guyatt_1 <- readxl::read_xlsx('data/reliability_01.xlsx',
                              sheet='Instrument AB')
knitr::kable(guyatt_1,
             booktabs = TRUE,
             linesep = "") |> 
  kableExtra::kable_styling(font_size = 7)
```

## Agreement versus Reliability @devet2006

### Agreement 

How close are repeated measurements?

### Reliability

How good can patients be distinguished?

```{r}
#| fig-height: .8 

df <- tibble(
  x = c(0.9,1,1.1, 1.9,2.0,2.1,2.05,2.15,2.25),
  y = 1,
  id = rep(c('A','B','C'), each=3)
)
ggplot(df, aes(x,y,color=id)) +
  geom_point(size=4) +
  scale_x_continuous("", labels=NULL)  +
  scale_y_continuous("", breaks=NULL) +
  theme_minimal() +
  theme(legend.position = 'none')
```


## Standard Error of Measurement 

\begin{align*}
SEM &= \sqrt{\sigma_{error}} \\
SEM_1 &= s_y \sqrt{1 - ICC} \\
SEM_H   &= \frac{s_{d_i}}{\sqrt{2}} 
\end{align*}^[$SEM_H$ = nach @hopkins2000, $s_y$ = Standardabweichung der Messung]



## Limits of Agreement $\text{loa} = \bar{d}\pm 1.96\ s_d$ ^[@bland1999]

```{r}
#| fig-cap: "Bland-Altman Plot der EMG-Frequenzdaten"
#| fig-height: 2

lil <- lil |> dplyr::mutate(d = Day_1 - Day_2, m = (Day_1+Day_2)/2)
lil_loa <- dplyr::summarize(lil, d_hat = mean(d), s_d = sd(d), n = dplyr::n(),
                            loa_u = d_hat + 1.96 * s_d,
                            loa_l = d_hat - 1.96 * s_d)
p_loa <- ggplot(lil, aes(m,d)) + 
  geom_point() +
  geom_hline(yintercept = 0, color = 'gray') +
  geom_hline(yintercept = lil_loa$d_hat, linetype = 'dashed') + 
  geom_hline(yintercept = c(lil_loa$loa_u, lil_loa$loa_l),
            linetype = 'dotted') +
  labs(x = 'Mittlere Median EMG Frequenz\n(Day 1 + Day 2)/2',
       y = 'Differenz\nDay 1 - Day 2\nder EMG Frequenzen') 
print(p_loa)
```

## Konfidenzintervalle Limits of agreement 

### Konfidenzintervall bias

$$
CI95\%_{\text{bias}} = \bar{d} \pm 1.96\frac{s_d}{\sqrt{n}}
$$

### Konfidenzintervall loa
\begin{align*}
\text{loa} &= \bar{d}\pm 1.96\ s_d \\
Var(\bar{d}\pm1.96\ s_d) &= \left(\frac{1}{n}+\frac{1.96^2}{2(n-1)}\right)s_d^2\approx1.71^2\frac{s_d^2}{n} \\
CI95\%_{\text{loa}} &= \text{loa}\pm q_{t,\alpha,df=n-1}\times 1.71\frac{s_d}{\sqrt{n}}
\end{align*}
^[$s_d$ = Standard deviation of differences]

## Konfidenzintervalle Limits of agreement 

```{r}
#| fig-cap: "Bland-Altman Plot mit Konfidenzintervallen (bias:rot, loa:grün)"

lil_loa <- lil_loa |> dplyr::mutate(bias_c = 1.96*s_d/sqrt(n),
                         loa_c = qt(0.975, n-1)*1.71*s_d/sqrt(n))
with(lil_loa, 
p_loa + 
  geom_ribbon(aes(ymin=d_hat - bias_c, ymax=d_hat + bias_c),
              alpha=0.1, col = 'red', fill='red') +
  geom_ribbon(aes(ymin=loa_u - loa_c, ymax=loa_u + loa_c),
              alpha=0.1, col = 'green', fill='green') +
  geom_ribbon(aes(ymin=loa_l - loa_c, ymax=loa_l + loa_c),
              alpha=0.1, col = 'green', fill='green'))
```


## Smallest Worthwhile Change (SWC)

```{r}
#| fig-cap: "Pre-Pre-Post Design um Limits of Agreement zu bestimmen."
#| fig-height: 2.5

{
s_1 <- 123
set.seed(s_1)
n <- 30
mu_s <- c(10, 10, 11)
R <- matrix(c(1,0.5,0.5,0.5,1,0.5,0.5,0.5,1), nr=3)
S <- diag(rep(0.5,3))
sigma <- S %*% R %*% S
y_i <- MASS::mvrnorm(n, mu_s, sigma)
sigma[3,1] <- sigma[1,3] <- 8;
dat <- tibble::tibble(
  time = rep(1:3, each=n),
  y = c(y_i[,1], y_i[,2], y_i[,3]),
  id = rep(paste('S',1:n), 3)
) |> dplyr::arrange(id)

loa_dat <- dat |> dplyr::filter(time != 3) |> dplyr::group_by(id) |> 
  dplyr::summarize(d_i = diff(y)) |> 
  dplyr::summarize(s_d = sd(d_i), d_hat = mean(d_i))
y_hat_pre_1 <- dat |> dplyr::filter(time == 1) |> dplyr::summarize(m = mean(y))
loa_l <- y_hat_pre_1$m - 1.96 * loa_dat$s_d
loa_u <- y_hat_pre_1$m + 1.96 * loa_dat$s_d
loa_tibl <- tibble::tibble(time = 2:3,
                           ymin = c(loa_l, loa_l),
                           ymax = c(loa_u, loa_u),
                           y = 0)
pos <- position_jitter(seed = s_1, width=.1)
ggplot(dat, aes(time, y)) +
  geom_boxplot(aes(group=time)) +
  geom_ribbon(data = loa_tibl, aes(ymin = ymin, ymax = ymax),
              alpha = 0.1, col = 'red', fill = 'red') +
  geom_point(aes(group=id), position = pos) +
  geom_line(aes(group=id), position=pos, linetype='dotted') + 
  scale_x_continuous('Zeit', breaks=1:3, label=c('Pre_0','Pre','Post')) +
  scale_y_continuous('Abhängige Variable', labels=NULL) 
}
```

## Analytical goal

## Zum Nacharbeiten

### Übersicht
@atkinson1998, @baumgartner1989

### Limits of agreement
@bland1999, @atkinson2000

### Analytical goal
@brown2007, @atkinson1998, @fraser1990

### SEM
@denegar1993
