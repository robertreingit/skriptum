# Completely Randomized Design 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
#source('../resources/nice_format_helper_fcn.R')
n <- 20
k <- 3
set.seed(11)
kaffee <- tibble(
  Zeit = rnorm(k*n, rep(c(1917,1927,1927), each=n), 8),
  Gruppe = gl(k,n,labels=c('Koffein','Placebo','Control'))
)
```

Das erste experimentelle Design, das wir uns anschauen, ist das completeley randomized design. Wir haben unterschiedliche experimentelle Konditionen von denen wir ausgehen, dass diese sich unterschiedlich auf die experimentellen units (EU) auswirken. Beispielsweise wollen wir die Balancierfähigkeit unter drei verschiedenen Konditionen untersuchen, z.B. auf festem Untergrund, auf weichem Untergrund und auf wackeligen Untergrund. Die Balancierfähigkeit ist aber auch durch zahlreiche andere Einflussfaktoren beeinflusst, z.B. Vorerfahrung, Kraftfähigkeit etc. Viele von diesen kennen wir vielleicht gar nicht bzw. für diese zu kontrollieren wäre zu aufwendig. Um diese Störgrößen zu *kontrollieren* setzen wir Randomisierung ein. Jeder einzelne Versuchsteilnehmer bzw. Versuchsteilnehmerinn soll daher randomisiert auf **eine** der drei Kondition verteilt werden. Damit werden die Teilnehmer(innen) zu den EUs. Nach Durchsicht der Literatur könnte die Balancierfähigkeit z.B. mit einer Kraftmessplatte erfasst werden. Hieran schließt sich noch die Festsetzung der observational units, d.h. in diesem Falle, der Anzahl der Messwiederholungen an um die Reliabität auf ein gewünschtes Niveau zu heben. Diesen Teil vernachlässigen wir zunächst einmal.

## Das Modell 

Um diesem Design ein statistisches Modell anzupassen, müssen wir uns nun Gedanken über den DGP machen. Zunächst einmal wird jede(r) Teilnehmer(in) eine bestimmte Balancierfähigkeit haben. Bzw. wenn wir die Kondition mit dem festen Untergrund als eine Referenzkondition festlegen, können wir davon ausgehen, dass es eine mittlere Balancierfähigkeit gibt und die einzelnen Personen aus der Population um diesen Mittelwert schwanken. Dieser Mittelwert bekommt einen eigenen Parameter $\mu$. Jetzt gegen wir davon  aus, dass die unterschiedlichen Konditionen dazu führen, dass die *Basisbalancierfähigkeit* von den Konditionen beeinflusst wird. D.h. es kommt zu einer Veränderung oder Abweichung von $\mu$. Diese Abweichungen bezeichnen wird mit $\tau_i$ wobei der Index $i$ dann die jeweilige Kondition $i$ kennzeichnet. Insgesamt führt dies zu dem Modell:


\begin{equation}
Y_{ij} = \mu + \tau_i + \epsilon_{ij}, \qquad \epsilon_{ij}\sim \mathcal{N}(0,\sigma^2)
\label{eq-ed-crd-model}
\end{equation}

i = Gruppenindikator, j = experimental unit-indikator, $\mu$ = Gesamtmittelwert, \mbox{$\tau_i$ = Einfluss der $i$-ten Stufe}

Natürlich brauchen wir Replikationen um den Einfluss $\tau_i$ der Konditionen zu bestimmen. Diese Replikationen, in unsererm Fall die Versuchspersonen, bekommen den Index $j$.

Die Annahmen des Modells sind dabei:

- Unabhängige Experimental Units (EU) 
- Die EUs sind **zufällig** in die k Gruppen eingeteilt worden
- Die Varianzen $\sigma_i^2$ in jeder Gruppe $i$ sind gleich 
- Die Werte in jeder Gruppe sind Normalverteilt $Y_{ij} \sim \mathcal{N}(\mu_i, \sigma)$

Die statistische Überprüfung führen wir nun wieder mit dem uns bekannten Modellvergleichen durch. Das Modell \eqref{eq-ed-crd-model} wird als das Full Model angesehen und wir definieren das reduzierte Modell mittels:

\begin{equation*}
Y_{ij} = \mu + \epsilon_{ij}
\end{equation*}

Dementsprechend folgt als Teststatistik

$$
F = \frac{\textrm{SSE(R)} - \textrm{SSE(F)}}{\textrm{df}_R - \textrm{df}_F} \frac{\textrm{df}_F}{\textrm{SSE(F)}} \sim F(\textrm{df}_R-\textrm{df}_F,\textrm{df}_F)
$$

mit den statistische Hypothesen:

\begin{align*}
H_0:& \tau_1 = \tau_2 = \ldots = \tau_k = 0 \\
H_1:& \exists\tau_i \neq \tau_j\ \textrm{mit}\ i \neq j, i,j \in \{1,2,\ldots,k\}
\end{align*}

D.h. wir überprüfen ob die Hinzunahme der Information über die Konditionen (Faktoren) zu einer statistisch signifikanten Verminderung der Residualvarianz führt. Wenn dem nicht der Fall, dann verbessert sich der Modellfit durch die Faktorstufen $\tau_i$ nicht. 

### Verbindung Modellhierarchien und BA-ANOVA

Im Bachelor wurde das completely randomized design aller Wahrscheinlichkeit nach unter der Bezeichnung Einfaktorielle ANOVA eingeführt. Was eigentlich nicht viel Sinn macht, da es sich bei der einfaktoriellen ANOVA um eine Analysemethode und streng genommen nicht um ein experimentelles Design handelt. Wenn wir die folgenden beiden Identitäten berücksichtigen. 

\begin{equation}
\sum_i (y_i - \hat{y}) = \sum_i y_i - n \hat{y} = n \hat{y} - n \hat{y} = 0 
\label{eq-ed-crd-bar-sum}
\end{equation}

\begin{align}
\begin{split}
\sum_i \sum_j 2 (y_{ij} - \hat{y}_j)(\hat{y}_j - \hat{y}) &= \sum_j \sum_i 2 (y_{ij} - \hat{y}_j)(\hat{y}_j - \hat{y}) \\
&= 2 \sum_j (\hat{y}_j - \hat{y}) \underbrace{\sum_i (y_{ij} - \hat{y}_j)}_{\text{mit} ~(\ref{eq-ed-crd-bar-sum})=0}\\
&= 2 \sum_j (\hat{y}_j - \hat{y}) 0  = 0 \\
\end{split}
\label{eq-ed-crd-cross-sum}
\end{align}

Dann können wir $SS_{\text{total}}$ nach dem folgenden Muster aufspalten.

\begin{align}
\begin{split}
\underbrace{\sum_i \sum_j (y_{ij} - \hat{y})^2}_{SS_{\text{Total}}} &= \sum_i \sum_j (y_{ij} - \hat{y}_j + \hat{y}_j - \hat{y})^2 \\ &= \sum_i \sum_j (y_{ij} - \hat{y}_j)^2 + \sum_i \sum_j (\hat{y}_j - \hat{y})^2 - \underbrace{\sum_i \sum_j 2 (y_{ij} - \hat{y}_j)(\hat{y}_j - \hat{y})}_{\text{mit}~(\ref{eq-ed-crd-cross-sum})=0}\\
&= \underbrace{\sum_i \sum_j (y_{ij} - \hat{y}_j)^2}_{SS_{\text{Error}}} + \underbrace{\sum_i \sum_j (\hat{y}_j - \hat{y})^2}_{SS_{\text{Regression}}} 
\end{split}
\label{eq-ed-crd-sse-total}
\end{align}

D.h. wir erhalten die schon bekannte Aufteilung in $SS_{\text{Error}}$ und $SS_{\text{Regression}}$ die uns in der Herleitung von $R^2$ begegnet ist. Ziehen wir jetzt $SSE(R) - SSE(F)$ voneinander ab.

\begin{align*}
SSE(R) - SSE(F) &= \sum_i \sum_j (y_{ij} - \hat{y})^2 - \sum_i \sum_j (y_{ij} - \hat{y}_j)^2 \\
 &= \underbrace{\sum_i \sum_j (y_{ij} - \hat{y}_j)^2 + \sum_i \sum_j (\hat{y}_j - \hat{y})^2}_{\text{mit}~\eqref{eq-ed-crd-sse-total}}  - \sum_i \sum_j (y_{ij} - \hat{y}_j)^2 \\
 &= \sum_i \sum_j (\hat{y}_j - \hat{y})^2 \\
\end{align*}

Dann ist dies der gleiche Term wir ihn in der BA-ANOVA Vorlesung gesehen haben und der dort als $QS_{\text{zwischen}}$ bezeichnet worden ist.

\begin{equation*}
QS_{zwischen} = \sum_{j=1}^K \sum_{i=1}^{N_j} (\bar{x}_{j}-\bar{x})^2
\end{equation*}

Letztendlich kommen wir daher mit dem Ansatz der Modellvergleiche zum gleichen Ergebnis, aber wieder mit dem Vorteil, das das Verfahren der Modellvergleiche leichter zu verallgemeinern ist.

## Beispieldaten

Schauen wir uns als nächstes einen Beispieldatensatz an und gehen durch die verschiedenen Schritte der Analyse eines CRD.

In @fig-ed-crd-coffeine-01 ist das Ergebnis einer Untersuchung zum Einfluss von Koffein auf die Laufleistung bei einem 8Km Ausdauerlauf zu abgebildet. Insgesamt sind $N=60$ Probanden randomisiert in drei Gruppen eingeteilt worden: Koffein, Placebo und Control. Die Gruppe Koffein hat vor dem Lauf ein Koffeinpräparat eingenommen, während die Placebogruppe ein Präparat ohne Wirkstoff eingenommen hat. Die Kontrollgruppe hat vor dem Lauf kein Zusatzpräparat eingekommen. Jeder Proband lief einmal die Strecke von $8$ Km so schnell wie möglich. Die abhängige Variable war die Laufzeit.

```{r}
#| fig-cap: "Einfluss von Koffeine auf die Laufleistung über 8km"
#| label: fig-ed-crd-coffeine-01

ggplot(kaffee, aes(Gruppe, Zeit)) +
  geom_boxplot() + 
  geom_jitter(width = 0.2, color = 'red', size = 2, alpha=.5) +
  labs(y = 'Zeit [s]',
       x = 'Gruppe') 
```

@fig-ed-crd-coffeine-01 deute an, das die Einnahme von Koffein zu einer Leistungsverbesserung führt, während der Einfluss des Placebos scheinbar möglicherweise nur zu einer leichten Verbesserung gegenüber der Kontrollkondition geführt hat.

Schauen wir uns die deskriptive Statistik der Daten an. In @tbl-ed-crd-coffeine-01 sind die deskriptiven Werte der Daten abgebildet.

```{r}
#| results: asis
#| label: tbl-ed-crd-coffeine-01
#| tbl-cap: "Deskriptive Statistiken der Koffeinstudie."

kaffee |> group_by(Gruppe) |>  
  summarytools::descr(stats = c('mean','med','sd','q1','q3'), plain.ascii = F,
                      style='rmarkdown', headings = FALSE) 
```



In `R` können wir uns eine die deskriptive Statistik der Daten mittels Funktionen aus dem Paket `summarytools` erstellen.

```{r, echo=T, eval=F}
kaffee |> group_by(Gruppe) |> 
  descr(stats = c('q1','mean','med','q3','sd'))
```




## Analyse in R mit `lm()`
\small
```{r, echo=T, results="hide"}
mod_lm <- lm(Zeit ~ Gruppe, data = kaffee)
summary(mod_lm)
```
```{r}
lm_tbl_knitr(mod_lm)
```

## Analyse in R mit `lm()`
```{r, echo=T, eval=F}
anova(mod_lm)
```
```{r}
lm_anova_tbl_knitr(anova(mod_lm))
```


## Analyse in R mit `aov()`
\small
```{r, echo=T, results="hide"}
mod_aov <- aov(Zeit ~ Gruppe, data = kaffee)
summary(mod_aov)
```
```{r}
broom::tidy(mod_aov) |> 
  knitr::kable(booktabs=T, digits=2,
               col.names = c('', 'DF', 'SSQ', 'MSQ', 'F', 'p'),
               caption='Summarytabelle von aov()')
```

## F-Tabelle Terminologie 

Table: Bezeichungen F-Tabelle

|   | DF | SSQ | MSQ | F | 
| --- | --- | --- | --- | :---: | 
| Between | $df_b$ | $SS_b$ | \mbox{$MS_b=\frac{SS_b}{df_b}$} | $\frac{MS_b}{MS_w}$  | 
| Residual | $df_w$ | $SS_w$ | \mbox{$MS_w=\frac{SS_w}{df_w}$} |  |
| Total | $df_{\text{total}}$ | $SS_{\text{total}}$ | $MS_{\text{total}}$ | |

## Plot of dummy variable model $y_{ij} = \mu+ \tau_2^* x_{1j} + \tau_3^* x_{2j} + \epsilon_{ij}$

```{r}
#| out.width="50%",
#| fig.asp=1.1,
#| fig.cap="Fitted planes for the reduced (blue) and the full (red) model"

mod_p <- lm(Zeit ~ Gruppe, kaffee)
X <- model.matrix(mod_p)
coefs <- coef(mod_p)
df <- tibble(
  x1 = c(0,1,0),
  x2 = c(0,0,1),
  y = c(coefs[1], sum(coefs[1:2]), sum(coefs[-2]))
)
s3d <- scatterplot3d::scatterplot3d(X[,2],X[,3],kaffee$Zeit, type='h', color='green', pch=16,
                     xlab=expression(x[1]),
                     ylab=expression(x[2]),
                     zlab='Zeit[s]',
                     x.ticklabs = c(0,1),
                     y.ticklabs = c(0,1),
                     lab = c(1,1,1),
                     scale.y=0.5,
                     angle=55,
                     cex.lab=1.4,
                     cex.axis=1.2,
                     mar=c(3,3,1,2),
                     box=F)
s3d$plane3d(coefs[1], coefs[2], coefs[3], col='blue',
            draw_polygon=T,
            polygon_args = list(col = rgb(1,0,0,.2)))
s3d$plane3d(mean(kaffee$Zeit), 1, 1, col='red',
            draw_polygon=T,
            polygon_args = list(col = rgb(0,0,1,.2)))
s3d$points3d(df, color='black', pch=16, cex=2)
```

## Voraussetzungen überprüfen bzw. Modelldiagnose


```{r}
#| fig.cap="Residuendiagnostik für einfache $\\hat{\\epsilon}_i$ und standardisierte $\\hat{\\epsilon}_{Si}$ Residuen.",
#| fig.width=4.5,

require(patchwork)
kaffee <- broom::augment(mod_lm, kaffee)
p1 <- ggplot(kaffee, aes(.fitted, .resid)) +
  geom_hline(yintercept = 0, color = 'red', linetype = 'dashed') +
  geom_point() +
  labs(x = expression(hat(y)[i]), y = expression(hat(epsilon)[i])) 
p2 <- ggplot(kaffee, aes(.fitted, .std.resid)) +
  geom_hline(yintercept = 0, color = 'red', linetype = 'dashed') +
  geom_point() +
  labs(x = expression(hat(y)[i]), y = expression(hat(epsilon)[Si])) 
p1 + p2
```

## Einfache Residuen im QQ-Plot

```{r}
#| fig.cap="qqplot der einfachen Residuen"

ggplot(kaffee, aes(sample=.resid)) +
  geom_qq() +
  geom_qq_line() +
  labs(x = 'Theoretisch', y = 'Beobachtet') 
```


## Varianzhomogenität formal mit Levene-Test


```{r, echo=T}
car::leveneTest(mod_aov)
```

## Effektstärke $f$

\begin{align*}
f &= \frac{\sigma_m}{\sigma_{\epsilon}} = \frac{\sqrt{\frac{\sum\tau_i^2}{k}}}{\sigma_{\epsilon}} \\
 &= \sqrt{\frac{(F - 1) \times df_{w}}{N}} \qquad \text{Alternativformel}
\end{align*}

N = Gesamtstichprobengröße, $F, df_w$ aus F-Tabelle

## Weitere Effektstärken $\omega^2$ und $\eta^2$

:::: columns
::: column
### Effektstärken 

\begin{align*}
\omega^2 &= \frac{f^2}{1 + f^2} \\
&= \frac{SS_B - (k-1)MS_W}{SS_{\text{Total}}+MS_W} \\
\eta^2 &= \frac{SS_{B}}{SS_{Total}}
\end{align*}

:::
::: column
\begin{table}[]
\caption{Einordnung}
\centering
\begin{tabular}{llll}
\toprule
 & $f$ & $\omega^2$ & $\eta^2$ \\
\midrule
 klein & 0.1 & 0.01 & 0.01 \\
 mittel & 0.25 & 0.06 & 0.06 \\
 groß & 0.40 & 0.14 & 0.14 \\
\bottomrule
\end{tabular}
\end{table}
:::
::::

^[$f^2=\frac{\omega^2}{1-\omega^2}$]

## Effektstärke $\eta^2$, $\omega^2$ und $f$ in R

\scriptsize
```{r, echo=T}
effectsize::cohens_f(mod_aov, ci=0.95)
effectsize::omega_squared(mod_aov, partial=F, ci=0.95 )
```


## Effektstärke $\eta^2$, $\omega^2$ und $f$ in R{.t}

\scriptsize
```{r, echo=T}
effectsize::eta_squared(mod_aov, partial=F, ci=0.95)
```


## Stichprobengröße a-prior ermitteln

Zwei Möglichkeiten: 

1) Anhand der Literatur wird $f$ bestimmt.
2) Es wird ein relevantes/plausibels $\Delta$ als der Unterschied zwischen zwei Gruppen angesetzt.^[$\sigma$ muss trotzdem anhand der Literatur abgeschätzt werden.]

$$
f = \sqrt{\frac{\Delta^2}{2k\sigma^2}}
$$

## Stichprobengröße a-prior ermitteln in R

\small
```{r, results='asis', echo=T}
pwr::pwr.anova.test(f = 0.89, k = 3, sig.level = 0.05, power = 0.8)
```

## Zum Nacharbeiten

### Design
@pos_design_comp_exp, @kutner2005[p.677-692]
