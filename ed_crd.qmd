# Completely Randomized Design 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
#source('../resources/nice_format_helper_fcn.R')
n <- 20
k <- 3
set.seed(11)
kaffee <- tibble(
  Zeit = rnorm(k*n, rep(c(1917,1927,1927), each=n), 8),
  Gruppe = gl(k,n,labels=c('Koffein','Placebo','Control'))
)
```

Das erste experimentelle Design, das wir uns anschauen, ist das completeley randomized design. Wir haben unterschiedliche experimentelle Konditionen von denen wir ausgehen, dass diese sich unterschiedlich auf die experimentellen units (EU) auswirken. Beispielsweise wollen wir die Balancierfähigkeit unter drei verschiedenen Konditionen untersuchen, z.B. auf festem Untergrund, auf weichem Untergrund und auf wackeligen Untergrund. Die Balancierfähigkeit ist aber auch durch zahlreiche andere Einflussfaktoren beeinflusst, z.B. Vorerfahrung, Kraftfähigkeit etc. Viele von diesen kennen wir vielleicht gar nicht bzw. für diese zu kontrollieren wäre zu aufwendig. Um diese Störgrößen zu *kontrollieren* setzen wir Randomisierung ein. Jeder einzelne Versuchsteilnehmer bzw. Versuchsteilnehmerinn soll daher randomisiert auf **eine** der drei Kondition verteilt werden. Damit werden die Teilnehmer(innen) zu den EUs. Nach Durchsicht der Literatur könnte die Balancierfähigkeit z.B. mit einer Kraftmessplatte erfasst werden. Hieran schließt sich noch die Festsetzung der observational units, d.h. in diesem Falle, der Anzahl der Messwiederholungen an um die Reliabität auf ein gewünschtes Niveau zu heben. Diesen Teil vernachlässigen wir zunächst einmal.

## Das Modell 

Um diesem Design ein statistisches Modell anzupassen, müssen wir uns nun Gedanken über den DGP machen. Zunächst einmal wird jede(r) Teilnehmer(in) eine bestimmte Balancierfähigkeit haben. Bzw. wenn wir die Kondition mit dem festen Untergrund als eine Referenzkondition festlegen, können wir davon ausgehen, dass es eine mittlere Balancierfähigkeit gibt und die einzelnen Personen aus der Population um diesen Mittelwert schwanken. Dieser Mittelwert bekommt einen eigenen Parameter $\mu$. Jetzt gegen wir davon  aus, dass die unterschiedlichen Konditionen dazu führen, dass die *Basisbalancierfähigkeit* von den Konditionen beeinflusst wird. D.h. es kommt zu einer Veränderung oder Abweichung von $\mu$. Diese Abweichungen bezeichnen wird mit $\tau_i$ wobei der Index $i$ dann die jeweilige Kondition $i$ kennzeichnet. Insgesamt führt dies zu dem Modell:


\begin{equation}
Y_{ij} = \mu + \tau_i + \epsilon_{ij}, \qquad \epsilon_{ij}\sim \mathcal{N}(0,\sigma^2)
\label{eq-ed-crd-model}
\end{equation}

i = Gruppenindikator, j = experimental unit-indikator, $\mu$ = Gesamtmittelwert, \mbox{$\tau_i$ = Einfluss der $i$-ten Stufe}

Natürlich brauchen wir Replikationen um den Einfluss $\tau_i$ der Konditionen zu bestimmen. Diese Replikationen, in unsererm Fall die Versuchspersonen, bekommen den Index $j$.

Die Annahmen des Modells sind dabei:

- Unabhängige Experimental Units (EU) 
- Die EUs sind **zufällig** in die k Gruppen eingeteilt worden
- Die Varianzen $\sigma_i^2$ in jeder Gruppe $i$ sind gleich 
- Die Werte in jeder Gruppe sind Normalverteilt $Y_{ij} \sim \mathcal{N}(\mu_i, \sigma)$

Die statistische Überprüfung führen wir nun wieder mit dem uns bekannten Modellvergleichen durch. Das Modell \eqref{eq-ed-crd-model} wird als das Full Model angesehen und wir definieren das reduzierte Modell mittels:

\begin{equation*}
Y_{ij} = \mu + \epsilon_{ij}
\end{equation*}

Dementsprechend folgt als Teststatistik

$$
F = \frac{\textrm{SSE(R)} - \textrm{SSE(F)}}{\textrm{df}_R - \textrm{df}_F} \frac{\textrm{df}_F}{\textrm{SSE(F)}} \sim F(\textrm{df}_R-\textrm{df}_F,\textrm{df}_F)
$$

mit den statistische Hypothesen:

\begin{align*}
H_0:& \tau_1 = \tau_2 = \ldots = \tau_k = 0 \\
H_1:& \exists\tau_i \neq \tau_j\ \textrm{mit}\ i \neq j, i,j \in \{1,2,\ldots,k\}
\end{align*}

D.h. wir überprüfen ob die Hinzunahme der Information über die Konditionen (Faktoren) zu einer statistisch signifikanten Verminderung der Residualvarianz führt. Wenn dem nicht der Fall, dann verbessert sich der Modellfit durch die Faktorstufen $\tau_i$ nicht. 

### Verbindung Modellhierarchien und BA-ANOVA

Im Bachelor wurde das completely randomized design aller Wahrscheinlichkeit nach unter der Bezeichnung Einfaktorielle ANOVA eingeführt. Was eigentlich nicht viel Sinn macht, da es sich bei der einfaktoriellen ANOVA um eine Analysemethode und streng genommen nicht um ein experimentelles Design handelt. Wenn wir die folgenden beiden Identitäten berücksichtigen. 

\begin{equation}
\sum_i (y_i - \hat{y}) = \sum_i y_i - n \hat{y} = n \hat{y} - n \hat{y} = 0 
\label{eq-ed-crd-bar-sum}
\end{equation}

\begin{align}
\begin{split}
\sum_i \sum_j 2 (y_{ij} - \hat{y}_j)(\hat{y}_j - \hat{y}) &= \sum_j \sum_i 2 (y_{ij} - \hat{y}_j)(\hat{y}_j - \hat{y}) \\
&= 2 \sum_j (\hat{y}_j - \hat{y}) \underbrace{\sum_i (y_{ij} - \hat{y}_j)}_{\text{mit} ~(\ref{eq-ed-crd-bar-sum})=0}\\
&= 2 \sum_j (\hat{y}_j - \hat{y}) 0  = 0 \\
\end{split}
\label{eq-ed-crd-cross-sum}
\end{align}

Dann können wir $SS_{\text{total}}$ nach dem folgenden Muster aufspalten.

\begin{align}
\begin{split}
\underbrace{\sum_i \sum_j (y_{ij} - \hat{y})^2}_{SS_{\text{Total}}} &= \sum_i \sum_j (y_{ij} - \hat{y}_j + \hat{y}_j - \hat{y})^2 \\ &= \sum_i \sum_j (y_{ij} - \hat{y}_j)^2 + \sum_i \sum_j (\hat{y}_j - \hat{y})^2 - \underbrace{\sum_i \sum_j 2 (y_{ij} - \hat{y}_j)(\hat{y}_j - \hat{y})}_{\text{mit}~(\ref{eq-ed-crd-cross-sum})=0}\\
&= \underbrace{\sum_i \sum_j (y_{ij} - \hat{y}_j)^2}_{SS_{\text{Error}}} + \underbrace{\sum_i \sum_j (\hat{y}_j - \hat{y})^2}_{SS_{\text{Regression}}} 
\end{split}
\label{eq-ed-crd-sse-total}
\end{align}

D.h. wir erhalten die schon bekannte Aufteilung in $SS_{\text{Error}}$ und $SS_{\text{Regression}}$ die uns in der Herleitung von $R^2$ begegnet ist. Ziehen wir jetzt $SSE(R) - SSE(F)$ voneinander ab.

\begin{align*}
SSE(R) - SSE(F) &= \sum_i \sum_j (y_{ij} - \hat{y})^2 - \sum_i \sum_j (y_{ij} - \hat{y}_j)^2 \\
 &= \underbrace{\sum_i \sum_j (y_{ij} - \hat{y}_j)^2 + \sum_i \sum_j (\hat{y}_j - \hat{y})^2}_{\text{mit}~\eqref{eq-ed-crd-sse-total}}  - \sum_i \sum_j (y_{ij} - \hat{y}_j)^2 \\
 &= \sum_i \sum_j (\hat{y}_j - \hat{y})^2 \\
\end{align*}

Dann ist dies der gleiche Term wir ihn in der BA-ANOVA Vorlesung gesehen haben und der dort als $QS_{\text{zwischen}}$ bezeichnet worden ist.

\begin{equation*}
QS_{zwischen} = \sum_{j=1}^K \sum_{i=1}^{N_j} (\bar{x}_{j}-\bar{x})^2
\end{equation*}

Letztendlich kommen wir daher mit dem Ansatz der Modellvergleiche zum gleichen Ergebnis, aber wieder mit dem Vorteil, das das Verfahren der Modellvergleiche leichter zu verallgemeinern ist.

## Beispieldaten

Schauen wir uns als nächstes einen Beispieldatensatz an und gehen durch die verschiedenen Schritte der Analyse eines CRD.

In @fig-ed-crd-coffeine-01 ist das Ergebnis einer Untersuchung zum Einfluss von Koffein auf die Laufleistung bei einem 8Km Ausdauerlauf zu abgebildet. Insgesamt sind $N=60$ Probanden randomisiert in drei Gruppen eingeteilt worden: Koffein, Placebo und Control. Die Gruppe Koffein hat vor dem Lauf ein Koffeinpräparat eingenommen, während die Placebogruppe ein Präparat ohne Wirkstoff eingenommen hat. Die Kontrollgruppe hat vor dem Lauf kein Zusatzpräparat eingekommen. Jeder Proband lief einmal die Strecke von $8$ Km so schnell wie möglich. Die abhängige Variable war die Laufzeit.

```{r}
#| fig-cap: "Einfluss von Koffeine auf die Laufleistung über 8km"
#| label: fig-ed-crd-coffeine-01

ggplot(kaffee, aes(Gruppe, Zeit)) +
  geom_boxplot() + 
  geom_jitter(width = 0.2, color = 'red', size = 2, alpha=.5) +
  labs(y = 'Zeit [s]',
       x = 'Gruppe') 
```

@fig-ed-crd-coffeine-01 deute an, das die Einnahme von Koffein zu einer Leistungsverbesserung führt, während der Einfluss des Placebos scheinbar möglicherweise nur zu einer leichten Verbesserung gegenüber der Kontrollkondition geführt hat.

Schauen wir uns die deskriptive Statistik der Daten an. In @tbl-ed-crd-coffeine-01 sind die deskriptiven Werte der Daten abgebildet.

```{r}
#| results: asis
#| label: tbl-ed-crd-coffeine-01
#| tbl-cap: "Deskriptive Statistiken der Koffeinstudie."

kaffee |> group_by(Gruppe) |>  
  summarytools::descr(stats = c('mean','med','sd','q1','q3'), plain.ascii = F,
                      style='rmarkdown', headings = FALSE) 
```



In `R` können wir uns eine die deskriptive Statistik der Daten mittels Funktionen aus dem Paket `summarytools` erstellen.

```{r, echo=T, eval=F}
kaffee |> group_by(Gruppe) |> 
  descr(stats = c('q1','mean','med','q3','sd'))
```




## Analyse in R mit `lm()`
\small
```{r, echo=T, results="hide"}
mod_lm <- lm(Zeit ~ Gruppe, data = kaffee)
summary(mod_lm)
```
```{r}
lm_tbl_knitr(mod_lm)
```

## Analyse in R mit `lm()`
```{r, echo=T, eval=F}
anova(mod_lm)
```
```{r}
lm_anova_tbl_knitr(anova(mod_lm))
```


## Analyse in R mit `aov()`
\small
```{r, echo=T, results="hide"}
mod_aov <- aov(Zeit ~ Gruppe, data = kaffee)
summary(mod_aov)
```
```{r}
broom::tidy(mod_aov) |> 
  knitr::kable(booktabs=T, digits=2,
               col.names = c('', 'DF', 'SSQ', 'MSQ', 'F', 'p'),
               caption='Summarytabelle von aov()')
```

## F-Tabelle Terminologie 

Table: Bezeichungen F-Tabelle

|   | DF | SSQ | MSQ | F | 
| --- | --- | --- | --- | :---: | 
| Between | $df_b$ | $SS_b$ | \mbox{$MS_b=\frac{SS_b}{df_b}$} | $\frac{MS_b}{MS_w}$  | 
| Residual | $df_w$ | $SS_w$ | \mbox{$MS_w=\frac{SS_w}{df_w}$} |  |
| Total | $df_{\text{total}}$ | $SS_{\text{total}}$ | $MS_{\text{total}}$ | |

## Plot of dummy variable model $y_{ij} = \mu+ \tau_2^* x_{1j} + \tau_3^* x_{2j} + \epsilon_{ij}$

```{r}
#| out.width="50%",
#| fig.asp=1.1,
#| fig.cap="Fitted planes for the reduced (blue) and the full (red) model"

mod_p <- lm(Zeit ~ Gruppe, kaffee)
X <- model.matrix(mod_p)
coefs <- coef(mod_p)
df <- tibble(
  x1 = c(0,1,0),
  x2 = c(0,0,1),
  y = c(coefs[1], sum(coefs[1:2]), sum(coefs[-2]))
)
s3d <- scatterplot3d::scatterplot3d(X[,2],X[,3],kaffee$Zeit, type='h', color='green', pch=16,
                     xlab=expression(x[1]),
                     ylab=expression(x[2]),
                     zlab='Zeit[s]',
                     x.ticklabs = c(0,1),
                     y.ticklabs = c(0,1),
                     lab = c(1,1,1),
                     scale.y=0.5,
                     angle=55,
                     cex.lab=1.4,
                     cex.axis=1.2,
                     mar=c(3,3,1,2),
                     box=F)
s3d$plane3d(coefs[1], coefs[2], coefs[3], col='blue',
            draw_polygon=T,
            polygon_args = list(col = rgb(1,0,0,.2)))
s3d$plane3d(mean(kaffee$Zeit), 1, 1, col='red',
            draw_polygon=T,
            polygon_args = list(col = rgb(0,0,1,.2)))
s3d$points3d(df, color='black', pch=16, cex=2)
```

## Voraussetzungen überprüfen bzw. Modelldiagnose


```{r}
#| fig.cap="Residuendiagnostik für einfache $\\hat{\\epsilon}_i$ und standardisierte $\\hat{\\epsilon}_{Si}$ Residuen.",
#| fig.width=4.5,

require(patchwork)
kaffee <- broom::augment(mod_lm, kaffee)
p1 <- ggplot(kaffee, aes(.fitted, .resid)) +
  geom_hline(yintercept = 0, color = 'red', linetype = 'dashed') +
  geom_point() +
  labs(x = expression(hat(y)[i]), y = expression(hat(epsilon)[i])) 
p2 <- ggplot(kaffee, aes(.fitted, .std.resid)) +
  geom_hline(yintercept = 0, color = 'red', linetype = 'dashed') +
  geom_point() +
  labs(x = expression(hat(y)[i]), y = expression(hat(epsilon)[Si])) 
p1 + p2
```

## Einfache Residuen im QQ-Plot

```{r}
#| fig.cap="qqplot der einfachen Residuen"

ggplot(kaffee, aes(sample=.resid)) +
  geom_qq() +
  geom_qq_line() +
  labs(x = 'Theoretisch', y = 'Beobachtet') 
```


## Varianzhomogenität formal mit Levene-Test


```{r, echo=T}
car::leveneTest(mod_aov)
```

## Effektstärke $f$

\begin{align*}
f &= \frac{\sigma_m}{\sigma_{\epsilon}} = \frac{\sqrt{\frac{\sum\tau_i^2}{k}}}{\sigma_{\epsilon}} \\
 &= \sqrt{\frac{(F - 1) \times df_{w}}{N}} \qquad \text{Alternativformel}
\end{align*}

N = Gesamtstichprobengröße, $F, df_w$ aus F-Tabelle

## Weitere Effektstärken $\omega^2$ und $\eta^2$

:::: columns
::: column
### Effektstärken 

\begin{align*}
\omega^2 &= \frac{f^2}{1 + f^2} \\
&= \frac{SS_B - (k-1)MS_W}{SS_{\text{Total}}+MS_W} \\
\eta^2 &= \frac{SS_{B}}{SS_{Total}}
\end{align*}

:::
::: column
\begin{table}[]
\caption{Einordnung}
\centering
\begin{tabular}{llll}
\toprule
 & $f$ & $\omega^2$ & $\eta^2$ \\
\midrule
 klein & 0.1 & 0.01 & 0.01 \\
 mittel & 0.25 & 0.06 & 0.06 \\
 groß & 0.40 & 0.14 & 0.14 \\
\bottomrule
\end{tabular}
\end{table}
:::
::::

^[$f^2=\frac{\omega^2}{1-\omega^2}$]

## Effektstärke $\eta^2$, $\omega^2$ und $f$ in R

\scriptsize
```{r, echo=T}
effectsize::cohens_f(mod_aov, ci=0.95)
effectsize::omega_squared(mod_aov, partial=F, ci=0.95 )
```


## Effektstärke $\eta^2$, $\omega^2$ und $f$ in R{.t}

\scriptsize
```{r, echo=T}
effectsize::eta_squared(mod_aov, partial=F, ci=0.95)
```


## Stichprobengröße a-prior ermitteln

Zwei Möglichkeiten: 

1) Anhand der Literatur wird $f$ bestimmt.
2) Es wird ein relevantes/plausibels $\Delta$ als der Unterschied zwischen zwei Gruppen angesetzt.^[$\sigma$ muss trotzdem anhand der Literatur abgeschätzt werden.]

$$
f = \sqrt{\frac{\Delta^2}{2k\sigma^2}}
$$

## Stichprobengröße a-prior ermitteln in R

\small
```{r, results='asis', echo=T}
pwr::pwr.anova.test(f = 0.89, k = 3, sig.level = 0.05, power = 0.8)
```

## Omnibus-Test

\centering
```{r}
#| out.width="80%"

knitr::include_graphics('pics/omnibus.jpg')
```

## Individual comparison and Post-hoc tests

```{r, fig.cap="Einfluss von Koffeine auf die Laufleistung über 8km", fig.height=2}
ggplot(kaffee, aes(Gruppe, Zeit)) +
  geom_boxplot() + 
  geom_jitter(width = 0.2, color = 'red', size = 2, alpha=.5) +
  labs(y = 'Zeit [s]',
       x = 'Gruppe') 
```

## Das multiple-comparison Problem

Sei $m$ die Anzahl der getesten Hypothesen.
$$
P(\text{min. }1\text{ Type-I Fehler}) = 1 - (1-\alpha)^m 
$$

^[Unter der Annahme das für alle Test die $H_0$-Hypothese zutrifft [siehe auch @rothman1990].]

```{r}
#| fig.cap="Inflation des $\\alpha$-Fehlers mit $\\alpha=0.05$",
#| fig.height=1.3,
#| fig.width=3

ggplot(tibble(m = 1:20, p = 1 - (1-0.05)**m),
       aes(m, p)) +
  geom_line() +
  labs(x = 'Anzahl der Tests', y = 'P min 1\nTyp-I Fehler')
```


## Unterscheidung von Fehlern

\begin{figure}
\centering
\begin{tikzpicture}[scale=0.7]
\tikzstyle{level 1}=[sibling distance=40mm]
\tikzstyle{level 2}=[sibling distance=20mm]
\tikzstyle{level 3}=[sibling distance=7mm]
\node {Experiment}
    child {node[text width=1.5cm, align=center] {Primary Endpoint}
    child {node {Factor 1}
    child {node {$\bar{Y}_{1}$}}
    child {node {$\bar{Y}_{2}$}}
    child {node {$\bar{Y}_{3}$}}}
    child {node {Factor 2}
    child [dashed]{node {}}
    child [dashed]{node {}}}
    child [dashed] {node {}}}
    child {node[text width=1.5cm, align=center]{Secondary Endpoint}
    child [dashed]{node {}}
    child [dashed]{node {}}}
    child [dashed] {node {}};
    \scriptsize
    \node [text width=2.5cm, align=center] at (-10,-4.7) (a) {error rate per test $\alpha_{PC}$};
    \node [text width=2.5cm, align=center] at (-10,-3) (a) {error rate per family $\alpha_{FW}$};
    \node [text width=3.5cm, align=center] at (-10,-1) (a) {error rate per experiment $\alpha_{EW}$};
\end{tikzpicture}
\end{figure}


## Kontraste $\psi$

Vergleiche zwischen den Gruppen werden mittels Kontrasten berechnet. Allgemein:

$$
\psi = \sum_{i=1}^k c_i \tau_i, \quad \text{mit } \sum_{i=1}^k c_i=0
$$

Konkret werden die Kontraste mittels der Gruppenmittelwerte gebildet.

$$
\hat{\psi} = \sum_{i=1}^k c_i \hat{\tau_i} = \sum_{i=1}^k c_i \bar{y}_{i.}
$$

## Paarweise Kontrastdefinition für das Beispiel 

\begin{table}
\centering
\caption{Paarvergleiche der Gruppen aus dem Beispiel}
\begin{tabular}{lcccc}
\toprule
Kontrast  & Koffein & Placebo & Control & $\sum_{i=1}^k c_i$ \\ 
\midrule
$\Delta_{\text{Koffein-Placebo}}$ & $1$ & $(-1)$ & 0  & 0 \\
$\Delta_{\text{Koffein-Control}}$ & $1$ & $0$ & $(-1)$ & 0  \\
$\Delta_{\text{Placebo-Control}}$ & $0$ & $1$ & $(-1)$ & 0  \\
\bottomrule
\end{tabular}
\end{table}

## Kontraste konkret

```{r}
k_bar <- kaffee |> dplyr::group_by(Gruppe) |> 
  dplyr::summarize(m = round(mean(Zeit),1))  
k_bar |> 
  knitr::kable(booktabs=T,
               col.names = c('Gruppe', '$\\bar{y}_{i.}$'),
               escape=F,
               caption="Gruppenmittelwerte")
```

Ein Vergleich bespielsweise zwischen Koffein und Placebo kann mittels des Kontrasts $c_{\text{K-C}} = (1,-1,0)$ berechnet werden.

$$
\hat{\psi}_{\text{K-C}} = \sum_{i=1}^k c_i \bar{y}_{i.} = 1 \cdot `r k_bar$m[1]` + (-1) \cdot `r k_bar$m[2]` + 0 \cdot `r k_bar$m[3]` = `r round(k_bar$m[1] - k_bar$m[2], 1)`
$$

## Unterscheidung von Kontrasten

### Paarweise Vergleiche: Einfache Kontraste

$$
c_i = 1, c_j = -1, c_k = 0, \forall k \neq i,j
$$

### Sonstige Vergleiche: Komplexe Kontraste

z.B. Vergleich der Mittelwerte von $\tau_1, \tau_2$ mit $\tau_3$.

$$
c_1 = \frac{1}{2}, c_2 = \frac{1}{2}, c_3 = -1, c_i = 0, \forall i \neq 1,2,3
$$

## Beispiel für einen komplexen Kontrast $\psi$

```{r}
k_bar <- kaffee |> dplyr::group_by(Gruppe) |> 
  dplyr::summarize(m = round(mean(Zeit),1))  
k_bar |> 
  knitr::kable(booktabs=T,
               col.names = c('Gruppe', '$\\bar{y}_{i.}$'),
               escape=F,
               caption="Gruppenmittelwerte")
```

Vergleich zwischen dem Mittelwert von Koffein und Placebo gegen Kontrolle mittels $c = (1/2,1/2,-1)$.

$$
\hat{\psi} = \sum_{i=1}^k c_i \bar{y}_{i.} = \frac{1}{2} \cdot `r k_bar$m[1]` + \frac{1}{2} \cdot `r k_bar$m[2]` + (-1) \cdot `r k_bar$m[3]` = `r round(sum(k_bar$m[1:2])/2 - k_bar$m[3],2)`
$$

## Reminder - Standardfehler und Varianz des Stichprobenmittelwerts

:::: columns
::: column
```{r}
#| fig.cap="Population",
#| fig.height=4.5

tibble(
  x = seq(-3, 3, length.out=100),
  d = dnorm(x)
) |> 
  ggplot(aes(x,d,ymin=0, ymax=d)) +
  geom_ribbon(alpha=0.3) +
  geom_line() +
  scale_x_continuous('Werte',
                     breaks = -2:2,
                     labels=c(
                       expression(-2*sigma),
                       expression(-sigma),
                       expression(mu),
                       expression(sigma),
                       expression(2*sigma)
                     )) +
  labs(y = 'Dichte') 
```

:::
::: column

**Standardfehler des Mittelwerts**

$$
s_{\bar{x}} = \frac{\sigma}{\sqrt{n}}
$$

**Varianz des Mittelwerts**

$$
Var(\bar{x}) = \frac{\sigma^2}{n}
$$

:::
::::

## Varianz von Kontrasten

### In der Population
$$
Var(\psi) = Var\left(\sum c_i \bar{Y}_{i.}\right) = \sum c_i^2 Var(\bar{Y}_{i.}) = \sum c_i^2(\sigma^2/n_i) = \sigma^2\sum(c_i^2/n_i)
$$

### Geschätzt anhand der Stichprobe
$$
\widehat{Var}(\psi) = \widehat{Var}\left(\sum c_i \bar{y}_{i.}\right) = MS_w\sum (c_i^2/n_i)
$$

### Standardfehler des Kontrasts
$$
s_{\psi} = \sqrt{MS_w\sum (c_i^2/n_i)}
$$

^[$n_i$ = Stichprobengröße in Gruppe i, $\hat{\sigma}^2 = MS_w$]


## Varianz von Kontrasten bei Paarvergleichen

Vergleich von Gruppe $i$ und $j$

$$
Var\left(\hat{\tau}_i - \hat{\tau}_j\right) = \sigma^2\left(\frac{1}{n_i} + \frac{1}{n_j}\right)
$$

Standardfehler bei gleicher Stichprobengröße $n_i = n_j = n, 2n = N$

$$
s_{\psi} = s_{\Delta} = \sqrt{\sigma^2\left(\frac{1}{N/2}
+\frac{1}{N/2}\right)}=\sqrt{\sigma^2\frac{2}{N/2}} = \sigma\sqrt\frac{4}{N}=\frac{2\sigma}{\sqrt{N}}
$$

## Reminder - Dualität von Signifikanztests und Konfidenzintervall

Wenn das Konfidenzintervall mit Niveau $1-\alpha\%$ die $H_0$ nicht beinhaltet, dann wird auch bei einem Signifikanztest die $H_0$ bei einer Irrtumswahrscheinlichkeit von $\alpha$ abgelehnt.

\begin{figure}
\centering
\begin{tikzpicture}
    \draw[dashed,thick] (0,-1) -- (0,1);
    \node[anchor=north] at (0,-1) {$H_0$};
    \fill[red] (2,0) circle (4pt);
    \draw[thick, color=red] (0.08,0) -- (3.92,0);
    \node[red] at (0.1,0) {(};
    \node[red] at (3.9,0) {)};
    \draw [->, thick] (-1,-1) -- (5,-1);
\end{tikzpicture}
\caption{Relation von $H_0$ und Konfidenzintervall}
\end{figure}

## Konfidenzintervalle von Kontrasten

### Berechnungsmuster

\begin{gather*}
\psi = \sum_i c_i \hat{\tau}_i \pm w \sqrt{\widehat{Var}\left(\sum c_i \hat{\tau}_i\right)} = w \times s_{\psi}\\
\text{estimate } \pm (\text{kritischer Wert}) \times (\text{Standardfehler})
\end{gather*}

Zwischen verschiedenen Methoden unterscheidet sich der kritische Wert $w$.

## Minimum significant difference ($msd$) 

\begin{figure}
\centering
\begin{tikzpicture}
    \draw[dashed,thick] (0,-1) -- (0,1);
    \node[anchor=north] at (0,-1) {$H_{0:\psi}$};
    \fill[red] (2,0) circle (4pt);
    \draw[thick, color=red] (0.08,0) -- (3.92,0);
    \node at (2,0.5) {$\hat{\psi}$};
    \node at (1,-0.5) {$-w\times s_{\psi}$};
    \node at (3,-0.5) {$+w\times s_{\psi}$};
    \node[red] at (0.1,0) {(};
    \node[red] at (3.9,0) {)};
    \draw [->, thick] (-1,-1) -- (5,-1);
\end{tikzpicture}
\caption{Kontrastkonfidenzintervall}
\end{figure}

$$
msd = w \sqrt{\widehat{Var}\left(\sum c_i \hat{\tau}_i\right)}=w \times s_{\psi}
$$


## Einteilung der Mehrfachvergleiche

Table: Systematik Mehrfachvergleiche

| Name | Zeitpunkt | Kontraste | Kontrolliert |
| --- | --- | --- | --- | 
| Bonferroni | pre-planned | einfache und komplexe | Ja |
| Tukey | pre-planned | alle paarweisen | Ja |
| Scheffé | post-hoc | einfache und komplexe | Ja |
| Dunnet | pre-planned | paarweise TRT gegen CON | Ja |
| FisherLSD| post-hoc | einfache und komplexe | Nein^[Außer wenn $K=3$] |

## Mehrfachvergleiche in `R`

### Package `emmeans()`

Zweistufiger Ablauf:

1) Berechnen der Zellmittelwerte mit der Funktion \
`emmeans(<MODEL>, ~<FAKTOR>)`
2) Vergleiche werden entweder mittels `pairs()` (paarweise Vergleiche) oder mit `contrast()` (beliebige Vergleiche) berechnet 

Alternative: `package:multcomp`

## Bonferroni (pre-planned)

Das Signifikanzlevel $\alpha$ wird angepasst indem ein neuer $\alpha$-Level, $\alpha^*$, mittels:

$$
\alpha^* = \alpha / m
$$

berechnet wird. $m$ ist die Anzahl der Kontraste.

Kontrolliert Gesamt-$\alpha$ für einfache und/oder komplexe Kontraste.

## Beispiel Bonferroni

Einfacher Vergleich Koffein geben Placebo und komplexer Vergleich des Mittelwerts von Koffein und Placebo gegen Kontrolle.

\scriptsize
```{r, echo=T}
library(emmeans)
mod_em <- emmeans(mod_aov, ~Gruppe)
contrast(mod_em, adjust='bonferroni', infer=T ,
         method = list(
           "Koffein vs. Placebo" = c(1, -1, 0),
           "Tablette vs. CON" = c(1/2, 1/2, -1)
         ))
```


## Tukey (H)onest (S)ignifikant (D)ifference (pre-planned)

Optimiert für alle paarweisen Kontraste.

\scriptsize
```{r, echo=T}
pairs(mod_em, adjust="tukey", infer=T)
```
^[TukeyHSD ist auch default wenn keine Argument für `adjust` angegeben wird.]

## Scheffé (post-hoc)

Sichert post-hoc $\alpha$-Level für alle möglichen Kontraste (beliebige Anzahl) ab.

Beispielsweise die gleichen Kontraste wie beim Bonferroni-Beispiel.
\scriptsize
```{r, echo=T}
contrast(mod_em, adjust='scheffe', infer=T ,
         method = list(
           "Koffein vs. Placebo" = c(1, -1, 0),
           "Tablette vs. CON" = c(1/2, 1/2, -1)
         ))
```


## Dunnett (pre-planned)

Optimiert für den Vergleich von Treatmentkonditionen gegen eine Kontrollkondition.
\vspace{.5cm}
\scriptsize
```{r, echo=T}
contrast(mod_em, method='trt.vs.ctrl', infer=T, ref='Control')
```


## Fisher (L)east (S)ignificant (D)ifference (post-hoc)

Durchführung von post-hoc Tests wenn ein statistisch signifikanter Haupteffekt über die ANOVA abgesichert wurde.
\vspace{.5cm}
\scriptsize
```{r, echo=T}
pairs(mod_em, adjust='none', infer=T)
```

\Large
\alert{Do not like!!!}^[Außer bei einem Faktor mit genau drei Stufen (siehe @levin1994)]

## Vergleich der kritischen Werte $w$

```{r}
tibble(
  'no_groups' = 2:7,
  'per_com' = qf(0.95, 1, 12),
  'tukey' = qtukey(0.95, no_groups, 12)**2/2,
  'bonferroni' = qf(1-0.05/(no_groups*(no_groups-1)/2), 1, 12),
  'scheffe' = (no_groups-1)*qf(0.95, no_groups-1, 12)
) |> 
  knitr::kable(
    booktabs=T,
    col.names=c('Stufen', '$\\alpha_{PC}$', 'Tukey', 'Bonferroni','Scheffé'),
    caption="Kritische Werte $w$ für alle $k(k-1)/2$ paarweisen Vergleiche bei $df_{\\text{error}}=12$.",
    digits=2,
    linesep = '',
    escape=F
  )
```

## Optional - Cohen's d für post-hocs

\scriptsize
```{r, echo=T}
eff_size(mod_em, sigma=sigma(mod_aov),
                 edf=df.residual(mod_aov))
```


## Dokumentation

\small
Eine einfaktorielle ANOVA mit dem Faktor Gruppe ergabe einen statistisch signifikanten Haupteffekt für Gruppe $F(2, 57) = 22,6, p < 0,001$.  Überprüfung auf Varianzgleichheit zwischen den Gruppen mittels eines Levene-Tests deutete auf keine Verletzung der Voraussetzungen hin, $F(2, 57) = 0,38, p = 0,69$. Daher wird die $H_0$, das kein Unterschied zwischen den Gruppen besteht, abgelehnt. Die beobachtete Effektstärke $\omega^2 = 0,42$,  CI$95\%[0,22, 0,56]$ ist als großer Effekt zu interpretieren. Pre-planned Paarweisetestung mittels Tukey-Korrektur deutete auf statistisch signifikate Unterschiede zwischen den Gruppen Koffein und Placebo $z = -10.4$, CI95\%$[-15,5, -5,5], p < 0,001$, und Koffein und Kontrolle, $z = -13,3$, CI95$\%[-18,4, -8,3], p < 0,001$, hin. Insgesamt deuten die Ergebnisse daher darauf hin, dass die Gabe von Koffein zu einer bedeutsamen Leistungssteigerung $(>5-10s)$ in der beobachteten Untersuchungsgruppe geführt hat.

## Zum Nacharbeiten

### Design
@pos_design_comp_exp, @kutner2005[p.677-692]

### Multiple-comparisons
@feise2002, @rothman1990
