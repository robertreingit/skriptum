# Statistische Signifikanz, p-Wert und Power 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```

```{r stats_significance_defs}
n <- 20
set.seed(123)
world <- tibble(ID = paste0('P',stringr::str_pad(1:n, width=2, pad="0")),
                Kraft = sample(2000:2500, n))
world$Kraft[13] <- 1800
world$Kraft[17] <- 3200
d_gr <- 100
d_x <- 2 
mu_lummer <- 0
sd_lummer <- 230
```


Im vorherigen Kapitel haben wir gesehen, wie Unsicherheit ein zentrales Problem bei der Interpretation von Ergebnissen von Experimenten oder Daten allgemein ist. Im nun folgenden Abschnitt wollen wir eine Prozess aufbauen, der es uns vor dem Hintergrund dieser Unsicherheit eine Entscheidung zu treffen.

## Wie treffe ich eine Entscheidung? 

In unserem kleine Welt Bespiel waren wir in der komfortablen Position, das wir genau wussten was passiert bzw. welcher Prozess unseren beobachteten Datenpunkt erzeugt hat. D.h wir kannten den datengenerieren Prozesses.

::: {#def-dgp}
## Datengenerierender Prozess (DGP)

Der Prozess in der realen Welt der die beobachteten Daten und damit die daraus folgende Statistik erzeugt wird als datengenerierender Prozess\index{Datengenerierender Prozess} bezeichnet.
:::

Letztendlich zielt unsere Untersuchung, unser Experiment, darauf ab, Informationen über den DGP zu erhalten, weil diese Information uns erlaubt Aussagen über die reale Welt zu treffen. Dabei muss allerdings beachtet werden, dass dieser Prozess in den allermeisten Fällen ein starke Vereinfachung des tatsächlichen Prozesses in der Realität darstellt. Meistens sind die Abläufe in der Realität zu komplex um sie ins Gänze abzubilden. Somit wird fast immer nur ein Modell verwendet. 

Zurück zu unseren Problem, wenn wir ein Experiment durchführen, dann haben wir normalerweise nur eine einzige beobachtete Statistik. In unseren bisherigen Beispiel also den berechneten Unterschied $D$ in der Kraftfähigkeit nach der Intervention zwischen der Kontroll- und der Interventionsgruppe.

```{r}
#| fig.cap: "Beobachteter Unterschied nach der Durchführung unseres Experiments"
#| label: fig-sts-sig-result-1 
#| fig.height: 1.5

D_obs <- tibble(Kraft = 50)
ggplot(D_obs,
       aes(Kraft, 1)) +
  geom_point(size=3, color = 'red') +
  scale_x_continuous('D[N]', limits = c(-500, 700), breaks = seq(-500, 700, 200)) +
  scale_y_continuous('', breaks = NULL)
```

In @fig-sts-sig-result-1 ist der beobachtete Wert, $D = `r D_obs$Kraft[1]`$ abgetragen. Wir wissen von vorne herein, dass dieser Wert beeinflusst ist durch die zufällige Wahl der Stichprobe und die daran geknüpfte Streuung der Werte in der Population. Wie können wir den nun überhaupt eine Aussage treffen darüber, ob das Krafttraining was bringt oder vielleicht nur einen sehr kleinen Effekt zeigt oder möglicherweise sogar schädlich ist also zu einer Abnahme der Kraft führt?

Überlegen wir uns zunächst, welche Prozesse unseren beobachteten Wert zustande gebracht haben könnten. Wir haben schon zwei Prozesse kennengelernt, einmal den Prozess mit $\Delta = 100$ wie auch den Prozess mit $\Delta = 0$

```{r}
#| fig.cap: "Mögliche datengenerierende Prozesse für den beobachteten Unterschied $D$ (rot)"
#| label: fig-sts-sig-dgp-1
#| fig.height: 2

x <- seq(-1000, 1000, length.out = 100)
tibble(x = x,
       d_0 = dnorm(x, 0, sd_lummer),
       d_100 = dnorm(x, 100, sd_lummer)) |> 
  pivot_longer(-x, names_to = 'Verteilung', values_to = 'd') |> 
  ggplot(aes(x, d, ymin=0, ymax=d, group=Verteilung)) +
  geom_ribbon(aes(fill = Verteilung), alpha=.5) +
  geom_line() +
  annotate('point', x = D_obs$Kraft, y = 0, color = 'red', size = 3) +
  labs(x = 'D[N]', y = 'Dichte')

```

In @fig-sts-sig-dgp-1 ist wieder unser beobachteter Wert $D = `r D_obs$Kraft[1]`$ und die beiden Verteilungen abgetragen. Leider können wir nicht eineindeutig sagen, welche der beiden Verteilungen, bzw. deren zugrundeliegende Prozesse, unseren beobachteten Wert erzeugt haben könnte. Da unser beobachteter Wert $D$ genau zwischen den beiden Maxima der Verteilungen liegt. Etwas motiviertes Starren auf die Abbildung wird uns allerdings auf die Idee bringen, dass der beobachtete Wert nicht nur von diesen beiden Verteilungen erzeugt worden sein muss, sondern durchaus noch mehr Verteilungen in Frage kommen.

```{r}
#| fig.cap: "Beispiele für weitere mögliche Verteilungen als DGP."
#| label: fig-sts-sig-dgp-2
#| fig.height: 2

tibble(x = x,
       d_0 = dnorm(x, 0, sd_lummer),
       d_100 = dnorm(x, 100, sd_lummer),
       d_350 = dnorm(x, 350, sd_lummer),
       d_n250 = dnorm(x, -250, sd_lummer)) |> 
  pivot_longer(-x, names_to = 'Verteilung', values_to = 'd') |> 
  ggplot(aes(x, d, ymin=0, ymax=d, group=Verteilung)) +
  geom_ribbon(aes(fill = Verteilung), alpha=.5) +
  geom_line() +
  annotate('point', x = D_obs$Kraft, y = 0, color = 'red', size = 3) +
  labs(x = 'D[N]', y = 'Dichte')
```

@fig-sts-sig-dgp-2 zeigt, dass selbst die Verteilung mit $\Delta = -250N$ und $\Delta = 350N$ nicht unplausibel sind den beobachteten Wert erzeugt zu haben. Warum aber bei diesen fünf Verteilungen aufhören, warum sollte $Delta$ nicht $-50$ oder $127$ sein. Und überhaupt, keiner kann behaupten die Natur kennt nur ganzzahlige Werte (siehe $\pi$). Warum sollte $D$ also nicht auch $123.4567N$ sein?

Wenn diese Überlegung weitergeführt wird, dann wird schnell klar, dass letztendlich eine unendliche Anzahl von Verteilung in der Lage ist unseren beobachteten Wert plausibel zu generieren. D.h. wir haben ein Experiment durchgeführt und den ganzen Aufwand betrieben und haben wochenlang mit unseren ProbandInnen Krafttraining durchgeführt und sind hinterher eigentlich keinen Schritt weiter da wir immer noch nicht wissen was der datengenerierende Prozess ist. Also können wir selbst nach dem Experiment nicht sagen ob unser Krafttraining tatsächlich wirksam ist.

Zum Glück werden wir später sehen, das unser Unterfangen nicht ganz so aussichtslos ist. Schauen wir uns zum Beispiel die Verteilung für $\Delta = -350N$ an (@fig-sts-sig-dgp-3).

```{r}
#| fig.cap: "Verteilung für $\\Delta = -350N$ und der beobachtete Wert $D$"
#| label: fig-sts-sig-dgp-3
#| fig.height: 2

tibble(x = x,
       d = dnorm(x, -350, sd_lummer)) |>  
  ggplot(aes(x, d, ymin=0, ymax=d)) +
  geom_ribbon(alpha=.5) +
  geom_line() +
  annotate('point', x = D_obs$Kraft, y = 0, color = 'red', size = 3) +
  labs(x = 'D[N]', y = 'Dichte')
```

Unser beobachteter Wert unter der Annahme das $\Delta = -350N$ ist nicht vollkommen unmöglich, aber so richtig *wahrscheinlich* erscheint er auch nicht. Der Wert liegt relativ weit am Rand der Verteilung. Die Kurve ist dort schon ziemlich nahe bei Null. D.h. der beobachtete Wert ist zwar durchaus möglich, aber es wäre schon überraschend wenn wir bei einer Durchführung des Experiments ausgerechnet so einen Wert beobachten würden wenn unsere angenommenes $\Delta$ korrekt ist.

Wenn wir jetzt dagegen von der Annahme ausgehen, dass dem DGP der Wert $\Delta = 50N$ zugrundeliegen würde, hätten wir die Verteilung in @fig-sts-sig-dgp-4. Zunächst ist dieser Wert möglich unter der Annahme. Zusätzlich liegt der beobachtete Wert mitten drin in dem Teil der Verteilung der auch zu erwarten wäre. D.h. der beobachtete Wert ist durchaus plausibel unter der Annahme und bei der einmaligen Durchführung des Experiments würde uns der beobachtete Wert nicht unbedingt überraschen.

```{r}
#| fig.cap: "Verteilung für $\\Delta = 50N$ und der beobachtete Wert $D$"
#| label: fig-sts-sig-dgp-4
#| fig.height: 2

tibble(x = x,
       d = dnorm(x, 50, sd_lummer)) |>  
  ggplot(aes(x, d, ymin=0, ymax=d)) +
  geom_ribbon(alpha=.5) +
  geom_line() +
  annotate('point', x = D_obs$Kraft, y = 0, color = 'red', size = 3) +
  labs(x = 'D[N]', y = 'Dichte')
```

Diesen Ansatz können wir verwenden um mit Hilfe unseres Experiments doch etwas über den DGP auszusagen. Allerdings müssen wir uns noch einmal etwas eingehender mit Verteilungen auseinandersetzen um z.B. genauer zu bestimmen welche Ergebnisse uns überraschen würden. D.h. wir müssen uns erst ein mal ein paar neue Konzepte erarbeiten.

## Die Verteilung - 1. deep dive

Wir versuchen jetzt als erstes zu Verstehen was nochmal genau der Graph der Verteilung bedeutet. Auf der x-Achse werden die verschiedenen möglichen Werte der jeweiligen Statistik abgebildet. In unserem bisherigen Beispiel was das die Unterschiede $D$ zwischen der Kontroll- und der Treatmentgruppe. Der Wert auf der y-Achse was zunächst die relative Häufigkeit was auch Sinn gemacht hatte, da wir nur eine bestimmte endliche Anzahl von möglichen Unterschieden $D$ (ihr erinnert auch an die Zahl) vorliegen hatten. Was passiert aber wenn wir tatsächlich eine kontiuierliche Statistik haben, also eine Statistik die alle Werte innerhalb eines Intervalls einnehmen kann. Um den Fall zu verstehen fangen wir aber erst mal wieder mit einem einfachen Modell an.

### Der Münzwurf

Wir fangen mit dem einfachsten Experiment an: dem Münzwurf. Beim Münzwurf haben wir zwei mögliche Ausgänge unseres Experiments, entweder Kopf oder Zahl. Wir gehen von einer perfekten Münze aus, d.h. die Münze ist vollkommen symmetrisch auf beiden System und keine der Seiten ist in irgendeiner Form schwere oder beeinflusst in einer Art den Ausgang.

Wenn wir uns an die Schule zurück erinnern, dann haben wir in Wahrscheinlichkeitstheorie schon mal was gehört, das im Fall gleichwahrscheinlicher Ereignisse die Wahrscheinlichkeit für ein bestimmtes Ereignis, mittels der Anzahl der vorteilhaften Ausgänge geteilt durch die Anzahl der möglichen Ausgänge berechnet wird. Also beim einmaligen Münzwurf haben wir zwei Ausgänge $\{\text{Kopf}, \text{Zahl}\}$ und jeweils nur vorteilhaften Ausang als entweder Kopf oder Zahl, daher folgt daraus.

\begin{align}
P(\text{Kopf}) &= \frac{1}{2} \\
P(\text{Zahl}) &= \frac{1}{2}
\end{align}

Wenn wir das jetzt als Graphen in Form einer Wahrscheinlichkeitsverteilung abtragen, dann sieht das noch wenig interessant aus (siehe @fig-sts-sig-coin-toss-1). Das Muster ist aber trotzdem wichtig, damit wir später wissen worauf wir hier eigentlich schauen. Auf der x-Achse haben wir die möglichen Ausgänge, Kopf oder Zahl, und auf der y-Achse haben wir die Wahrscheinlichkeit abgetragen.

```{r}
#| fig.cap: "Wahrscheinlichkeitsverteilung des einmaligen Münzwurfes"
#| label: fig-sts-sig-coin-toss-1

ggplot(tibble(x = 1:2, y = 0.5),
       aes(x, y=0,xend=x, yend=y)) +
  geom_segment(size=2) +
  scale_x_continuous('Ereignis', limits = c(0, 3), breaks=1:2,
                     labels = c('Kopf','Zahl')) +
  scale_y_continuous('Wahrscheinlichkeit P', limits = c(0, 1))

```

Da sich mit einem Münzwurf aber so wenig anfangen lässt, machen wir das Ganze jetzt etwas komplizierter und schauen uns an, wie unser Experiment aussieht wenn wir zwei Münzwwürfe uns anschauen. Rein operational, wir schmeißen unsere Münze in die Luft, schreiben uns das Ergebnis auf, und machen das Ganze noch ein zweites Mal und schreiben uns das Ergebnis auf. D.h. was auch immer im ersten Durchgang passiert, hat keine Auswirkungen auf das Ergebnis des zweiten Wurfs. Wir könnten auch zwei Münzen nehmen und beide gleichzeitig in die Luft werfen. Das wäre das gleiche Experiment. Welche Ausgänge haben wir jetzt beim zweimaligen Münzwurf? Zunächst einmal haben wir jetzt nicht mehr nur einen einzelnen Ausgang sondern wir haben ein Ausgangstupel, eine Liste mit zwei Elementen. Etwas motiviertes krizteln auf einem Schmierblatt wird wahrscheinlich relativ schnell zu folgender Tabelle führen (siehe @tbl-sts-sig-coin-toss-2)

| Ausgang 1. Wurf | Ausgang 2. Wurf | Tupel |
| --- | --- | --- |
| Kopf | Kopf | (Kopf, Kopf) |
| Kopf | Zahl | (Kopf, Zahl) |
| Zahl | Kopf | (Zahl, Kopf) |
| Zahl | Zahl | (Zahl, Zahl) |

: Mögliche Ausgänge bei einem zweimaligen Münzwurf {#tbl-sts-sig-coin-toss-2}

Jetzt können wir uns wieder fragen, was die Wahrscheinlichkeit für die jeweiligen Ereignistupel ist. Eine direkte Methode wäre, wieder mittels der Symmetrie zu argumentieren. Es gibt vier verschiedene Ausgänge von denen jetzt keiner in irgendeiner Weise bevorzugt ist, daraus würde folgen das alle vier Ausgänge eine Wahrscheinlichkeit von $P = \frac{1}{4}$ haben.

Eine weitere Möglichkeit wäre mit den Wahrscheinlichkeiten aus dem einfachen Wurf an das Problem heran zu gehen. Wir betrachten die beiden Münzwürfe jetzt wieder sequentiell (siehe @fig-sts-sig-coin-toss-tree). Im ersten Schritt können wir entweder Kopf oder Zahl beobachten. Beide Wahrscheinlichkeiten sind $P = \frac{1}{2}$. Darauf folgend können wir wieder zwei verschiedene Ausgänge beobachten, eben Kopf oder Zahl, wieder mit der Wahrscheinlichkeit $P = \frac{1}{2}$. 

```{r}
#| fig.cap: "Auswahlmöglichkeiten beim sequentiellen zweimaligen Münzwurf"
#| label: fig-sts-sig-coin-toss-tree

DiagrammeR::grViz("digraph {
  graph [layout = dot, rankdir = LR]
  
  node [shape = ellipse]        
  rec1 [label = 'Start']
  rec2 [label = 'Kopf']
  rec3 [label =  'Zahl']
  rec4 [label = 'Kopf']
  rec5 [label = 'Zahl']
  rec6 [label = 'Kopf']
  rec7 [label = 'Zahl']
  
  # edge definitions with the node IDs
  rec1 -> rec2; rec1 -> rec3; rec2->rec4; rec2->rec5;rec3->rec6;rec3->rec7;
  }",
  height = 500)
```

Da die Münzwürfe voneinander unabhängig sind und keinen Einfluss aufeinander ausüben, folgt daraus, dass die Wahrscheinlichkeiten für jede spezielle Folge von Kopf oder Zahl sich berechnet nach:

$$
P(\text{Ausgang}) = P(\text{1. Wurf}) \times P(\text{2. Wurf})
$$ {#eq-2coin-toss}

Also in unseren Fall:

$$
P(\text{Ausgang}) = \frac{1}{2} \times \frac{1}{2} = \frac{1}{4}
$$ {#eq-2coin-toss-prob}

Womit wir wieder beim gleichen Ergebnis wie vorher angekommen sind. Der Vorteil dieser Herangehensweise ist jedoch, dass wir damit eine einfache Möglichkeit gefunden haben das Ergebnis auf mehr als nur zwei Würfe zu verallgemeinern. Nehmen wir zum Beispiel den dreifachen Münzwurf, dann können wir die Wahrscheinlichkeit für die Folge $P(\text{KKZ}) = \frac{1}{2}\times \frac{1}{2} \times \frac{1}{2} = \frac{1}{8}$ direkt angeben.

Bleiben wir aber erst noch mal kurz beim zweimaligen Münzwurf und schauen uns die Wahrscheinlichkeitsverteilung an. Hier stoßen wir nämlich auf ein Problem in der Darstellung. Wenn wir bei dem Muster aus @fig-sts-sig-oin-toss-1 bleiben wollen und auf der x-Achse die möglichen Ergnisse und auf der y-Achse die dazugehörende Wahrscheinlichkeit abtragen wollen, dann ist nicht ganz klar wie wir die Ergebnisse ordnen sollen. Eine mögliche Lösung ist in @fig-sts-sig-coin-toss-2a zu sehen.

```{r}
#| fig.cap: "Wahrscheinlichkeitsverteilung des zweimaligen Münzwurfes (K: Kopf, Z: Zahl)" 
#| label: fig-sts-sig-coin-toss-2a

ggplot(tibble(x = 1:4, y = 0.25),
       aes(x, y=0,xend=x, yend=y)) +
  geom_segment(size=2) +
  scale_x_continuous('Ereignis', limits = c(0, 5), breaks=1:4,
                     labels = c('KK','KZ','ZK','ZZ')) +
  scale_y_continuous('Wahrscheinlichkeit P', limits = c(0, 1))

```

Dies ist natürlich nicht die einzige Möglichkeit wie wir die Ereignisse ordenen können sondern wahrscheinlich ist jede der 24 möglichen Anordnungen gleich sinnig. Wir könnten auch beispielsweise nicht mehr die beiden einzelnen Ausgänge als Ereignisse wählen, sondern könnten zum Beispiel nur noch die Anzahl der Köpfe in unseren zwei Würfen zählen. Dies würde zu der folgenden Zuordnung führen (siehe @tbl-sts-sig-coin-toss-2a).

| Ereignisse | Anzahl der Köpfe |
| --- | --- |
| (Kopf, Kopf) | 2 |
| (Kopf, Zahl) | 1 |
| (Zahl, Kopf) | 1 |
| (Zahl, Zahl) | 0 |

: Zuordnung der Anzahl der Köpfe zu den Ereignissen beim zweimaligen Münzwurf {# tbl-sts-sig-coin-toss-2a}

Wir verliegen bei dieser Zuordnung nachtürlich die Information bei welchem Wurf die Zahl beobachtet wurde, aber eigentlich interessiert uns das sowieso nicht so brennend. In der Terminologie der Wahrscheinlichkeitstheorie wird die Anzahl der Köpfe als Zufallsvariable bezeichnet.

::: {#def-random-variable}
## Zufallsvariable

Eine Zufallsvariable\index{Zufallsvariable} ist die Abbildung eines Zufallsereignisses auf eine Zahl.

:::

Anders dargestellt, ist eine Zufallsvariable eine Funktion, die einem Ereignis eine Zahl zuordnet (siehe @fig-sts-sig-random-variable.

```{r}
#| fig.cap: "Eine Zufallsvariable ist eine Abbildung."
#| label: fig-sts-sig-random-variable
#| fig.height: 2

DiagrammeR::grViz("digraph {
  graph [layout = dot, rankdir = LR]
  
  node [shape = ellipse]        
  rec1 [label = 'Ereignis']
  rec2 [label = 'Zahl']
 
  # edge definitions with the node IDs
  rec1 -> rec2; 
  }",
  height = 300)
```

Wenn wir uns jetzt die Wahrscheinlichkeiten für unsere Zufallsvariable anschauen, dann sehen wir aber, dass wir nicht mehr vier verschiedne Ausgänge haben, sondern nur noch drei und das die gleiche Wahrscheinlichkeit für nicht gleich sind.

|Ereignisse | Zufallsvariale | Wahrscheinlichkeit |
|---| --- | --- |
| (Zahl, Zahl) | Keine Köpfe | $\frac{1}{4}$ |
| (Kopf, Zahl)(Zahl,Kopf)| 1 Kopf | $\frac{1}{4} + \frac{1}{4} = \frac{1}{2}$ |
|(Kopf,Kopf) | 2 Köpfe | $\frac{1}{4}$ |

: Wahrscheinlichkeitstabelle für Zufallsvariable "Anzahl der Köpfe beim zweimaligen Münzwurf". {#tbl-sts-sig-coin-toss-2b}

Jetzt können wir wieder eine Wahrscheinlichkeitsverteilung für unsere Zufallsvariable abtragen (siehe @fig-sts-sig-coin-toss-2c).

```{r}
#| fig.cap: "Wahrscheinlichkeitsverteilung für die Anzahl der Köpfe beim zweimaligen Münzwurf"
#| label: fig-sts-sig-coin-toss-2c
#| fig.height: 2

ggplot(tibble(x = 0:2, y = c(0.25,0.5,0.25)), 
       aes(x, y=y,xend=x, yend=0)) +
  geom_segment(size=1) +
  geom_point(size=2) +
  scale_x_continuous('Anzahl der Köpfe', breaks=0:2) +
  scale_y_continuous('Wahrscheinlichkeit P', limits = c(0, 1))

```

Nur nebenher noch einmal das offensichtliche Ansprechen, die Summe der Wahrscheinlichkeiten muss zu $1$ addieren. Das sollte auch einsichtig sein. Wenn ich alle möglichen Ereignisse abfrage also: "*Was ist die Wahrscheinlichkeit das ich keine Köpfe, 1 Kopf oder 2 Köpfe beim zweimaligen Münzwurf erhalte*", dann sind das alle möglichen Ausgänge und dementsprechend sollte die Wahrscheinlichkeit dafür "1" sein oder mathematisch ausgedrückt:

$$
P(\text{0 Köpfe} \cup \text{1 Kopf} \cup \text{2 Köpfe}) = \frac{1}{4} + \frac{1}{2} + \frac{1}{4} = 1
$$

### Lage- und Skalenparameter

In @fig-sts-sig-dgp-2 sind verschiedene Verteilungen abgebildet die sich eigentlich nur in ihrer Position bzw. Lage unterscheiden. Der Parameter der bei einer Verteilungen die Lage steuert ist der Mittelwert den wir bereits schon kennengelernt haben. Hier jetzt aber nicht der Mittelwert $\bar{x}$ in der Stichprobe, sondern der Mittelwert der zugrundeliegenden Population der dann mit dem Symbol $\mu$ bezeichnet wird. Die Beschreibung als Parameter der Verteilung heißt nichts anderes das die Verteilung von $\mu$ abhängt, oder formal das die Verteilung eine Funktion von $\mu$ ist. Wenn wir uns an Funktionen aus der Schule zurück erinnen wo wir Funktionen $f$ von $x$ kennengelernt haben und als $f(x)$ dargestellt haben. Übertragen auf die Verteilung könnte dies mittels $f(\mu)$ dargestellt werden.

```{r}
#| fig.cap: "Eine Dichtefunktion"

d_x <- 0.025
x <- seq(-3, 3, d_x)
dat_0 <- tibble(
  x = x,
  v = dnorm(x, 0, 1) 
)
low <- tibble(
  x = seq(-3,-2,d_x),
  v = dnorm(x, 0, 1)
)
up <- tibble(
  x = seq(2, 3, d_x),
  v = dnorm(x, 0, 1)
)
```

Nehmen wir nun zwei Verteilungen die sich bezüglich ihrer Mittelwerte $\mu$ unterscheiden. Zum Beispiel sei $\mu_1 = 0$ und $\mu_2 = 3$. Wie in @fig-sts-sig-dist-mu zu sehen ist, führt dies dazu,  das die beiden Verteilungen gegeneinander verschoben sind.

```{r}
#| fig.cap: "Verteilungen mit zwei unterschiedlichen Mittelwerten"
#| label: fig-sts-sig-dist-mu

xx <- seq(-3,6,d_x)
n_pts <- length(xx)
dat_1 <- tibble(
  x = rep(xx,2),
  v = c(dnorm(xx, 0, 1),
        dnorm(xx, 3, 1)),
  pos = rep(c('x0','x3'), c(n_pts,n_pts))
)
ggplot(dat_1, aes(x,v,ymin=0, ymax=v, fill=pos)) +
  geom_ribbon(alpha=.5) +
  geom_line() +
  labs(x = 'Werte', y = 'Dichte') +
  scale_fill_discrete("Lageparameter",
                      labels = c(expression(mu == 0), expression(mu == 3))) 
```

Der Mittelwert $\mu$ der Verteilung wird auch als Erwartungswert bezeichnet. Dies kann dahingehend interpretiert werden, das wenn Stichproben aus dieser Verteilungen gezogen werden, im Mittel der Wert $\mu$ erwartet wird. Soweit ist dies eigentlich noch nichts wirklich Neues, sondern hatten dies schon vorher gesehen, als wir alle möglichen Unterschiede zwischen der Kontrollgruppe und der Interventionsgruppe ermittelt haben. Hier war der Mittelwert der Verteilung genau derjenige Wert von $\Delta$.

An dieser Stelle sollte nochmal der Unterschied zwischen $\mu$ und $\bar{x}$ klargestellt werden. Der Mittelwert $\mu$ ist eine Eigenschaft der Population, also letztendlich ein Wert den wir niemals kennen werden ohne die gesamte Population zu untersuchen. Der Mittelwert $\bar{x}$ ist eine Eigenschaft der Stichprobe aus der Population. Also der konkrete Wert den wir anhand der Stichprobe berechnen. In vielen Fällen versuchen wir über $\bar{x}$ einen Rückschluss auf $\mu$ zu ziehen.

Als zweite Eigenschaft von Verteilungen schauen wir uns jetzt die Streuung in der Population an. Die Streuung in der Population wird als Varianz bezeichnet und wird mit dem Symbol $\sigma^2$ bezeichnet. Schauen wir uns zunächst an, welchen Einfluss $\sigma^2$ auf die Form der Verteilung hat. In @fig-sts-sig-dist-sigma sind wieder zwei Verteilungen abgetragen. Dieses Mal ist $\mu$ in beiden Fällen gleich, aber die Varianzen $\sigma$ sind mit $\sigma_1^2 = 2$ und $\sigma_2^2=1$ unterschiedlich.

```{r}
#| fig.cap: "Verteilungen mit unterschiedlichen Varianzen"
#| label: fig-sts-sig-dist-sigma

xx <- seq(-5,5,d_x)
n_pts <- length(xx)
dat_2 <- tibble(
  x = rep(xx,2),
  v = c(dnorm(xx, 0, 1),
        dnorm(xx, 0, sqrt(2))),
  type = rep(c('s1','s0.5'), c(n_pts,n_pts))
)
ggplot(dat_2, aes(x,v,ymin=0, ymax=v,fill=type)) +
  geom_ribbon(alpha=.5) +
  geom_line() +
  labs(x = 'Werte', y = 'Dichte') +
  scale_fill_discrete("Varianz",labels = c(
    expression(sigma^2 == 2),
    expression(sigma^2 == 1)
  )) 
```

^[auch Skalenparameter]

## Formeln 

\begin{table}[]
    \caption{Parameter einer Verteilung und deren Sch\"atzer}
    \centering
    \begin{tabular}{llr}
     \toprule
     Population & Stichprobe & \\
     \midrule
     Mittelwert $\mu$ & $\bar{x} = \frac{1}{n}\sum_{i=1}^n x_i$  \\
     Varianz $\sigma^2$ & $s^2 = \frac{1}{n-1}\sum_{i=1}^n (x_i - \bar{x})^2$ \\
     Standardabweichung $\sigma$ & $s = \sqrt{s^2}$ \\
     \bottomrule
    \end{tabular}
\end{table}

n := Anzahl der Stichprobenelemente, $x_i$ := Messwerte


## Nebenbei: Warum der Mittelwert Sinn macht
```{r}
#| fig.cap: "Verteilung der Mittelwerte von Stichproben der Größe $n=10$, Kleine Welt Population $\\mu$ (rot)"

bar <- function(world, k=3) {
  n <- dim(world)[1]
  x <- 1:n
  N <- choose(n,k)
  x_bars <- numeric(N)
  # get all permutations
  id_1 <- t(combn(x,k))
  for (i in 1:nrow(id_1)) {
    x_bars[i] <- mean(world$Kraft[id_1[i,]])
  }
  x_bars
}
x_bars <- bar(world, 10)
mu <- mean(world$Kraft)
ggplot(tibble(x=x_bars),aes(x)) +
  geom_histogram(aes(y = stat(density)), bins = 30) +
  geom_vline(xintercept = mu,
             color = 'red', linetype = 'dashed') +
  labs(x = 'Mittelwerte[N]', y = 'Häufigkeit') 
```

## Mit der Verteilung die annimmt das nichts passiert!

```{r}
#| fig.cap: "Verteilung wenn nichts passiert."

d_x <- 0.025
x <- seq(-3, 3, d_x)
dat_0 <- tibble(
  x = x,
  v = dnorm(x, 0, 1) 
)

ggplot(dat_0, aes(x,v,ymin=0, ymax=v)) +
  #geom_area(data = low, fill='red', alpha=.8) +
  #geom_area(data = up, fill='red', alpha=.8) +
  geom_line() +
  labs(x = 'Werte', y = 'Dichte') 
```

```{r}
#| fig.cap: "Quantilefunktion wenn nichts passiert."

xx <- seq(0,1,0.01)
n_pts <- length(xx)
dat_4 <- tibble(
  x = xx,
  v = qnorm(xx) 
)
ggplot(dat_4, aes(x,v,ymin=0, ymax=v)) +
  geom_line() +
  labs(x = 'Quantile', y = 'Werte') 
```

## *Signifikanter* Wert

```{r}
#| fig.cap: "Verteilung wenn nichts passiert und kritische Regionen."
low <- tibble(x = seq(-3, -2, length.out=50), v = dnorm(x))
up <- tibble(x = seq(2, 3, length.out=50), v = dnorm(x))
ggplot(dat_0, aes(x,v,ymin=0, ymax=v)) +
  geom_area(fill='green', alpha=.5) +
  geom_area(data = low, fill='red', alpha=.8) +
  geom_area(data = up, fill = 'red', alpha=.8) +
  geom_vline(xintercept = c(-2,2), color='red', linetype='dashed') +
  geom_label(data = tibble(x = c(-2,2), v = 0.3,
                           labels=c(expression(k[lower]),
                                    expression(k[upper]))),
             aes(x,v,label=labels), parse=T) +
  geom_line() +
  labs(x = 'Werte', y = 'Dichte') 
```

Wenn der Stichprobenwert der Statistik in der *kritischen* Region auftritt, dann wird von einem **statistisch** signifikanten Effekt gesprochen. *Unter der $H_0$ bin ich überrascht diesen Wert zu sehen!*

## Der p-Wert

```{r}
#| fig.cap: "Der gelben Flächen zeigen den p-Wert für den Wert der Statistik von d = 2,5 an."

p_val <- 2.5
p_dat_up <- tibble(
  x = seq(p_val, 3, length.out=40),
  v = dnorm(x)
)
p_dat_low <- tibble(
  x = seq(-3, -p_val, length.out=40),
  v = dnorm(x)
)
ggplot(dat_0, aes(x,v,ymin=0, ymax=v)) +
  geom_area(data = low, fill='red', alpha=.8) +
  geom_area(data = up, fill='red', alpha=.8) +
  geom_area(data = p_dat_low, fill='yellow', alpha=0.9) +
  geom_area(data = p_dat_up, fill='yellow', alpha=0.9) +
  geom_vline(xintercept = c(-2,2), color='red', linetype='dashed') +
  geom_label(data = tibble(x = c(-2,2), v = 0.3,
                           labels=c(expression(k[lower]),
                                    expression(k[upper]))),
             aes(x,v,label=labels), parse=T) +
  geom_line() +
  geom_point(data = tibble(x = p_val, v = 0), size=2) +
  labs(x = 'Werte', y = 'Dichte') 
```

## p-Werte

Der p-Wert gibt die Wahrscheinlichkeit für den gefundenen oder einen noch extremeren Wert unter der $H_0$ an.


```{r}
#| fig.cap="Verschiedene P-Werte"

foo <- function(p, lo=-3, up=3, d_x=0.025) {
  len <- 40
  x <- c(seq(lo, -abs(p), length.out=len))
  tibble(x, v= dnorm(x), type=p)
}
foo2 <- function(p, lo=-3, up=3, d_x=0.025) {
  len <- 40
  x <- c(seq(abs(p), up, length.out=len))
  tibble(x, v= dnorm(x), type=p)
}
p_s <- c(-2.7, -1.13, 0.7, 2.1) 
p_vals <- round(2*(1 - pnorm(abs(p_s))),2)
dat_3 <- purrr::map_dfr(p_s, foo)
dat_3_up <- purrr::map_dfr(p_s, foo2)
ggplot(dat_3, aes(x,v,ymin=0, ymax=v)) +
  geom_ribbon(alpha=0.5) +
  geom_ribbon(data=dat_3_up, alpha=0.5) +
  geom_line(data=dat_0) +
  geom_point(data = tibble(x=p_s, v=0,type=p_s), color='red') +
  facet_grid(~type, labeller=as_labeller(function(p){
    paste("Statistik = ", p, "\np-Wert = ", p_vals[which(p_s == p)])
  })) +
  labs(x = 'Werte', y = 'Dichte') + 
  scale_x_continuous(breaks=c(-3,0,3)) +
  theme(strip.text = element_text(size=8))
```

## p-Werte

*"[A] p-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value."* [@wasserstein2016, p.131]

*"[T]he P value is the probability of seeing data that are as weird or more weird than those that were
actually observed."* [@christensen2018, p.38]

## Signifikanter Wert - Das Kleingedruckte

- **Vor** dem Experiment wird für ein $H_0$ ein $\alpha$-Level angesetzt (per Konvention $\alpha=0,05 = 5\%$)
- Anhand des $\alpha$-Levels können **kritische Werte** ($k_{lower}, k_{upper}$) bestimmt werden. Diese bestimmen die Grenzen der **kritischen Regionen**.
- Wenn der gemessene Wert w der Statistik in die kritische Region fällt, also $w \leq k_{lower}$ oder $w \geq k_{upper}$ gilt, dann wird von einem **statistisch** signifikanten Wert gesprochen und die dazugehörige Hypothese wird **abgelehnt**. Äquivalent: Der p-Wert ist kleiner als $\alpha$.
- Da in $\alpha$-Fällen ein Wert in der kritischen Region auftritt, auch wenn die $H_0$ zutrifft, wird in $\alpha$-Fällen ein $\alpha$-Fehler gemacht.

## Signifikanter Wert - Das Kleingedruckte

- Wenn der Wert w der Statistik nicht in den kritischen Regionen liegt, oder gleichwertig der p-Wert größer als $\alpha$ ist, wird die $H_0$ **beibehalten**. D.h. nicht, dass **kein Effekt** vorliegt, sondern lediglich, dass anhand der Daten keine Evidenz diesbezüglich gefunden werden konnte!
- Die **statistische** Signifikanz sagt nichts über die Wahrscheinlichkeit der Theorie aus!
- Ein p-Wert von $p = 0.0001$ heißt nicht, dass mit 99,99\% Wahrscheinlichkeit ein Effekt vorliegt!
- *Statistisch* signifikant heißt nicht automatisch *praktisch* relevant!

## Nochmal, wenn die $H_0$ nicht abgelehnt wird

![Ausschnitt aus @altman1995](pics/altman_1995.png){height=6cm}

## Nochmal p-Wert (@wasserstein2016)

1. P-values can indicate how incompatible the data are with a specified statistical model.
2. P-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.
3. Scientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.
4. Proper inference requires full reporting and transparency
5. A p-value, or statistical significance, does not measure the size of an effect or the importance of a result.
6. By itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis.

## Was passiert nun aber wenn die "andere" Hypothese zutrifft? 

```{r}
#| fig.cap: "Differenzen mit kritischen Regionen (rot) mit einer Wahrscheinlichkeit von $\\alpha$ wenn $H_0$ zutrifft."

differences <- readr::read_csv('data/combinations_differences.csv')
n_sim <- dim(differences)[1]
sigma <- sd(differences$d)
xx <- -750:1250
n_pts <- length(xx)
q_crit <- qnorm(0.975, 0, sd = sigma)
dat_power <- tibble(
  x = rep(xx,2),
  y = c(dnorm(xx,0,sigma), dnorm(xx,500,sigma)),
  hypo = rep(c("H0","H500"), c(n_pts, n_pts))
)
low <- tibble(x = seq(-750,-q_crit), y = dnorm(x, 0, sigma), hypo='H50')
up <- tibble(x = seq(q_crit, 750), y = dnorm(x, 0, sigma), hypo='H50')
ggplot(dat_power, aes(x,y,fill=hypo,ymin=0,ymax=y)) +
  geom_ribbon(alpha=.5) +
  geom_area(data = up, fill='red', alpha=0.8) +
  geom_area(data = low, fill='red', alpha=.8) +
  geom_line() +
  scale_fill_discrete('Hypothese') +
  labs(x = 'Differenzen[N]', y = 'relative Häufigkeit') 
```

## Wir machen einen $\beta$-Fehler! 
```{r}
#| fig.cap: "Differenzen mit kritischen Regionen (rot) mit einer Wahrscheinlichkeit von $\\alpha$ wenn $H_0$ zutrifft und $\\beta$ (grün) wenn $H_1$ zutrifft."

beta <- tibble(
  x = -300:q_crit,
  y = dnorm(x, 500, sigma)
)
ggplot(dat_power, aes(x,y,fill=hypo,ymin=0,ymax=y)) +
  geom_ribbon(alpha=.5) +
  geom_area(data = up, fill='red', alpha=0.8) +
  geom_area(data = low, fill='red', alpha=.8) +
  geom_area(data = beta, fill='green', alpha=0.5) +
  geom_line() +
  scale_fill_discrete('Hypothese') +
  labs(x = 'Differenzen[N]', y = 'relative Häufigkeit') 
```

## Snap!(1989) - The Power

```{r}
#| fig.cap: "$1-\\beta$ = Power des Tests (blaue Fläche)."

beta <- tibble(
  x = -300:q_crit,
  y = dnorm(x, 500, sigma)
)
power <- tibble(
  x = q_crit:max(dat_power$x),
  y = dnorm(x, 500, sigma)
)
ggplot(dat_power, aes(x,y,fill=hypo,ymin=0,ymax=y)) +
  geom_ribbon(alpha=.5) +
  geom_area(data = up, fill='red', alpha=0.8) +
  geom_area(data = low, fill='red', alpha=.8) +
  geom_area(data = beta, fill='green', alpha=0.5) +
  geom_area(data = power, fill='blue', alpha=0.5) +
  geom_line() +
  scale_fill_discrete('Hypothese') +
  labs(x = 'Differenzen[N]', y = 'relative Häufigkeit') 
```

## Terminologie noch mal

- $\alpha$: Die Wahrscheinlichkeit sich gegen die $H_0$ zu entscheiden, wenn die $H_0$ zutrifft. $\alpha$-Level wird vor dem Experiment festgelegt um zu kontrollieren welche Fehlerrate toleriert wird.
- $\beta$: Die Wahrscheinlichkeit sich gegen die $H_1$ zu entscheiden, wenn die $H_1$ zutrifft.
- Power := $1 - \beta$: Die Wahrscheinlichkeit sich für die $H_1$ zu entscheiden, wenn die $H_1$ zutrifft. Sollte ebenfalls **vor** dem Experiment festgelegt werden.


## Wie können wir die Power erhöhen? 

```{r}
#| fig.cap: "Verteilungen wenn $\\delta$=500 und $\\delta$=0 in unserem kleine Welt Beispiel mit n = 3."

dat <- tibble(
  di = c(differences$d + 500, differences$d),
  hypo = rep(c('H500','H0'), c(n_sim,n_sim))
)
p_h500 <- ggplot(dat, aes(di, fill=hypo)) +
  geom_density(alpha=0.5) +
  labs(x = 'Differenzen[N]', y = 'relative Häufigkeit') +
  scale_fill_discrete("Hypothese", labels=c(
    expression(H[0]  ), expression(H[500])
  ))
print(p_h500)
```


## Stichprobengröße von n = 3 auf n = 9 erhöhen?

```{r}
#| fig.cap: "Stichprobenverteilungen der Differenz unter $H_0$ und $H_1:\\delta=500$N bei einer Stichprobengröße von n = 9"

sample_k9 <- readr::read_csv('data/sample_k9.csv')
sigma <- sample_k9$sd[1]
d <- sample_k9$m[2]
xx = seq(-4*sigma,d+4*sigma)
n_pts = length(xx)
dat_k9 <- tibble(
  x = rep(xx,2),
  y = c(dnorm(xx, 0, sigma), dnorm(xx, d, sigma)),
  hypo = rep(c('H0','H500'), c(n_pts, n_pts))
)
ggplot(dat_k9, aes(x,y,fill=hypo, ymin=0, ymax=y)) +
  geom_ribbon(alpha=0.5) +
  geom_line() +
  scale_fill_discrete("Hypothese", labels=c(
    expression(H[0]  ), expression(H[500])
  )) +  
  lims(x = c(-750, 1250)) +
  labs(x = 'Differenzen[N]', y = 'relative Häufigkeiten') 
```

## Standardfehler 

Die Standardabweichung der Statistik wird als **Standardfehler** $s_e$ bezeichnet^[Der Standardfehler schätzt die Reliabilität der Statistik ab (@cohen1988)]. Der Standardfehler ist nicht gleich der Standardabweichung in der Population bzw. der Stichprobe. Es gilt für den Mittelwert:


\begin{table}[]
    \caption{Standardfehler des Mittelwerts, n = Stichprobengröße}
    \centering
    \begin{tabular}{ll}
     \toprule
     Population & Stichprobe \\
     \midrule
     $\sigma_{\bar{X}} =  \sqrt{\frac{\sigma^2}{n}} = \frac{\sigma}{\sqrt{n}}$ & 
     $ s_e =  \sqrt{\frac{s^2}{n}} = \frac{s}{\sqrt{n}}$ \\ 
     \bottomrule
    \end{tabular}
    \label{tab:s_e}
\end{table}



# Parameterschätzung 

## Problem bei einer dichotomen Betrachtung der Daten

![Auszug aus @cumming2013 [p.1]](../pics/cumming_luck.png)


## Wie groß ist der Effekt? 

```{r}
#| fig.cap: "Stichprobenverteilungen der Differenz unter $H_0$ und $H_1:\\delta=500$N bei einer Stichprobengröße von n = 9"

d_x <- 2 
sigma <- sample_k9$sd[1]
d <- sample_k9$m[2]
xx = seq(-4*sigma,d+4*sigma)
n_pts = length(xx)
dat_k9 <- tibble(
  x = rep(xx,2),
  y = c(dnorm(xx, 0, sigma), dnorm(xx, d, sigma)),
  hypo = rep(c('H0','H500'), c(n_pts, n_pts))
)
ggplot(dat_k9, aes(x,y,fill=hypo, ymin=0, ymax=y)) +
  geom_ribbon(alpha=0.5) +
  geom_line() +
  scale_fill_discrete("Hypothese", labels=c(
    expression(H[0]  ), expression(H[500])
  )) +  
  lims(x = c(-750, 1250)) +
  labs(x = 'Differenzen[N]', y = 'relative Häufigkeiten') 
```


## Schätzung der Populationsparameter

```{r}
alpha <- 0.05
delta <- 500
mu <- delta
d_hat <- 350
s_hat <- 132
s_e <- round(s_hat/sqrt(9))
c_i <- d_hat + c(-1,1)*qnorm(1-alpha/2)*s_e
```

Kleine Welt: Experiment wird einmal mit n = 9 durchgeführt 

### Beobachtete Stichprobenkennwerte

\begin{align*}
d = \bar{x}_{treat} - \bar{x}_{con} &= `r d_hat` \\
s &= `r s_hat` \\
s_e &= `r s_e`
\end{align*}

Wie präzise ist meine Schätzung und welche anderen Unterschiedswerte sind anhand der beobachteten Daten noch plausibel?

## Welche $\delta$s sind plausibel für $d = `r d_hat`$? 

```{r}
#| fig.cap: "Verschiedene Verteilungen von Gruppendifferenzen, beobachteter Unterschied (rot)"

cut_h <- 0.00002
dat_con <- tibble(
  x = seq(-500, 1000, length.out=200),
  d0 = dnorm(x, 0, s_e),
  dm75 = dnorm(x, -75, s_e),
  d500 = dnorm(x, 500, s_e),
  d350 = dnorm(x, 350, s_e),
  d250 = dnorm(x, 250, s_e)
) %>% tidyr::pivot_longer(-x, names_to="x_bar", values_to="v") %>% 
  dplyr::filter(v > cut_h)
ggplot(dat_con, aes(x,v,ymin=cut_h, ymax=v, fill=x_bar)) + 
  geom_line() +
  geom_ribbon(alpha=0.3) +
  geom_vline(xintercept = d_hat, col = 'red', linetype='dashed') +
  scale_fill_discrete("Verteilungen",
                      breaks = c('d0', 'd500', 'd350', 'dm75', 'd250'),
                      labels = c(expression(delta==0),
                                 expression(delta==500),
                                 expression(delta==350),
                                 expression(delta==-75),
                                 expression(delta==250))) +
  labs(x = "Differenz", y = "Dichte") 
```

Plausibel unter einem gegebenem **$\alpha$-Level**!


## Alle möglichen $\delta$s die plausibel sind

```{r}
#| fig.cap: "Konfidenzintervall (grün), Populationsparameter $\\delta$ und $\\alpha$-Level für die beobachtete Differenz (gelb)."

mu_s <- seq(150, 550, length.out=25) 
q_s <- qnorm(alpha, mu_s, s_e)
df <- tibble(mu_s = mu_s,
             lu = qnorm(alpha/2,mu_s, s_e),
             up = qnorm(1-alpha/2, mu_s, s_e)) %>%
  dplyr::mutate(inside = dplyr::if_else(mu_s >= c_i[1] & mu_s <= c_i[2], 'ja', 'nein'))
ggplot(df, aes(x = mu_s, y = mu_s, ymin = lu, ymax = up, color = inside)) +
  geom_hline(yintercept = d_hat, color = 'yellow') +
  geom_hline(yintercept = c_i, color = 'green') +
  geom_hline(yintercept = delta, color = 'black') +
  geom_pointrange(size=0.3) +
  labs(x = bquote('Mögliche'~delta), y = "") +
  scale_color_manual("plausibel", values = c('green','red')) +
  scale_y_continuous(breaks = seq(50,700,50)) +
  scale_x_continuous(breaks = NULL) +
  annotate("text", y=550,x=100,label=expression(delta==500), size=4) +
  annotate("text", y=400,x=100,label=expression(d==350), size=4) +
  coord_flip() 
```

## Was passiert wenn ich das Experiment ganz oft wiederhole?

```{r}
#| fig.cap: "Simulation von $n = 100$ Konfidenzintervallen."
#| cache: true

foo <- function(mu = 500, se = 132, n = 20, alpha = 0.05) {
  sam <- rnorm(n, mu, se)
  x_hat <- mean(sam)
  s_e <- sd(sam)/sqrt(n)
  q <- qnorm(alpha/2)
  c(x_hat, x_hat + c(1,-1) * q * s_e)
}
N <- 100
set.seed(2)
c_is <- t(replicate(N, foo(mu, sigma, 20)))
colnames(c_is) <- c("x_hat","lo","up")
df_2 <- as_tibble(c_is) %>% dplyr::mutate(id = dplyr::row_number(),
                                   inside = dplyr::if_else((mu >= lo) & (mu <= up), 'ja','nein'))
ggplot(df_2, aes(id, x_hat, color = inside)) + 
  geom_pointrange(aes(ymin = lo, ymax = up), size=0.3) +
  geom_hline(yintercept = mu, color = 'black') +
  scale_color_manual("enthalten", values = c('green','red')) +
  labs(x = 'Experiment[#]', y = "d") +
  coord_flip()
```

## Konfidenzintervall - Das Kleingedruckte

- Das Konfidenzintervall für ein gegebenes $\alpha$-Niveau gibt nicht die Wahrscheinlichkeit an mit der der *wahre* Parameter in dem Intervall liegt.
- Das Konfidenzintervall gibt alle mit den Daten kompatiblen Populationsparameter an.
- Das $\alpha$-Niveau des Konfidenzintervalls gibt an bei welchem Anteil von Wiederholungen davon auszugehen ist, das das Konfidenzintervall den wahren Populationsparameter enthält. 

## Konfidenzintervall herleiten nach @spiegelhalter2019 [p.241]
\scriptsize
1. We use probability theory to tell us, for any particular population
parameter, an interval in which we expect the observed statistic to lie
with 95% probability.
2. Then we observe a particular statistic.
3. Finally (and this is the difficult bit) we work out the range of possible
population parameters for which our statistic lies in their 95\%
intervals. This we call a "95\% confidence interval".
4. This resulting confidence interval is given the label "95\%" since, with
repeated application, 95% of such intervals should contain the true
value.^[Strictly speaking, a 95\% confidence interval does ***not*** mean there is a 95\% probability that this particular interval contains the true value [...]]

All clear? If it isn’t, then please be reassured that you have joined
generations of baffled students.


## Konfidenzintervall berechnen (Vorschau)

$$
\textrm{CI}_{1-\alpha} = \bar{x} \pm z_{\alpha/2} \times s_e 
$$


## Dualität von Signifikanztests und Konfidenzintervall

Wenn das Konfidenzintervall mit Niveau $1-\alpha\%$ die $H_0$ nicht beinhaltet, dann wird auch bei einem Signifikanztest die $H_0$ bei einer Irrtumswahrscheinlichkeit von $\alpha$ abgelehnt.






