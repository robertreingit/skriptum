# Logistische Regression

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```

```{r defs}
require(tidyverse)
require(knitr)
require(MASS)
library(pROC)
library(CalibrationCurves)
```

In der bishergen Behandlung der Regression war die Kriteriumsvariable, also die abhängige Variable, immer eine metrische Variable deren Wertebereich im Prinzip von $-\infty$ bis $\infty$ ging. In der Realität ist dies natürlich nicht tatsächlich der Fall, da beispielsweise die Wurfgeschwindigkeit im Handball in der Realität durch die physiologische Kapazität der Spieler:Innen beschränkt ist. Allerdings gibt es auch den Fall, dass die Kriteriumsvariable überhaupt nur Werte innerhalb eines bestimmten Intervalls zulässt. Die Wahrscheinlichkeit ein Tor im Handball zu werfen beispielsweise kann nur Werte im Intervall $[0,1]$ einnehmen. Soll nun Beispielsweise ein Regressionsmodell erstellt werden um die Torwahrscheinlichkeit $p_{\text{Tor}}$ beispielsweise anhand des Abstands $d$ zum Tor und des Winkels $\alpha$ von der Torfläche vorherzusagen, dann kann dies im Prinzip mit einem multiplen Regressionmodell durchgeführt werden.

$$
p_{\text{Tor},i} = \beta_0 + \beta_1 d_i + \beta_2 \alpha_i + \epsilon_i
$$

Allerdings verhindert nichts, dass $p_{\text{Tor},i}$ Werte außerhalb des Bereichs $[0,1]$ einnehmen kann. D.h. um die Idee eines linearen Regressionsmodells auf dieses Problem auszuweiten ist eine Beschränkung der möglichen Werte notwendig.

Eine weitere Besonderheit im Zusammenhang mit dem Handballbeispiel, hängt mit Eigenschaft zusammen, dass die Werte der abhängigen Variable $Y$ in der Realität nur zwei Werte einehmen können. Mit der Zuweisung $\text{Tor} = 1$ und $\text{Fehlversuch} = 1$ nimmt $Y$ immer nur die Werte $0$ oder $1$ ein. Entsprechend würde ein Datensatz die folgende Form haben:

| Tor | Abstand[m] | Winkel[°] |
| --- | --- | --- |
| 0   | 4  | 45 |
| 1   | 5 | 90 |
| 0   | 3.5 | 30 |

: Beispiel für einen Datensatz zur Trefferwahrscheinlichkeit im Handball in Abhängigkeit von der Distanz zum Tor und Winkel zur Grundlinie.

Unter diesem Aspekt, kann dieses Problem auch als Klassifikationsproblem interpretiert werden. Es sind zwei verschiedene *Klassen* vorhanden, **Tor** und **kein Tor** und es soll anhand bestimmter Prädiktorvariablen vorhergesagt werden, zu welcher Klasse ein Objekt zugeordnet werden kann. Ähnliche Problemstellung ergeben sich auch im medizinischen Kontext, wo beispielsweise anhand einer Reihe von Prädiktorvariablen bestimmt werden soll, ob ein:e Patient:In erkrankt oder gesund bleibt.

Die Lösung für diese beiden Problem bietet die **Logistische Regression** die im Folgenden behandelt wird. Glücklicherweise können die meisten bereits gelernten Konzepte auch im Kontext der logistischen Regression angewendet werden und alles was es braucht ist ein zusätzlicher Kniff um die Beschränkung des Wertebereichs zu erreichen. Zusätzlich kommt noch ein komplett neuer Aspekt hinzu, da die logistische Regression eben auch als die Lösung für ein Klassifikationsproblem interpretiert werden kann. Dadurch ergibt sich eine enge Anbindung an den Bereich des Maschinellen Lernens in die Klassifikationsalgorithm eine zentrale Rolle spielen.

## Logistische Funktion

$$
f(z) = \frac{1}{1 + e^{-z}} 
$$

```{r}
#| fig-cap: "Logistische Funktion" 

z <- seq(-20, 20, length.out = 200)
y <- 1/(1 + exp(-z))
df_1 <- tibble(z,y)
ggplot(df_1, aes(z,y)) +
  geom_line() +
  labs(x = 'z', y = expression(frac(1,1+e^(-z))))
```

## Alternative Formulierung der logistischen Funktion

\begin{align*}
f(z) &= \frac{1}{1 + e^{-z}} \\
 &= \frac{e^z}{e^z + e^{-z}e^z} \\
 &= \frac{e^z}{e^z + e^{-z+z}} \\
 &= \frac{e^z}{e^z + 1}
\end{align*}

## logistic function $f(z,a) = \frac{1}{1+e^{-az}}$

```{r}
#| fig-cap: "Variations of the logistic function"

logistic <- function(z,a=1) 1/(1+exp(-a*z))
tibble(z,
               f_1 = logistic(z),
               f_2 = logistic(z,0.2),
               f_3 = logistic(z,5)) |> 
  pivot_longer(cols = -z) |> 
  ggplot(aes(z,value, color=name)) +
  geom_line() +
  scale_x_continuous("z") +
  scale_y_continuous(expression(frac(1,1+e^(-az)))) +
  scale_color_discrete("a", labels=c(expression(a==1.0),expression(a==.2),expression(a==5.0)))
```



## Logistic function to model probabilities

\begin{align*}
p(X) = f(\beta_0 + \beta_1 X) &= \frac{e^{\beta_0+\beta_1 X}}{1 + e^{\beta_0 + \beta_1 X}} \\
&= \frac{1}{1+e^{-(\beta_0 + \beta_1 X)}}
\end{align*}

$p(X)$ as the probability of scoring a goal, or the risk of developing a disease, etc.

$$
P(Y = 1|X) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 X)}}
$$

## Logistische Regression in `R` 

```{r}
#| echo: true

```

## Vorhersage

```{r}
#| fig-cap: "Model predictions"


```

## Chance 

```{r}

include_graphics('pics/comic_horse_and_duck.jpg')
```

\begin{align*}
\text{odds}  &= \frac{P(\text{Event})}{P(\text{Not Event})} \\
&= \frac{p}{1-p} \\
\end{align*}

## odds and the logistic model

\begin{align*}
p(X) &= \frac{e^{\beta_0 + \beta_1X}}{1 + e^{\beta_0 + \beta_1 X}}  \\
\Leftrightarrow p(X)(1 + e^{\beta_0 + \beta_1 X}) &= e^{\beta_0 + \beta_1X}  \\
\Leftrightarrow p(X) + p(X)e^{\beta_0 + \beta_1 X} &= e^{\beta_0 + \beta_1X} \\
\Leftrightarrow p(X) &= e^{\beta_0 + \beta_1X} - p(X)e^{\beta_0 + \beta_1 X} \\
\Leftrightarrow p(X) &= e^{\beta_0 + \beta_1X}(1 - p(X)) \\
\Leftrightarrow \frac{p(X)}{1 - p(X)} &= e^{\beta_0 + \beta_1X} \\
\end{align*}

## Logit function

$$
\text{logit}(x) = \text{log}\left(\frac{x}{1-x}\right)
$$

```{r}
#| fig-cap: "Logit function"
#| fig-width: 3

z <- seq(0, 1, length.out = 400)
y <- log(z/(1-z))
df_2 <- tibble(z,y)
ggplot(df_2, aes(z,y)) +
  geom_line() +
  labs(x = 'z', y = expression(frac(x,1-x))) 
```

## log-odds or logit

$$
\text{logit}\left(\frac{p(X)}{1-p(X)} \right) = \beta_0 + \beta_1 X
$$

The logistic regression model is linear for $X$ in the **log-odds**.
\begin{align*}
\left(\frac{p(X)}{1-p(X)} \right) &= e^{\beta_0 + \beta_1 (X + \Delta)} = e^{\beta_0 + \beta_1X}e^{\beta_1 \Delta} \\
log\left(\frac{p(X)}{1-p(X)} \right) &= log\left(e^{\beta_0 + \beta_1X}e^{\beta_1\Delta}\right)  = \beta_0 + \beta_1 X + \beta_1 \Delta
\end{align*}

## Changes in $Y$ according to $X$


```{r}
#| fig-cap: "$f(x) = \\frac{e^{0.5+0.2x}}{1+e^{0.5+0.2x}}$"
#| layout-ncol: 2
#| fig-height: 3 
#| fig-subcap:
#|   - Logit
#|   - Logistic

logistic_2 <- function(z,b0,b1) 1/(1+exp(-(b0 + b1*z)))
df <- tibble(
  x = seq(-20,20,length.out=50),
  p = logistic_2(x, 0.5, 0.2),
  odds = exp(0.5 + 0.2*x)
)
ggplot(df, aes(x,odds)) + geom_line() +
  scale_x_continuous(expression(X), breaks=seq(-20,20,2))
ggplot(df, aes(x,p)) + geom_line() +
  scale_x_continuous(expression(X), breaks=seq(-20,20,2))
```

## Konfusionsmatrize

|                        | Predicted: Positive | Predicted: Negative |
|------------------------|---------------------|---------------------|
| **Actual: Positive**   | True Positive (TP)  | False Negative (FN) |
| **Actual: Negative**   | False Positive (FP) | True Negative (TN)  |

- **Accuracy:** $(TP + TN) / \text{Total Samples}$
- **Precision (Positive Predictive Value):** $TP / (TP + FP)$
- **Recall (Sensitivity):** $TP / (TP + FN)$
- **F1 Score:** $\frac{2}{\frac{1}{\text{Precision}} + \frac{1}{\text{Sensitivity}}} \in [0,1]$

## Welche Eigenschaften sind wichtig für einen Klassifikationsalgorithmus?

- Discrimination
- Calibration

## Discrimination 

### Definition
Discrimination refers to a model's ability to distinguish between positive and negative cases. Discrimination assesses how well a model separates different outcome classes.  

**Intuition**:
Discrimination tells us *how well* the model differentiates between classes, regardless of the predicted probability values being perfectly aligned with real-world outcomes.  


## Kalibrierung 

### Definition:
Calibration refers to the agreement between predicted probabilities and the observed proportions of outcomes. A well-calibrated model outputs probabilities that reflect the true likelihood of an event.  

**Intuition**:
Calibration ensures that the model's predictions are not just *accurate* in classification but also *reliable* as probability estimates.  


## Receiver Operator Characteristic (ROC) 

$$
\text{True Positive Rate (TPR, Sensitivity)} = \frac{\text{True Positives}}{\text{True Positives + False Negatives}}
$$

$$
\text{False Positive Rate (FPR)} = \frac{\text{False Positives}}{\text{False Positives + True Negatives}}
$$

$$
\text{Specificity} = \frac{\text{True Negatives}}{\text{True Negatives + False Positives}}
$$

$$
\text{FPR} = 1 - \text{Specificity}
$$

## ROC 

```{r}
set.seed(125)
df <- tibble(
  x = seq(-20,20,length.out=50),
  p = logistic_2(x, 0.5, 0.4),
  odds = exp(0.5 + 0.2*x))
df_pts <- tibble(
    x = c(runif(20,-20,5), runif(20, -4, 20)),
    p = c(rbinom(20,1,0.2), rbinom(20, 1, 0.9)))

ggplot(df, aes(x,p)) + geom_line() +
  scale_x_continuous(expression(X), breaks=seq(-20,20,2)) +
  scale_y_continuous(expression(hat(p))) +
  geom_point(data=df_pts, size=2)
```


## ROC curve
```{r}
#| fig-cap: "Example of a ROC curve"

roc_data <- tibble(
  FPR = seq(0.01, 1, length.out=100),
  TPR = (log(FPR) - log(0.01))/4.605
)
ggplot(roc_data, aes( FPR, TPR)) +
  geom_line(color = "blue", linewidth = 1) + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "grey") + # Random chance line
  scale_x_continuous("False Positive Rate\n(FPR)") +
  scale_y_continuous("True Positive Rate\n(TPR)") +
  coord_equal() 

# Print AUC value
```

## Area under the curve (AUC) 

```{r}
#| fig-cap: "Example of AUC"

ggplot(roc_data, aes(FPR, TPR)) +
  geom_ribbon(aes(ymax=TPR, ymin=0), alpha=.5, fill='blue') + 
  geom_line(color = "blue", linewidth = 1) + 
  scale_x_continuous("False Positive Rate\n(FPR)") +
  scale_y_continuous("True Positive Rate\n(TPR)") +
  coord_equal() 
```

## Calibration curve

```{r}
#| fig-cap: "Example of a calibration curve (red) and perfect calibration (black)"
df_cb <-tibble(
  x = seq(0, 1, length.out=100),
  y = (10*x+ 300*(x-0.5)**3+ 0.5)/100+.5
)
lab <- seq(0,1,.2)
ggplot(tibble(x=0:1, y=0:1), aes(x,y)) +
  geom_line(linetype='dashed') +
  geom_line(data = df_cb, color='red') +
  scale_x_continuous('Predicted\nprobability', breaks=lab, labels=lab) +
  scale_y_continuous('Observed\nprobability', breaks=seq(0,1,.2)) +
  coord_equal()
```

## Calculating a prediction curve


## `CalibrationCurves`

```{r}
#| fig-height: 3

df <- read_csv('data/Hecht_1942_SR1.csv') |> 
  mutate(logQuanta = log(Quanta))
mod <- glm(response ~ logQuanta, df, family=binomial())

pHat <- predict(mod, type='response')
odds <- predict(mod)
y <- mod$y
cc <- valProbggplot(pHat, y)
print(cc$ggPlot)
```


## Take-aways Diskriminierung vs. Kalibrierung 

| **Aspect**        | **Discrimination**                      | **Calibration**                      |
|-------------------|-----------------------------------------|--------------------------------------|
| **Focus**         | Ability to distinguish classes          | Accuracy of predicted probabilities  |
| **Measurement**   | AUC, ROC curves                         | Calibration curves                   |
| **Key Question**  | "How well does the model rank cases?"   | "Are the probabilities realistic?"   |
