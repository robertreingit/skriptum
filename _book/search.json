[
  {
    "objectID": "stats_basics.html",
    "href": "stats_basics.html",
    "title": "1  Eine kleine Welt und die Ungewissheit",
    "section": "",
    "text": "2 Entscheiden"
  },
  {
    "objectID": "stats_basics.html#alle-möglichkeiten-wenn-delta0",
    "href": "stats_basics.html#alle-möglichkeiten-wenn-delta0",
    "title": "1  Eine kleine Welt",
    "section": "1.1 Alle Möglichkeiten wenn \\(\\delta=0\\)",
    "text": "1.1 Alle Möglichkeiten wenn \\(\\delta=0\\)\n\n\n\n\n\nVerteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe"
  },
  {
    "objectID": "stats_basics.html#alle-möglichkeiten-wenn-delta0-oder-delta100",
    "href": "stats_basics.html#alle-möglichkeiten-wenn-delta0-oder-delta100",
    "title": "1  Eine kleine Welt",
    "section": "1.1 Alle Möglichkeiten wenn \\(\\delta=0\\) oder \\(\\delta=100\\)",
    "text": "1.1 Alle Möglichkeiten wenn \\(\\delta=0\\) oder \\(\\delta=100\\)\n\n\n\n\n\nVerteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe"
  },
  {
    "objectID": "stats_basics.html#ungewissheit",
    "href": "stats_basics.html#ungewissheit",
    "title": "1  Eine kleine Welt",
    "section": "1.1 Ungewissheit",
    "text": "1.1 Ungewissheit\nDie Anwendung von statistischen Methoden bietet die Möglichkeiten unter Ungewissheit in möglichst vielen Fällen korrekte Entscheidungen zu treffen. Die getroffene Aussage bezieht sich immer nur auf die vorliegenden Daten und ist keine Aussage über die zugrundeliegende Theorie."
  },
  {
    "objectID": "stats_basics.html#wie-kann-ich-anhand-eines-datenpunktes-etwas-sagen",
    "href": "stats_basics.html#wie-kann-ich-anhand-eines-datenpunktes-etwas-sagen",
    "title": "1  Eine kleine Welt und die Ungewissheit",
    "section": "1.1 Wie kann ich anhand eines Datenpunktes etwas sagen?",
    "text": "1.1 Wie kann ich anhand eines Datenpunktes etwas sagen?\n\n\n\n\n\nVerteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe mit Stichproben der Größen k = 3"
  },
  {
    "objectID": "stats_basics.html#entscheidungsmöglichkeiten",
    "href": "stats_basics.html#entscheidungsmöglichkeiten",
    "title": "1  Eine kleine Welt und die Ungewissheit",
    "section": "2.1 Entscheidungsmöglichkeiten",
    "text": "2.1 Entscheidungsmöglichkeiten\n1"
  },
  {
    "objectID": "stats_basics.html#nehmen-wir-einen-einfacheren-fall-mit-delta-500n",
    "href": "stats_basics.html#nehmen-wir-einen-einfacheren-fall-mit-delta-500n",
    "title": "1  Eine kleine Welt und die Ungewissheit",
    "section": "2.2 Nehmen wir einen einfacheren Fall mit \\(\\delta = 500\\)N",
    "text": "2.2 Nehmen wir einen einfacheren Fall mit \\(\\delta = 500\\)N\n\n\n\n\n\nVerteilungen wenn \\(\\delta\\)=500 und \\(\\delta\\)=0\n\n\n\n\n\n\n\n\nWild, Christopher J, und Georg AF Seber. 2000. Chance encounters: A first course in data analysis and inference. Wiley Press."
  },
  {
    "objectID": "slm_model_fit.html#residuen",
    "href": "slm_model_fit.html#residuen",
    "title": "7  Modellfit",
    "section": "7.1 Residuen",
    "text": "7.1 Residuen"
  },
  {
    "objectID": "slm_model_fit.html#was-sind-noch-mal-residuen-epsilon_i-bzw.-deren-schätzer-hatepsilon_i-e_i",
    "href": "slm_model_fit.html#was-sind-noch-mal-residuen-epsilon_i-bzw.-deren-schätzer-hatepsilon_i-e_i",
    "title": "7  Modellfit",
    "section": "7.2 Was sind noch mal Residuen \\(\\epsilon_i\\) bzw. deren Schätzer \\(\\hat{\\epsilon}_i = e_i\\)",
    "text": "7.2 Was sind noch mal Residuen \\(\\epsilon_i\\) bzw. deren Schätzer \\(\\hat{\\epsilon}_i = e_i\\)\n\\[\ny_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i\n\\]\n\n\n\n\n\nSpielzeugbeispiel mit Residuen \\(\\hat{\\epsilon}_i = e_i = y_i - \\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#annahme-epsilon_i-sim-mathcaln0-sigma2",
    "href": "slm_model_fit.html#annahme-epsilon_i-sim-mathcaln0-sigma2",
    "title": "7  Modellfit",
    "section": "7.3 Annahme: \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)",
    "text": "7.3 Annahme: \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)\n\n\n\n\n\nVerteilung der Werte für verschiedene x-Werte (rote Punkte) und die resultierende Regressionsgerade mit den Vorhersagewerte \\(\\hat{y}_i\\) (schwarze Punkte)"
  },
  {
    "objectID": "slm_model_fit.html#übersicht-residuen",
    "href": "slm_model_fit.html#übersicht-residuen",
    "title": "7  Modellfit",
    "section": "7.4 Übersicht Residuen",
    "text": "7.4 Übersicht Residuen\n\nÜbersicht über verschiedene Arten von Residuen1\n\n\n\n\n\n\n\nTyp\nBerechnung\nZiel\n\n\n\n\nEinfache Residuen\n\\(e_i = y_i - \\hat{y}_i\\)\nVerteilungsannahme\n\n\nStandardisierte Residuen\n\\(e_{Si} = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_i}}\\)\nVerteilungsannahme\n\n\nStudentized Residuen\n\\(e_{Ti} = \\frac{e_i}{\\hat{\\sigma}_{(-i)}\\sqrt{1-h_i}}\\)\nEinfluss auf Modell"
  },
  {
    "objectID": "slm_model_fit.html#residuen-in-r-berechnen-mit-residuals-und-freunden",
    "href": "slm_model_fit.html#residuen-in-r-berechnen-mit-residuals-und-freunden",
    "title": "7  Modellfit",
    "section": "7.5 Residuen in R berechnen mit residuals() und Freunden",
    "text": "7.5 Residuen in R berechnen mit residuals() und Freunden\n\nresiduals(mod)[1:5] # einfache Residuen\n\n         1          2          3          4          5 \n -9.300928  -9.368288 -11.217658  -5.572108  -6.363565 \n\nrstandard(mod)[1:5] # standardisierte Residuen\n\n         1          2          3          4          5 \n-1.4592936 -1.4598906 -1.7440573 -0.8724351 -0.9916310 \n\nrstudent(mod)[1:5] # studentized Residuen\n\n         1          2          3          4          5 \n-1.4814779 -1.4821191 -1.7928881 -0.8697060 -0.9914135"
  },
  {
    "objectID": "slm_model_fit.html#residuen-in-r-inspizieren",
    "href": "slm_model_fit.html#residuen-in-r-inspizieren",
    "title": "7  Modellfit",
    "section": "7.6 Residuen in R inspizieren",
    "text": "7.6 Residuen in R inspizieren\n\ny_hat <- predict(mod)\nplot(y_hat, residuals(mod))\nplot(y_hat, rstandard(mod))\nplot(y_hat, rstudent(mod))"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---einfache-residuen-hatepsilon_i-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---einfache-residuen-hatepsilon_i-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.7 Diagnoseplot - Einfache Residuen \\(\\hat{\\epsilon_i} \\sim \\hat{y_i}\\)",
    "text": "7.7 Diagnoseplot - Einfache Residuen \\(\\hat{\\epsilon_i} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der Residuen \\(\\hat{\\epsilon_i}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---standardisierte-residuen-hatepsilon_si-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---standardisierte-residuen-hatepsilon_si-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.8 Diagnoseplot - Standardisierte Residuen \\(\\hat{\\epsilon}_{Si} \\sim \\hat{y_i}\\)",
    "text": "7.8 Diagnoseplot - Standardisierte Residuen \\(\\hat{\\epsilon}_{Si} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der standardisierten Residuen \\(\\hat{\\epsilon}_{Si}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---studentized-residuen-hatepsilon_ti-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---studentized-residuen-hatepsilon_ti-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.9 Diagnoseplot - Studentized Residuen \\(\\hat{\\epsilon}_{Ti} \\sim \\hat{y_i}\\)",
    "text": "7.9 Diagnoseplot - Studentized Residuen \\(\\hat{\\epsilon}_{Ti} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der studentized Residuals \\(\\hat{\\epsilon}_{Ti}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus",
    "href": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus",
    "title": "7  Modellfit",
    "section": "7.10 Diagnoseplot - Wie sehen Probleme aus?",
    "text": "7.10 Diagnoseplot - Wie sehen Probleme aus?\n\n\n\n\n\nBeispielstreudiagramm"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus-1",
    "href": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus-1",
    "title": "7  Modellfit",
    "section": "7.11 Diagnoseplot - Wie sehen Probleme aus?",
    "text": "7.11 Diagnoseplot - Wie sehen Probleme aus?\n\n\n\n\n\nBeispielstreudiagramm"
  },
  {
    "objectID": "slm_model_fit.html#wie-kann-die-verteilung-der-residuen-überprüft-werden",
    "href": "slm_model_fit.html#wie-kann-die-verteilung-der-residuen-überprüft-werden",
    "title": "7  Modellfit",
    "section": "7.12 Wie kann die Verteilung der Residuen überprüft werden?",
    "text": "7.12 Wie kann die Verteilung der Residuen überprüft werden?\n\n\n\nSpielzeugbeispieldaten mit \\(n=5\\)\n\n\ny\n\n\n\n\n-2.0\n\n\n5.0\n\n\n-1.2\n\n\n0.1\n\n\n7.0\n\n\n\n\n\n\n\n\n\n\nDichtefunktion der Standardnormalverteilung"
  },
  {
    "objectID": "slm_model_fit.html#konstruktion-eines-qq-graphen",
    "href": "slm_model_fit.html#konstruktion-eines-qq-graphen",
    "title": "7  Modellfit",
    "section": "7.13 Konstruktion eines qq-Graphen",
    "text": "7.13 Konstruktion eines qq-Graphen\n\n\n\n\n\n\nSortierte Datenwerte\n\n\nkleinster\n2.kleinster\nmittlerer\n2.größter\ngrößter\n\n\n\n\n-2\n-1.2\n0.1\n5\n7"
  },
  {
    "objectID": "slm_model_fit.html#konstruktion-eines-qq-graphen-1",
    "href": "slm_model_fit.html#konstruktion-eines-qq-graphen-1",
    "title": "7  Modellfit",
    "section": "7.14 Konstruktion eines qq-Graphen",
    "text": "7.14 Konstruktion eines qq-Graphen\n\n\n\n\n\nStreudiagramm der empirischen Werte gegen die theoretischen Quantilen"
  },
  {
    "objectID": "slm_model_fit.html#beispiele-für-qq-graphen-mit-qqnorm-und-qqline",
    "href": "slm_model_fit.html#beispiele-für-qq-graphen-mit-qqnorm-und-qqline",
    "title": "7  Modellfit",
    "section": "7.15 Beispiele für qq-Graphen mit qqnorm() und qqline()",
    "text": "7.15 Beispiele für qq-Graphen mit qqnorm() und qqline()"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---qq-diagramm",
    "href": "slm_model_fit.html#diagnoseplot---qq-diagramm",
    "title": "7  Modellfit",
    "section": "7.16 Diagnoseplot - QQ-Diagramm",
    "text": "7.16 Diagnoseplot - QQ-Diagramm\n\n\n\n\n\nQQ-Diagramm der Residuen des ADAS-ADCS-Modells\n\n\n\n\n2"
  },
  {
    "objectID": "slm_model_fit.html#summary",
    "href": "slm_model_fit.html#summary",
    "title": "7  Modellfit",
    "section": "7.17 summary()",
    "text": "7.17 summary()\n\n\n\nCall:\nlm(formula = adcs ~ adas, data = adl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.2177  -3.8033  -0.4663   2.7950  20.9634 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  26.5445     4.3052   6.166 3.05e-07 ***\nadas         -0.2638     0.1015  -2.599   0.0131 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.516 on 39 degrees of freedom\nMultiple R-squared:  0.1477,    Adjusted R-squared:  0.1258 \nF-statistic: 6.757 on 1 and 39 DF,  p-value: 0.01312"
  },
  {
    "objectID": "slm_model_fit.html#neue-idee-zu-residuen",
    "href": "slm_model_fit.html#neue-idee-zu-residuen",
    "title": "7  Modellfit",
    "section": "7.18 Neue Idee zu Residuen",
    "text": "7.18 Neue Idee zu Residuen\n\n\n\n\n\nSpielzeugbeispiel mit Residuen \\(\\hat{\\epsilon}_i = e_i = y_i - \\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#zum-nacharbeiten",
    "href": "slm_model_fit.html#zum-nacharbeiten",
    "title": "7  Modellfit",
    "section": "7.19 Zum Nacharbeiten",
    "text": "7.19 Zum Nacharbeiten\nKutner u. a. (2005, p.100–114) Altman und Krzywinski (2016b) Fox (2011, p.285–296)"
  },
  {
    "objectID": "slm_model_fit.html#hebelwerte",
    "href": "slm_model_fit.html#hebelwerte",
    "title": "7  Modellfit",
    "section": "7.20 Hebelwerte",
    "text": "7.20 Hebelwerte\n\n\n\n\n\n\n\n\nStreudiagramm der ADCS-MCI-ADL scores gegen ADAS-cos scores\n\n\n\n\n\n\n\n\n\nHebelwerte der jeweiligen \\(x_i\\)s\n\n\n\n\n\n\n\n\n\nHebelwerte der jeweiligen Datenpunkte"
  },
  {
    "objectID": "slm_model_fit.html#dffits",
    "href": "slm_model_fit.html#dffits",
    "title": "7  Modellfit",
    "section": "7.21 DFFITS",
    "text": "7.21 DFFITS\nMit Hilfe der Hebelwerte lassen sich verschiedene Maße erstellen um den Einfluss von Datenpunkten auf das Modell zu überprüfen. Ein Maß wird als bezeichnet (siehe Gleichung 7.1)\n\\[\n(DFFITS)_i = \\frac{\\hat{y}_i - \\hat{y}_{i(i)}}{\\sqrt{\\hat{\\sigma}^2h_i}}\n\\tag{7.1}\\]\nIm Zähler kommen vin Gleichung 7.1 zweimal vorhergesagte \\(y\\)-Werte vor. \\(\\hat{y}_i\\) ist dabei der ganz normale Vorhersagewert der uns mittlerweile schon mehrfach begegnet ist. Der zweite Wert \\(\\hat{y}_{i(i)}\\) bezeichnet den vorhergesagten Wert aus dem Modell aus dem der Wert \\(y_i\\) weggelassen wurde. D.h, dass Modell ist mit einem Wert weniger gefittet worden. Daher misst die Differenz \\(\\hat{y}_i - \\hat{y}_{i(i)}\\) den Unterschied in den Vorhersagewerte zwischen zwei Modellen bei denen einmal der Wert \\(y_i\\) zum fitten verwendet wurde und einmal wenn \\(y_i\\) nicht zum fitten verwendet wurde. Umso größer der Unterschied zwischen diesen beiden Werte umso größer ist der Einfluss des Wertes \\(y_i\\) auf den Modellfit. Den Nenner von Gleichung 7.1 lassen wir mal fallen, da es sich dabei nur um einen Normierungswert handelt. Dementsprechend, wird mittels DFFITS für jeden Datenpunkt ein Wert ermittelt und umso größer dieser Wert ist umso größer ist der Einfluss des jeweiligen Datenpunktes auf den Modellfit.\nIm idealen Fall sollte alle Datenpunkt ungefähr den gleichen Einfluss haben und einzelne Datenpunkte die einen übermäßig großen Einfluss auf das Modell haben sollten noch einmal genauer inspiziert werden.\n\n\n\n\n\n\nTipp\n\n\n\nAls Daumenregel, kann für kleine bis mittlere Datensätze ein DFFITS von \\(\\approx 1\\) auf Probleme hindeuten, während bei großen Datensätzen \\(\\approx 2\\sqrt{k/N}\\) als Orientierungshilfe verwendet werden kann (k := Anzahl der Prediktoren, N := Stichprobengröße).\n\n\n\n\n\n\n\n\nWarnung\n\n\n\nWenn ein Wert außerhalb der Daumenregel liegt, heißt das nicht, dass er automatisch ausgeschlossen werden muss/soll, sondern lediglich inspiziert werden sollte und das Modell mit und ohne diesen Wert interpretiert werden sollte.\n\n\nIn R können die DFFITS werden mittels der dffits()-Funktion berechnet werden. Als Parameter erwartet dffits() das gefittete lm()-Objekt. Ähnlich wie bei den Residuen, werden die DFFITS-Werte gegen die vorhergesagten \\(y_i\\)-Werte graphisch abgetragen um die Wert zu inspizieren und Probleme in der Modellspezifikation zu identifizieren.\n\nplot(adl$y_hat, dffits(mod),\n     ylim=c(-2,2),\n     xlab=expression(hat(y)[i]),\n     ylab='DFFIT-Wert')\nabline(h=c(-1,1), col='red', lty=2)\n\n\n\n\nAbbildung 7.1: Beispiel für DFFITS gegen \\(\\hat{y}_i\\)\n\n\n\n\nIn Abbildung 7.1 sind die DFFITS-Werte gegen die vorhergesagten Werte \\(\\hat{y}_i\\) abgetragen und zusätzlich die Daumenregel \\(\\pm1\\) eingezeichnet. Hier ist ein Wert nur gerade so außerhalb des vorgeschlagenen Bereichs. Hier könnte daher sich dieser Datenpunkt noch einmal genauer angeschaut werden, ob bei Ausschluß des Wertes es zu einer qualitativ anderen Interpretation der Daten kommt oder ob bespielsweise Übertragungsfehler für diesen Wert vorliegen oder sonstige Gründe."
  },
  {
    "objectID": "slm_model_fit.html#cooks-abstand",
    "href": "slm_model_fit.html#cooks-abstand",
    "title": "7  Modellfit",
    "section": "7.22 Cooks-Abstand",
    "text": "7.22 Cooks-Abstand\nEin Maß um den Einfluss von einzelnen Datenpunkten auf die Vorhersagewerte \\(\\hat{y}_i\\) über alle Werte abzuschätzen.\n\\[\nD_i = \\frac{\\sum_{j=1}^N(\\hat{y_j} - \\hat{y}_{j(i)})}{k\\hat{\\sigma}^2}\n\\]\n\n7.22.1 Daumenregel\n\\(D_i > 1\\)\n\n\n7.22.2 In R\ncooks.distance()"
  },
  {
    "objectID": "slm_model_fit.html#cooks-abstand-plot",
    "href": "slm_model_fit.html#cooks-abstand-plot",
    "title": "7  Modellfit",
    "section": "7.23 Cooks-Abstand plot",
    "text": "7.23 Cooks-Abstand plot\n\n\n\n\n\nCook’s \\(D_i\\) gegen \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#dfbetas",
    "href": "slm_model_fit.html#dfbetas",
    "title": "7  Modellfit",
    "section": "7.24 DFBETAS",
    "text": "7.24 DFBETAS\nEin Maß für die Veränderung der \\(\\beta\\)-Koeffizienten durch einzelne Datenpunkte \\(i\\).\n\\[\n(DFBETAS)_{k(i)} = \\frac{\\hat{\\beta}_k - \\hat{\\beta}_{k(i)}}{\\sqrt{\\hat{\\sigma}^2c_{kk}}}\n\\]\n\n7.24.1 Daumenregel\nFür kleine bis mittlere Datensätze \\(\\approx 1\\)\nFür große Datensätze \\(\\approx 2/\\sqrt{N}\\)\n\n\n7.24.2 In R\ndfbeta()3"
  },
  {
    "objectID": "slm_model_fit.html#dfbetas-1",
    "href": "slm_model_fit.html#dfbetas-1",
    "title": "7  Modellfit",
    "section": "7.25 DFBETAS",
    "text": "7.25 DFBETAS\n\n\n\n\n\nDFBETA-Werte für \\(\\beta_0\\) und \\(\\beta_1\\) gegen \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#zusammenfassung",
    "href": "slm_model_fit.html#zusammenfassung",
    "title": "7  Modellfit",
    "section": "7.26 Zusammenfassung",
    "text": "7.26 Zusammenfassung\n\nÜbersicht über die verschiedene Einflussmaße zur Bewertung der Modellgüte\n\n\nTyp\nVeränderung\nDaumenregel\n\n\n\n\n\\((DFFITS)_i\\)\nVorhersagewert i\n\\(2\\sqrt{k/N}\\)\n\n\nCook\nDurchschnittliche Vorhersagewerte\n\\(>1\\)\n\n\n\\((DFBETAS)_{k(i)}\\)\nKoeffizient i\n\\(2\\sqrt{N}\\)\n\n\n\\(e_{Ti}\\)\nResiduum i\nt-Verteilung(n-k-2)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplots-in-r-mit-plotmod",
    "href": "slm_model_fit.html#diagnoseplots-in-r-mit-plotmod",
    "title": "7  Modellfit",
    "section": "7.27 Diagnoseplots in R mit plot(mod)",
    "text": "7.27 Diagnoseplots in R mit plot(mod)\n\nplot(mod)"
  },
  {
    "objectID": "slm_model_fit.html#zum-nacharbeiten-1",
    "href": "slm_model_fit.html#zum-nacharbeiten-1",
    "title": "7  Modellfit",
    "section": "7.28 Zum Nacharbeiten",
    "text": "7.28 Zum Nacharbeiten\nAltman und Krzywinski (2016a) Fox (2011, p.294–302)\n\n7.28.1 Weiterführendes\nYoung (2019)\n\n\n\n\nAltman, Naomi, und Martin Krzywinski. 2016a. „Points of significance: Analyzing outliers: influential or nuisance“. Nature Methods 13 (4): 281–82.\n\n\n———. 2016b. „Points of significance: regression diagnostics“. Nature Methods 13 (5): 385–86.\n\n\nFox, John. 2011. An R companion to applied regression. 2. Aufl. SAGE Publication Inc., Thousand Oaks.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York.\n\n\nYoung, Alwyn. 2019. „Channeling fisher: Randomization tests and the statistical insignificance of seemingly significant experimental results“. The Quarterly Journal of Economics 134 (2): 557–98."
  },
  {
    "objectID": "slm_prediction.html#vorhergesagte-werte-haty_i",
    "href": "slm_prediction.html#vorhergesagte-werte-haty_i",
    "title": "8  Vorhersage",
    "section": "8.1 Vorhergesagte Werte \\(\\hat{y}_i\\)",
    "text": "8.1 Vorhergesagte Werte \\(\\hat{y}_i\\)\n\n\n\nWenn ein einfaches lineares Modell gefittet wurde ist eine zentrale Frage welche Vorhersagen anhand des Modell getroffen werden können. Die Vorhersagen \\(\\hat{y}_i\\) liegen auf der vorhergesagten Regressionsgerade und berechnen sich nach dem Modell für einen gegeben \\(x\\)-Wert.\n\\[\n\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_0} x\n\\]\nWie schon mehrfach besprochen unterliegt die Regressionsgerade inherent der Unsicherheit bezüglich der geschätzen Modellkoeffizienten \\(\\hat{\\beta}_0\\) und \\(\\hat{\\beta}_1\\). Diese Unsicherheit überträgt sich auf die geschätzen Werte \\(\\hat{y}_i\\) und muss daher bei deren Interpretation berücksichtigt werden.\nIn Abbildung 8.1 sind die bereits behandelten Sprungdaten gegen die Anlaufgeschwindigkeiten zusammen mit der Regressionsgeraden und vorhergesagten Werten (rot) abgetragen.\n\n\n\n\n\nAbbildung 8.1: Vorhersagewerte \\(\\hat{y}_i\\) (rote Punkte) für die Sprungdaten.\n\n\n\n\nIn R können die vorhergesagten Werte des mittels lm() gefitteten Modells mit der Hilfsfunktion predict() bestimmt werden. Wenn der Funktion predict() keine weiteren Parameter außer dem lm-Objekt übergeben werden, berechnet predict() die vorhergesagten Werte \\(\\hat{y}_i\\) für alle die \\(x\\)-Werte die auch zum fitten des Modells benutzt wurden. Die Reihenfolge der Werte \\(\\hat{y}_i\\) enspricht dabei den Werten im Original-data.frame().\n\npredict(mod)[1:5] \n\n       1        2        3        4        5 \n4.523537 4.725140 4.856256 4.761778 5.416207 \n\n\nWir haben uns hier nur die ersten fünf Werte ausgeben lassen, da nur demonstriert werden soll wie die predict()-Funktion angewendet werden kann. Um eine Anwendung zu geben, so können mittels predict() die Residuen auch von Hand ohne die resid()-Funktion erhalten werden.\n\n(jump$jump_m - predict(mod))[1:5]\n\n          1           2           3           4           5 \n-0.16267721 -0.41248842 -0.29359256 -0.01047071  0.09927500 \n\nresid(mod)[1:5]\n\n          1           2           3           4           5 \n-0.16267721 -0.41248842 -0.29359256 -0.01047071  0.09927500 \n\n\nWiederum nur zur Demonstration die ersten fünf Wert um die Äquivalenz der beiden Methoden zu demonstrieren.\nMeistens liegt das Interesse jedoch weniger auf den vorhergesagten Werten \\(\\hat{y}_i\\) für die gemessenen Werte, sondern es sollen Werte vorhergesagt werden für \\(x\\)-Werte die nicht im Datensatz enthalten sind. Operational ändert sich nichts, es wird immer noch das gefittete Modell verwendetet und es müssen lediglich neue \\(x\\)-Werte übergeben werden.\nIn R kann dies mittels des zweite Parameter in predict() erreicht werden. Soll zum Beispiel die Sprungweite für eine Anlaufgeschwindigkeit von \\(v = 11.5[m/s]\\) berechnen werden, muss zunächst ein neues tibble() erstellt werden, welches den gewünschten \\(x\\)-Wert enthält. Dabei muss der Spaltenname in dem neuen tibble() demjenigen im Original-tibble() entsprechen. Ansonsten funktioniert die Anwendung von predict() nicht.\n\ndf <- tibble(v_ms = 11.5)\ndf\n\n# A tibble: 1 × 1\n   v_ms\n  <dbl>\n1  11.5\n\n\nDieses tibble() kann nun zusammen mit dem lm()-Objekt an predict() übergeben werden.\n\npredict(mod, newdata = df)\n\n       1 \n8.614136 \n\n\nD.h., bei einer Anlaufgeschwindigkeit von \\(v = 11.5[m/s]\\) ist anhand des Modells eine Sprungweite von \\(8.6m\\) zu erwarten."
  },
  {
    "objectID": "slm_prediction.html#unsicherheit-in-der-vorhersage",
    "href": "slm_prediction.html#unsicherheit-in-der-vorhersage",
    "title": "8  Vorhersage",
    "section": "8.2 Unsicherheit in der Vorhersage",
    "text": "8.2 Unsicherheit in der Vorhersage\nWie schon angesprochen ist unser Modell natürlich mit Unsicherheiten behaftet. Diese drücken sich in den Standardfehler für die beiden Koeffizienten \\(\\hat{\\beta_0}\\) und \\(\\hat{\\beta_1}\\) (siehe Tabelle 8.1).\n\n\n\n\nTabelle 8.1: Modellparameter und Standardfehler\n\n\n\nSchätzer\n\\(s_e\\)\n\n\n\n\n(Intercept)\n-0.14\n0.23\n\n\nv_ms\n0.76\n0.02\n\n\n\n\n\n\nDer vorhergesagte Wert \\(\\hat{y}\\) ist daher für sich alleine ist noch nicht brauchbar, da auch Informationen über dessen Unsicherheit notwendig sind um die Ergebnisse korrekt zu interpretieren.\nEs können zwei unterschiedliche Anwendungsfälle voneinander unterschieden werden.\n\nDer mittlere, erwartete Wert \\(\\hat{\\bar{y}}_{neu}\\)\nDie Vorhersage eines einzelnen Wertes \\(\\bar{y}_{neu}\\)\n\nIm konkreten Fall werden damit zwei unterschiedliche Fragestellungen beantwortet. Im 1. Fall lautet die Frage, ich habe eine Trainingsgruppe und möchte wissen was der mittlere Wert der Gruppe anhand des Modells ist, wenn alle eine bestimmte Anlaufgeschwindigkeit \\(v_{neu}\\) haben. Im 2. Fall lautet die Frage welche Weite eine einzelne Athletin für die Anlaufgeschwindigkeit \\(v_{neu}\\) springen sollte. In beiden Fällen werden keiner genau den Wert des Regressionsmodells treffen, aber im 1. Fall der Gruppe werden sich Streuungen nach oben bzw. nach unten gegenseitig im Schnitt ausbalancieren während im 2. Fall der einzelnen Athletin dies nicht der Fall ist. Daher hat die Vorhersage im 2. Fall eine höhere Unsicherheit. Diese Unterschied sollte sich dementsprechend in den Varianzen der beiden Vorhersagen wiederspiegeln.\nWie bereits erwähnt, der vorhergesagte Wert \\(\\hat{y}_{neu}\\) ist in beiden Fällen gleich und entsprecht der oben beschriebenen Methode anhand des Modell \\(y_{neu} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\times x_{\\text{neu}}\\).\nFür den erwarteten Mittelwert errechnet sich die Varianz nach:\n\\[\\begin{equation}\nVar(\\hat{\\bar{y}}_{neu}) = \\hat{\\sigma}^2 \\left[\\frac{1}{n} + \\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\\right] = \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}^2\n\\end{equation}\\]\nDas dazugehörige Konfidenzintervall errechnet sich danach mittels:\n\\[\\begin{equation}\n\\hat{\\bar{y}}_{neu} \\pm q_{t(1-\\alpha/2;n-2)} \\times \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}\n\\end{equation}\\]\nDie Varianz für die Vorhersage eines einzelnen Wertes errechnet sich:\n\\[\\begin{equation}\nVar(\\hat{y}_{neu}) = \\hat{\\sigma}^2 \\left[1 + \\frac{1}{n} + \\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\\right] = \\hat{\\sigma}^2 + \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}^2 = \\hat{\\sigma}_{\\hat{y}_{neu}}^2\n\\end{equation}\\]\nWas wiederum zu dem folgenden Konfidenzintervall führt:\n\\[\\begin{equation}\n\\hat{y}_{neu} \\pm q_{t(1-\\alpha/2;n-2)} \\times \\hat{\\sigma}_{\\hat{y}_{neu}}\n\\end{equation}\\]\nIn beiden Fällen ist der Term\n\\[\n\\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\n\\]\nenthalten. Anhand des Zählers kann abgeleitet werden, dass die Unsicherheit der Vorhersage mit dem Abstand vom Mittelwert der \\(x\\)-Werte zunimmt. Rein heuristisch macht dies Sinn, da davon ausgegangen werden kann, dass um den Mittelwert der \\(x\\)-Werte auch die meiste Information über \\(y\\) vorhanden ist und dementsprechend umso weiter die Werte sich vom \\(\\bar{x}\\) entfernen die Information abnimmt. Im Nenner ist wiederum wie auch beim Standardfehler \\(\\sigma_{\\beta_1}\\) des Steigungskoeffizienten \\(\\beta_1\\) zu sehen, dass die Varianz abnimmt mit der Streuung der \\(x\\)-Werte. Daher, wenn eine Vorhersage in einem bestimmten Bereich von \\(x\\)-Werten durchgeführt werden soll, dann sollte darauf geachtet werden möglichst diesen Bereich auch zu samplen um die Unsicherheit so klein wie möglich zu halten."
  },
  {
    "objectID": "slm_prediction.html#vorhersagen-in-r-mit-predict",
    "href": "slm_prediction.html#vorhersagen-in-r-mit-predict",
    "title": "8  Vorhersage",
    "section": "8.3 Vorhersagen in R mit predict()",
    "text": "8.3 Vorhersagen in R mit predict()\n\n8.3.1 Erwarteter Mittelwert\n\ndf <- data.frame(v_ms = 11.5) # oder tibble(v_ms = 11.5)\npredict(mod, newdata = df, interval = 'confidence')\n\n       fit      lwr      upr\n1 8.614136 8.482039 8.746234\n\n\n\n\n8.3.2 Individuelle Werte\n\npredict(mod, newdata = df, interval = 'prediction')\n\n       fit      lwr      upr\n1 8.614136 8.118445 9.109827"
  },
  {
    "objectID": "slm_prediction.html#konfidenzintervalle-graphisch",
    "href": "slm_prediction.html#konfidenzintervalle-graphisch",
    "title": "8  Vorhersage",
    "section": "8.4 Konfidenzintervalle graphisch",
    "text": "8.4 Konfidenzintervalle graphisch\n\n\n\n\n\nWeiterführende Literatur sind Kutner u. a. (2005)"
  },
  {
    "objectID": "slm_prediction.html#r2-und-root-mean-square",
    "href": "slm_prediction.html#r2-und-root-mean-square",
    "title": "8  Vorhersage",
    "section": "8.5 \\(R^2\\) und Root-mean-square",
    "text": "8.5 \\(R^2\\) und Root-mean-square"
  },
  {
    "objectID": "slm_prediction.html#einfaches-modell",
    "href": "slm_prediction.html#einfaches-modell",
    "title": "8  Vorhersage",
    "section": "8.6 Einfaches Modell",
    "text": "8.6 Einfaches Modell\n\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n\n\nCall:\nlm(formula = y ~ x, data = simple)\n\nResiduals:\n      1       2       3       4 \n-0.5817  0.9898 -0.2345 -0.1736 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.8414     0.7008   2.628    0.119\nx             0.4574     0.3746   1.221    0.346\n\nResidual standard error: 0.8376 on 2 degrees of freedom\nMultiple R-squared:  0.4271,    Adjusted R-squared:  0.1406 \nF-statistic: 1.491 on 1 and 2 DF,  p-value: 0.3465"
  },
  {
    "objectID": "slm_prediction.html#nochmal-abweichungen",
    "href": "slm_prediction.html#nochmal-abweichungen",
    "title": "8  Vorhersage",
    "section": "8.7 Nochmal Abweichungen",
    "text": "8.7 Nochmal Abweichungen\n\nGesamtvarianz: \\[\nSSTO := \\sum_{i=1}^N (y_i - \\bar{y})^2\n\\]\nRegressionsvarianz: \\[\nSSR :=\\sum_{i=1}^N(\\hat{y}_i - \\bar{y})^2\n\\]\nResidualvarianz: \\[\nSSE := \\sum_{i=1}^N (y_i - \\hat{y}_i)^2\n\\]\n\n\n\n\n\n\nMinimalmodell der Abweichungen"
  },
  {
    "objectID": "slm_prediction.html#verhältnis-von-ssr-zu-ssto",
    "href": "slm_prediction.html#verhältnis-von-ssr-zu-ssto",
    "title": "8  Vorhersage",
    "section": "8.8 Verhältnis von \\(SSR\\) zu \\(SSTO\\)",
    "text": "8.8 Verhältnis von \\(SSR\\) zu \\(SSTO\\)\n\n\n\n\n\nPerfekter Zusammenhang\n\n\n\n\n\\[\n\\frac{SSR}{SSTO} = 1\n\\]\n\n\n\n\n\nKein Zusammenhang\n\n\n\n\n\\[\n\\frac{SSR}{SSTO} = 0\n\\]"
  },
  {
    "objectID": "slm_prediction.html#determinationskoeffizient-r2",
    "href": "slm_prediction.html#determinationskoeffizient-r2",
    "title": "8  Vorhersage",
    "section": "8.9 Determinationskoeffizient \\(R^2\\)",
    "text": "8.9 Determinationskoeffizient \\(R^2\\)\nEs gilt: \\(SSTO = SSR + SSE\\)\n\\[\nR^2 = \\frac{SSR}{SSTO} = 1 - \\frac{SSE}{SSTO} \\in [0,1]\n\\] 1\n\n8.9.1 Korrigierter Determinationskoeffizient \\(R_a^2\\)\n\\[\nR_a^2 = 1 - \\frac{\\frac{SSE}{n-p}}{\\frac{SSTO}{n-1}} = 1 - \\frac{n-1}{n-p}\\frac{SSE}{SSTO}\n\\]\n\n\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "mlm_title.html",
    "href": "mlm_title.html",
    "title": "Multiple Regression",
    "section": "",
    "text": "Im folgenden wird das Modell der einfachen linearen Regression erweitert indem zusätzliche Terme in das Modell aufgenommen werden. Die Prinzipien bleiben dabei jedoch weitestgehendst gleich und können direkt auf den komplizierteren Fall der multiplen Regression übertragen werden. Im Laufe der Erweiterung des Modells wird sich dabei wird herausstellen, dass neben mehreren kontinuierlichen Variablen auch nominale Faktoren in das Modell intergriert werden können. Daraus entsteht ein sehr flexibler Modellapparat, der in den verschiedensten Zusammenhängen angewendet werden kann."
  },
  {
    "objectID": "mlm_basics.html#bedeutung-der-koeffizienten-bei-der-multiplen-regression",
    "href": "mlm_basics.html#bedeutung-der-koeffizienten-bei-der-multiplen-regression",
    "title": "9  Einführung",
    "section": "9.1 Bedeutung der Koeffizienten bei der multiplen Regression",
    "text": "9.1 Bedeutung der Koeffizienten bei der multiplen Regression\nUm die Bedeutung der Regressionskoeffzienten bei der multiple Regression besser zu verstehen ist es von Vorteil sich noch einmal die Bedeutung der Koeffizienten im einfachen Regressionsmodell zu vergegenwärtigen (siehe Abbildung 9.1).\n\n\n\n\n\nAbbildung 9.1: Beispiel für eine einfache Regression und der resultierenden Regressiongeraden\n\n\n\n\nBei der einfachen Regression haben mittels der Methode der kleinsten Quadrate eine Regressiongerade durch unsere Punktwolke gelegt. Dabei haben wir die Regressionsgerade so gewählt, dass die senkrechten Abstände der beobachteten Punkte von der Regressionsgerade minimiert werden bzw. die Abstände zwischen denen auf der Gerade liegenden, vorhergesagten Werte \\(\\hat{y}_i\\) und den beobachteten Wert \\(y_i\\).\nWenn wir nun den Übergang von einer Prädiktorvariablenzum nächstkomplizierteren Fall nehmen mit zwei Prädiktorvariablen \\(x_1\\) und \\(x_2\\), dann wäre eine mögliche Darstellungsform der Daten eine Punktwolke im dreidimensionalen Raum (siehe Abbildung 9.2 (a)).\n\n\n\n\n\n\n\n(a) 3D Punktwolke\n\n\n\n\n\n\n\n(b) 3D Punktwolke mit gefitteter Ebene\n\n\n\n\nAbbildung 9.2: Punktwolken bei der multiple Regression\n\n\nDa jetzt eine einzelne Gerade nicht mehr in der Lage ist die Daten zu fitten, ist die nächst Möglichkeit eine Ebene die in die Punktwolke gelegt wird (siehe Abbildung 9.2 (b)). Dies ermöglicht dann genau die gleiche Herangehensweise wie bei der einfachen linearen Regression anzuwenden. Als Zielgröße wird aus den möglichen Ebenen diejenigen gesucht deren vorhergesagten, auf der Ebene liegenden Punkte \\(\\hat{y}_i\\) die geringsten senkrechten Abstand zu den beobachteten Punkten \\(y_i\\) haben. Anders, wir suchen diejenigen Ebene durch die Punktwolke deren Summe der quadrierten Residuen \\(e_i = y_i - \\hat{y}_i\\) minimal ist.\nDiese Herangehensweise hat den Vorteil, dass sie zum einem die einfache lineare Regression als Spezialfall mit \\(K=1\\) beinhaltet und sich beliebig erweitern lässt mit der Einschränkung, dass bei \\(K>2\\) die dreidimenionale Darstellung mittels einer Grafik nicht mehr möglich ist. Das Prinzip der Minimierung der Abweichungen von \\(\\hat{y}_i\\) zu \\(y\\) bleibt aber immer erhalten. Zusammenfassend hat dieser Ansatz somit die folgenden Vorteile:\n\nDie Berechnungen bleiben alle gleich\nAbweichungen \\(\\hat{\\epsilon_i}\\) sind jetzt nicht mehr Abweichungen von einer Gerade sondern von einer \\(K\\)-dimensionalen Hyperebene. Die Eigenschaften der Residuen bleiben aber alle erhalten.\nDie Modellannahmen bleiben gleich: Unabhängige \\(y_i\\) und \\(\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\) iid\nInferenz für die Koeffizienten mittels \\(t_k = \\frac{\\hat{\\beta}_k}{s_k} \\sim t(N-K-1)\\) (Konfidenzintervall dito)\nKonzepte für die Vorhersage bleiben erhalten\nModelldiagnosetools bleiben alle erhalten\n\nAls nächster Schritt versuchen wir nun die Interpretation der Koeffizienten im multiplen Regressionsmodell besser zu verstehen."
  },
  {
    "objectID": "mlm_basics.html#einfaches-beispiel",
    "href": "mlm_basics.html#einfaches-beispiel",
    "title": "9  Einführung",
    "section": "9.2 Einfaches Beispiel",
    "text": "9.2 Einfaches Beispiel\n\\[\\begin{align*}\ny_i &= \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\epsilon_i \\\\\n\\beta_0 &= 1 ,\\beta_1 = 3, \\beta_2 = 0.7 \\\\\n\\epsilon_i &\\sim N(0,\\sigma = 0.5)\n\\end{align*}\\]\n\nN <- 50 # Anzahl Datenpunkte\nbeta_0 <- 1\nbeta_1 <- 3\nbeta_2 <- 0.7\nsigma <- 0.5\nset.seed(123)\ndf <- tibble(\n  x1 = runif(N, -2, 2),\n  x2 = runif(N, -2, 2),\n  y = beta_0 + beta_1*x1 + beta_2*x2 + \n    rnorm(N, 0, sigma)) \n\n\n\n\n\n\nEinfacher Zusammenhang y~x1\n\n\n\n\n\n\n\n\n\nEinfacher Zusammenhang y~x2"
  },
  {
    "objectID": "mlm_basics.html#wie-sieht-der-fit-aus",
    "href": "mlm_basics.html#wie-sieht-der-fit-aus",
    "title": "9  Einführung",
    "section": "9.3 Wie sieht der Fit aus?",
    "text": "9.3 Wie sieht der Fit aus?\n\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.20883 -0.26741 -0.00591  0.27315  1.01322 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.07674    0.06552   16.43  < 2e-16 ***\nx1           2.96537    0.05604   52.91  < 2e-16 ***\nx2           0.70815    0.05961   11.88 9.27e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4604 on 47 degrees of freedom\nMultiple R-squared:  0.9849,    Adjusted R-squared:  0.9842 \nF-statistic:  1529 on 2 and 47 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "mlm_basics.html#was-bedeuten-die-einzelnen-koeffizienten",
    "href": "mlm_basics.html#was-bedeuten-die-einzelnen-koeffizienten",
    "title": "9  Einführung",
    "section": "9.4 Was bedeuten die einzelnen Koeffizienten?",
    "text": "9.4 Was bedeuten die einzelnen Koeffizienten?\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n1.077\n0.066\n\n\nx1\n2.965\n0.056\n\n\nx2\n0.708\n0.060\n\n\n\n\n\nDer Unterschied in der abhängigen Variablen, wenn zwei Objekte sich in \\(x_i\\) um eine Einheit unterscheiden und die paarweise gleichen Werte in den verbleibenden \\(x_j, j \\neq i\\) annehmen."
  },
  {
    "objectID": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination",
    "href": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination",
    "title": "9  Einführung",
    "section": "9.5 Was bedeuten die Koeffizienten in Kombination?",
    "text": "9.5 Was bedeuten die Koeffizienten in Kombination?\n\n9.5.1 Full model\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n1.077\n0.066\n\n\nx1\n2.965\n0.056\n\n\nx2\n0.708\n0.060\n\n\n\n\n\n\n\n9.5.2 um x2 bereinigt\n\nmod_x1_x2 <- lm(x1 ~ x2, df)\nres_mod_x1_x2 <- resid(mod_x1_x2)\nmod_x1_res <- lm(y ~ res_mod_x1_x2, df)\n\n\n\n              Estimate Std. Error t value\n(Intercept)       1.25       0.16    7.61\nres_mod_x1_x2     2.97       0.14   20.97\n\n\n\n\n9.5.3 um x1 bereinigt\n\nmod_x2_x1 <- lm(x2 ~ x1, df)\nres_mod_x2_x1 <- resid(mod_x2_x1)\nmod_x2_res <- lm(y ~ res_mod_x2_x1, df)\n\n\n\n              Estimate Std. Error t value\n(Intercept)       1.25       0.51    2.44\nres_mod_x2_x1     0.71       0.47    1.51"
  },
  {
    "objectID": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination-1",
    "href": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination-1",
    "title": "9  Einführung",
    "section": "9.6 Was bedeuten die Koeffizienten in Kombination?",
    "text": "9.6 Was bedeuten die Koeffizienten in Kombination?\n\n\\(\\hat{\\beta}_1\\): Wenn ich \\(x_2\\) weiß, welche zusätzlichen Informationen bekomme ich durch \\(x_1\\)\n\\(\\hat{\\beta}_2\\): Wenn ich \\(x_1\\) weiß, welche zusätzlichen Informationen bekomme ich durch \\(x_2\\)\n\nIn Beispiel nicht problematisch, weil nach Konstruktion \\(x_1\\) und \\(x_2\\) unabhängig voneinander sind:\n\nround(cor(df),3)\n\n      x1    x2     y\nx1 1.000 0.078 0.969\nx2 0.078 1.000 0.289\ny  0.969 0.289 1.000"
  },
  {
    "objectID": "mlm_basics.html#added-variable-plots",
    "href": "mlm_basics.html#added-variable-plots",
    "title": "9  Einführung",
    "section": "9.7 Added-variable plots",
    "text": "9.7 Added-variable plots\n\n\n\n\n\nZusammenhang zwischen y und x2 bereinigt um den Einfluß von x1."
  },
  {
    "objectID": "mlm_basics.html#added-variable-plots-mit-caravplots",
    "href": "mlm_basics.html#added-variable-plots-mit-caravplots",
    "title": "9  Einführung",
    "section": "9.8 Added-variable plots mit car::avPlots()",
    "text": "9.8 Added-variable plots mit car::avPlots()\n\ncar::avPlots(mod, ~x2)"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-ich-einen-prädiktor-weg-lasse",
    "href": "mlm_basics.html#was-passiert-wenn-ich-einen-prädiktor-weg-lasse",
    "title": "9  Einführung",
    "section": "9.9 Was passiert wenn ich einen Prädiktor weg lasse?",
    "text": "9.9 Was passiert wenn ich einen Prädiktor weg lasse?\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n1.077\n0.066\n\n\nx1\n2.965\n0.056\n\n\nx2\n0.708\n0.060\n\n\n\n\n\n\ncoef(lm(y ~ x1, df))\n\n(Intercept)          x1 \n   1.007466    3.017589 \n\ncoef(lm(y ~ x2, df))\n\n(Intercept)          x2 \n  1.3377771   0.9555316 \n\n\nIn unserem Beispiel wieder nicht viel, da die Variablen unabhängig (orthogonal) voneinander sind."
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren",
    "title": "9  Einführung",
    "section": "9.10 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.10 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\n\n\nAusschnitt von Körperfettdaten\n\n\ntriceps\nthigh\nmidarm\nbody_fat\n\n\n\n\n19.5\n43.1\n29.1\n11.9\n\n\n24.7\n49.8\n28.2\n22.8\n\n\n30.7\n51.9\n37.0\n18.7\n\n\n29.8\n54.3\n31.1\n20.1\n\n\n19.1\n42.2\n30.9\n12.9\n\n\n25.6\n53.9\n23.7\n21.7\n\n\n\n\n\n1"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-1",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-1",
    "title": "9  Einführung",
    "section": "9.11 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.11 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\nGGally::ggpairs(bodyfat) + theme(text = element_text(size = 10))\n\n\n\n\nKorrelationsmatrize"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-2",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-2",
    "title": "9  Einführung",
    "section": "9.12 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.12 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\n# Alle drei Prädiktoren\nmod_full <- lm(body_fat ~ triceps + thigh + midarm, bodyfat)\n# ohne Arm\nmod_wo_midarm <- lm(body_fat ~ triceps + thigh, bodyfat)\n# Ohne Oberschenkel\nmod_wo_thigh <- lm(body_fat ~ triceps + midarm, bodyfat)\n# Ohne Triceps\nmod_wo_triceps <- lm(body_fat ~ thigh + midarm, bodyfat)"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-3",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-3",
    "title": "9  Einführung",
    "section": "9.13 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.13 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\n\n\nfull model\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n117.085\n99.782\n\n\ntriceps\n4.334\n3.016\n\n\nthigh\n-2.857\n2.582\n\n\nmidarm\n-2.186\n1.595\n\n\n\n\n\n\n\n\nw/o midarm\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n-19.174\n8.361\n\n\ntriceps\n0.222\n0.303\n\n\nthigh\n0.659\n0.291\n\n\n\n\n\n\n\n\nw/o thigh\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n6.792\n4.488\n\n\ntriceps\n1.001\n0.128\n\n\nmidarm\n-0.431\n0.177\n\n\n\n\n\n\n\n\nw/o triceps\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n-25.997\n6.997\n\n\nthigh\n0.851\n0.112\n\n\nmidarm\n0.096\n0.161"
  },
  {
    "objectID": "mlm_basics.html#multikollinearität",
    "href": "mlm_basics.html#multikollinearität",
    "title": "9  Einführung",
    "section": "9.14 Multikollinearität2",
    "text": "9.14 Multikollinearität2\n\nGroße Änderungen in den Koeffizienten wenn Prädiktoren ausgelassen/eingefügt werden\nKoeffizienten haben eine andere Richtung als erwartet\nHohe (einfache) Korrelationen zwischen Prädiktoren\nBreite Konfidenzintervalle für “wichtige” Prädiktoren \\(b_j\\)\n\n\\[\n\\widehat{\\text{Var}}(b_j) = \\frac{\\hat{\\sigma}^2}{(n-1)s_j^2}\\frac{1}{1-R_j^2}\n\\]\n\\(R_j^2\\) = Multipler Korrelationskoeffizient der Prädiktoren auf Prädiktorvariable \\(j\\)."
  },
  {
    "objectID": "mlm_basics.html#variance-inflation-factor-vif",
    "href": "mlm_basics.html#variance-inflation-factor-vif",
    "title": "9  Einführung",
    "section": "9.15 Variance Inflation Factor (VIF)",
    "text": "9.15 Variance Inflation Factor (VIF)\n\\[\n\\text{VIF}_j = \\frac{1}{1-R_j^2}\n\\]\n\n\n\n\n\n\nTipp\n\n\n\nWenn VIF > 10 ist, dann deutet dies auf hohe Multikollinearität hin.\n\n\n3"
  },
  {
    "objectID": "mlm_basics.html#variance-inflation-factor-vif-1",
    "href": "mlm_basics.html#variance-inflation-factor-vif-1",
    "title": "9  Einführung",
    "section": "9.16 Variance Inflation Factor (VIF)",
    "text": "9.16 Variance Inflation Factor (VIF)\n\ncar::vif(mod_full) \n\n triceps    thigh   midarm \n708.8429 564.3434 104.6060 \n\n\n4\nÜblicherweise wird der größte Wert betrachtet um die Multikollinearität zu bewerten."
  },
  {
    "objectID": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren",
    "href": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren",
    "title": "9  Einführung",
    "section": "9.17 Wenn Prädiktoren sich gegenseitig maskieren5",
    "text": "9.17 Wenn Prädiktoren sich gegenseitig maskieren5\n\n\n\n\n\nx_pos maskiert den Einfluss von x_neg"
  },
  {
    "objectID": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren-1",
    "href": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren-1",
    "title": "9  Einführung",
    "section": "9.18 Wenn Prädiktoren sich gegenseitig maskieren",
    "text": "9.18 Wenn Prädiktoren sich gegenseitig maskieren\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n0.235\n0.135\n\n\nx_pos\n0.218\n0.147\n\n\n\n\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n0.228\n0.116\n\n\nx_neg\n-0.618\n0.103\n\n\n\n\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n0.135\n0.096\n\n\nx_pos\n0.850\n0.123\n\n\nx_neg\n-0.976\n0.099"
  },
  {
    "objectID": "mlm_basics.html#multiple-regression",
    "href": "mlm_basics.html#multiple-regression",
    "title": "9  Einführung",
    "section": "9.19 Multiple Regression",
    "text": "9.19 Multiple Regression\nAus der einfachen Regression\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\n\\]\nwird\n\\[\ny_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\dots + \\beta_K x_{Ki} + \\epsilon_i\n\\]\nmit K Prädiktorvariablen und Multikollinearität."
  },
  {
    "objectID": "mlm_basics.html#zum-nacharbeiten",
    "href": "mlm_basics.html#zum-nacharbeiten",
    "title": "9  Einführung",
    "section": "9.20 Zum Nacharbeiten",
    "text": "9.20 Zum Nacharbeiten\nAltman und Krzywinski (2015) Kutner u. a. (2005, p.278–288) Fox (2011, p.325–327)\n\n\n\n\nAltman, Naomi, und Martin Krzywinski. 2015. „Points of significance: Multiple linear regression“. Nature Methods 12 (12): 1103–4.\n\n\nFox, John. 2011. An R companion to applied regression. 2. Aufl. SAGE Publication Inc., Thousand Oaks.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York.\n\n\nMcElreath, Richard. 2016. Statistical rethinking, A Bayesian Course with Examples in R and Stan. 1. Aufl. Boca Raton: CRC Press."
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten",
    "href": "mlm_interactions.html#beispieldaten",
    "title": "10  Interaktionseffekte",
    "section": "10.1 Beispieldaten1",
    "text": "10.1 Beispieldaten1\n\n\n\nBeispieldaten (synthetisch)\n\n\nVelocity[m/s]\nbody mass[kg]\narm span[cm]\n\n\n\n\n185.42\n68.71\n20.14\n\n\n184.08\n73.85\n21.29\n\n\n200.74\n89.43\n27.57\n\n\n170.34\n84.97\n19.88\n\n\n176.89\n82.40\n20.51\n\n\n200.68\n91.57\n29.22"
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten---deskriptiv",
    "href": "mlm_interactions.html#beispieldaten---deskriptiv",
    "title": "10  Interaktionseffekte",
    "section": "10.2 Beispieldaten - Deskriptiv",
    "text": "10.2 Beispieldaten - Deskriptiv\n\n\n\nDeskriptive Statistik der Handballdaten\n\n\n\nMean\nStd.Dev\nMin\nMax\n\n\n\n\narm_span\n184.3\n7.7\n169.4\n200.7\n\n\nbody_mass\n77.5\n10.3\n58.0\n101.1\n\n\nvel\n21.9\n2.3\n18.5\n29.2"
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten-1",
    "href": "mlm_interactions.html#beispieldaten-1",
    "title": "10  Interaktionseffekte",
    "section": "10.3 Beispieldaten",
    "text": "10.3 Beispieldaten\n\n\n\n\n\nGeschwindigkeit gegen Körpergewicht\n\n\n\n\n\n\n\n\n\nGeschwindigkeit gegen Armspannweite"
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten---startmodell",
    "href": "mlm_interactions.html#beispieldaten---startmodell",
    "title": "10  Interaktionseffekte",
    "section": "10.4 Beispieldaten - Startmodell",
    "text": "10.4 Beispieldaten - Startmodell\n\\[\nY_{i} = \\beta_0 + \\beta_1 \\times \\textrm{bm}_i + \\beta_2 \\times \\textrm{as}_i + \\epsilon_i\n\\]\n\nmod_1 <- lm(vel ~ body_mass + arm_span, handball)\n\n\n\n\nModell 1\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n-1.768\n7.632\n-0.232\n0.818\n\n\nbody_mass\n0.077\n0.033\n2.359\n0.024\n\n\narm_span\n0.096\n0.044\n2.192\n0.035\n\n\n\\(\\hat{\\sigma}\\)\n1.996"
  },
  {
    "objectID": "mlm_interactions.html#modellfit",
    "href": "mlm_interactions.html#modellfit",
    "title": "10  Interaktionseffekte",
    "section": "10.5 Modellfit",
    "text": "10.5 Modellfit\n\n\n\n\n\n3D Streudiagramm"
  },
  {
    "objectID": "mlm_interactions.html#zentrierung",
    "href": "mlm_interactions.html#zentrierung",
    "title": "10  Interaktionseffekte",
    "section": "10.6 Zentrierung",
    "text": "10.6 Zentrierung\n\nhandball <- dplyr::mutate(handball,\n                          body_mass_c = body_mass - mean(body_mass),\n                          arm_span_c = arm_span - mean(arm_span))\n\n\n\n\nDeskriptive Statistik\n\n\n\nMean\nStd.Dev\n\n\n\n\narm_span\n184.29\n7.72\n\n\narm_span_c\n0.00\n7.72\n\n\nbody_mass\n77.46\n10.26\n\n\nbody_mass_c\n0.00\n10.26\n\n\nvel\n21.85\n2.31"
  },
  {
    "objectID": "mlm_interactions.html#modell-mit-zentrierten-variablen",
    "href": "mlm_interactions.html#modell-mit-zentrierten-variablen",
    "title": "10  Interaktionseffekte",
    "section": "10.7 Modell mit zentrierten Variablen",
    "text": "10.7 Modell mit zentrierten Variablen\n\nmod_2 <- lm(vel ~ body_mass_c + arm_span_c, handball)\n\n\n\n\nModell 2\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n21.852\n0.316\n69.247\n<0.001\n\n\nbody_mass_c\n0.077\n0.033\n2.359\n0.024\n\n\narm_span_c\n0.096\n0.044\n2.192\n0.035\n\n\n\\(\\hat{\\sigma}\\)\n1.996"
  },
  {
    "objectID": "mlm_interactions.html#residuen-im-zentrierten-additiven-modell",
    "href": "mlm_interactions.html#residuen-im-zentrierten-additiven-modell",
    "title": "10  Interaktionseffekte",
    "section": "10.8 Residuen im zentrierten, additiven Modell",
    "text": "10.8 Residuen im zentrierten, additiven Modell\n\n\n\n\n\nResiduenplot"
  },
  {
    "objectID": "mlm_interactions.html#added-variable-plot",
    "href": "mlm_interactions.html#added-variable-plot",
    "title": "10  Interaktionseffekte",
    "section": "10.9 Added-variable plot",
    "text": "10.9 Added-variable plot\n\n\n\n\n\nAbbildung 10.1: Added-variable Graph mit car::avPlots()"
  },
  {
    "objectID": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind",
    "href": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind",
    "title": "10  Interaktionseffekte",
    "section": "10.10 Was passiert wenn die Effekte nicht mehr nur additiv sind?",
    "text": "10.10 Was passiert wenn die Effekte nicht mehr nur additiv sind?\n\n\n\n\n\nUnterteilung von Körpergewicht und Armspannweite in Kategorien"
  },
  {
    "objectID": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind-1",
    "href": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind-1",
    "title": "10  Interaktionseffekte",
    "section": "10.11 Was passiert wenn die Effekte nicht mehr nur additiv sind?",
    "text": "10.11 Was passiert wenn die Effekte nicht mehr nur additiv sind?\n\n10.11.1 Neues Modell mit Interaktionen:\n\\[\nY_{i} = \\beta_0 + \\beta_1 \\times \\textrm{bm}_i + \\beta_2 \\times \\textrm{as}_i + \\beta_3 \\times \\textrm{bm}_i \\times \\textrm{as}_i + \\epsilon_i\n\\]"
  },
  {
    "objectID": "mlm_interactions.html#modellierung",
    "href": "mlm_interactions.html#modellierung",
    "title": "10  Interaktionseffekte",
    "section": "10.12 Modellierung",
    "text": "10.12 Modellierung\n\nmod_3 <- lm(vel ~ body_mass_c * arm_span_c, handball) \n\n\n\n\nModell 3\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n21.346\n0.143\n149.296\n<0.001\n\n\nbody_mass_c\n0.119\n0.015\n8.133\n<0.001\n\n\narm_span_c\n0.083\n0.019\n4.380\n<0.001\n\n\nbody_mass_c:arm_span_c\n0.021\n0.002\n12.633\n<0.001\n\n\n\\(\\hat{\\sigma}\\)\n0.868\n\n\n\n\n\n\n\n\n2"
  },
  {
    "objectID": "mlm_interactions.html#einfache-steigungen-in-vergleich",
    "href": "mlm_interactions.html#einfache-steigungen-in-vergleich",
    "title": "10  Interaktionseffekte",
    "section": "10.13 Einfache Steigungen in Vergleich",
    "text": "10.13 Einfache Steigungen in Vergleich\n\n\n\n\n\nModell ohne Interaktionen\n\n\n\n\n\n\n\n\n\nModell mit Interaktionen"
  },
  {
    "objectID": "mlm_interactions.html#interaktionen-sind-symmetrisch",
    "href": "mlm_interactions.html#interaktionen-sind-symmetrisch",
    "title": "10  Interaktionseffekte",
    "section": "10.14 Interaktionen sind symmetrisch",
    "text": "10.14 Interaktionen sind symmetrisch\n\n\n\n\n\nVeränderung mit der Körpergewicht\n\n\n\n\n\n\n\n\n\nVeränderung mit dem Armspannweite"
  },
  {
    "objectID": "mlm_interactions.html#warum-das-model-sinn-macht",
    "href": "mlm_interactions.html#warum-das-model-sinn-macht",
    "title": "10  Interaktionseffekte",
    "section": "10.15 Warum das Model Sinn macht",
    "text": "10.15 Warum das Model Sinn macht\n\n\n\n\n\nVeränderung mit dem Körpergewicht\n\n\n\n\n\n\n\nEinfache Steigungen\n\n\narm span\\centered\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\n\n\n\n10\n22.18\n0.33\n\n\n0\n21.35\n0.12\n\n\n-10\n20.51\n-0.09"
  },
  {
    "objectID": "mlm_interactions.html#warum-das-modell-sinn-macht",
    "href": "mlm_interactions.html#warum-das-modell-sinn-macht",
    "title": "10  Interaktionseffekte",
    "section": "10.16 Warum das Modell Sinn macht",
    "text": "10.16 Warum das Modell Sinn macht\n\n\n\nEinfache Steigungen\n\n\narm span\\centered\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\n\n\n\n10\n22.18\n0.33\n\n\n0\n21.35\n0.12\n\n\n-10\n20.51\n-0.09\n\n\n\n\n\n\n\n\nModellkoeffizienten\n\n\n\nbetas\n\n\n\n\nb0\n21.35\n\n\nbm_c\n0.12\n\n\nas_c\n0.08\n\n\nbm_c:as_c\n0.02"
  },
  {
    "objectID": "mlm_interactions.html#interpretation-der-koeffizienten",
    "href": "mlm_interactions.html#interpretation-der-koeffizienten",
    "title": "10  Interaktionseffekte",
    "section": "10.17 Interpretation der Koeffizienten",
    "text": "10.17 Interpretation der Koeffizienten\n\\[\nY = b_0 + b_1 \\cdot x_1 + b_2 \\cdot x_2 + b_3 \\cdot x_1 \\cdot x_2 + \\epsilon_i\n\\]\n\n\\(b_0\\): (y-Achsenabschnitt) der Wert von \\(\\hat{Y}\\) wenn \\(x_1 = 0\\) und \\(x_2 = 0\\) gilt.\n\\(b_1\\): Der Unterschied in \\(\\hat{Y}\\) wenn zwei Objekte sich in \\(x_1\\) um eine Einheit unterscheiden und \\(x_2 = 0\\) ist.\n\\(b_2\\): Der Unterschied in \\(\\hat{Y}\\) wenn zwei Objekte sich in \\(x_2\\) um eine Einheit unterscheiden und \\(x_1 = 0\\) ist.\n\\(b_3\\): (Interaktionskoeffizient) Die Veränderung des Effekts von \\(x_1\\) auf \\(\\hat{Y}\\) wenn \\(x_2\\) um eine Einheit größer wird bzw. genau andersherum für \\(x_2\\)."
  },
  {
    "objectID": "mlm_interactions.html#aus-der-ebene-wird-eine-gekrümmte-fläche",
    "href": "mlm_interactions.html#aus-der-ebene-wird-eine-gekrümmte-fläche",
    "title": "10  Interaktionseffekte",
    "section": "10.18 Aus der Ebene wird eine gekrümmte Fläche",
    "text": "10.18 Aus der Ebene wird eine gekrümmte Fläche\n\n\n\n\n\n3D Streudiagramm des Interaktionsmodells"
  },
  {
    "objectID": "mlm_interactions.html#residuenvergleich",
    "href": "mlm_interactions.html#residuenvergleich",
    "title": "10  Interaktionseffekte",
    "section": "10.19 Residuenvergleich",
    "text": "10.19 Residuenvergleich\n\n\n\n\n\nResiduen im additiven Modell\n\n\n\n\n\n\n\n\n\nResiduen im Interaktionsmodell"
  },
  {
    "objectID": "mlm_interactions.html#residuenvergleich---qq-plot",
    "href": "mlm_interactions.html#residuenvergleich---qq-plot",
    "title": "10  Interaktionseffekte",
    "section": "10.20 Residuenvergleich - qq-Plot",
    "text": "10.20 Residuenvergleich - qq-Plot\n\n\n\n\n\nadditives Modell\n\n\n\n\n\n\n\n\n\nInteraktionsmodell"
  },
  {
    "objectID": "mlm_interactions.html#take-away",
    "href": "mlm_interactions.html#take-away",
    "title": "10  Interaktionseffekte",
    "section": "10.21 Take-away",
    "text": "10.21 Take-away\nInteraktionsmodell\n\nErhöht die Flexibilität des linearen Modells.\nBei Interaktionen hängt der Einfluss der einzelnen Variablen immer von den Werten der anderen Variablen ab.\nAchtung: Interpretation der einfachen Haupteffekte nicht mehr möglich bzw. sinnvoll!"
  },
  {
    "objectID": "mlm_interactions.html#zuschlag",
    "href": "mlm_interactions.html#zuschlag",
    "title": "10  Interaktionseffekte",
    "section": "10.22 Zuschlag",
    "text": "10.22 Zuschlag\nWas passiert im Interaktionsmodell mit den Koeffizienten wenn die \\(x_{ki}\\)s zentriert werden?\n\\[\\begin{align*}\ny_i &= \\beta_0 + \\beta_1 (x_{1i} - \\bar{x}_1) + \\beta_2 (x_{2i} - \\bar{x}_2) + \\beta_3 (x_{1i}-\\bar{x}_1)(x_{2i}-\\bar{x}_2) \\\\\n&= \\beta_0 + \\beta_1 x_{1i} - \\beta_1 \\bar{x}_1 + \\beta_2 x_{2i} - \\beta_2 \\bar{x}_2 + \\beta_3 x_{1i} x_{2i} - \\beta_3 x_{1i} \\bar{x}_2 - \\beta_3 \\bar{x}_1 x_{2i} + \\beta_3 \\bar{x}_1 \\bar{x}_2 \\\\\n&= \\beta_0 - \\beta_1 \\bar{x}_1 - \\beta_2 \\bar{x}_2 + \\beta_3 \\bar{x}_1 \\bar{x}_2 + \\beta_1 x_{1i}- \\beta_3 \\bar{x}_2 x_{1i} + \\beta_2 x_{2i} - \\beta_3 \\bar{x}_1 x_{2i} + \\beta_3 x_{1i} x_{2i} \\\\\n&= \\underbrace{\\beta_0 - \\beta_1 \\bar{x}_1 - \\beta_2 \\bar{x}_2 + \\beta_3 \\bar{x}_1 \\bar{x}_2}_{\\beta_0} + \\underbrace{(\\beta_1 - \\beta_3 \\bar{x}_2) x_{1i}}_{\\beta_1 x_{1i}} + \\underbrace{(\\beta_2 - \\beta_3 \\bar{x}_1) x_{2i}}_{\\beta_2 x_{2i}} + \\beta_3 x_{1i} x_{2i}\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_interactions.html#zum-nacharbeiten",
    "href": "mlm_interactions.html#zum-nacharbeiten",
    "title": "10  Interaktionseffekte",
    "section": "10.23 Zum Nacharbeiten",
    "text": "10.23 Zum Nacharbeiten\nKutner u. a. (2005, p.306–313)\n\n\n\n\nDebanne, Thierry, und Guillaume Laffaye. 2011. „Predicting the throwing velocity of the ball in handball with anthropometric variables and isotonic tests“. Journal of Sports Sciences 29 (7): 705–13.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "mlm_dummy_coding.html#beispiel-körpergröße-bei-frauen-und-männern",
    "href": "mlm_dummy_coding.html#beispiel-körpergröße-bei-frauen-und-männern",
    "title": "11  Integration von nominale Variablen",
    "section": "11.1 Beispiel: Körpergröße bei Frauen und Männern",
    "text": "11.1 Beispiel: Körpergröße bei Frauen und Männern\n\n\n\n\n\nSimulierte Daten: Verteilung von Körpergrößen nach Geschlecht"
  },
  {
    "objectID": "mlm_dummy_coding.html#datensatz",
    "href": "mlm_dummy_coding.html#datensatz",
    "title": "11  Integration von nominale Variablen",
    "section": "11.2 Datensatz",
    "text": "11.2 Datensatz\n\n\n\nAusschnitt aus den Daten\n\n\ncm\ngender\n\n\n\n\n174.4\nm\n\n\n177.7\nm\n\n\n195.6\nm\n\n\n171.3\nf\n\n\n164.0\nf\n\n\n176.0\nf"
  },
  {
    "objectID": "mlm_dummy_coding.html#nominale-variablen-in-r",
    "href": "mlm_dummy_coding.html#nominale-variablen-in-r",
    "title": "11  Integration von nominale Variablen",
    "section": "11.3 Nominale Variablen in R",
    "text": "11.3 Nominale Variablen in R\nNominale Variablen werden in R als factor() dargestellt.\n\ngender <- factor(c(0,0,1,1),\n                 levels = c(0,1),\n                 labels = c('m','f'))\ngender\n\n[1] m m f f\nLevels: m f\n\n\n1"
  },
  {
    "objectID": "mlm_dummy_coding.html#t-test-in-r-mit-t.test",
    "href": "mlm_dummy_coding.html#t-test-in-r-mit-t.test",
    "title": "11  Integration von nominale Variablen",
    "section": "11.4 t-Test in R mit t.test()",
    "text": "11.4 t-Test in R mit t.test()\n\nt.test(cm ~ gender, data=height, var.equal=T)\n\n\n\n\n Two Sample t-test\n\ndata: cm by gender\nt = -4.57, df = 58, p-value = <0.001\nd = -10.75, s_e = 2.35\n95 percent confidence interval\n[-15.45, -6.04]"
  },
  {
    "objectID": "mlm_dummy_coding.html#modellformulierung-beim-t-test-n_w-n_m",
    "href": "mlm_dummy_coding.html#modellformulierung-beim-t-test-n_w-n_m",
    "title": "11  Integration von nominale Variablen",
    "section": "11.5 Modellformulierung beim t-Test \\((n_w = n_m)\\)",
    "text": "11.5 Modellformulierung beim t-Test \\((n_w = n_m)\\)\n\\[\\begin{align*}\nY_{if} &= \\mu_{f} + \\epsilon_{if}, \\quad \\epsilon_{if} \\sim \\mathcal{N}(0,\\sigma^2) \\\\\nY_{im} &= \\mu_{m} + \\epsilon_{im}, \\quad \\epsilon_{im} \\sim \\mathcal{N}(0,\\sigma^2)\n\\end{align*}\\]\n\n11.5.1 Hypothesen\n\\[\\begin{align*}\nH_0&: \\delta = 0 \\\\\nH_1&: \\delta \\neq 0\n\\end{align*}\\]\n\n\n11.5.2 Teststatistik\n\\[\nt = \\frac{\\bar{y}_m - \\bar{y}_w}{\\sqrt{\\frac{s_m^2 + s_w^2}{2}}\\sqrt{\\frac{2}{n}}}\n\\]\n\n\n11.5.3 Referenzverteilung\n\\[\nt \\sim t_{df=2n-2}\n\\]\n\n\n\n\n\nt-Verteilung mit \\(df=58\\)"
  },
  {
    "objectID": "mlm_dummy_coding.html#kann-ich-aus-dem-t-test-ein-lineares-modell-machen",
    "href": "mlm_dummy_coding.html#kann-ich-aus-dem-t-test-ein-lineares-modell-machen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.6 Kann ich aus dem t-Test ein lineares Modell machen?",
    "text": "11.6 Kann ich aus dem t-Test ein lineares Modell machen?\n\n11.6.1 t-Test\n\\[\\begin{align*}\nY_{if} &= \\mu_{f} + \\epsilon_{if}, \\quad \\epsilon_{if} \\sim \\mathcal{N}(0,\\sigma^2) \\\\\nY_{im} &= \\mu_{m} + \\epsilon_{im}, \\quad \\epsilon_{im} \\sim \\mathcal{N}(0,\\sigma^2) \\\\\nt &= \\frac{\\bar{y}_m - \\bar{y}_w}{\\sqrt{\\frac{s_m^2 + s_w^2}{2}}\\sqrt{\\frac{2}{n}}} \\\\\nt &\\sim t_{df=2n-2}\n\\end{align*}\\]\n\n\n11.6.2 Lineares Modell\n\\[\\begin{align*}\nY_i &= \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i \\\\\n\\Delta_m &= \\mu_m - \\mu_f \\\\\nY_i &= \\beta_0 + \\beta_1 \\times x_{??} + \\epsilon_i \\\\\nY_i &= \\mu_f + \\Delta_{m} \\times x_{??} + \\epsilon_i\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#dummy--oder-indikatorkodierung",
    "href": "mlm_dummy_coding.html#dummy--oder-indikatorkodierung",
    "title": "11  Integration von nominale Variablen",
    "section": "11.7 Dummy- oder Indikatorkodierung",
    "text": "11.7 Dummy- oder Indikatorkodierung\n\\[\\begin{align*}\nY_i &= \\mu_f + \\Delta_{m} \\times x_{1i} + \\epsilon_i \\\\\n\\Delta_m &= \\mu_m - \\mu_f \\\\\nx_1 &=\n\\begin{cases}\n0\\text{ wenn weiblich}\\\\\n1\\text{ wenn männlich}\n\\end{cases}\n\\end{align*}\\]\nFür eine nominale Variable wird eine Indikatorvariablen (Dummyvariable) definiert. Über diese Indikatorvariable kann die Zugehörigkeit eines Messwerts \\(Y_i\\) zu einer Faktorstufe \\(k\\) bestimmt werden. Eine Faktorstufe ist dabei immer die Referenzstufe bei der die Indikatorvariable gleich \\(0\\) ist."
  },
  {
    "objectID": "mlm_dummy_coding.html#einfach-mal-stumpf-in-lm-eingeben",
    "href": "mlm_dummy_coding.html#einfach-mal-stumpf-in-lm-eingeben",
    "title": "11  Integration von nominale Variablen",
    "section": "11.8 Einfach mal stumpf in lm() eingeben",
    "text": "11.8 Einfach mal stumpf in lm() eingeben\n\nmod <- lm(cm ~ gender, height)\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n168.783\n1.663\n101.477\n<0.001\n\n\ngenderm\n10.746\n2.352\n4.568\n<0.001\n\n\n\n\n\n2"
  },
  {
    "objectID": "mlm_dummy_coding.html#vergleich-der-konfidenzintervalle",
    "href": "mlm_dummy_coding.html#vergleich-der-konfidenzintervalle",
    "title": "11  Integration von nominale Variablen",
    "section": "11.9 Vergleich der Konfidenzintervalle",
    "text": "11.9 Vergleich der Konfidenzintervalle\n\n11.9.1 Lineares Modell\n\nconfint(mod)\n\n                2.5 %    97.5 %\n(Intercept) 165.45401 172.11276\ngenderm       6.03713  15.45403\n\n\n\n\n11.9.2 t-Test\n\nt.test(cm ~ gender,\n       data = height,\n       var.equal=T)$conf\n\n[1] -15.45403  -6.03713\nattr(,\"conf.level\")\n[1] 0.95\n\n\n3"
  },
  {
    "objectID": "mlm_dummy_coding.html#auf-welchen-werten-wird-ein-lineares-modell-gerechnet",
    "href": "mlm_dummy_coding.html#auf-welchen-werten-wird-ein-lineares-modell-gerechnet",
    "title": "11  Integration von nominale Variablen",
    "section": "11.10 Auf welchen Werten wird ein lineares Modell gerechnet???",
    "text": "11.10 Auf welchen Werten wird ein lineares Modell gerechnet???\n\n\n\nRepräsentation der Faktorvariablen\n\n\ncm\ngender\n\\(x_1\\)\n\n\n\n\n174.40\nm\n1\n\n\n177.70\nm\n1\n\n\n195.59\nm\n1\n\n\n160.05\nf\n0\n\n\n164.92\nf\n0\n\n\n154.35\nf\n0"
  },
  {
    "objectID": "mlm_dummy_coding.html#residuen",
    "href": "mlm_dummy_coding.html#residuen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.11 Residuen",
    "text": "11.11 Residuen\n\n\n\n\n\nResiduen"
  },
  {
    "objectID": "mlm_dummy_coding.html#wens-interessiert---t-wert",
    "href": "mlm_dummy_coding.html#wens-interessiert---t-wert",
    "title": "11  Integration von nominale Variablen",
    "section": "11.12 Wen’s interessiert - t-Wert",
    "text": "11.12 Wen’s interessiert - t-Wert\nSeien beide Gruppen gleich groß (\\(n\\)) mit \\(N = n_m + n_w = 2 \\times n\\). Der t-Wert für \\(\\beta_1\\) berechnet sich aus \\(t = \\frac{b_1}{s_b}\\) mit:\n\\[\ns_b = \\sqrt{\\frac{\\sum_{i=1}^N (y_i - \\bar{y})^2}{N-2}\\frac{1}{\\sum_{i=1}^N(x_i-\\bar{x})^2}}\n\\] Dadurch, das die \\(x_i\\) entweder gleich \\(0\\) oder \\(1\\) sind, ist \\(\\bar{x}=0.5\\) und die Abweichungsquadrate im zweiten Term sind alle gleich \\(\\frac{1}{4}\\).\n\\[\n\\sum_{i=1}^N(x_i - \\bar{x})^2=\\sum_{i=1}^N\\left(x_i - \\frac{1}{2}\\right)^2 = \\sum_{i=1}^N\\frac{1}{4}=\\frac{N}{4}=\\frac{2n}{4}=\\frac{n}{2}\n\\]\nDer ersten Term kann mit etwas Algebra und der Definition für die Stichprobenvarianz \\(s^2\\) auf die gewünschte Form gebracht werden.\n\\[\n\\frac{\\sum_{i=1}^N(y_i-\\hat{y})^2}{N-2}=\\frac{\\sum_{i=1}^n(\\overbrace{y_{im} - \\bar{y}_m}^{Männer})^2+\\sum_{i=1}^n(\\overbrace{y_{iw}-\\bar{y}_w}^{Frauen})^2}{2(n-1)}=\\frac{(n-1)s_m^2+(n-1)s_w^2}{2(n-1)}=\\frac{s_m^2+s_w^2}{2}\n\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#wens-interessiert---beta_1-mu_w---mu_m",
    "href": "mlm_dummy_coding.html#wens-interessiert---beta_1-mu_w---mu_m",
    "title": "11  Integration von nominale Variablen",
    "section": "11.13 Wen’s interessiert - \\(\\beta_1 = \\mu_w - \\mu_m\\)",
    "text": "11.13 Wen’s interessiert - \\(\\beta_1 = \\mu_w - \\mu_m\\)\nMit \\(s_x^2 = \\frac{N\\frac{1}{4}}{N-1} = \\frac{N}{4(N-1)}\\) \\[\\begin{align*}\n    b_1 &= \\frac{cov(x,y)}{s_x^2} \\\\\n    &= \\frac{\\sum_{i=1}^N(y_i - \\bar{y})(x_i - \\bar{x})}{N-1} \\frac{4(N-1)}{N} \\\\\n    &= 4\\frac{\\sum_{i=1}^n(y_{im}-\\bar{y})\\frac{-1}{2}+\\sum(y_{iw}-\\bar{y})\\frac{1}{2}}{N} \\\\\n    &= \\frac{4}{2}\\frac{\\sum_{i=1}^n(y_{iw}-\\bar{y}) - \\sum_{i=1}^n(y_{im}-\\bar{y})}{2n} \\\\\n    &= \\frac{\\sum_{i=1}^n y_{iw}}{n} - \\frac{n\\bar{y}}{n} - \\frac{\\sum_{i=1}^n y_{im}}{n} + \\frac{n\\bar{y}}{n} \\\\\n    &= \\bar{y}_w - \\bar{y}_m = \\Delta\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#wens-interessiert---beta_0-mu_m",
    "href": "mlm_dummy_coding.html#wens-interessiert---beta_0-mu_m",
    "title": "11  Integration von nominale Variablen",
    "section": "11.14 Wen’s interessiert - \\(\\beta_0 = \\mu_m\\)",
    "text": "11.14 Wen’s interessiert - \\(\\beta_0 = \\mu_m\\)\nMit \\(b_1 = \\Delta = \\bar{y}_w - \\bar{y}_m\\): \\[\\begin{align*}\nb_0 &= \\bar{y} - \\Delta \\times \\bar{x} \\\\\n&= \\frac{\\sum_{i=1}^N y_i}{N} - \\Delta \\times \\frac{1}{2} \\\\\n&= \\frac{\\sum_{i=1}^n y_{im} + \\sum_{i=1}^n y_{iw}}{2n} - \\frac{1}{2}(\\bar{y}_w - \\bar{y}_m)  \\\\\n&= \\frac{1}{2}\\frac{\\sum_{i=1}^ny_{im}}{n} + \\frac{1}{2}\\frac{\\sum_{i=1}^ny_{iw}}{n} - \\frac{1}{2}\\bar{y}_w + \\frac{1}{2}\\bar{y}_m \\\\\n&= \\frac{1}{2}\\bar{y}_m + \\frac{1}{2}\\bar{y}_w - \\frac{1}{2}\\bar{y}_w + \\frac{1}{2}\\bar{y}_m \\\\\n&= \\bar{y}_m\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#können-auch-mehr-als-zwei-stufen-verwendet-werden",
    "href": "mlm_dummy_coding.html#können-auch-mehr-als-zwei-stufen-verwendet-werden",
    "title": "11  Integration von nominale Variablen",
    "section": "11.15 Können auch mehr als zwei Stufen verwendet werden?",
    "text": "11.15 Können auch mehr als zwei Stufen verwendet werden?\n\n\n\n\n\nEin Reaktionszeitexperiment mit vier Stufen A, B, C und D"
  },
  {
    "objectID": "mlm_dummy_coding.html#deskriptive-daten",
    "href": "mlm_dummy_coding.html#deskriptive-daten",
    "title": "11  Integration von nominale Variablen",
    "section": "11.16 Deskriptive Daten",
    "text": "11.16 Deskriptive Daten"
  },
  {
    "objectID": "mlm_dummy_coding.html#reaktionszeitexperiment-als-lineares-modell",
    "href": "mlm_dummy_coding.html#reaktionszeitexperiment-als-lineares-modell",
    "title": "11  Integration von nominale Variablen",
    "section": "11.17 Reaktionszeitexperiment als lineares Modell",
    "text": "11.17 Reaktionszeitexperiment als lineares Modell\n\n11.17.1 Modell\n\\[\ny_i = \\mu_A + \\Delta_{B-A} x_1 + \\Delta_{C-A} x_2 + \\Delta_{D-A} x_3 + \\epsilon_i\n\\]\n\n\n11.17.2 Dummyvariablen"
  },
  {
    "objectID": "mlm_dummy_coding.html#nochmal-allgemeiner",
    "href": "mlm_dummy_coding.html#nochmal-allgemeiner",
    "title": "11  Integration von nominale Variablen",
    "section": "11.18 Nochmal allgemeiner",
    "text": "11.18 Nochmal allgemeiner\nMit \\(K\\) Faktorstufen werden (K-1) Dummyvariablen \\(x_1, x_2, \\ldots, x_{K-1}\\) benötigt. Eine Stufe wird als Referenz definiert. Die \\(x_1\\) bis \\(x_{K-1}\\) kodieren die Abweichungen der anderen Stufen von dieser Stufe.4"
  },
  {
    "objectID": "mlm_dummy_coding.html#reaktionszeitexperiment-mit-lm",
    "href": "mlm_dummy_coding.html#reaktionszeitexperiment-mit-lm",
    "title": "11  Integration von nominale Variablen",
    "section": "11.19 Reaktionszeitexperiment mit lm()",
    "text": "11.19 Reaktionszeitexperiment mit lm()\n\nmod <- lm(rt ~ group, data)\n\n\n\n\n\nModellfit\n \n  \n      \n    $\\hat{\\beta}$ \n    $s_e$ \n    t \n    p \n  \n \n\n  \n    (Intercept) \n    509.526 \n    10.235 \n    49.784 \n    <0.001 \n  \n  \n    groupB \n    90.150 \n    14.474 \n    6.228 \n    <0.001 \n  \n  \n    groupC \n    197.414 \n    14.474 \n    13.639 \n    <0.001 \n  \n  \n    groupD \n    295.561 \n    14.474 \n    20.420 \n    <0.001"
  },
  {
    "objectID": "mlm_dummy_coding.html#ausblick",
    "href": "mlm_dummy_coding.html#ausblick",
    "title": "11  Integration von nominale Variablen",
    "section": "11.20 Ausblick",
    "text": "11.20 Ausblick\n\nanova(mod)\n\n\n\n\n\nANOVA-Tabelle\n \n  \n     \n    Df \n    SSQ \n    MSQ \n    F \n    p \n  \n \n\n  \n    group \n    3 \n    988935.1 \n    329645.04 \n    157.35 \n    <0.001 \n  \n  \n    Residuals \n    76 \n    159221.0 \n    2095.01"
  },
  {
    "objectID": "mlm_dummy_coding.html#kombination-von-kontinuierlichen-und-nominalen-variablen",
    "href": "mlm_dummy_coding.html#kombination-von-kontinuierlichen-und-nominalen-variablen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.21 Kombination von kontinuierlichen und nominalen Variablen",
    "text": "11.21 Kombination von kontinuierlichen und nominalen Variablen\n\n\n\n\n\nHypothetische Leistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#modellansatz",
    "href": "mlm_dummy_coding.html#modellansatz",
    "title": "11  Integration von nominale Variablen",
    "section": "11.22 Modellansatz",
    "text": "11.22 Modellansatz\n\nAus gender (K = 2) wird eine Dummyvariable\nFrauen werden (zufällig) als Referenz genommen\n\n\\[\\begin{align*}\nY_i &= \\beta_{ta = 0,x_1=0} + \\Delta_m \\times x_1 + \\beta_{ta} \\times ta + \\epsilon_i \\\\\nx_1 &=\n\\begin{cases}\n0\\text{ wenn weiblich}\\\\\n1\\text{ wenn männlich}\n\\end{cases} \\\\\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#modellieren-mit-lm",
    "href": "mlm_dummy_coding.html#modellieren-mit-lm",
    "title": "11  Integration von nominale Variablen",
    "section": "11.23 Modellieren mit lm()",
    "text": "11.23 Modellieren mit lm()\n\nmod <- lm(perf ~ gender_f + ta, lew)\n\n\n\n\n\nModellfit\n \n  \n      \n    $\\hat{\\beta}$ \n    $s_e$ \n  \n \n\n  \n    (Intercept) \n    41.181 \n    1.083 \n  \n  \n    gender\\_fm \n    -10.877 \n    0.805 \n  \n  \n    ta \n    1.927 \n    0.145 \n  \n  \n    $\\hat{\\sigma}$ \n    2.845"
  },
  {
    "objectID": "mlm_dummy_coding.html#die-resultierenden-graden",
    "href": "mlm_dummy_coding.html#die-resultierenden-graden",
    "title": "11  Integration von nominale Variablen",
    "section": "11.24 Die resultierenden Graden",
    "text": "11.24 Die resultierenden Graden\n\n\n\n\n\nLeistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#interaktion-zwischen-kontinuierlichen-und-nominalen-variablen",
    "href": "mlm_dummy_coding.html#interaktion-zwischen-kontinuierlichen-und-nominalen-variablen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.25 Interaktion zwischen kontinuierlichen und nominalen Variablen",
    "text": "11.25 Interaktion zwischen kontinuierlichen und nominalen Variablen\n\n\n\n\n\nLeistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#ansatz-für-ein-interaktionsmodell",
    "href": "mlm_dummy_coding.html#ansatz-für-ein-interaktionsmodell",
    "title": "11  Integration von nominale Variablen",
    "section": "11.26 Ansatz für ein Interaktionsmodell",
    "text": "11.26 Ansatz für ein Interaktionsmodell\nDas vorhergehendes Modell wird um einen Interaktionsterm erweitert.\n\\[\ny_i = \\beta_{ta=0,x_1=0} + \\Delta_m \\times x_1 + \\beta_{ta} \\times ta + \\beta_{ta \\times gender} \\times x_1 \\times ta + \\epsilon_i\n\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#interaktionsmodell-mit-lm",
    "href": "mlm_dummy_coding.html#interaktionsmodell-mit-lm",
    "title": "11  Integration von nominale Variablen",
    "section": "11.27 Interaktionsmodell mit lm()",
    "text": "11.27 Interaktionsmodell mit lm()\n\nmod <- lm(perf ~ gender_f * ta, lew)\n\n\n\n\n\nModellfit\n \n  \n      \n    $\\hat{\\beta}$ \n    $s_e$ \n  \n \n\n  \n    (Intercept) \n    31.354 \n    1.370 \n  \n  \n    gender\\_fm \n    8.575 \n    2.010 \n  \n  \n    ta \n    1.763 \n    0.195 \n  \n  \n    gender\\_fm:ta \n    2.362 \n    0.290 \n  \n  \n    $\\hat{\\sigma}$ \n    2.828"
  },
  {
    "objectID": "mlm_dummy_coding.html#regressionsgeraden",
    "href": "mlm_dummy_coding.html#regressionsgeraden",
    "title": "11  Integration von nominale Variablen",
    "section": "11.28 Regressionsgeraden",
    "text": "11.28 Regressionsgeraden\n\n\n\n\n\nLeistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#zum-nacharbeiten",
    "href": "mlm_dummy_coding.html#zum-nacharbeiten",
    "title": "11  Integration von nominale Variablen",
    "section": "11.29 Zum Nacharbeiten",
    "text": "11.29 Zum Nacharbeiten\nKutner u. a. (2005, p.313–319) \n\n\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "mlm_hierarchies.html#einfaches-modell",
    "href": "mlm_hierarchies.html#einfaches-modell",
    "title": "12  Modellhierarchien",
    "section": "12.1 Einfaches Modell",
    "text": "12.1 Einfaches Modell\n\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n\n\nCall:\nlm(formula = y ~ x, data = simple)\n\nResiduals:\n      1       2       3       4 \n-0.5817  0.9898 -0.2345 -0.1736 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.8414     0.7008   2.628    0.119\nx             0.4574     0.3746   1.221    0.346\n\nResidual standard error: 0.8376 on 2 degrees of freedom\nMultiple R-squared:  0.4271,    Adjusted R-squared:  0.1406 \nF-statistic: 1.491 on 1 and 2 DF,  p-value: 0.3465"
  },
  {
    "objectID": "mlm_hierarchies.html#einfaches-modell-1",
    "href": "mlm_hierarchies.html#einfaches-modell-1",
    "title": "12  Modellhierarchien",
    "section": "12.2 Einfaches Modell",
    "text": "12.2 Einfaches Modell\n\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n\n\nCall:\nlm(formula = y ~ x, data = simple)\n\nResiduals:\n      1       2       3       4 \n-0.5817  0.9898 -0.2345 -0.1736 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.8414     0.7008   2.628    0.119\nx             0.4574     0.3746   1.221    0.346\n\nResidual standard error: 0.8376 on 2 degrees of freedom\nMultiple R-squared:  0.4271,    Adjusted R-squared:  0.1406 \nF-statistic: 1.491 on 1 and 2 DF,  p-value: 0.3465"
  },
  {
    "objectID": "mlm_hierarchies.html#abweichungen-noch-mal",
    "href": "mlm_hierarchies.html#abweichungen-noch-mal",
    "title": "12  Modellhierarchien",
    "section": "12.3 Abweichungen … noch mal",
    "text": "12.3 Abweichungen … noch mal\n\n12.3.1 Sum of squares of error\n\\[\nSSE = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n\\]\nTypischerweise beinhaltet ein Modell zum berechnen der \\(\\hat{y}_i\\) verschiedene Parameter. Bei der einfachen Regression zum Beispiel \\(\\beta_0\\) und \\(\\beta_1\\) (#Modellparameter \\(p\\) = 2) .\n\n\n12.3.2 Freiheitsgrade (degrees of freedom) von SSE\n\\[\ndfE := n - p\n\\]\nDie effektive Anzahl der Beobachtungen um die Varianz \\(\\sigma^2\\) abzuschätzen."
  },
  {
    "objectID": "mlm_hierarchies.html#mse-als-schätzer-für-sigma2",
    "href": "mlm_hierarchies.html#mse-als-schätzer-für-sigma2",
    "title": "12  Modellhierarchien",
    "section": "12.4 MSE als Schätzer für \\(\\sigma^2\\)",
    "text": "12.4 MSE als Schätzer für \\(\\sigma^2\\)\n\n12.4.1 Mean squared error MSE\n\\[\nMSE = \\frac{SSE}{dfE} = \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{n-p}\n\\]\nAls Schätzer \\(\\hat{\\sigma}^2\\) für \\(\\sigma^2\\) aus \\(\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\)\n\n\n12.4.2 Parallel zur Berechnung der Stichprobenvarianz\n\\[\n\\hat{\\sigma}^2 = s^2 = \\frac{1}{n-1}\\sum_{i=1}^2(y_i - \\bar{y})^2\n\\]\nwo \\(s^2\\) ein Schätzer für die Varianz von \\(y\\) ist."
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz",
    "title": "12  Modellhierarchien",
    "section": "12.5 Genereller Linearer Modell Testansatz1",
    "text": "12.5 Genereller Linearer Modell Testansatz1\n\n12.5.1 Idee\nWir bauen uns eine Teststatistik die die Verbesserung in der Vorhersage (\\(=\\) Reduktion der Fehlervarianz) als Metrik verwendet. Modelle werden in eine Hierarchie gesetzt mit einfacheren Modellen untergeordnet zu komplexeren Modellen.\n\n\n12.5.2 Leitfrage:\nBringt mir die Aufnahme Modellparameter eine in der Vorhersage von Y bzw. bezüglich der Aufklärung der Varianz in Y?"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---full-model",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---full-model",
    "title": "12  Modellhierarchien",
    "section": "12.6 Genereller Linearer Modell Testansatz - Full model",
    "text": "12.6 Genereller Linearer Modell Testansatz - Full model\nBeispiel einfache lineare Regression\n\n12.6.1 Volles Modell\n\\[\nY_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\n\\]\n\n\n12.6.2 Residualvarianz SSE(F)\n\\[\n\\textrm{SSE(F)}  = \\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = \\sum_{i=1}^n [y_i - (\\beta_0 + \\beta_1 x_i)]^2\n\\]\nmit \\(p = 2, dfE(F) = n - 2\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---reduced-model",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---reduced-model",
    "title": "12  Modellhierarchien",
    "section": "12.7 Genereller Linearer Modell Testansatz - Reduced model",
    "text": "12.7 Genereller Linearer Modell Testansatz - Reduced model\n\n12.7.1 Reduziertes Modell\n\\[\nY_i = \\beta_0 + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\n\\]\n\n\n12.7.2 Residualvarianz SSE(R)\n\\[\n\\textrm{SSE(R)} = \\sum_{i=1}^n (y_i - \\beta_0)^2 = \\sum_{i=1}^n(y_i - \\bar{y})^2 = \\textrm{SSTO}\n\\]\nmit \\(p = 1, dfE(R) = n - 1\\)\nIm Allgemeinen gilt: \\(SSE(F) \\leq SSE(R)\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#link-reduziertes-modell-und-stichprobenvarianz",
    "href": "mlm_hierarchies.html#link-reduziertes-modell-und-stichprobenvarianz",
    "title": "12  Modellhierarchien",
    "section": "12.8 Link: Reduziertes Modell und Stichprobenvarianz",
    "text": "12.8 Link: Reduziertes Modell und Stichprobenvarianz\n\\[\\begin{align*}\nSSE &= \\sum_{i=1}^n(y_i - \\beta_0)^2 = \\sum_{i=1}^n (y_i^2 - 2y_i\\beta_0 + \\beta_0^2) \\\\\n0 &= \\frac{\\mathrm{d}}{\\mathrm{d} \\beta_0}\\sum_{i=1}^n (y_i^2 - 2y_i\\beta_0 + \\beta_0^2) \\\\\n0 &= \\sum_{i=1}^n (-2y_i + 2 \\beta_0) = -2\\sum_{i=1}^n y_i + 2\\sum_{i=1}^n \\beta_0\\\\\nn\\beta_0 &= \\sum_{i=1}^n y_i \\\\\n\\beta_0 &= \\frac{\\sum_{i=1}^n y_i}{n} = \\bar{y} \\rightarrow \\frac{SSE}{n-1} = \\hat{\\sigma}^2 = s^2\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz-1",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz-1",
    "title": "12  Modellhierarchien",
    "section": "12.9 Genereller Linearer Modell Testansatz",
    "text": "12.9 Genereller Linearer Modell Testansatz\nAnnahme: Das reduzierte Modell ist korrekt. Dann sollte \\[\n\\textrm{SSE(R)} - \\textrm{SSE(F)}\n\\] eher klein sein (Beide Modelle haben einen gleich guten fit).\nAnnahme: Das reduzierte Modell ist falsch: Dann sollte \\[\n\\textrm{SSE(R)} - \\textrm{SSE(F)}\n\\] eher groß sein (Das reduzierte Modell kann die Daten nicht so gut fitten wie das komplizierte Modell)"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---teststatistik",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---teststatistik",
    "title": "12  Modellhierarchien",
    "section": "12.10 Genereller Linearer Modell Testansatz - Teststatistik",
    "text": "12.10 Genereller Linearer Modell Testansatz - Teststatistik\nWenn das reduzierte Modell korrekt ist, dann lässt sich zeigen, dass: \\[\nMS_{\\textrm{test}} = \\frac{\\textrm{SSE(R)} - \\textrm{SSE(F)}}{\\textrm{dfE(R)} - \\textrm{dfE(F)}}\n\\] ein Schätzer für die Varianz \\(\\sigma^2\\) (\\(\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\)) ist.\nWenn das reduzierte Modell korrekt ist, dann ist auch das volle Modell korrekt. Daher ist dann:\n\\[\n\\textrm{MSE(F)} = \\frac{\\textrm{SSE(F)}}{\\textrm{dfE(F)}}\n\\] auch ein Schätzer für \\(\\sigma^2\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#f-wert-als-teststatistik",
    "href": "mlm_hierarchies.html#f-wert-als-teststatistik",
    "title": "12  Modellhierarchien",
    "section": "12.11 F-Wert als Teststatistik",
    "text": "12.11 F-Wert als Teststatistik\n\\[\nF = \\frac{MS_{\\textrm{test}}}{MSE(F)}= \\frac{\\frac{\\textrm{SSE(R)} - \\textrm{SSE(F)}}{\\textrm{dfE(R)} - \\textrm{dfE(F)}}}{ \\frac{\\textrm{SSE(F)}}{\\textrm{dfE(F)}}}\n\\]"
  },
  {
    "objectID": "mlm_hierarchies.html#verteilung-der-f-statistik",
    "href": "mlm_hierarchies.html#verteilung-der-f-statistik",
    "title": "12  Modellhierarchien",
    "section": "12.12 Verteilung der F-Statistik",
    "text": "12.12 Verteilung der F-Statistik\n\\[\nF = \\frac{MS_{\\textrm{test}}}{MSE(F)}  \\sim F(\\textrm{dfE(R)}-\\textrm{dfE(F)},\\textrm{dfE(F)})\n\\]\n\n\n\n\n\nBeispiele für die F-Verteilung mit verschiedenen Freiheitsgraden \\(df_1, df_2\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#hypothesentest-mit-f-wert",
    "href": "mlm_hierarchies.html#hypothesentest-mit-f-wert",
    "title": "12  Modellhierarchien",
    "section": "12.13 Hypothesentest mit F-Wert",
    "text": "12.13 Hypothesentest mit F-Wert\n\n\n\n\n\nF-Verteilung mit \\(df_1 = 5, df_2 = 10\\) und kritischem Wert bei \\(\\alpha=0.05\\)\n\n\n\n\n2"
  },
  {
    "objectID": "mlm_hierarchies.html#teilziel",
    "href": "mlm_hierarchies.html#teilziel",
    "title": "12  Modellhierarchien",
    "section": "12.14 Teilziel",
    "text": "12.14 Teilziel\n\nDurch den Vergleich von Modellen kann die Verbesserung/Verschlechterung der Modellvorhersage statistisch Überprüft werden\nAlternativ: Brauchen ich zusätzliche Parameter oder reicht mir das einfache Modell?"
  },
  {
    "objectID": "mlm_hierarchies.html#beispiel-candy-problem",
    "href": "mlm_hierarchies.html#beispiel-candy-problem",
    "title": "12  Modellhierarchien",
    "section": "12.15 Beispiel: Candy-Problem",
    "text": "12.15 Beispiel: Candy-Problem\n\n\n\n\n\nZusammenhang zwischen der Präferenz für ein Bonbon und dem Süßgrad für verschiedene Weichheitsgrade"
  },
  {
    "objectID": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen",
    "href": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen",
    "title": "12  Modellhierarchien",
    "section": "12.16 Modelle als Hierarchien auffassen",
    "text": "12.16 Modelle als Hierarchien auffassen\n\n12.16.1 Full model\n\\[\ny_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i}x_{2i} + \\epsilon_i\n\\]\n\n\n12.16.2 Hierarchie\n\\[\\begin{align*}\nm_0&: y_i = \\beta_0 + \\epsilon_i \\\\\nm_1&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i \\\\\nm_2&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i \\\\\nm_3&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i}x_{2i} + \\epsilon_i\n\\end{align*}\\]\nEs gilt: \\(m_0 \\subseteq m_1 \\subseteq m_2 \\subseteq m_3\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen-in-r",
    "href": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen-in-r",
    "title": "12  Modellhierarchien",
    "section": "12.17 Modelle als Hierarchien auffassen in R",
    "text": "12.17 Modelle als Hierarchien auffassen in R\nIn R:\n\nmod_0 <- lm(like ~ 1, candy)\nmod_1 <- lm(like ~ sweetness, candy)\nmod_2 <- lm(like ~ sweetness + moisture, candy)\nmod_3 <- lm(like ~ sweetness * moisture, candy)"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-m_0-gegen-m_1",
    "href": "mlm_hierarchies.html#vergleich-m_0-gegen-m_1",
    "title": "12  Modellhierarchien",
    "section": "12.18 Vergleich \\(m_0\\) gegen \\(m_1\\)",
    "text": "12.18 Vergleich \\(m_0\\) gegen \\(m_1\\)\n\\[\\begin{align*}\nm_0: y_i &= \\beta_0 + \\epsilon_i \\\\\nm_1: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_0, mod_1)\n\n\n\n\nVergleich der Modellfits\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ 1\n77\n\n\n\n\n\n\nModel 2: like ~ sweetness\n76\n1\n20398.79\n38.73\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-m_1-gegen-m_2",
    "href": "mlm_hierarchies.html#vergleich-m_1-gegen-m_2",
    "title": "12  Modellhierarchien",
    "section": "12.19 Vergleich \\(m_1\\) gegen \\(m_2\\)",
    "text": "12.19 Vergleich \\(m_1\\) gegen \\(m_2\\)\n\\[\\begin{align*}\nm_1: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i \\\\\nm_2: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_1, mod_2)\n\n\n\n\nVergleich der Modellfits\n\n\n\n\n\n\n\n\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ sweetness\n76\n\n\n\n\n\n\nModel 2: like ~ sweetness + moisture\n75\n1\n31508.98\n277.3\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-m_2-gegen-full-model-m_3",
    "href": "mlm_hierarchies.html#vergleich-m_2-gegen-full-model-m_3",
    "title": "12  Modellhierarchien",
    "section": "12.20 Vergleich \\(m_2\\) gegen full model \\(m_3\\)",
    "text": "12.20 Vergleich \\(m_2\\) gegen full model \\(m_3\\)\n\\[\\begin{align*}\nm_2: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i  \\\\\nm_3: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i} x_{2i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_2, mod_3)\n\n\n\n\nVergleich der Modellfits\n\n\n\n\n\n\n\n\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ sweetness + moisture\n75\n\n\n\n\n\n\nModel 2: like ~ sweetness * moisture\n74\n1\n8235.7\n2127.22\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-full-model-m_3-gegen-minmales-modell-m_0",
    "href": "mlm_hierarchies.html#vergleich-full-model-m_3-gegen-minmales-modell-m_0",
    "title": "12  Modellhierarchien",
    "section": "12.21 Vergleich full model \\(m_3\\) gegen minmales Modell \\(m_0\\)",
    "text": "12.21 Vergleich full model \\(m_3\\) gegen minmales Modell \\(m_0\\)\n\\[\\begin{align*}\nm_0: y_i &= \\beta_0 + \\epsilon_i  \\\\\nm_3: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i} x_{2i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_0, mod_3)\n\n\n\n\nVergleich der Modellfits\n\n\n\n\n\n\n\n\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ 1\n77\n\n\n\n\n\n\nModel 2: like ~ sweetness * moisture\n74\n3\n60143.47\n5178.21\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#in-summary-m_3-gegen-m_0",
    "href": "mlm_hierarchies.html#in-summary-m_3-gegen-m_0",
    "title": "12  Modellhierarchien",
    "section": "12.22 In summary() \\(m_3\\) gegen \\(m_0\\)",
    "text": "12.22 In summary() \\(m_3\\) gegen \\(m_0\\)\n\n\n\nCall:\nlm(formula = like ~ sweetness * moisture, data = candy)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.6086 -1.3320 -0.1377  1.4379  4.0998 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(>|t|)    \n(Intercept)         2.728341   0.999909   2.729  0.00794 ** \nsweetness          -0.017103   0.052033  -0.329  0.74331    \nmoisture           -0.033573   0.067747  -0.496  0.62167    \nsweetness:moisture  0.164768   0.003572  46.122  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.968 on 74 degrees of freedom\nMultiple R-squared:  0.9953,    Adjusted R-squared:  0.9951 \nF-statistic:  5178 on 3 and 74 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "mlm_hierarchies.html#eine-nominale-variable-mit-vier-stufen",
    "href": "mlm_hierarchies.html#eine-nominale-variable-mit-vier-stufen",
    "title": "12  Modellhierarchien",
    "section": "12.23 Eine nominale Variable mit vier Stufen",
    "text": "12.23 Eine nominale Variable mit vier Stufen\n\n\n\n\n\nEin Reaktionszeitexperiment mit vier Stufen A, B, C und D"
  },
  {
    "objectID": "mlm_hierarchies.html#früher---analysis-of-variance-anova-bzw.-aov",
    "href": "mlm_hierarchies.html#früher---analysis-of-variance-anova-bzw.-aov",
    "title": "12  Modellhierarchien",
    "section": "12.24 Früher - Analysis of Variance (ANOVA bzw. AOV)",
    "text": "12.24 Früher - Analysis of Variance (ANOVA bzw. AOV)\n\\[\\begin{align*}\ns_{zwischen}^2 &= \\frac{1}{K-1}\\sum_{j=1}^K N_j (\\bar{x}_{j.}-\\bar{x})^2 \\\\\ns_{innerhalb}^2 &= \\frac{1}{N-K}\\sum_{j=1}^K\\sum_{i=1}^{N_j}(x_{ji}-\\bar{x}_{j.})^2 = \\frac{1}{N-K}\\sum_{j=1}^K(N_j-1)s_j^2 \\\\\nF &= \\frac{\\hat{\\sigma}_{zwischen}^2} {\\hat{\\sigma}_{innerhalb}^2} \\sim F(K-1,N-K)\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_hierarchies.html#anova-in-r",
    "href": "mlm_hierarchies.html#anova-in-r",
    "title": "12  Modellhierarchien",
    "section": "12.25 ANOVA in R",
    "text": "12.25 ANOVA in R\n\nmod_aov <- aov(rt ~ group, rt_tbl)\nsummary(mod_aov)\n\n\n\n\nAusgabe mit aov()\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\ngroup\n3\n988935.1\n329645\n157.3\n0\n\n\nResiduals\n76\n159221.0\n2095"
  },
  {
    "objectID": "mlm_hierarchies.html#ansatz-mittels-modellhierarchien",
    "href": "mlm_hierarchies.html#ansatz-mittels-modellhierarchien",
    "title": "12  Modellhierarchien",
    "section": "12.26 Ansatz mittels Modellhierarchien",
    "text": "12.26 Ansatz mittels Modellhierarchien\n\n12.26.1 Full model\n\\[\ny_i = \\beta_0 + \\beta_{\\Delta_{B-A}} x_1 + \\beta_{\\Delta_{C-A}} x_2 + \\beta_{\\Delta_{D-A}} x_3 + \\epsilon_i\n\\]\n\n\n12.26.2 Reduced model\n\\[\ny_i = \\beta_0 + \\epsilon_i\n\\]\nWenn das reduced model die Daten gleich gut fittet wie das full model \\(\\Rightarrow\\) Information über das Treatment verbessert meine Vorhersage von \\(y_i\\) nicht."
  },
  {
    "objectID": "mlm_hierarchies.html#model-fit---full-model",
    "href": "mlm_hierarchies.html#model-fit---full-model",
    "title": "12  Modellhierarchien",
    "section": "12.27 Model fit - Full model",
    "text": "12.27 Model fit - Full model\n\nmod <- lm(rt ~ group, rt_tbl)\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n509.526\n10.235\n49.784\n<0.001\n\n\ngroupB\n90.150\n14.474\n6.228\n<0.001\n\n\ngroupC\n197.414\n14.474\n13.639\n<0.001\n\n\ngroupD\n295.561\n14.474\n20.420\n<0.001"
  },
  {
    "objectID": "mlm_hierarchies.html#anova-mit-nur-einem-modell",
    "href": "mlm_hierarchies.html#anova-mit-nur-einem-modell",
    "title": "12  Modellhierarchien",
    "section": "12.28 anova() mit nur einem Modell",
    "text": "12.28 anova() mit nur einem Modell\n\nanova(mod)\n\n\n\n\nÄquivalent zum Vergleich full gegen reduced model\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\ngroup\n3\n988935.1\n329645\n157.3\n0\n\n\nResiduals\n76\n159221.0\n2095"
  },
  {
    "objectID": "mlm_hierarchies.html#zum-nacharbeiten",
    "href": "mlm_hierarchies.html#zum-nacharbeiten",
    "title": "12  Modellhierarchien",
    "section": "12.29 Zum Nacharbeiten",
    "text": "12.29 Zum Nacharbeiten\nChristensen (2018, p.57–64) \n\n\n\n\nChristensen, Ronald. 2018. Analysis of variance, design, and regression: Linear modeling for unbalanced data. CRC Press.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Altman, Douglas G, and J Martin Bland. 1995. “Statistics Notes:\nAbsence of Evidence Is Not Evidence of Absence.” Bmj 311\n(7003): 485.\n\n\nAltman, Naomi, and Martin Krzywinski. 2015a. “Points of\nSignificance: Multiple Linear Regression.” Nature\nMethods 12 (12): 1103–4.\n\n\n———. 2015b. “Points of Significance: Simple Linear\nRegression.” Nature Methods 12 (11).\n\n\n———. 2016a. “Points of Significance: Analyzing Outliers:\nInfluential or Nuisance.” Nature Methods 13 (4): 281–82.\n\n\n———. 2016b. “Points of Significance: Regression\nDiagnostics.” Nature Methods 13 (5): 385–86.\n\n\nChristensen, Ronald. 2018. Analysis of Variance, Design, and\nRegression: Linear Modeling for Unbalanced Data. CRC Press.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. 2nd ed. Routledge.\n\n\nCumming, Geoff. 2013. Understanding the New Statistics: Effect\nSizes, Confidence Intervals, and Meta-Analysis. Routledge.\n\n\nDebanne, Thierry, and Guillaume Laffaye. 2011. “Predicting the\nThrowing Velocity of the Ball in Handball with Anthropometric Variables\nand Isotonic Tests.” Journal of Sports Sciences 29 (7):\n705–13.\n\n\nFox, John. 2011. An r Companion to Applied Regression. 2nd ed.\nSAGE Publication Inc., Thousand Oaks.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, and William Li.\n2005. Applied Linear Statistical Models. 5th ed. McGraw-Hill\nIrwin New York.\n\n\nMcElreath, Richard. 2016. Statistical Rethinking, a Bayesian Course\nwith Examples in r and Stan. 1st ed. Boca Raton: CRC Press.\n\n\nSpiegelhalter, David. 2019. The Art of Statistics: Learning from\nData. Penguin UK.\n\n\nWasserstein, Ronald L, and Nicole A Lazar. 2016. “The ASA\nStatement on p-Values: Context, Process, and Purpose.” Taylor\n& Francis.\n\n\nWild, Christopher J, and Georg AF Seber. 2000. Chance Encounters: A\nFirst Course in Data Analysis and Inference. Wiley Press.\n\n\nYoung, Alwyn. 2019. “Channeling Fisher: Randomization Tests and\nthe Statistical Insignificance of Seemingly Significant Experimental\nResults.” The Quarterly Journal of Economics 134 (2):\n557–98."
  }
]