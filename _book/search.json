[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Scriptum - Fortgeschrittene Statistik",
    "section": "",
    "text": "Vorwort\nDies ist das Skriptum für den Master-Statistikkurse Fortgeschrittene Statistik und ist die Vorlage für die Kurse LTC4 und SBG4. Es werden in den Kursen nicht alle Themen des Skriptums behandelt. Das Skriptum befindet sich derzeit noch in einem frühen Stadium, so dass die Inhalte noch nicht vollständig ausgearbeitet sind."
  },
  {
    "objectID": "stats_title.html",
    "href": "stats_title.html",
    "title": "Statistik",
    "section": "",
    "text": "Die erste Frage die sich im Umgang mit der Anwendung von Verfahren der Statistik stellt ist: Wofür benötigen wir Statistik überhaupt?\nBeispielsweise wurden ein Datensatz gesammelt, bei dem zwei Gruppen miteinander verglichen werden, eine Treatmentgruppe (TRT) und eine Kontrollgruppe (CON). In beiden Gruppen wurden jeweils \\(N_i = 20\\) Personen untersucht. Es wurde das folgende Ergebnis erhalten (siehe Abbildung 1).\n\n\n\n\n\nAbbildung 1: Boxplot der Kontroll- und der Treatmentgruppe bezüglich einer abhängigen Variable\n\n\n\n\nOffensichtlich sind die Werte in der Treatmentgruppe deutlich höher als diejenigen in der Kontrollgruppe. Warum ist es nicht ausreichend das offensichtliche zu dokumentieren? Warum ist eine statistische Analyse der Daten notwendig?\nDiese Fragestellung wird in dem folgenden Abschnitt untersucht. Gleichzeitig werden die notwendigen Werkzeuge entwickelt um die verschiendenen Schritte die einer statistische Analyse von Daten zugrundeliegenen zu verstehen und anwenden zu können."
  },
  {
    "objectID": "stats_basics.html#ein-experiment",
    "href": "stats_basics.html#ein-experiment",
    "title": "1  Eine kleine Welt der Unsicherheit",
    "section": "1.1 Ein Experiment",
    "text": "1.1 Ein Experiment\nWir wollen nun eine Krafttrainingsstudie durchführen um die Beinkraft zu erhöhen. Wir haben allerdings nur sehr wenige Ressourcen (bzw. wir sind faul) und können insgesamt nur sechs Messungen durchführen. Aus einem kürzlich durchgeführten Census haben wir aber die Kraftwerte der ganzen Population. Wir stellen die Kraftwerte zunächst mittels einer Tabelle dar (siehe Tabelle 1.1)\n\n\n\n\nTabelle 1.1: Kraftwerte (in Newton) der Lummerländer an der einbeinigen Beinpresse\n\n\nID\nKraft[N]\nID\nKraft[N]\n\n\n\n\nP01\n2414\nP11\n2243\n\n\nP02\n2462\nP12\n2497\n\n\nP03\n2178\nP13\n1800\n\n\nP04\n2013\nP14\n2152\n\n\nP05\n2194\nP15\n2089\n\n\nP06\n2425\nP16\n2090\n\n\nP07\n2305\nP17\n3200\n\n\nP08\n2117\nP18\n2196\n\n\nP09\n2298\nP19\n2485\n\n\nP10\n2228\nP20\n2440\n\n\n\n\n\n\nSelbst bei 20 Werten ist diese Darstellung wenig übersichtlich. Wir könnten zwar Zeile für Zeile durchgehen und nach etwas notieren und suchen würden wir sehen das der Maximalwert bei \\(3200\\)N für P17 und der Minimalwert von Person P13 bei \\(1800\\)N liegt. Aber wirklich einfach ist diese Darstellung nicht. Für solche univariaten Daten (uni = eins) kann eine übersichtlichere Darstellung mittels eines sogenannten Dotplots erreicht werden (siehe Abbildung 1.2).\n\n\n\n\n\nAbbildung 1.2: Dotplot der Lummerlandkraftdaten\n\n\n\n\nHier kann deutlich schneller abgelesen werden was das Minimum und das Maximum der Daten ist, sowie es kann auch direkt abgeschätzt werden in welchem Bereich sich der Großteil der Daten befindet. Allerdings wird durch diese Art der Darstellung die Information über welche Person die jeweiligen Werte besitzt nicht mehr dargestellt. Dies stellt in den meisten Fällen allerdings kein Problem dar, da wir in den meisten Fällen aussagen über die Gruppe und weniger über einzelne Personen machen wollen.\nGehen wir jetzt von der folgenden Fragestellung aus. Wir wollen den Gesundheitsstatus unserer Lummerländer verbessern und wollen dazu ein Krafttraining durchführen. Da evidenzbasiert arbeiten wollen, möchten wir überprüfen ob wirklich ein Verbesserung der Kraft durch das Training stattgefunden hat. Da es sich aber gleichzeitig um unsere selbst geschaffene Welt handelt führen wir natürlich ein perfektes Krafttraining, eine perfekte Intervention, durch. D.h wir stellen uns immer wieder als unwissend da und geben vor das wir gar nicht wissen, das das Training perfekt effektiv ist.\nD.h. wir führen gleichzeitig ein Gedankenexperiment durch. Wir führen ein Krafttraining für die Beine durch. Das Training ist perfekt und verbessert die Kraftleistung um genau \\(+100\\)N. Dieser Kraftzuwachs unabhängig davon welche Person aus unserer Population das Training durchführt (Warum ist das keine realistische Annahme?). Wir wollen zwei Gruppen miteinander vergleichen eine Interventionsgruppe und eine Kontrollgruppe. In beiden Gruppen sollen jeweils \\(n_{\\text{TRT}} = n_{\\text{CON}} = 3\\) TeilnehmerInnen bzw. Teilnehmer einbezogen werden da wir nicht mehr Ressourcen für mehr ProbandInnen haben.\nDie erste Frage die sich nun stellt ist wie wählen wir die sechs Personen aus unserer Population aus und wie teilen wir die sechs Personen in die beiden Gruppen? Nach etwas überlegen kommen wir darauf, dass wir am besten eine zufällige Stichprobe ziehen sollten (Warum?).\n\nDefinition 1.2 (Stichprobe) Eine Stichprobe ist eine Teilmenge der Objekte aus der Population.\n\n\nDefinition 1.3 (Zufallsstichprobe) Eine Zufallsstichprobe ist eine Teilmenge der Objekte aus der Population die zufällig ausgewählt wurde.\n\nDiese sechs Personen, unsere Stichprobe, wird dann wiederum zufällig auf die beiden Gruppen aufgeteilt.\n\n\n\nEin Zufallszahlengenerator hat die Zahlen \\(i = \\{3,7,8,9,10,20\\}\\) gezogen. Die entsprechenden Personen werden aus der Population ausgewählt und wiederum zufällig in die beiden Gruppen aufgeteilt (siehe Tabelle 1.2).\n\n\n\n\nTabelle 1.2: Zufällig ausgewählte Stichprobe der Kontrollgruppe (CON) und der Interventionsgruppe (TRT).\n\n\nID\nKraft[N]\nGruppe\n\n\n\n\nP08\n2117\nCON\n\n\nP09\n2298\nCON\n\n\nP03\n2178\nCON\n\n\nP07\n2305\nTRT\n\n\nP10\n2228\nTRT\n\n\nP20\n2440\nTRT\n\n\n\n\n\n\nMit diesen sechs Personen führen wir jetzt unser Experiment durch. Die drei Personen aus der Kontrollgruppe, unterlaufen im Interventionszeitraum nur ein Stretchtraining während die Interventionsgruppe zweimal die Woche für 12 Wochen unser perfektes Krafttraining durchführt. Nach diesem Zeitraum messen wir alle Personen aus beiden Gruppen und erhalten das folgende Ergebnis (siehe Tabelle 1.3).\n\n\nTabelle 1.3: Ergebnis der Intervention in Experiment 1 für die Kontroll- und die Interventionsgruppe.\n\n\n\n\n(a) Kontrollgruppe\n\n\nID\nKraft[N]\n\n\n\n\nP08\n2117\n\n\nP09\n2298\n\n\nP03\n2178\n\n\n\\(\\bar{K}\\)\n2198\n\n\n\n\n\n\n(b) Interventionsgruppe\n\n\nID\nKraft[N]\n\n\n\n\nP07\n2405\n\n\nP10\n2328\n\n\nP20\n2540\n\n\n\\(\\bar{K}\\)\n2424\n\n\n\n\n\n\nFür beide Gruppen ist jeweils der Mittelwert berechnet worden, um die Wert miteinander vergleichen zu können. Später werden wir noch weitere Maße kennenlernen die es ermöglichen zwei Mengen von Werten miteinander zu vergleichen.\n\nDefinition 1.4 (Mittelwert) Der Mittelwert über \\(n\\) Werte berechnet sich nach der Formel:\n\\[\n\\bar{x} = \\frac{\\sum_{i=1}^n x_i}{n}\n\\tag{1.1}\\]\nDer Mittelwert wird mit einem Strich über der Variable dargestellt.\n\nDamit lernen wir direkt auch ein neues Konzept kennen. Nämlich das der Statistik. Ein Wert der auf der erhobenen Stichprobe berechnet wird, wird als Statistik bezeichnet.\n\nDefinition 1.5 (Statistik) Ein auf einer Stichprobe berechnet Wert, wird als Statistik bezeichnet.\n\nUm jetzt Unterschied zwischen den beiden Gruppen zu untersuchen berechnen wir die Differenz D zwischen den beiden Mittelwerten \\(D = \\bar{K}_{\\text{TRT}} - \\bar{K}_{\\text{CON}}\\). Die Differenz kann natürlich auch in die andere Richtung berechnet werden und es würde sich das Vorzeichen ändern. Hier gibt es keine Vorgaben, sondern die Richtung kann frei bestimmt werden. Wenn bekannt ist in welcher Richtung der Unterschied berechnet wird, dann stellt dies keine Problem dar. Im vorliegenden Fall ziehen wir die Interventionsgruppe von der Kontrollgruppe ab, da wir davon ausgehen, dass die Intervention zu einer Krafterhöhung führt und wir dadurch einen positiven Unterschied erhalten (vgl. Gleichung 1.2)\n\n\n\n\\[\nD = 2424N - 2198N = 226 N\n\\tag{1.2}\\]\nDa der Wert D, wiederum auf den Daten der Stichprobe berechnet wird, handelt es sich ebenfalls um eine Statistik.\n\n\n\n\n\nAbbildung 1.3: Dotplot der beiden Stichproben. Senkrechte Striche zeigen die jeweiligen Mittelwerte an.\n\n\n\n\nIn Abbildung 1.3 sind die Werte der beiden Gruppen, deren Mittelwerte \\(\\bar{K}_{\\text{CON}}\\) und \\(\\bar{K}_{\\text{TRT}}\\) und der Unterschied \\(D\\) zwischen diesen abgebildet. Wie erwartet zeigt die Interventionsgruppen den höheren Kraftwert im Vergleich zu der Kontrollgruppe. Allerdings ist der Wert mit \\(D = 226\\) größer als der tatsächliche Zuwachs von \\(\\Delta_{\\text{Training}} = 100\\) (Warum ist das so?).\nDer Unterschied zwischen den beiden Gruppen ist natürlich auch zum Teil auf die Unterschiede die zwischen den beiden Gruppen vor der Intervention bestanden haben zurück zu führen. Was wäre denn passiert, wenn wir eine andere Stichprobe gezogen hätten?\n\n\n\nSei \\(i = \\{12,2,19,4,8,16\\}\\) eine zweite Stichprobe. Dies würde zu den folgenden Werten führen nach der Intervention führen.\n\n\n\n\nTabelle 1.4: Ergebnis der Intervention in Experiment 2 für die Kontroll- und die Interventionsgruppe.\n\n\nID\nKraft[N]\nGruppe\n\n\n\n\nP08\n2117\nCON\n\n\nP09\n2298\nCON\n\n\nP03\n2178\nCON\n\n\nP07\n2405\nTRT\n\n\nP10\n2328\nTRT\n\n\nP20\n2540\nTRT\n\n\n\n\n\n\n\n\n\n\n\nAbbildung 1.4: Dotplot der beiden Stichproben in Experiment 2. Senkrechte Striche zeigen die jeweiligen Mittelwerte an.\n\n\n\n\nIn Abbildung 1.4 sind wiederum die Datenpunkte, Mittelwerte und der Unterschied abgetragen. In diesem Fall ist allerdings die Differenz zwischen den beiden Gruppen genau in der anderen Richtung \\(D = -308\\), so dass die Interpretation des Ergebnisses genau in der anderen Richtung wäre. Nämlich, nicht nur hat das Krafttraining zu keiner Verbesserung in der Kraftfähigkeit geführt, sondern zu einer Verschlechterung!\n\n\n\nEs hätte aber auch sein können, das wir noch eine andere Stichprobe gezogen hätten, z.B. \\(i = \\{6,5,7,20,14,16\\}\\). Dies würde zu dem folgenden Ergebnis führen (siehe Tabelle 1.5).\n\n\n\n\nTabelle 1.5: Mittelwertsdaten aus Experiment 3 und der Unterschied \\(D\\) zwischen den beiden Gruppenmittelwerten\n\n\nGruppe\nKraft[N]\n\n\n\n\nCON\n2308\n\n\nTRT\n2327\n\n\n\\(D\\)\n19\n\n\n\n\n\n\nIn diesem Fall haben wird zwar wieder einen positiven Unterschied zwischen den beiden Gruppen in der zu erwartenden Richtung gefunden. Der Unterschied von \\(D = 19\\) ist allerdings deutlich kleiner als das tatsächlichen \\(\\Delta = 100\\). Daher würden wir möglicherweise das Ergebnis so interpretieren, führen, dass wir das Krafttraining als ineffektiv bewerten würden und keine Empfehlung ausprechen.\nZusammengenommen, ist keines der Ergebnisse 100% korrekt. Entweder der Unterschied zwischen den beiden Gruppen ist deutlich zu groß, oder in der anderen Richtung oder deutlich zu klein. Das Ergebnis des Experiments hängt ursächlich damit zusammen, welche Stichprobe gezogen wird. Diese Einsicht gilt in jedem Fall generell für jedes Ergebnis eines Experiments.\nDas Phänomen, das der Wert der berechneten Statistik zwischen Wiederholungen des Experiments schwankt wird als Stichprobenvariabilität bezeichnet.\n\nDefinition 1.6 (Stichprobenvariabilität) Durch die Anwendung von Zufallsstichproben, variiert eine auf den Daten berechnete Statistik. Die Variabilität wird als Stichprobenvariabilität bezeichnet.\n\nStreng genommen, führt die Stichprobenvariabilität für sich genommen noch nicht dazu, das sich die Statistik zwischen Wiederholungen des Experiments verändert, sondern die zu untersuchenden Werte in der Population müssen selbst auch noch eine Streuung aufweisen. Wenn wir eine Population untersuchen würden, bei der alle Personen die gleiche Beinkraft hätten, würden unterschiedliche Stichproben immer den gleichen Mittelwert haben und wiederholte Durchführung des Experiment würden immer wieder zu dem selben Ergebnis führen. Dieser Fall ist in der Realität aber praktisch nie gegeben und sämtlich Parameter für die wir uns hier interessieren zeigen immer eine natürlich Streuung in der Population. Diese Streuung in der Population führt daher zu dem besagten Ergebnis, das das gleiche Experiment mehrmals wiederholt zu unterschiedlichen Zufallsstichproben führt und dementsprechend immer zu unterschiedlichen Ergebnissen führt.\nDaher ist eine der zentrale Aufgabe der Statistik mit dieser Variabilität umzugehen und die Forscherin trotzdem in die Lage zu versetzen rationale Entscheidungen zu treffen. Eine implizite Kernannahme dabei ist, das wir mit Hilfe von Daten überhaupt etwas über die Welt lernen können. D.h. das uns die Erhebung von Daten überhaupt auch in die Lage versetzt rationale Entscheidungen zu treffen. Entscheidungen wie ein spezialisiertes Krafttraining mit einer klinischen Population durchzführen oder eine bestimmte taktische Variante mit meiner Mannschaft zu trainieren um die Gegner besser auszuspielen. Alle diese Entscheidungen sollten rational vor dem Hintergrund von Variabilität getroffen werden und auch möglichst oft korrekte Entscheidungen zu treffen. Wie wir sehen werden, kann uns die Statistik leider nicht garantieren immer die korrekte Entscheidungen zu treffen. Nochmal auf den Punkt gebracht nach Wild und Seber (2000, p.28)\n\nThe subject matter of statistics is the process of finding out more about the real world by collecting and then making sense of data.\n\nUntersuchen wir jedoch zunächst unsere Einsicht, das Wiederholungen des gleichen Experiments zu unterschiedlichen Ergebnissen führt, weiter. In unserem Beispiel aus Lummerland haben wir nämlich den Vorteil, das uns die Wahrheit bekannt ist. In Abbildung 1.5 ist die Verteilung unsere bisheringen drei \\(D\\)s abgetragen.\n\n\n\n\n\nAbbildung 1.5: Bisherige Verteilung der Unterschiede \\(D\\)\n\n\n\n\nDie drei Werte liegen ja relativ weiter auseiander. Eien Anschlussfrage könnte jetzt sein: “Welche weiteren Werte sind denn überhaupt möglich mit der vorliegenden Population?”."
  },
  {
    "objectID": "stats_basics.html#die-stichprobenverteilung",
    "href": "stats_basics.html#die-stichprobenverteilung",
    "title": "1  Eine kleine Welt der Unsicherheit",
    "section": "1.2 Die Stichprobenverteilung",
    "text": "1.2 Die Stichprobenverteilung\nWir können jetzt ja einfach mal das Experiment anfangen zu wiederholen. In Abbildung 1.6 sind mal 15 verschiedene Stichproben abgetragen. Wir haben in jeder Zeile jeweils sechs TeilnehmerInnen gezogen. Drei für die Kontrollgruppe und drei für die Inervationsgruppe. Für jede dieser Zeilen können wir jeweils den Gruppenmittelwert berechnen und den Unterschied \\(D\\) bestimmen.\n\n\n\n\n\nAbbildung 1.6: Beispiele für verschiedene Möglichkeiten zwei Stichproben mit jeweils \\(n_i = 3\\) aus der Population zu ziehen\n\n\n\n\nWarum eigentlich bei 15 aufhören. Wir haben ja den Vorteil, das unsere Population relativ übersichtlich ist. Vielleicht können wir uns ja noch aus unserer Schulezeit an Kombinatorik erinnern. Da haben wir den Binomialkoeffizienten kennengelernt. Die Anzahl der möglichken Kombination von \\(k\\) Elementen aus einer Menge von \\(n\\) Elementen berechnet sich nach:\n\\[\n\\text{Anzahl} = \\binom{n}{k} = \\frac{n!}{k!(n-k)!}\n\\tag{1.3}\\]\nIn unserem Fall wollen wir zunächst sechs Elemente aus \\(N = 20\\) auswählen und dann drei Elemente aus den sechs gezogenen Elementen auswählen um diese entweder der Interventionsgruppe oder der Kontrollgruppe zu zuweisen (Warum brauchen wir uns nur eine Gruppe anzuschauen?). Die Anzahl der möglichen Stichprobenkombinationen ist folglich:\n\n\n\n\\[\n\\text{Anzahl} = \\binom{20}{6}\\binom{6}{3} = 7.752\\times 10^{5}\n\\tag{1.4}\\]\nDas sind jetzt natürlich selbst bei dieser kleinen Population ein große Menge von einzelnen Experimenten, aber dafür sind Computer da, die können alle diese Experiment in kurzer Zeit durchführen. In Abbildung 1.7 ist die Verteilung aller möglichen Experimentausgänge, d.h. alle Differenzen \\(D\\) zwischen der Interventions- und der Kontrollgruppe, abgebildet.\n\n\n\n\n\nAbbildung 1.7: Verteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe bei einer Intervention mit \\(\\Delta = 100\\) (im Graphen mittels der roten Linie angezeigt).\n\n\n\n\nAuf der x-Achse sind die möglichen Differenzen \\(D\\) abgetragen, während auf der y-Achse die relative Häufigkeit, d.h. die Häufigkeit für einen bestimmten \\(D\\)-Wert geteilt durch die Anzahl \\(7.752\\times 10^{5}\\) aller möglichen Werte. Die Verteilung der D’s wird als Stichprobenverteilung bezeichnet.\n\nDefinition 1.7 Die Stichprobenverteilung kennzeichnet die Verteilung der beobachteten Statistik.\n\nDie Abbildung 1.7 zeigt, dass die überwiegende Anzahl der Ausgänge tatsächlich auch im Bereich von \\(\\Delta = 100\\) liegen. Noch präziser das Maximum der Verteilung, also die höchste relative Häufigkeit liegt genau auf der roten Linie. Dies sollte uns etwas beruhigen, denn es zeigt, das unsere Art der Herangehensweise mittels zweier Stichproben auch tatsächlich in den meisten Fällen einen nahezu korrekten Wert ermittelt. Allerdings zeigt die Stichprobenverteilung auch das Werte am rechten Ende die deutlich zu hoch sind wie auch Werte am linken Ende der Verteilung die deutlich in der falschen Richtung möglich sind. Das bedeutet, wenn wir das Experiment nur einmal durchführen wir uns eigentlich nie sich sein können, welches dieser vielen Experimente wir durchgeführt haben. Es ist zwar warscheinlicher, dass wir eins aus der Mitte der Verteilung durchgeführt haben, einfach da die Anzahl größer ist, aber wir haben keine 100% Versicherung, das wir nicht Pech gehabt haben und das Experiment ganz links mit \\(D = -500\\) oder aber das Experiment ganz rechts mit \\(D = 700\\) durchgeführt haben. Diese Unsicherheit wird leider keine Art von Experiment vollständig auflösen können. Eine weitere Eigenschaft der Verteilung ist ihre Symmetrie bezüglich des Maximums mit abnehmenden relativen Häufigkeiten umso weiter von Maximum \\(D\\) entfernt ist (Warum macht das heuristisch Sinn?).\nDie Darstellungsform von Abbildung 1.7 wird als Histogramm bezeichnet und eignet sich vor allem dazu die Verteilung einer Variablen z.B. \\(x\\) darzustellen. Dazu wird der Wertebereich von \\(x\\) zwischen dem Minimalwert \\(x_{\\text{min}}\\) und dem Maximalwert \\(x_{\\text{max}}\\) in \\(k\\) gleich große Intervalle unterteilt und die Anzahl der Werte innerhalb jedes Intervalls wird abgezählt und durch die Anzahl der Gesamtwerte geteilt um die relative Häufigkeit zu erhalten.\n\n\n\nZum Beispiel für die Werte:\n\\[\nx_i \\in \\{1,1.5,1.8,2.1,2.2,2.7,2.8,3.5,4 \\}\n\\] könnte das Histogram ermittelt werden, indem der Bereich von \\(x_{\\text{min}} = 1\\) bis \\(x_{\\text{max}} = 4\\) in vier Intervalle unterteilt wird und dann die Anzahl der Werte in den jewiligen Intervallen ermittelt wird (siehe Abbildung 1.8). Die ermittelte Anzahl würde dann noch durch die Gesamtanzahl \\(9\\) der Elemente geteilt um die relative Häufigkeit zu berechnen.\n\n\n\n\n\nAbbildung 1.8: Beispiel für die Darstellung eines Histogramms für die Daten \\(x_i\\).\n\n\n\n\nDie Form des Histogramms hängt davon ab wie viele Intervalle verwendet werden, so wird die Auflösung mit mehr Intervallen besser, aber es die Anzahl wird geringer und andersherum wird die Auflösung mit weniger Intervallen geringer aber die Anzahl der Elemente pro Intervall wird größer und somit stabiler. Daher sollte in den meisten praktischen Fällen die Anzahl variiert werden um sicher zu gehen, das nicht nur zufällig eine spezielle Darstellung verwendet wird.\nZurück zu unserer Verteilung von \\(D\\) unter \\(\\Delta = 100\\)N in Abbildung 1.7. Wie schon besprochen sind alle Werte zwischen etwa \\(D = -500N\\) und \\(D = 700\\)N plausibel bzw. möglich. Schauen wir uns doch einmal an, was passiert wenn das Training überhaupt nichts bringen würde und es keine Verbesserung gibt, also \\(\\Delta = 0\\).\n\n\n\n\n\nAbbildung 1.9: Verteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe wenn \\(\\Delta = 0\\) (rote Linie).\n\n\n\n\nDie Verteilung in Abbildung 1.9 sieht praktisch genau gleich aus, wie diejenige für \\(\\Delta = 100\\). Der einzige Unterschied ist lediglich das sie nach links verschoben ist und zwar scheinbar genau um die \\(100\\)N Unterschied zwischen den beiden \\(\\Delta\\)s. Dies ist letztendlich auch nicht weiter verwunderlich, bei der Berechnung des Unterschied \\(D\\) zwischen den beiden Gruppen kommen in beiden Fällen genau die gleichen Kombination vor. Bei \\(\\Delta = 100\\) wird aber zu der Interventionsgruppe das \\(\\Delta\\) dazuaddiert bevor die Differenz der Mittelwerte berechnet wird. Da aber gilt:\n\\[\nD = \\frac{1}{3}\\sum_{i=1}^3 x_{\\text{KON}i} - \\frac{1}{3}\\sum_{j=1}^3 (x_{\\text{TRT}j} + \\Delta) = \\bar{x}_{\\text{KON}} - \\bar{x}_{\\text{TRT}} + \\Delta\n\\]\nDaher bleibt die Form der Verteilung immer genau gleich und wird lediglich um den Wert \\(\\Delta\\) im Vergleich zur Nullintervention verschoben. Wobei mit Nullintervention Umgangssprachlich die Intervention bezeichnet, bei der nichts passiert also \\(\\Delta = 0\\) gilt."
  },
  {
    "objectID": "stats_basics.html#unsicherheit-in-lummerland",
    "href": "stats_basics.html#unsicherheit-in-lummerland",
    "title": "1  Eine kleine Welt der Unsicherheit",
    "section": "1.3 Unsicherheit in Lummerland",
    "text": "1.3 Unsicherheit in Lummerland\nDas führt jetzt aber zu einem Problem für uns. Gehen wir jetzt nämlich von diesen beiden Annahmen aus, das entweder die Intervention effektiv ist \\(\\Delta = 100\\) gilt oder das die Intervention nichts bringt also \\(\\Delta = 0\\) gilt. Wenn wir diese beiden Verteilungen übereinander legen erhalten wir Abbildung 1.10. Wir haben die Darstellung jetzt etwas verändert und eine Kurve durch die relativen Häufigkeiten gelegt. Dieser Graphen wird jetzt nicht mehr als Histogramm sondern als Dichtegraph bezeichnet.\n\n\n\n\n\nAbbildung 1.10: Verteilung aller möglichen Differenzen zwischen Kontroll- und Interventionsgruppe wenn \\(\\Delta = 0\\) und \\(\\Delta = 100\\).\n\n\n\n\nIn Abbildung 1.10 ist klar zu sehen, dass die beiden Graphen zu großen Teilen überlappen und dazu noch in einem Bereich wo beide Ergebnisse ihrer höchsten relativen Häufigkeiten, also auch die größte Wahrscheinlichkeit haben unter den jeweiligen Annahmen aufzutreten. Unser Problem besteht jetzt darin, dass wir in der Realität gar nicht diese Information haben welchen Effekt unser Training auf die Stichprobe ausführt. Wenn wir dies wüssten, dann müssten wir das Experiment ja gar nicht durchführen. Wir haben im Normalfall nur ein einziges Ergebnis, nämlich den Ausgang unseres einen Experiments.\n\n\n\n\n\nAbbildung 1.11: Zuweisung eines beobachteten Unterschieds \\(D\\) nach einem Experiment\n\n\n\n\nWenn wir jetzt unser Experiment einmal durchgeführt haben und ein einziges Ergebnis für \\(D\\) erhalten haben, sei zum Beispiel \\(D = 50\\) dann haben wir ein Zuweisungsproblem (siehe Abbildung 1.11). Wie weisen wir unser Ergebnis jetzt den beiden möglichen Realität zu? Einmal kann es sein, das das Krafttraining aber auch gar nichts gebracht hat und wir haben lediglich eine der vielen möglichen Stichprobenkombination beobachtet haben die zu einem positiven Wert für \\(D\\) führt. Oder aber das Krafttraining ist effektiv gewesen und hat zu einer Verbesserung von \\(\\Delta = 100\\)N geführt und wir haben lediglich ein Stichprobenkombination aus den vielen möglichen Stichprobenkombination gezogen die zu einem Ergebnis von \\(D = 50\\) führt. Noch mal, in der Realität wissen wir nicht welche der beiden Annahmen korrekt ist und können es auch nie vollständig wissen. Denn egal wie viele Experimente wir machen, wir können immer den zwar unwahrscheinlichen aber nicht unmöglichen Fall haben, das wir nur Werte beispielsweise aus dem linken Teil der Verteilung beobachten. Das heißt wir haben immer mit einer Ungewissheit zu kämpfen. Wir können nicht im Sinne eines Beweises zeigen, das das Training effektiv ist.\nDie Methoden der Statistik liefern uns nun Werkzeuge an die Hand um trotzdem rational zu Entscheiden welche der beiden Annahmen möglicherweise wahrscheinlicher ist. Gleichzeitig ermöglicht uns die Statistik abzuschätzen respektive zu berechnen wie groß die Unsicherheit in dieser Entscheidung ist. Die Statistik sagt dabei immer nur etwas über die beobachteten Daten aus. Die Statistik sagt jedoch nichts über die zugrundeliegenden wissenschaftlichen Theorien aus.\nSchauen wir uns jetzt als vorläufig letzten Punkt an welche Entscheidungsmöglichkeiten wir haben."
  },
  {
    "objectID": "stats_basics.html#eine-entscheidung-treffen",
    "href": "stats_basics.html#eine-entscheidung-treffen",
    "title": "1  Eine kleine Welt der Unsicherheit",
    "section": "1.4 Eine Entscheidung treffen",
    "text": "1.4 Eine Entscheidung treffen\nWir hatten im Beispiel zwei verschiedene Annahmen, einmal das das Training nichts bringt und keine Verbesserung der Kraftfähigkeit folgt \\(\\Delta = 0N\\). Andererseits hatten wir das Beispiel gestartet damit, dass die Kraftfähigkeit um \\(100N\\) zunimmt, also \\(\\Delta = 100N\\). Wie bezeichnen jetzt diese beiden Annahmen als Hypothesen und bezeichnen \\(\\Delta = 0N\\) als die Nullhypothese \\(H_0\\) und \\(\\Delta = 100N\\) als die Alternativhypothese \\(H_1\\).\nWenn wir jetzt das Experiment durchgeführt haben, können wir uns also entweder für die \\(H_0\\) oder die \\(H_1\\) entscheiden. Aus Gründen der Symmetrie ist dies gleichbedeutend wenn wir uns nur auf die \\(H_0\\) fokussieren und entweder die \\(H_0\\) annehmen bzw. beibehalten oder verwerfen also uns gegen \\(H_0\\) entscheiden.\n\n\n\n\nTabelle 1.6:  Entscheidungsmöglichkeiten wenn entweder H_0 oder H_{1} zutrifft. \n \n\n\nRealität\n\n  \n     \n    $H_0$ \n    $H_1$ \n  \n \n\n  \n    $H_0$ \n    korrekt \n    $\\beta$ \n  \n  \n    $H_1$ \n    $\\alpha$ \n    korrekt \n  \n\n\n\n\n\n\nIn Tabelle 1.6 sind die verschiedenen Entscheidungsmöglichkeiten abgetragen. In der Realität gehen wir, wie gesagt, von zwei Fällen aus. Entweder trifft die \\(H_0\\) oder die \\(H_1\\) zu. Wenn die \\(H_=\\) zutrifft und wir uns für die \\(H_0\\) entscheiden, dann haben wir eine korrekte Entscheidung getroffen. Wenn \\(H_0\\) zutrifft und wir allerdings die \\(H_0\\) ablehnen, also uns für die \\(H_1\\) entscheiden ist unsere Entscheidung falsch und wir begehen einen Fehler. Dieser Fehler wird als Fehler 1. Art bzw. \\(\\alpha\\)-Fehler bezeichnet. Trifft in der Realität dagegen die \\(H_1\\) zu und wir entscheiden uns gegen die \\(H_0\\) und für die \\(H_1\\), dann haben wir wiederum eine korrekte Entscheidung getroffen. Zuletzt, wenn die \\(H_1\\) zutrifft und wir uns aber für die \\(H_0\\) entscheiden, also die \\(H_0\\) beibehalten bzw. uns gegen die \\(H_1\\) entscheiden, treffen wir wieder eine falsche Entscheidung. Dieser Fehler wird als Fehler 2. Art, bzw. \\(\\beta\\)-Fehler bezeichnet.\n\nDefinition 1.8 Wenn eine Entscheidung gegen die \\(H_0\\) getroffen wird, obwohl die \\(H_0\\) korrekt ist, wird dies als \\(\\alpha\\)-Fehler bezeichnet.\n\n\nDefinition 1.9 Wenn eine Entscheidung gegen die \\(H_1\\) getroffen wird, obwohl die \\(H_1\\) korrekt ist, wird dies als \\(\\beta\\)-Fehler bezeichnet.\n\n\n\n\n\nWild, Christopher J, und Georg AF Seber. 2000. Chance encounters: A first course in data analysis and inference. Wiley Press."
  },
  {
    "objectID": "stats_significance.html",
    "href": "stats_significance.html",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "",
    "text": "3 Parameterschätzung"
  },
  {
    "objectID": "stats_significance.html#wie-treffe-ich-eine-entscheidung",
    "href": "stats_significance.html#wie-treffe-ich-eine-entscheidung",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.1 Wie treffe ich eine Entscheidung?",
    "text": "2.1 Wie treffe ich eine Entscheidung?\nIn unserem kleine Welt Bespiel waren wir in der komfortablen Position, das wir genau wussten was passiert bzw. welcher Prozess unseren beobachteten Datenpunkt erzeugt hat. D.h wir kannten den datengenerieren Prozesses.\n\nDefinition 2.1 (Datengenerierender Prozess (DGP)) Der Prozess in der realen Welt der die beobachteten Daten und damit die daraus folgende Statistik erzeugt wird als datengenerierender Prozess bezeichnet.\n\nLetztendlich zielt unsere Untersuchung, unser Experiment, darauf ab, Informationen über den DGP zu erhalten, weil diese Information uns erlaubt Aussagen über die reale Welt zu treffen. Dabei muss allerdings beachtet werden, dass dieser Prozess in den allermeisten Fällen ein starke Vereinfachung des tatsächlichen Prozesses in der Realität darstellt. Meistens sind die Abläufe in der Realität zu komplex um sie ins Gänze abzubilden. Somit wird fast immer nur ein Modell verwendet.\nZurück zu unseren Problem, wenn wir ein Experiment durchführen, dann haben wir normalerweise nur eine einzige beobachtete Statistik. In unseren bisherigen Beispiel also den berechneten Unterschied \\(D\\) in der Kraftfähigkeit nach der Intervention zwischen der Kontroll- und der Interventionsgruppe.\n\n\n\n\n\nAbbildung 2.1: Beobachteter Unterschied nach der Durchführung unseres Experiments\n\n\n\n\nIn Abbildung 2.1 ist der beobachtete Wert, \\(D = 50\\) abgetragen. Wir wissen von vorne herein, dass dieser Wert beeinflusst ist durch die zufällige Wahl der Stichprobe und die daran geknüpfte Streuung der Werte in der Population. Wie können wir den nun überhaupt eine Aussage treffen darüber, ob das Krafttraining was bringt oder vielleicht nur einen sehr kleinen Effekt zeigt oder möglicherweise sogar schädlich ist also zu einer Abnahme der Kraft führt?\nÜberlegen wir uns zunächst, welche Prozesse unseren beobachteten Wert zustande gebracht haben könnten. Wir haben schon zwei Prozesse kennengelernt, einmal den Prozess mit \\(\\Delta = 100\\) wie auch den Prozess mit \\(\\Delta = 0\\)\n\n\n\n\n\nAbbildung 2.2: Mögliche datengenerierende Prozesse für den beobachteten Unterschied \\(D\\) (rot)\n\n\n\n\nIn Abbildung 2.2 ist wieder unser beobachteter Wert \\(D = 50\\) und die beiden Verteilungen abgetragen. Leider können wir nicht eineindeutig sagen, welche der beiden Verteilungen, bzw. deren zugrundeliegende Prozesse, unseren beobachteten Wert erzeugt haben könnte. Da unser beobachteter Wert \\(D\\) genau zwischen den beiden Maxima der Verteilungen liegt. Etwas motiviertes Starren auf die Abbildung wird uns allerdings auf die Idee bringen, dass der beobachtete Wert nicht nur von diesen beiden Verteilungen erzeugt worden sein muss, sondern durchaus noch mehr Verteilungen in Frage kommen.\n\n\n\n\n\nAbbildung 2.3: Beispiele für weitere mögliche Verteilungen als DGP.\n\n\n\n\nAbbildung 2.3 zeigt, dass selbst die Verteilung mit \\(\\Delta = -250N\\) und \\(\\Delta = 350N\\) nicht unplausibel sind den beobachteten Wert erzeugt zu haben. Warum aber bei diesen fünf Verteilungen aufhören, warum sollte \\(Delta\\) nicht \\(-50\\) oder \\(127\\) sein. Und überhaupt, keiner kann behaupten die Natur kennt nur ganzzahlige Werte (siehe \\(\\pi\\)). Warum sollte \\(D\\) also nicht auch \\(123.4567N\\) sein?\nWenn diese Überlegung weitergeführt wird, dann wird schnell klar, dass letztendlich eine unendliche Anzahl von Verteilung in der Lage ist unseren beobachteten Wert plausibel zu generieren. D.h. wir haben ein Experiment durchgeführt und den ganzen Aufwand betrieben und haben wochenlang mit unseren ProbandInnen Krafttraining durchgeführt und sind hinterher eigentlich keinen Schritt weiter da wir immer noch nicht wissen was der datengenerierende Prozess ist. Also können wir selbst nach dem Experiment nicht sagen ob unser Krafttraining tatsächlich wirksam ist.\nZum Glück werden wir später sehen, das unser Unterfangen nicht ganz so aussichtslos ist. Schauen wir uns zum Beispiel die Verteilung für \\(\\Delta = -350N\\) an (Abbildung 2.4).\n\n\n\n\n\nAbbildung 2.4: Verteilung für \\(\\Delta = -350N\\) und der beobachtete Wert \\(D\\)\n\n\n\n\nUnser beobachteter Wert unter der Annahme das \\(\\Delta = -350N\\) ist nicht vollkommen unmöglich, aber so richtig wahrscheinlich erscheint er auch nicht. Der Wert liegt relativ weit am Rand der Verteilung. Die Kurve ist dort schon ziemlich nahe bei Null. D.h. der beobachtete Wert ist zwar durchaus möglich, aber es wäre schon überraschend wenn wir bei einer Durchführung des Experiments ausgerechnet so einen Wert beobachten würden wenn unsere angenommenes \\(\\Delta\\) korrekt ist.\nWenn wir jetzt dagegen von der Annahme ausgehen, dass dem DGP der Wert \\(\\Delta = 50N\\) zugrundeliegen würde, hätten wir die Verteilung in Abbildung 2.5. Zunächst ist dieser Wert möglich unter der Annahme. Zusätzlich liegt der beobachtete Wert mitten drin in dem Teil der Verteilung der auch zu erwarten wäre. D.h. der beobachtete Wert ist durchaus plausibel unter der Annahme und bei der einmaligen Durchführung des Experiments würde uns der beobachtete Wert nicht unbedingt überraschen.\n\n\n\n\n\nAbbildung 2.5: Verteilung für \\(\\Delta = 50N\\) und der beobachtete Wert \\(D\\)\n\n\n\n\nDiesen Ansatz können wir verwenden um mit Hilfe unseres Experiments doch etwas über den DGP auszusagen. Allerdings müssen wir uns noch einmal etwas eingehender mit Verteilungen auseinandersetzen um z.B. genauer zu bestimmen welche Ergebnisse uns überraschen würden. D.h. wir müssen uns erst ein mal ein paar neue Konzepte erarbeiten."
  },
  {
    "objectID": "stats_significance.html#verteilungen---1.-deep-dive",
    "href": "stats_significance.html#verteilungen---1.-deep-dive",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.2 Verteilungen - 1. deep dive",
    "text": "2.2 Verteilungen - 1. deep dive\nIn Abbildung 2.3 sind verschiedene Verteilungen abgebildet die sich eigentlich nur in ihrer Position bzw. Lage unterscheiden. Der Parameter der bei einer Verteilungen die Lage steuert ist der Mittelwert den wir bereits schon kennengelernt haben. Hier jetzt aber nicht der Mittelwert \\(\\bar{x}\\) in der Stichprobe, sondern der Mittelwert der zugrundeliegenden Population der dann mit dem Symbol \\(\\mu\\) bezeichnet wird. Die Beschreibung als Parameter der Verteilung heißt nichts anderes das die Verteilung von \\(\\mu\\) abhängt, oder formal das die Verteilung eine Funktion von \\(\\mu\\) ist. Wenn wir uns an Funktionen aus der Schule zurück erinnen wo wir Funktionen \\(f\\) von \\(x\\) kennengelernt haben und als \\(f(x)\\) dargestellt haben. Übertragen auf die Verteilung könnte dies mittels \\(f(\\mu)\\) dargestellt werden.\n\n\n\nNehmen wir nun zwei Verteilungen die sich bezüglich ihrer Mittelwerte \\(\\mu\\) unterscheiden. Zum Beispiel sei \\(\\mu_1 = 0\\) und \\(\\mu_2 = 3\\). Wie in Abbildung 2.6 zu sehen ist, führt dies dazu, das die beiden Verteilungen gegeneinander verschoben sind.\n\n\n\n\n\nAbbildung 2.6: Verteilungen mit zwei unterschiedlichen Mittelwerten\n\n\n\n\nDer Mittelwert \\(\\mu\\) der Verteilung wird auch als Erwartungswert bezeichnet. Dies kann dahingehend interpretiert werden, das wenn Stichproben aus dieser Verteilungen gezogen werden, im Mittel der Wert \\(\\mu\\) erwartet wird. Soweit ist dies eigentlich noch nichts wirklich Neues, sondern hatten dies schon vorher gesehen, als wir alle möglichen Unterschiede zwischen der Kontrollgruppe und der Interventionsgruppe ermittelt haben. Hier war der Mittelwert der Verteilung genau derjenige Wert von \\(\\Delta\\).\nAn dieser Stelle sollte nochmal der Unterschied zwischen \\(\\mu\\) und \\(\\bar{x}\\) klargestellt werden. Der Mittelwert \\(\\mu\\) ist eine Eigenschaft der Population, also letztendlich ein Wert den wir niemals kennen werden ohne die gesamte Population zu untersuchen. Der Mittelwert \\(\\bar{x}\\) ist eine Eigenschaft der Stichprobe aus der Population. Also der konkrete Wert den wir anhand der Stichprobe berechnen. In vielen Fällen versuchen wir über \\(\\bar{x}\\) einen Rückschluss auf \\(\\mu\\) zu ziehen.\nAls zweite Eigenschaft von Verteilungen schauen wir uns jetzt die Streuung in der Population an. Die Streuung in der Population wird als Varianz bezeichnet und wird mit dem Symbol \\(\\sigma^2\\) bezeichnet. Schauen wir uns zunächst an, welchen Einfluss \\(\\sigma^2\\) auf die Form der Verteilung hat. In Abbildung 2.7 sind wieder zwei Verteilungen abgetragen. Dieses Mal ist \\(\\mu\\) in beiden Fällen gleich, aber die Varianzen \\(\\sigma\\) sind mit \\(\\sigma_1^2 = 2\\) und \\(\\sigma_2^2=1\\) unterschiedlich.\n\n\n\n\n\nAbbildung 2.7: Verteilungen mit unterschiedlichen Varianzen\n\n\n\n\n1"
  },
  {
    "objectID": "stats_significance.html#eigenschaften-von-verteilungen---mittelwert-mu",
    "href": "stats_significance.html#eigenschaften-von-verteilungen---mittelwert-mu",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.3 Eigenschaften von Verteilungen - Mittelwert \\(\\mu\\)",
    "text": "2.3 Eigenschaften von Verteilungen - Mittelwert \\(\\mu\\)\n\n\n\n\n\nAbbildung 2.6: Verteilungen mit zwei unterschiedlichen Mittelwerten\n\n\n\n\n1"
  },
  {
    "objectID": "stats_significance.html#eigenschaften-von-verteilungen---varianz-sigma2",
    "href": "stats_significance.html#eigenschaften-von-verteilungen---varianz-sigma2",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.4 Eigenschaften von Verteilungen - Varianz \\(\\sigma^2\\)",
    "text": "2.4 Eigenschaften von Verteilungen - Varianz \\(\\sigma^2\\)\n\n\n\n\n\nVerteilungen mit unterschiedlichen Varianzen\n\n\n\n\n2"
  },
  {
    "objectID": "stats_significance.html#formeln",
    "href": "stats_significance.html#formeln",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.3 Formeln",
    "text": "2.3 Formeln\nn := Anzahl der Stichprobenelemente, \\(x_i\\) := Messwerte"
  },
  {
    "objectID": "stats_significance.html#nebenbei-warum-der-mittelwert-sinn-macht",
    "href": "stats_significance.html#nebenbei-warum-der-mittelwert-sinn-macht",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.4 Nebenbei: Warum der Mittelwert Sinn macht",
    "text": "2.4 Nebenbei: Warum der Mittelwert Sinn macht\n\n\n\n\n\nVerteilung der Mittelwerte von Stichproben der Größe \\(n=10\\), Kleine Welt Population \\(\\mu\\) (rot)"
  },
  {
    "objectID": "stats_significance.html#mit-der-verteilung-die-annimmt-das-nichts-passiert",
    "href": "stats_significance.html#mit-der-verteilung-die-annimmt-das-nichts-passiert",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.5 Mit der Verteilung die annimmt das nichts passiert!",
    "text": "2.5 Mit der Verteilung die annimmt das nichts passiert!\n\n\n\n\n\nVerteilung wenn nichts passiert.\n\n\n\n\n\n\n\n\n\nQuantilefunktion wenn nichts passiert."
  },
  {
    "objectID": "stats_significance.html#signifikanter-wert",
    "href": "stats_significance.html#signifikanter-wert",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.6 Signifikanter Wert",
    "text": "2.6 Signifikanter Wert\n\n\n\n\n\nVerteilung wenn nichts passiert und kritische Regionen.\n\n\n\n\nWenn der Stichprobenwert der Statistik in der kritischen Region auftritt, dann wird von einem statistisch signifikanten Effekt gesprochen. Unter der \\(H_0\\) bin ich überrascht diesen Wert zu sehen!"
  },
  {
    "objectID": "stats_significance.html#der-p-wert",
    "href": "stats_significance.html#der-p-wert",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.7 Der p-Wert",
    "text": "2.7 Der p-Wert\n\n\n\n\n\nDer gelben Flächen zeigen den p-Wert für den Wert der Statistik von d = 2,5 an."
  },
  {
    "objectID": "stats_significance.html#p-werte",
    "href": "stats_significance.html#p-werte",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.8 p-Werte",
    "text": "2.8 p-Werte\nDer p-Wert gibt die Wahrscheinlichkeit für den gefundenen oder einen noch extremeren Wert unter der \\(H_0\\) an.\n\n\n\n\n\nVerschiedene P-Werte"
  },
  {
    "objectID": "stats_significance.html#p-werte-1",
    "href": "stats_significance.html#p-werte-1",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.9 p-Werte",
    "text": "2.9 p-Werte\n“[A] p-value is the probability under a specified statistical model that a statistical summary of the data (e.g., the sample mean difference between two compared groups) would be equal to or more extreme than its observed value.” (Wasserstein und Lazar 2016, p.131)\n“[T]he P value is the probability of seeing data that are as weird or more weird than those that were actually observed.” (Christensen 2018, p.38)"
  },
  {
    "objectID": "stats_significance.html#signifikanter-wert---das-kleingedruckte",
    "href": "stats_significance.html#signifikanter-wert---das-kleingedruckte",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.10 Signifikanter Wert - Das Kleingedruckte",
    "text": "2.10 Signifikanter Wert - Das Kleingedruckte\n\nVor dem Experiment wird für ein \\(H_0\\) ein \\(\\alpha\\)-Level angesetzt (per Konvention \\(\\alpha=0,05 = 5\\%\\))\nAnhand des \\(\\alpha\\)-Levels können kritische Werte (\\(k_{lower}, k_{upper}\\)) bestimmt werden. Diese bestimmen die Grenzen der kritischen Regionen.\nWenn der gemessene Wert w der Statistik in die kritische Region fällt, also \\(w \\leq k_{lower}\\) oder \\(w \\geq k_{upper}\\) gilt, dann wird von einem statistisch signifikanten Wert gesprochen und die dazugehörige Hypothese wird abgelehnt. Äquivalent: Der p-Wert ist kleiner als \\(\\alpha\\).\nDa in \\(\\alpha\\)-Fällen ein Wert in der kritischen Region auftritt, auch wenn die \\(H_0\\) zutrifft, wird in \\(\\alpha\\)-Fällen ein \\(\\alpha\\)-Fehler gemacht."
  },
  {
    "objectID": "stats_significance.html#signifikanter-wert---das-kleingedruckte-1",
    "href": "stats_significance.html#signifikanter-wert---das-kleingedruckte-1",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.11 Signifikanter Wert - Das Kleingedruckte",
    "text": "2.11 Signifikanter Wert - Das Kleingedruckte\n\nWenn der Wert w der Statistik nicht in den kritischen Regionen liegt, oder gleichwertig der p-Wert größer als \\(\\alpha\\) ist, wird die \\(H_0\\) beibehalten. D.h. nicht, dass kein Effekt vorliegt, sondern lediglich, dass anhand der Daten keine Evidenz diesbezüglich gefunden werden konnte!\nDie statistische Signifikanz sagt nichts über die Wahrscheinlichkeit der Theorie aus!\nEin p-Wert von \\(p = 0.0001\\) heißt nicht, dass mit 99,99% Wahrscheinlichkeit ein Effekt vorliegt!\nStatistisch signifikant heißt nicht automatisch praktisch relevant!"
  },
  {
    "objectID": "stats_significance.html#nochmal-wenn-die-h_0-nicht-abgelehnt-wird",
    "href": "stats_significance.html#nochmal-wenn-die-h_0-nicht-abgelehnt-wird",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.12 Nochmal, wenn die \\(H_0\\) nicht abgelehnt wird",
    "text": "2.12 Nochmal, wenn die \\(H_0\\) nicht abgelehnt wird\n\n\n\nAusschnitt aus Altman und Bland (1995)"
  },
  {
    "objectID": "stats_significance.html#nochmal-p-wert-wasserstein2016",
    "href": "stats_significance.html#nochmal-p-wert-wasserstein2016",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.13 Nochmal p-Wert (Wasserstein und Lazar (2016))",
    "text": "2.13 Nochmal p-Wert (Wasserstein und Lazar (2016))\n\nP-values can indicate how incompatible the data are with a specified statistical model.\nP-values do not measure the probability that the studied hypothesis is true, or the probability that the data were produced by random chance alone.\nScientific conclusions and business or policy decisions should not be based only on whether a p-value passes a specific threshold.\nProper inference requires full reporting and transparency\nA p-value, or statistical significance, does not measure the size of an effect or the importance of a result.\nBy itself, a p-value does not provide a good measure of evidence regarding a model or hypothesis."
  },
  {
    "objectID": "stats_significance.html#was-passiert-nun-aber-wenn-die-andere-hypothese-zutrifft",
    "href": "stats_significance.html#was-passiert-nun-aber-wenn-die-andere-hypothese-zutrifft",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.14 Was passiert nun aber wenn die “andere” Hypothese zutrifft?",
    "text": "2.14 Was passiert nun aber wenn die “andere” Hypothese zutrifft?\n\n\n\n\n\nDifferenzen mit kritischen Regionen (rot) mit einer Wahrscheinlichkeit von \\(\\alpha\\) wenn \\(H_0\\) zutrifft."
  },
  {
    "objectID": "stats_significance.html#wir-machen-einen-beta-fehler",
    "href": "stats_significance.html#wir-machen-einen-beta-fehler",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.15 Wir machen einen \\(\\beta\\)-Fehler!",
    "text": "2.15 Wir machen einen \\(\\beta\\)-Fehler!\n\n\n\n\n\nDifferenzen mit kritischen Regionen (rot) mit einer Wahrscheinlichkeit von \\(\\alpha\\) wenn \\(H_0\\) zutrifft und \\(\\beta\\) (grün) wenn \\(H_1\\) zutrifft."
  },
  {
    "objectID": "stats_significance.html#snap1989---the-power",
    "href": "stats_significance.html#snap1989---the-power",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.16 Snap!(1989) - The Power",
    "text": "2.16 Snap!(1989) - The Power\n\n\n\n\n\n\\(1-\\beta\\) = Power des Tests (blaue Fläche)."
  },
  {
    "objectID": "stats_significance.html#terminologie-noch-mal",
    "href": "stats_significance.html#terminologie-noch-mal",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.17 Terminologie noch mal",
    "text": "2.17 Terminologie noch mal\n\n\\(\\alpha\\): Die Wahrscheinlichkeit sich gegen die \\(H_0\\) zu entscheiden, wenn die \\(H_0\\) zutrifft. \\(\\alpha\\)-Level wird vor dem Experiment festgelegt um zu kontrollieren welche Fehlerrate toleriert wird.\n\\(\\beta\\): Die Wahrscheinlichkeit sich gegen die \\(H_1\\) zu entscheiden, wenn die \\(H_1\\) zutrifft.\nPower := \\(1 - \\beta\\): Die Wahrscheinlichkeit sich für die \\(H_1\\) zu entscheiden, wenn die \\(H_1\\) zutrifft. Sollte ebenfalls vor dem Experiment festgelegt werden."
  },
  {
    "objectID": "stats_significance.html#wie-können-wir-die-power-erhöhen",
    "href": "stats_significance.html#wie-können-wir-die-power-erhöhen",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.18 Wie können wir die Power erhöhen?",
    "text": "2.18 Wie können wir die Power erhöhen?\n\n\n\n\n\nVerteilungen wenn \\(\\delta\\)=500 und \\(\\delta\\)=0 in unserem kleine Welt Beispiel mit n = 3."
  },
  {
    "objectID": "stats_significance.html#stichprobengröße-von-n-3-auf-n-9-erhöhen",
    "href": "stats_significance.html#stichprobengröße-von-n-3-auf-n-9-erhöhen",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.19 Stichprobengröße von n = 3 auf n = 9 erhöhen?",
    "text": "2.19 Stichprobengröße von n = 3 auf n = 9 erhöhen?\n\n\n\n\n\nStichprobenverteilungen der Differenz unter \\(H_0\\) und \\(H_1:\\delta=500\\)N bei einer Stichprobengröße von n = 9"
  },
  {
    "objectID": "stats_significance.html#standardfehler",
    "href": "stats_significance.html#standardfehler",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.20 Standardfehler",
    "text": "2.20 Standardfehler\nDie Standardabweichung der Statistik wird als Standardfehler \\(s_e\\) bezeichnet2. Der Standardfehler ist nicht gleich der Standardabweichung in der Population bzw. der Stichprobe. Es gilt für den Mittelwert:"
  },
  {
    "objectID": "stats_significance.html#problem-bei-einer-dichotomen-betrachtung-der-daten",
    "href": "stats_significance.html#problem-bei-einer-dichotomen-betrachtung-der-daten",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.1 Problem bei einer dichotomen Betrachtung der Daten",
    "text": "3.1 Problem bei einer dichotomen Betrachtung der Daten\n\n\n\nAuszug aus Cumming (2013, p.1)"
  },
  {
    "objectID": "stats_significance.html#wie-groß-ist-der-effekt",
    "href": "stats_significance.html#wie-groß-ist-der-effekt",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.2 Wie groß ist der Effekt?",
    "text": "3.2 Wie groß ist der Effekt?\n\n\n\n\n\nStichprobenverteilungen der Differenz unter \\(H_0\\) und \\(H_1:\\delta=500\\)N bei einer Stichprobengröße von n = 9"
  },
  {
    "objectID": "stats_significance.html#schätzung-der-populationsparameter",
    "href": "stats_significance.html#schätzung-der-populationsparameter",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.3 Schätzung der Populationsparameter",
    "text": "3.3 Schätzung der Populationsparameter\n\n\n\nKleine Welt: Experiment wird einmal mit n = 9 durchgeführt\n\n3.3.1 Beobachtete Stichprobenkennwerte\n\\[\\begin{align*}\nd = \\bar{x}_{treat} - \\bar{x}_{con} &= 350 \\\\\ns &= 132 \\\\\ns_e &= 44\n\\end{align*}\\]\nWie präzise ist meine Schätzung und welche anderen Unterschiedswerte sind anhand der beobachteten Daten noch plausibel?"
  },
  {
    "objectID": "stats_significance.html#welche-deltas-sind-plausibel-für-d-350",
    "href": "stats_significance.html#welche-deltas-sind-plausibel-für-d-350",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.4 Welche \\(\\delta\\)s sind plausibel für \\(d = 350\\)?",
    "text": "3.4 Welche \\(\\delta\\)s sind plausibel für \\(d = 350\\)?\n\n\n\n\n\nVerschiedene Verteilungen von Gruppendifferenzen, beobachteter Unterschied (rot)\n\n\n\n\nPlausibel unter einem gegebenem \\(\\alpha\\)-Level!"
  },
  {
    "objectID": "stats_significance.html#alle-möglichen-deltas-die-plausibel-sind",
    "href": "stats_significance.html#alle-möglichen-deltas-die-plausibel-sind",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.5 Alle möglichen \\(\\delta\\)s die plausibel sind",
    "text": "3.5 Alle möglichen \\(\\delta\\)s die plausibel sind\n\n\n\n\n\nKonfidenzintervall (grün), Populationsparameter \\(\\delta\\) und \\(\\alpha\\)-Level für die beobachtete Differenz (gelb)."
  },
  {
    "objectID": "stats_significance.html#was-passiert-wenn-ich-das-experiment-ganz-oft-wiederhole",
    "href": "stats_significance.html#was-passiert-wenn-ich-das-experiment-ganz-oft-wiederhole",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.6 Was passiert wenn ich das Experiment ganz oft wiederhole?",
    "text": "3.6 Was passiert wenn ich das Experiment ganz oft wiederhole?\n\n\n\n\n\nSimulation von \\(n = 100\\) Konfidenzintervallen."
  },
  {
    "objectID": "stats_significance.html#konfidenzintervall---das-kleingedruckte",
    "href": "stats_significance.html#konfidenzintervall---das-kleingedruckte",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.7 Konfidenzintervall - Das Kleingedruckte",
    "text": "3.7 Konfidenzintervall - Das Kleingedruckte\n\nDas Konfidenzintervall für ein gegebenes \\(\\alpha\\)-Niveau gibt nicht die Wahrscheinlichkeit an mit der der wahre Parameter in dem Intervall liegt.\nDas Konfidenzintervall gibt alle mit den Daten kompatiblen Populationsparameter an.\nDas \\(\\alpha\\)-Niveau des Konfidenzintervalls gibt an bei welchem Anteil von Wiederholungen davon auszugehen ist, das das Konfidenzintervall den wahren Populationsparameter enthält."
  },
  {
    "objectID": "stats_significance.html#konfidenzintervall-herleiten-nach-spiegelhalter2019-p.241",
    "href": "stats_significance.html#konfidenzintervall-herleiten-nach-spiegelhalter2019-p.241",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.8 Konfidenzintervall herleiten nach Spiegelhalter (2019, p.241)",
    "text": "3.8 Konfidenzintervall herleiten nach Spiegelhalter (2019, p.241)\n\nWe use probability theory to tell us, for any particular population parameter, an interval in which we expect the observed statistic to lie with 95% probability.\nThen we observe a particular statistic.\nFinally (and this is the difficult bit) we work out the range of possible population parameters for which our statistic lies in their 95% intervals. This we call a “95% confidence interval”.\nThis resulting confidence interval is given the label “95%” since, with repeated application, 95% of such intervals should contain the true value.3\n\nAll clear? If it isn’t, then please be reassured that you have joined generations of baffled students."
  },
  {
    "objectID": "stats_significance.html#konfidenzintervall-berechnen-vorschau",
    "href": "stats_significance.html#konfidenzintervall-berechnen-vorschau",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.9 Konfidenzintervall berechnen (Vorschau)",
    "text": "3.9 Konfidenzintervall berechnen (Vorschau)\n\\[\n\\textrm{CI}_{1-\\alpha} = \\bar{x} \\pm z_{\\alpha/2} \\times s_e\n\\]"
  },
  {
    "objectID": "stats_significance.html#dualität-von-signifikanztests-und-konfidenzintervall",
    "href": "stats_significance.html#dualität-von-signifikanztests-und-konfidenzintervall",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "3.10 Dualität von Signifikanztests und Konfidenzintervall",
    "text": "3.10 Dualität von Signifikanztests und Konfidenzintervall\nWenn das Konfidenzintervall mit Niveau \\(1-\\alpha\\%\\) die \\(H_0\\) nicht beinhaltet, dann wird auch bei einem Signifikanztest die \\(H_0\\) bei einer Irrtumswahrscheinlichkeit von \\(\\alpha\\) abgelehnt.\n\n\n\n\nAltman, Douglas G, und J Martin Bland. 1995. „Statistics notes: Absence of evidence is not evidence of absence“. Bmj 311 (7003): 485.\n\n\nChristensen, Ronald. 2018. Analysis of variance, design, and regression: Linear modeling for unbalanced data. CRC Press.\n\n\nCohen, Jacob. 1988. Statistical power analysis for the behavioral sciences. 2. Aufl. Routledge.\n\n\nCumming, Geoff. 2013. Understanding the new statistics: Effect sizes, confidence intervals, and meta-analysis. Routledge.\n\n\nSpiegelhalter, David. 2019. The art of statistics: learning from data. Penguin UK.\n\n\nWasserstein, Ronald L, und Nicole A Lazar. 2016. „The ASA statement on p-values: context, process, and purpose“. Taylor & Francis."
  },
  {
    "objectID": "stats_distributions.html",
    "href": "stats_distributions.html",
    "title": "3  Verteilungen",
    "section": "",
    "text": "4 Die Normalverteilung"
  },
  {
    "objectID": "stats_distributions.html#normalverteilung---fxmusigma2-frac1sqrt2-pi-sigma2eleft-fracx-mu22sigma2right",
    "href": "stats_distributions.html#normalverteilung---fxmusigma2-frac1sqrt2-pi-sigma2eleft-fracx-mu22sigma2right",
    "title": "3  Verteilungen",
    "section": "4.1 Normalverteilung - \\(f(x|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)}\\)",
    "text": "4.1 Normalverteilung - \\(f(x|\\mu,\\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}}e^{\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)}\\)\n\n\n\n\n\nDichtefunktion der Normalverteilung mit Parametern \\(\\mu\\) und \\(\\sigma\\)."
  },
  {
    "objectID": "stats_distributions.html#zentraler-grenzwertsatz-oder-warum-die-normalverteilung-überall-auftaucht.",
    "href": "stats_distributions.html#zentraler-grenzwertsatz-oder-warum-die-normalverteilung-überall-auftaucht.",
    "title": "3  Verteilungen",
    "section": "4.2 Zentraler Grenzwertsatz oder Warum die Normalverteilung überall auftaucht.",
    "text": "4.2 Zentraler Grenzwertsatz oder Warum die Normalverteilung überall auftaucht.\nSeien \\(X_1, X_2, \\ldots, X_n\\) n unabhängige, gleichverteilte Zufallsvariablen mit \\(E(X_i)=\\mu\\) und \\(Var(X_i)=\\sigma^2\\). \\[\n\\lim_{n\\to\\infty}\\frac{\\bar{x} - \\mu}{\\frac{\\sigma}{\\sqrt{n}}}\\ \\rightarrow\\ \\mathcal{N}(\\mu=0,\\sigma^2=1)\n\\]"
  },
  {
    "objectID": "stats_distributions.html#normalverteilung-und-standardabweichung",
    "href": "stats_distributions.html#normalverteilung-und-standardabweichung",
    "title": "3  Verteilungen",
    "section": "4.3 Normalverteilung und Standardabweichung",
    "text": "4.3 Normalverteilung und Standardabweichung\n\n\n\n\n\nDichtefunktion von \\(\\mathcal{N}(\\mu,\\sigma^2)\\)"
  },
  {
    "objectID": "stats_distributions.html#normalverteilung-und-standardabweichung-1",
    "href": "stats_distributions.html#normalverteilung-und-standardabweichung-1",
    "title": "3  Verteilungen",
    "section": "4.4 Normalverteilung und Standardabweichung",
    "text": "4.4 Normalverteilung und Standardabweichung\n\\[P(x\\in[\\mu-1.96\\sigma, \\mu+1.96\\sigma]) = 0.95\\]"
  },
  {
    "objectID": "stats_distributions.html#standardnormalverteilung-phix",
    "href": "stats_distributions.html#standardnormalverteilung-phix",
    "title": "3  Verteilungen",
    "section": "4.5 Standardnormalverteilung \\(\\phi(x)\\)",
    "text": "4.5 Standardnormalverteilung \\(\\phi(x)\\)\n\n\n\n\n\nDichtefunktion der Standardnormalverteilung \\(\\phi(x)\\) mit \\(\\mu=0\\) und \\(\\sigma^2=1\\)"
  },
  {
    "objectID": "stats_distributions.html#abbildung-nmusigma-auf-n01",
    "href": "stats_distributions.html#abbildung-nmusigma-auf-n01",
    "title": "3  Verteilungen",
    "section": "4.6 Abbildung N(\\(\\mu\\),\\(\\sigma\\)) auf N(\\(0\\),\\(1\\))",
    "text": "4.6 Abbildung N(\\(\\mu\\),\\(\\sigma\\)) auf N(\\(0\\),\\(1\\))\n\n\n\n\n\nStandardnormalverteilung mit \\(\\mu=12, \\sigma^2=2\\)\n\n\n\n\n\n\n\n\n\nNormalverteilung mit \\(\\mu=0, \\sigma=1\\)"
  },
  {
    "objectID": "stats_distributions.html#z-transformation-allgemein-bzw.-standardisierung",
    "href": "stats_distributions.html#z-transformation-allgemein-bzw.-standardisierung",
    "title": "3  Verteilungen",
    "section": "4.7 z-Transformation allgemein bzw. Standardisierung",
    "text": "4.7 z-Transformation allgemein bzw. Standardisierung"
  },
  {
    "objectID": "stats_distributions.html#t-verteilung",
    "href": "stats_distributions.html#t-verteilung",
    "title": "3  Verteilungen",
    "section": "5.1 t-Verteilung",
    "text": "5.1 t-Verteilung\n\n\n\n\n\nBeispiel für verschiedene Dichtefunktionen der t-Verteilung"
  },
  {
    "objectID": "stats_distributions.html#chi2-verteilung",
    "href": "stats_distributions.html#chi2-verteilung",
    "title": "3  Verteilungen",
    "section": "5.2 \\(\\chi^2\\)-Verteilung",
    "text": "5.2 \\(\\chi^2\\)-Verteilung\n\n\n\n\n\nBeispiele für verschiedene Dichtefunktion der \\(\\chi^2\\)-Verteilung."
  },
  {
    "objectID": "stats_distributions.html#f-verteilung",
    "href": "stats_distributions.html#f-verteilung",
    "title": "3  Verteilungen",
    "section": "5.3 F-Verteilung",
    "text": "5.3 F-Verteilung\n\n\n\n\n\nBeispiele für verschiedene Dichtefunktion der F-Verteilung."
  },
  {
    "objectID": "stats_hypotheses.html#wahrscheinlichkeitstheorie",
    "href": "stats_hypotheses.html#wahrscheinlichkeitstheorie",
    "title": "4  Hypothesen testen",
    "section": "4.1 Wahrscheinlichkeitstheorie",
    "text": "4.1 Wahrscheinlichkeitstheorie"
  },
  {
    "objectID": "stats_hypotheses.html#schätzer",
    "href": "stats_hypotheses.html#schätzer",
    "title": "4  Hypothesen testen",
    "section": "4.2 Schätzer",
    "text": "4.2 Schätzer"
  },
  {
    "objectID": "stats_hypotheses.html#hypothesentestung",
    "href": "stats_hypotheses.html#hypothesentestung",
    "title": "4  Hypothesen testen",
    "section": "4.3 Hypothesentestung",
    "text": "4.3 Hypothesentestung"
  },
  {
    "objectID": "slm_title.html",
    "href": "slm_title.html",
    "title": "Das einfache Regressionmodell",
    "section": "",
    "text": "Wir beginnen nun mit dem einfachen Regressionsmodell. Das Modell knüpft an unsere Vorkenntnisse aus der Schule und bietet die Möglichkeit eine einfaches mentales Template zu erarbeiten auf das wir immer wieder zurück greifen können, da sich bis auf ein paar wenige Konzepte alle wichtige Eigenschaften von linearen Modellen anhand des einfachen Regressionsmodells erklären können. Wenn dann im zweiten Schritt der Übergang auf die multiple Regression durchgeführt wird, sollte dies keine größeren Probleme mehr bereiten, da immer nur ein paar wenige neue Konzepte dazu kommen."
  },
  {
    "objectID": "slm_basics.html#back-to-school",
    "href": "slm_basics.html#back-to-school",
    "title": "5  Einführung",
    "section": "5.1 Back to school",
    "text": "5.1 Back to school\nWir beginnen mit ein Konzept das wir schon alle kennen. Nämlich die Punkt-Steigungsform aus der Schule (siehe Gleichung 5.1).\n\\[\ny = m x + b\n\\tag{5.1}\\]\nWir haben eine abhängige Variable \\(y\\) und eine lineare Formel \\(mx + b\\) die den funktionalen Zusammenhang zwischen den Variablen \\(y\\) und \\(x\\) beschreibt. Um das Ganz einmal konkret zu machen setzen wir \\(m = 2\\) und \\(b = 3\\) fest. Die Formel Gleichung 5.1 wird dann zu:\n\n\n\n\\[\ny = 2 x + 3\n\\tag{5.2}\\]\nUm ein paar Werte für \\(y\\) zu erhalten setzen wir jetzt verschiedene Wert für \\(x\\) ein indem wir \\(x\\) in Einserschritten zwischen \\([0, \\ldots, 5]\\) erhöhen. Um die Werte darzustellen verwenden wir zunächst eine Tabelle (vlg. Tabelle 5.1)\n\n\n\n\nTabelle 5.1: Tabelle der Daten\n\n\nx\ny\n\n\n\n\n0\n3\n\n\n1\n5\n\n\n2\n7\n\n\n3\n9\n\n\n4\n11\n\n\n5\n13\n\n\n\n\n\n\nWenig überraschend nimmt \\(y\\) für den Wert \\(x = 0\\) den Wert \\(3\\) an und z.B. für den Wert \\(x = 3\\) nimmt \\(y\\) den Wert \\(2 \\cdot 3 + 3 = 9\\) an.\nTODO: Einführung eines Index \\(i\\)\nEine andere Darstellungsform ist naturlich eine graphische Darstellung in dem wir die Werte von \\(y\\) gegen \\(x\\) auf einem Graphen abtragen (siehe Abbildung 5.1).\n\n\n\n\n\nAbbildung 5.1: Graphische Darstellung der Daten aus Tabelle 5.1\n\n\n\n\nWiederum wenig überraschen sehen wir einen linearen Zuwachs der \\(y\\)-Wert mit den größerwerdenden \\(x\\)-Werte. Da in der Definition der Formel Gleichung 5.2 nirgends festgelt wurde, dass diese nur für ganzzahlige \\(x\\)-Werte gilt, haben wir direkt eine Gerade durch die Punkte gelegt. Hier wird auch die Bedeutung von \\(m\\) und \\(b\\) direkt klar. Die Variable \\(m\\) bestimmt die Steigung der Gleichung während \\(b\\) den y-Achsenabschnitt beschreibt.\n\nDefinition 5.1 (\\(y\\)-Achsenabschnitt) Der y-Achsenabschnitt ist der Wert den \\(y\\) einnimmt wenn \\(x\\) den Wert \\(0\\) annimmt. Sei \\(y\\) durch eine lineare Gleichung \\(y = mx + b\\) definiert, dann wird der y-Achsenabschnitt durch den Wert \\(b\\) bestimmt.\n\nDie Variable \\(m\\) dahingehend bestimmt die Steigung der Gerade.\n\nDefinition 5.2 Wenn \\(y\\) durch eine lineare Gleichung \\(y = mx + b\\) definiert ist, dann bestimmt die Variable \\(m\\) die Steiung der dazugehörenden Gerade. D.h. wenn sich die Variable \\(x\\) um einen Einheit vergrößert (verkleinert) wird der Wert von \\(y\\) um \\(m\\) Einheiten größer (kleiner). Gilt \\(m < 0\\) dann umgekehrt.\n\nDiese beiden trivialen Konzepte mit eigenen Definitionen zu versehen erscheint im ersten Moment vielleicht etwas übertrieben. Wie sich allerdings später zeigen wird, sind diese beiden Einsichten immer wieder zentral wenn es um die Interpretation von linearen statistischen Modellen geht."
  },
  {
    "objectID": "slm_basics.html#einfaches-beispiel---daten",
    "href": "slm_basics.html#einfaches-beispiel---daten",
    "title": "5  Einführung",
    "section": "5.2 Einfaches Beispiel - Daten",
    "text": "5.2 Einfaches Beispiel - Daten\n\n\n\nAusschnitt der Sprungdaten\n\n\njump_m\nv_ms\n\n\n\n\n4.36\n6.13\n\n\n4.31\n6.39\n\n\n4.56\n6.56\n\n\n4.75\n6.44\n\n\n5.52\n7.30\n\n\n5.63\n7.19\n\n\n5.70\n7.30"
  },
  {
    "objectID": "slm_basics.html#einfaches-beispiel---grafik",
    "href": "slm_basics.html#einfaches-beispiel---grafik",
    "title": "5  Einführung",
    "section": "5.3 Einfaches Beispiel - Grafik",
    "text": "5.3 Einfaches Beispiel - Grafik\n\n\n\n\n\nZusammenhang der Anlaufgeschwindigkeit und der Sprungweite"
  },
  {
    "objectID": "slm_basics.html#einfaches-beispiel---regressionsgerade",
    "href": "slm_basics.html#einfaches-beispiel---regressionsgerade",
    "title": "5  Einführung",
    "section": "5.4 Einfaches Beispiel - Regressionsgerade",
    "text": "5.4 Einfaches Beispiel - Regressionsgerade\n\n\n\n\n\nZusammenhang der Anlaufgeschwindigkeit und der Sprungweite"
  },
  {
    "objectID": "slm_basics.html#loss-function",
    "href": "slm_basics.html#loss-function",
    "title": "5  Einführung",
    "section": "5.5 Loss function",
    "text": "5.5 Loss function\n\\[\n\\sum_{i=1}^n(y_i - (\\beta_0 + \\beta_1 v_i))^2\n\\]\n\\[\ny = -0.14 + 0.76 \\times v\n\\]"
  },
  {
    "objectID": "slm_basics.html#regression-in-r",
    "href": "slm_basics.html#regression-in-r",
    "title": "5  Einführung",
    "section": "5.6 Regression in R",
    "text": "5.6 Regression in R\n\n5.6.1 Model fitten mit lm()\n\nmod <- lm(jump_m ~ v_ms, data = jump)\nmod\n\n\nCall:\nlm(formula = jump_m ~ v_ms, data = jump)\n\nCoefficients:\n(Intercept)         v_ms  \n    -0.1385       0.7611"
  },
  {
    "objectID": "slm_basics.html#formelsyntax-in-lmy-x-data",
    "href": "slm_basics.html#formelsyntax-in-lmy-x-data",
    "title": "5  Einführung",
    "section": "5.7 Formelsyntax in lm(y ~ x, data)",
    "text": "5.7 Formelsyntax in lm(y ~ x, data)\n\nFormelsyntaxbeispiele für lm()\n\n\nModell\nFormel\nErklärung\n\n\n\n\n\\(y=\\beta_0\\)\ny ~ 1\ny-Ab\n\n\n\\(y=\\beta_0+\\beta x\\)\ny ~ x\ny-Ab und StKoef\n\n\n\\(y=\\beta_0+\\beta_1x_1+\\beta_2x_2\\)\ny ~ x1 + x2\ny-Ab und 2 StKoe\n\n\n\ny-Ab = y-Achsenabshnitt, StKoef = Steigungskoeffizient"
  },
  {
    "objectID": "slm_basics.html#lm-fit-mit-summary-inspizieren",
    "href": "slm_basics.html#lm-fit-mit-summary-inspizieren",
    "title": "5  Einführung",
    "section": "5.8 lm()-fit mit summary() inspizieren",
    "text": "5.8 lm()-fit mit summary() inspizieren\n\nsummary(mod)\n\n\nCall:\nlm(formula = jump_m ~ v_ms, data = jump)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.44314 -0.22564  0.02678  0.19638  0.42148 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.13854    0.23261  -0.596    0.555    \nv_ms         0.76110    0.02479  30.702   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2369 on 43 degrees of freedom\nMultiple R-squared:  0.9564,    Adjusted R-squared:  0.9554 \nF-statistic: 942.6 on 1 and 43 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "slm_basics.html#lm-und-ein-paar-friends",
    "href": "slm_basics.html#lm-und-ein-paar-friends",
    "title": "5  Einführung",
    "section": "5.9 lm() und ein paar friends…",
    "text": "5.9 lm() und ein paar friends…\nKoeffizienten und Standardschätzfehler\n\ncoef(mod)\n\n(Intercept)        v_ms \n -0.1385361   0.7611019 \n\nsigma(mod)\n\n[1] 0.2369055\n\n\nResiduen\n\n# Nur die ersten beiden\n# Residuen\n# damit der Ausdruck\n# auf das Slide passt.\nresid(mod)[1:2]\n\n         1          2 \n-0.1626772 -0.4124884"
  },
  {
    "objectID": "slm_inference.html#inferenz",
    "href": "slm_inference.html#inferenz",
    "title": "6  Inferenz",
    "section": "6.1 Inferenz",
    "text": "6.1 Inferenz\n\n6.1.1 Modellannahmen\n\\[\\begin{align*}\ny_i &= \\beta_0 + \\beta_1 x_i + \\epsilon_i \\quad i=1,\\ldots,N \\\\\n\\epsilon_i &\\sim N(0,\\sigma^2) \\quad \\textrm{identisch, unabhängig verteilt}\n\\end{align*}\\]"
  },
  {
    "objectID": "slm_inference.html#modellannahmen---verteilung-der-werte-für-gegebene-x-werte",
    "href": "slm_inference.html#modellannahmen---verteilung-der-werte-für-gegebene-x-werte",
    "title": "6  Inferenz",
    "section": "6.2 Modellannahmen - Verteilung der Werte für gegebene x-Werte",
    "text": "6.2 Modellannahmen - Verteilung der Werte für gegebene x-Werte\n\\[\nY|X \\sim N(\\beta_0+ \\beta_1 X,\\sigma^2)\n\\]\n\n\n\n\n\nVerteilung der Daten für verschiedene \\(x\\)-Werte"
  },
  {
    "objectID": "slm_inference.html#statistische-hypothesen",
    "href": "slm_inference.html#statistische-hypothesen",
    "title": "6  Inferenz",
    "section": "6.3 Statistische Hypothesen",
    "text": "6.3 Statistische Hypothesen\n\n6.3.1 Ungerichtet\n\\[\\begin{gather*}\nH_0: \\beta_1 = 0  \\\\\nH_1: \\beta_1 \\neq 0\n\\end{gather*}\\]\n\n\n6.3.2 Gerichtet\n\\[\\begin{gather*}\nH_0: \\beta_1 \\leq 0  \\\\\nH_1: \\beta_1 > 0\n\\end{gather*}\\]"
  },
  {
    "objectID": "slm_inference.html#teststatistik-informell-herleiten",
    "href": "slm_inference.html#teststatistik-informell-herleiten",
    "title": "6  Inferenz",
    "section": "6.4 Teststatistik informell herleiten",
    "text": "6.4 Teststatistik informell herleiten\n\n6.4.1 Simulation unter der \\(H_0\\)\n\\[\\begin{align*}\nN &= 45 \\\\\nx &\\sim \\mathcal{U}(-1,1) \\\\\ny &\\sim \\mathcal{N}(0,\\sigma) \\\\\n\\sigma &= 1 \\\\\nH_0: & \\beta_1 = 0\n\\end{align*}\\]"
  },
  {
    "objectID": "slm_inference.html#teststatistik-informell-herleiten-1",
    "href": "slm_inference.html#teststatistik-informell-herleiten-1",
    "title": "6  Inferenz",
    "section": "6.5 Teststatistik informell herleiten",
    "text": "6.5 Teststatistik informell herleiten\n\n\n\n\n\nAcht Zufallsziehung unter der \\(H_0\\)"
  },
  {
    "objectID": "slm_inference.html#stichprobenverteilung-von-beta_1-unter-der-annahme-beta_1-0",
    "href": "slm_inference.html#stichprobenverteilung-von-beta_1-unter-der-annahme-beta_1-0",
    "title": "6  Inferenz",
    "section": "6.6 Stichprobenverteilung von \\(\\beta_1\\) unter der Annahme \\(\\beta_1 = 0\\)",
    "text": "6.6 Stichprobenverteilung von \\(\\beta_1\\) unter der Annahme \\(\\beta_1 = 0\\)\n\n\n\n\n\nVerteilung der \\(\\beta_1\\)s - 1000 Simulationen unter der Annahme der \\(H_0\\)."
  },
  {
    "objectID": "slm_inference.html#verteilung-der-statistik-unter-der-h_0",
    "href": "slm_inference.html#verteilung-der-statistik-unter-der-h_0",
    "title": "6  Inferenz",
    "section": "6.7 Verteilung der Statistik unter der \\(H_0\\)",
    "text": "6.7 Verteilung der Statistik unter der \\(H_0\\)\n\n\n\n6.7.0.1 Standardfehler von \\(\\beta_1\\)\n\\[ \\sigma_{\\beta_1} = \\sqrt{\\frac{\\sigma^2}{\\sum{(X_i - \\bar{X})^2}}}\\]\n\\(\\sigma\\) lässt sich abschätzen mit:\n\\[\n\\hat{\\sigma} = \\sqrt{\\sum_{i=1}^N e_i^2/(N-K)}\n\\]\n\n\n\n6.7.1 in R\n\nsigma(mod)\n\n[1] 0.2369055"
  },
  {
    "objectID": "slm_inference.html#verteilung-der-statistik-unter-der-h_0-1",
    "href": "slm_inference.html#verteilung-der-statistik-unter-der-h_0-1",
    "title": "6  Inferenz",
    "section": "6.8 Verteilung der Statistik unter der \\(H_0\\)",
    "text": "6.8 Verteilung der Statistik unter der \\(H_0\\)\nUnter den Annahmen des Regressionsmodells und der \\(H_0\\) gilt:\n\\[\n\\frac{\\beta_1}{\\sigma_{\\beta_1}} \\sim t_{N-2}\n\\]\nMittels \\(\\alpha\\) lässt sich daher wieder ein kritischer Wert bestimmen ab dem die \\(H_0\\) verworfen wird."
  },
  {
    "objectID": "slm_inference.html#teststatistik",
    "href": "slm_inference.html#teststatistik",
    "title": "6  Inferenz",
    "section": "6.9 Teststatistik",
    "text": "6.9 Teststatistik\n\n\n\n\n\nVerteilung von \\(\\frac{\\beta_1}{s_{\\beta_1}}\\),Dichtefunktion der t-Verteilung (rot) mit \\(df = n - 2\\)"
  },
  {
    "objectID": "slm_inference.html#verteilung-der-hatsigma-sqrtsum_i1n-e_i2n-k",
    "href": "slm_inference.html#verteilung-der-hatsigma-sqrtsum_i1n-e_i2n-k",
    "title": "6  Inferenz",
    "section": "6.10 Verteilung der \\(\\hat{\\sigma} = \\sqrt{\\sum_{i=1}^N e_i^2/(N-K)}\\)",
    "text": "6.10 Verteilung der \\(\\hat{\\sigma} = \\sqrt{\\sum_{i=1}^N e_i^2/(N-K)}\\)\n\n\n\n\n\nVerteilung von \\(\\hat{\\sigma}\\)"
  },
  {
    "objectID": "slm_inference.html#nochmal-summary",
    "href": "slm_inference.html#nochmal-summary",
    "title": "6  Inferenz",
    "section": "6.11 Nochmal summary()",
    "text": "6.11 Nochmal summary()\n\nsummary(mod)\n\n\nCall:\nlm(formula = jump_m ~ v_ms, data = jump)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.44314 -0.22564  0.02678  0.19638  0.42148 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept) -0.13854    0.23261  -0.596    0.555    \nv_ms         0.76110    0.02479  30.702   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2369 on 43 degrees of freedom\nMultiple R-squared:  0.9564,    Adjusted R-squared:  0.9554 \nF-statistic: 942.6 on 1 and 43 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "slm_inference.html#konfidenzintervalle-für-die-koeffizienten",
    "href": "slm_inference.html#konfidenzintervalle-für-die-koeffizienten",
    "title": "6  Inferenz",
    "section": "6.12 Konfidenzintervalle für die Koeffizienten",
    "text": "6.12 Konfidenzintervalle für die Koeffizienten\n\n6.12.1 Formel\n\\[\n\\hat{\\beta_j} \\pm q_{t_{\\alpha/2,df=N-2}} \\times \\hat{\\sigma}_{\\beta_j}\n\\]\n\n\n6.12.2 In R\n\nconfint(mod)\n\n                 2.5 %    97.5 %\n(Intercept) -0.6076488 0.3305767\nv_ms         0.7111082 0.8110957"
  },
  {
    "objectID": "slm_inference.html#zum-nacharbeiten",
    "href": "slm_inference.html#zum-nacharbeiten",
    "title": "6  Inferenz",
    "section": "6.13 Zum Nacharbeiten",
    "text": "6.13 Zum Nacharbeiten\nAltman und Krzywinski (2015) und Kutner u. a. (2005, p.40–48)\n\n\n\n\nAltman, Naomi, und Martin Krzywinski. 2015. „Points of Significance: Simple linear regression.“ Nature methods 12 (11).\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "slm_model_fit.html#residuen",
    "href": "slm_model_fit.html#residuen",
    "title": "7  Modellfit",
    "section": "7.1 Residuen",
    "text": "7.1 Residuen"
  },
  {
    "objectID": "slm_model_fit.html#was-sind-noch-mal-residuen-epsilon_i-bzw.-deren-schätzer-hatepsilon_i-e_i",
    "href": "slm_model_fit.html#was-sind-noch-mal-residuen-epsilon_i-bzw.-deren-schätzer-hatepsilon_i-e_i",
    "title": "7  Modellfit",
    "section": "7.2 Was sind noch mal Residuen \\(\\epsilon_i\\) bzw. deren Schätzer \\(\\hat{\\epsilon}_i = e_i\\)",
    "text": "7.2 Was sind noch mal Residuen \\(\\epsilon_i\\) bzw. deren Schätzer \\(\\hat{\\epsilon}_i = e_i\\)\n\\[\ny_i = \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i\n\\]\n\n\n\n\n\nSpielzeugbeispiel mit Residuen \\(\\hat{\\epsilon}_i = e_i = y_i - \\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#annahme-epsilon_i-sim-mathcaln0-sigma2",
    "href": "slm_model_fit.html#annahme-epsilon_i-sim-mathcaln0-sigma2",
    "title": "7  Modellfit",
    "section": "7.3 Annahme: \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)",
    "text": "7.3 Annahme: \\(\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\\)\n\n\n\n\n\nVerteilung der Werte für verschiedene x-Werte (rote Punkte) und die resultierende Regressionsgerade mit den Vorhersagewerte \\(\\hat{y}_i\\) (schwarze Punkte)"
  },
  {
    "objectID": "slm_model_fit.html#übersicht-residuen",
    "href": "slm_model_fit.html#übersicht-residuen",
    "title": "7  Modellfit",
    "section": "7.4 Übersicht Residuen",
    "text": "7.4 Übersicht Residuen\n\nÜbersicht über verschiedene Arten von Residuen1\n\n\n\n\n\n\n\nTyp\nBerechnung\nZiel\n\n\n\n\nEinfache Residuen\n\\(e_i = y_i - \\hat{y}_i\\)\nVerteilungsannahme\n\n\nStandardisierte Residuen\n\\(e_{Si} = \\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_i}}\\)\nVerteilungsannahme\n\n\nStudentized Residuen\n\\(e_{Ti} = \\frac{e_i}{\\hat{\\sigma}_{(-i)}\\sqrt{1-h_i}}\\)\nEinfluss auf Modell"
  },
  {
    "objectID": "slm_model_fit.html#residuen-in-r-berechnen-mit-residuals-und-freunden",
    "href": "slm_model_fit.html#residuen-in-r-berechnen-mit-residuals-und-freunden",
    "title": "7  Modellfit",
    "section": "7.5 Residuen in R berechnen mit residuals() und Freunden",
    "text": "7.5 Residuen in R berechnen mit residuals() und Freunden\n\nresiduals(mod)[1:5] # einfache Residuen\n\n         1          2          3          4          5 \n -9.300928  -9.368288 -11.217658  -5.572108  -6.363565 \n\nrstandard(mod)[1:5] # standardisierte Residuen\n\n         1          2          3          4          5 \n-1.4592936 -1.4598906 -1.7440573 -0.8724351 -0.9916310 \n\nrstudent(mod)[1:5] # studentized Residuen\n\n         1          2          3          4          5 \n-1.4814779 -1.4821191 -1.7928881 -0.8697060 -0.9914135"
  },
  {
    "objectID": "slm_model_fit.html#residuen-in-r-inspizieren",
    "href": "slm_model_fit.html#residuen-in-r-inspizieren",
    "title": "7  Modellfit",
    "section": "7.6 Residuen in R inspizieren",
    "text": "7.6 Residuen in R inspizieren\n\ny_hat <- predict(mod)\nplot(y_hat, residuals(mod))\nplot(y_hat, rstandard(mod))\nplot(y_hat, rstudent(mod))"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---einfache-residuen-hatepsilon_i-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---einfache-residuen-hatepsilon_i-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.7 Diagnoseplot - Einfache Residuen \\(\\hat{\\epsilon_i} \\sim \\hat{y_i}\\)",
    "text": "7.7 Diagnoseplot - Einfache Residuen \\(\\hat{\\epsilon_i} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der Residuen \\(\\hat{\\epsilon_i}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---standardisierte-residuen-hatepsilon_si-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---standardisierte-residuen-hatepsilon_si-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.8 Diagnoseplot - Standardisierte Residuen \\(\\hat{\\epsilon}_{Si} \\sim \\hat{y_i}\\)",
    "text": "7.8 Diagnoseplot - Standardisierte Residuen \\(\\hat{\\epsilon}_{Si} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der standardisierten Residuen \\(\\hat{\\epsilon}_{Si}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---studentized-residuen-hatepsilon_ti-sim-haty_i",
    "href": "slm_model_fit.html#diagnoseplot---studentized-residuen-hatepsilon_ti-sim-haty_i",
    "title": "7  Modellfit",
    "section": "7.9 Diagnoseplot - Studentized Residuen \\(\\hat{\\epsilon}_{Ti} \\sim \\hat{y_i}\\)",
    "text": "7.9 Diagnoseplot - Studentized Residuen \\(\\hat{\\epsilon}_{Ti} \\sim \\hat{y_i}\\)\n\n\n\n\n\nStreudiagramm der studentized Residuals \\(\\hat{\\epsilon}_{Ti}\\) gegen die Vorhersagewerte \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus",
    "href": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus",
    "title": "7  Modellfit",
    "section": "7.10 Diagnoseplot - Wie sehen Probleme aus?",
    "text": "7.10 Diagnoseplot - Wie sehen Probleme aus?\n\n\n\n\n\nBeispielstreudiagramm"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus-1",
    "href": "slm_model_fit.html#diagnoseplot---wie-sehen-probleme-aus-1",
    "title": "7  Modellfit",
    "section": "7.11 Diagnoseplot - Wie sehen Probleme aus?",
    "text": "7.11 Diagnoseplot - Wie sehen Probleme aus?\n\n\n\n\n\nBeispielstreudiagramm"
  },
  {
    "objectID": "slm_model_fit.html#wie-kann-die-verteilung-der-residuen-überprüft-werden",
    "href": "slm_model_fit.html#wie-kann-die-verteilung-der-residuen-überprüft-werden",
    "title": "7  Modellfit",
    "section": "7.12 Wie kann die Verteilung der Residuen überprüft werden?",
    "text": "7.12 Wie kann die Verteilung der Residuen überprüft werden?\n\n\n\nSpielzeugbeispieldaten mit \\(n=5\\)\n\n\ny\n\n\n\n\n-2.0\n\n\n5.0\n\n\n-1.2\n\n\n0.1\n\n\n7.0\n\n\n\n\n\n\n\n\n\n\nDichtefunktion der Standardnormalverteilung"
  },
  {
    "objectID": "slm_model_fit.html#konstruktion-eines-qq-graphen",
    "href": "slm_model_fit.html#konstruktion-eines-qq-graphen",
    "title": "7  Modellfit",
    "section": "7.13 Konstruktion eines qq-Graphen",
    "text": "7.13 Konstruktion eines qq-Graphen\n\n\n\n\n\n\nSortierte Datenwerte\n\n\nkleinster\n2.kleinster\nmittlerer\n2.größter\ngrößter\n\n\n\n\n-2\n-1.2\n0.1\n5\n7"
  },
  {
    "objectID": "slm_model_fit.html#konstruktion-eines-qq-graphen-1",
    "href": "slm_model_fit.html#konstruktion-eines-qq-graphen-1",
    "title": "7  Modellfit",
    "section": "7.14 Konstruktion eines qq-Graphen",
    "text": "7.14 Konstruktion eines qq-Graphen\n\n\n\n\n\nStreudiagramm der empirischen Werte gegen die theoretischen Quantilen"
  },
  {
    "objectID": "slm_model_fit.html#beispiele-für-qq-graphen-mit-qqnorm-und-qqline",
    "href": "slm_model_fit.html#beispiele-für-qq-graphen-mit-qqnorm-und-qqline",
    "title": "7  Modellfit",
    "section": "7.15 Beispiele für qq-Graphen mit qqnorm() und qqline()",
    "text": "7.15 Beispiele für qq-Graphen mit qqnorm() und qqline()"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplot---qq-diagramm",
    "href": "slm_model_fit.html#diagnoseplot---qq-diagramm",
    "title": "7  Modellfit",
    "section": "7.16 Diagnoseplot - QQ-Diagramm",
    "text": "7.16 Diagnoseplot - QQ-Diagramm\n\n\n\n\n\nQQ-Diagramm der Residuen des ADAS-ADCS-Modells\n\n\n\n\n2"
  },
  {
    "objectID": "slm_model_fit.html#summary",
    "href": "slm_model_fit.html#summary",
    "title": "7  Modellfit",
    "section": "7.17 summary()",
    "text": "7.17 summary()\n\n\n\nCall:\nlm(formula = adcs ~ adas, data = adl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-11.2177  -3.8033  -0.4663   2.7950  20.9634 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  26.5445     4.3052   6.166 3.05e-07 ***\nadas         -0.2638     0.1015  -2.599   0.0131 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.516 on 39 degrees of freedom\nMultiple R-squared:  0.1477,    Adjusted R-squared:  0.1258 \nF-statistic: 6.757 on 1 and 39 DF,  p-value: 0.01312"
  },
  {
    "objectID": "slm_model_fit.html#neue-idee-zu-residuen",
    "href": "slm_model_fit.html#neue-idee-zu-residuen",
    "title": "7  Modellfit",
    "section": "7.18 Neue Idee zu Residuen",
    "text": "7.18 Neue Idee zu Residuen\n\n\n\n\n\nSpielzeugbeispiel mit Residuen \\(\\hat{\\epsilon}_i = e_i = y_i - \\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#zum-nacharbeiten",
    "href": "slm_model_fit.html#zum-nacharbeiten",
    "title": "7  Modellfit",
    "section": "7.19 Zum Nacharbeiten",
    "text": "7.19 Zum Nacharbeiten\nKutner u. a. (2005, p.100–114) Altman und Krzywinski (2016b) Fox (2011, p.285–296)"
  },
  {
    "objectID": "slm_model_fit.html#hebelwerte",
    "href": "slm_model_fit.html#hebelwerte",
    "title": "7  Modellfit",
    "section": "7.20 Hebelwerte",
    "text": "7.20 Hebelwerte\n\n\n\n\n\n\n\n\nStreudiagramm der ADCS-MCI-ADL scores gegen ADAS-cos scores\n\n\n\n\n\n\n\n\n\nHebelwerte der jeweiligen \\(x_i\\)s\n\n\n\n\n\n\n\n\n\nHebelwerte der jeweiligen Datenpunkte"
  },
  {
    "objectID": "slm_model_fit.html#dffits",
    "href": "slm_model_fit.html#dffits",
    "title": "7  Modellfit",
    "section": "7.21 DFFITS",
    "text": "7.21 DFFITS\nMit Hilfe der Hebelwerte lassen sich verschiedene Maße erstellen um den Einfluss von Datenpunkten auf das Modell zu überprüfen. Ein Maß wird als bezeichnet (siehe Gleichung 7.1)\n\\[\n(DFFITS)_i = \\frac{\\hat{y}_i - \\hat{y}_{i(i)}}{\\sqrt{\\hat{\\sigma}^2h_i}}\n\\tag{7.1}\\]\nIm Zähler kommen vin Gleichung 7.1 zweimal vorhergesagte \\(y\\)-Werte vor. \\(\\hat{y}_i\\) ist dabei der ganz normale Vorhersagewert der uns mittlerweile schon mehrfach begegnet ist. Der zweite Wert \\(\\hat{y}_{i(i)}\\) bezeichnet den vorhergesagten Wert aus dem Modell aus dem der Wert \\(y_i\\) weggelassen wurde. D.h, dass Modell ist mit einem Wert weniger gefittet worden. Daher misst die Differenz \\(\\hat{y}_i - \\hat{y}_{i(i)}\\) den Unterschied in den Vorhersagewerte zwischen zwei Modellen bei denen einmal der Wert \\(y_i\\) zum fitten verwendet wurde und einmal wenn \\(y_i\\) nicht zum fitten verwendet wurde. Umso größer der Unterschied zwischen diesen beiden Werte umso größer ist der Einfluss des Wertes \\(y_i\\) auf den Modellfit. Den Nenner von Gleichung 7.1 lassen wir mal fallen, da es sich dabei nur um einen Normierungswert handelt. Dementsprechend, wird mittels DFFITS für jeden Datenpunkt ein Wert ermittelt und umso größer dieser Wert ist umso größer ist der Einfluss des jeweiligen Datenpunktes auf den Modellfit.\nIm idealen Fall sollte alle Datenpunkt ungefähr den gleichen Einfluss haben und einzelne Datenpunkte die einen übermäßig großen Einfluss auf das Modell haben sollten noch einmal genauer inspiziert werden.\n\n\n\n\n\n\nTipp\n\n\n\nAls Daumenregel, kann für kleine bis mittlere Datensätze ein DFFITS von \\(\\approx 1\\) auf Probleme hindeuten, während bei großen Datensätzen \\(\\approx 2\\sqrt{k/N}\\) als Orientierungshilfe verwendet werden kann (k := Anzahl der Prediktoren, N := Stichprobengröße).\n\n\n\n\n\n\n\n\nWarnung\n\n\n\nWenn ein Wert außerhalb der Daumenregel liegt, heißt das nicht, dass er automatisch ausgeschlossen werden muss/soll, sondern lediglich inspiziert werden sollte und das Modell mit und ohne diesen Wert interpretiert werden sollte.\n\n\nIn R können die DFFITS werden mittels der dffits()-Funktion berechnet werden. Als Parameter erwartet dffits() das gefittete lm()-Objekt. Ähnlich wie bei den Residuen, werden die DFFITS-Werte gegen die vorhergesagten \\(y_i\\)-Werte graphisch abgetragen um die Wert zu inspizieren und Probleme in der Modellspezifikation zu identifizieren.\n\nplot(adl$y_hat, dffits(mod),\n     ylim=c(-2,2),\n     xlab=expression(hat(y)[i]),\n     ylab='DFFIT-Wert')\nabline(h=c(-1,1), col='red', lty=2)\n\n\n\n\nAbbildung 7.1: Beispiel für DFFITS gegen \\(\\hat{y}_i\\)\n\n\n\n\nIn Abbildung 7.1 sind die DFFITS-Werte gegen die vorhergesagten Werte \\(\\hat{y}_i\\) abgetragen und zusätzlich die Daumenregel \\(\\pm1\\) eingezeichnet. Hier ist ein Wert nur gerade so außerhalb des vorgeschlagenen Bereichs. Hier könnte daher sich dieser Datenpunkt noch einmal genauer angeschaut werden, ob bei Ausschluß des Wertes es zu einer qualitativ anderen Interpretation der Daten kommt oder ob bespielsweise Übertragungsfehler für diesen Wert vorliegen oder sonstige Gründe."
  },
  {
    "objectID": "slm_model_fit.html#cooks-abstand",
    "href": "slm_model_fit.html#cooks-abstand",
    "title": "7  Modellfit",
    "section": "7.22 Cooks-Abstand",
    "text": "7.22 Cooks-Abstand\nEin Maß um den Einfluss von einzelnen Datenpunkten auf die Vorhersagewerte \\(\\hat{y}_i\\) über alle Werte abzuschätzen.\n\\[\nD_i = \\frac{\\sum_{j=1}^N(\\hat{y_j} - \\hat{y}_{j(i)})}{k\\hat{\\sigma}^2}\n\\]\n\n7.22.1 Daumenregel\n\\(D_i > 1\\)\n\n\n7.22.2 In R\ncooks.distance()"
  },
  {
    "objectID": "slm_model_fit.html#cooks-abstand-plot",
    "href": "slm_model_fit.html#cooks-abstand-plot",
    "title": "7  Modellfit",
    "section": "7.23 Cooks-Abstand plot",
    "text": "7.23 Cooks-Abstand plot\n\n\n\n\n\nCook’s \\(D_i\\) gegen \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#dfbetas",
    "href": "slm_model_fit.html#dfbetas",
    "title": "7  Modellfit",
    "section": "7.24 DFBETAS",
    "text": "7.24 DFBETAS\nEin Maß für die Veränderung der \\(\\beta\\)-Koeffizienten durch einzelne Datenpunkte \\(i\\).\n\\[\n(DFBETAS)_{k(i)} = \\frac{\\hat{\\beta}_k - \\hat{\\beta}_{k(i)}}{\\sqrt{\\hat{\\sigma}^2c_{kk}}}\n\\]\n\n7.24.1 Daumenregel\nFür kleine bis mittlere Datensätze \\(\\approx 1\\)\nFür große Datensätze \\(\\approx 2/\\sqrt{N}\\)\n\n\n7.24.2 In R\ndfbeta()3"
  },
  {
    "objectID": "slm_model_fit.html#dfbetas-1",
    "href": "slm_model_fit.html#dfbetas-1",
    "title": "7  Modellfit",
    "section": "7.25 DFBETAS",
    "text": "7.25 DFBETAS\n\n\n\n\n\nDFBETA-Werte für \\(\\beta_0\\) und \\(\\beta_1\\) gegen \\(\\hat{y}_i\\)"
  },
  {
    "objectID": "slm_model_fit.html#zusammenfassung",
    "href": "slm_model_fit.html#zusammenfassung",
    "title": "7  Modellfit",
    "section": "7.26 Zusammenfassung",
    "text": "7.26 Zusammenfassung\n\nÜbersicht über die verschiedene Einflussmaße zur Bewertung der Modellgüte\n\n\nTyp\nVeränderung\nDaumenregel\n\n\n\n\n\\((DFFITS)_i\\)\nVorhersagewert i\n\\(2\\sqrt{k/N}\\)\n\n\nCook\nDurchschnittliche Vorhersagewerte\n\\(>1\\)\n\n\n\\((DFBETAS)_{k(i)}\\)\nKoeffizient i\n\\(2\\sqrt{N}\\)\n\n\n\\(e_{Ti}\\)\nResiduum i\nt-Verteilung(n-k-2)"
  },
  {
    "objectID": "slm_model_fit.html#diagnoseplots-in-r-mit-plotmod",
    "href": "slm_model_fit.html#diagnoseplots-in-r-mit-plotmod",
    "title": "7  Modellfit",
    "section": "7.27 Diagnoseplots in R mit plot(mod)",
    "text": "7.27 Diagnoseplots in R mit plot(mod)\n\nplot(mod)"
  },
  {
    "objectID": "slm_model_fit.html#zum-nacharbeiten-1",
    "href": "slm_model_fit.html#zum-nacharbeiten-1",
    "title": "7  Modellfit",
    "section": "7.28 Zum Nacharbeiten",
    "text": "7.28 Zum Nacharbeiten\nAltman und Krzywinski (2016a) Fox (2011, p.294–302)\n\n7.28.1 Weiterführendes\nYoung (2019)\n\n\n\n\nAltman, Naomi, und Martin Krzywinski. 2016a. „Points of significance: Analyzing outliers: influential or nuisance“. Nature Methods 13 (4): 281–82.\n\n\n———. 2016b. „Points of significance: regression diagnostics“. Nature Methods 13 (5): 385–86.\n\n\nFox, John. 2011. An R companion to applied regression. 2. Aufl. SAGE Publication Inc., Thousand Oaks.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York.\n\n\nYoung, Alwyn. 2019. „Channeling fisher: Randomization tests and the statistical insignificance of seemingly significant experimental results“. The Quarterly Journal of Economics 134 (2): 557–98."
  },
  {
    "objectID": "slm_prediction.html#vorhergesagte-werte-haty_i",
    "href": "slm_prediction.html#vorhergesagte-werte-haty_i",
    "title": "8  Vorhersage",
    "section": "8.1 Vorhergesagte Werte \\(\\hat{y}_i\\)",
    "text": "8.1 Vorhergesagte Werte \\(\\hat{y}_i\\)\n\n\n\nWenn ein einfaches lineares Modell gefittet wurde ist eine zentrale Frage welche Vorhersagen anhand des Modell getroffen werden können. Die Vorhersagen \\(\\hat{y}_i\\) liegen auf der vorhergesagten Regressionsgerade und berechnen sich nach dem Modell für einen gegeben \\(x\\)-Wert.\n\\[\n\\hat{y} = \\hat{\\beta_0} + \\hat{\\beta_0} x\n\\]\nWie schon mehrfach besprochen unterliegt die Regressionsgerade inherent der Unsicherheit bezüglich der geschätzen Modellkoeffizienten \\(\\hat{\\beta}_0\\) und \\(\\hat{\\beta}_1\\). Diese Unsicherheit überträgt sich auf die geschätzen Werte \\(\\hat{y}_i\\) und muss daher bei deren Interpretation berücksichtigt werden.\nIn Abbildung 8.1 sind die bereits behandelten Sprungdaten gegen die Anlaufgeschwindigkeiten zusammen mit der Regressionsgeraden und vorhergesagten Werten (rot) abgetragen.\n\n\n\n\n\nAbbildung 8.1: Vorhersagewerte \\(\\hat{y}_i\\) (rote Punkte) für die Sprungdaten.\n\n\n\n\nIn R können die vorhergesagten Werte des mittels lm() gefitteten Modells mit der Hilfsfunktion predict() bestimmt werden. Wenn der Funktion predict() keine weiteren Parameter außer dem lm-Objekt übergeben werden, berechnet predict() die vorhergesagten Werte \\(\\hat{y}_i\\) für alle die \\(x\\)-Werte die auch zum fitten des Modells benutzt wurden. Die Reihenfolge der Werte \\(\\hat{y}_i\\) enspricht dabei den Werten im Original-data.frame().\n\npredict(mod)[1:5] \n\n       1        2        3        4        5 \n4.523537 4.725140 4.856256 4.761778 5.416207 \n\n\nWir haben uns hier nur die ersten fünf Werte ausgeben lassen, da nur demonstriert werden soll wie die predict()-Funktion angewendet werden kann. Um eine Anwendung zu geben, so können mittels predict() die Residuen auch von Hand ohne die resid()-Funktion erhalten werden.\n\n(jump$jump_m - predict(mod))[1:5]\n\n          1           2           3           4           5 \n-0.16267721 -0.41248842 -0.29359256 -0.01047071  0.09927500 \n\nresid(mod)[1:5]\n\n          1           2           3           4           5 \n-0.16267721 -0.41248842 -0.29359256 -0.01047071  0.09927500 \n\n\nWiederum nur zur Demonstration die ersten fünf Wert um die Äquivalenz der beiden Methoden zu demonstrieren.\nMeistens liegt das Interesse jedoch weniger auf den vorhergesagten Werten \\(\\hat{y}_i\\) für die gemessenen Werte, sondern es sollen Werte vorhergesagt werden für \\(x\\)-Werte die nicht im Datensatz enthalten sind. Operational ändert sich nichts, es wird immer noch das gefittete Modell verwendetet und es müssen lediglich neue \\(x\\)-Werte übergeben werden.\nIn R kann dies mittels des zweite Parameter in predict() erreicht werden. Soll zum Beispiel die Sprungweite für eine Anlaufgeschwindigkeit von \\(v = 11.5[m/s]\\) berechnen werden, muss zunächst ein neues tibble() erstellt werden, welches den gewünschten \\(x\\)-Wert enthält. Dabei muss der Spaltenname in dem neuen tibble() demjenigen im Original-tibble() entsprechen. Ansonsten funktioniert die Anwendung von predict() nicht.\n\ndf <- tibble(v_ms = 11.5)\ndf\n\n# A tibble: 1 x 1\n   v_ms\n  <dbl>\n1  11.5\n\n\nDieses tibble() kann nun zusammen mit dem lm()-Objekt an predict() übergeben werden.\n\npredict(mod, newdata = df)\n\n       1 \n8.614136 \n\n\nD.h., bei einer Anlaufgeschwindigkeit von \\(v = 11.5[m/s]\\) ist anhand des Modells eine Sprungweite von \\(8.6m\\) zu erwarten."
  },
  {
    "objectID": "slm_prediction.html#unsicherheit-in-der-vorhersage",
    "href": "slm_prediction.html#unsicherheit-in-der-vorhersage",
    "title": "8  Vorhersage",
    "section": "8.2 Unsicherheit in der Vorhersage",
    "text": "8.2 Unsicherheit in der Vorhersage\nWie schon angesprochen ist unser Modell natürlich mit Unsicherheiten behaftet. Diese drücken sich in den Standardfehler für die beiden Koeffizienten \\(\\hat{\\beta_0}\\) und \\(\\hat{\\beta_1}\\) (siehe Tabelle 8.1).\n\n\n\n\nTabelle 8.1: Modellparameter und Standardfehler\n\n\n\nSchätzer\n\\(s_e\\)\n\n\n\n\n(Intercept)\n-0.14\n0.23\n\n\nv_ms\n0.76\n0.02\n\n\n\n\n\n\nDer vorhergesagte Wert \\(\\hat{y}\\) ist daher für sich alleine ist noch nicht brauchbar, da auch Informationen über dessen Unsicherheit notwendig sind um die Ergebnisse korrekt zu interpretieren.\nEs können zwei unterschiedliche Anwendungsfälle voneinander unterschieden werden.\n\nDer mittlere, erwartete Wert \\(\\hat{\\bar{y}}_{neu}\\)\nDie Vorhersage eines einzelnen Wertes \\(\\bar{y}_{neu}\\)\n\nIm konkreten Fall werden damit zwei unterschiedliche Fragestellungen beantwortet. Im 1. Fall lautet die Frage, ich habe eine Trainingsgruppe und möchte wissen was der mittlere Wert der Gruppe anhand des Modells ist, wenn alle eine bestimmte Anlaufgeschwindigkeit \\(v_{neu}\\) haben. Im 2. Fall lautet die Frage welche Weite eine einzelne Athletin für die Anlaufgeschwindigkeit \\(v_{neu}\\) springen sollte. In beiden Fällen werden keiner genau den Wert des Regressionsmodells treffen, aber im 1. Fall der Gruppe werden sich Streuungen nach oben bzw. nach unten gegenseitig im Schnitt ausbalancieren während im 2. Fall der einzelnen Athletin dies nicht der Fall ist. Daher hat die Vorhersage im 2. Fall eine höhere Unsicherheit. Diese Unterschied sollte sich dementsprechend in den Varianzen der beiden Vorhersagen wiederspiegeln.\nWie bereits erwähnt, der vorhergesagte Wert \\(\\hat{y}_{neu}\\) ist in beiden Fällen gleich und entsprecht der oben beschriebenen Methode anhand des Modell \\(y_{neu} = \\hat{\\beta}_0 + \\hat{\\beta}_1 \\times x_{\\text{neu}}\\).\nFür den erwarteten Mittelwert errechnet sich die Varianz nach:\n\\[\\begin{equation}\nVar(\\hat{\\bar{y}}_{neu}) = \\hat{\\sigma}^2 \\left[\\frac{1}{n} + \\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\\right] = \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}^2\n\\end{equation}\\]\nDas dazugehörige Konfidenzintervall errechnet sich danach mittels:\n\\[\\begin{equation}\n\\hat{\\bar{y}}_{neu} \\pm q_{t(1-\\alpha/2;n-2)} \\times \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}\n\\end{equation}\\]\nDie Varianz für die Vorhersage eines einzelnen Wertes errechnet sich:\n\\[\\begin{equation}\nVar(\\hat{y}_{neu}) = \\hat{\\sigma}^2 \\left[1 + \\frac{1}{n} + \\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\\right] = \\hat{\\sigma}^2 + \\hat{\\sigma}_{\\hat{\\bar{y}}_{neu}}^2 = \\hat{\\sigma}_{\\hat{y}_{neu}}^2\n\\end{equation}\\]\nWas wiederum zu dem folgenden Konfidenzintervall führt:\n\\[\\begin{equation}\n\\hat{y}_{neu} \\pm q_{t(1-\\alpha/2;n-2)} \\times \\hat{\\sigma}_{\\hat{y}_{neu}}\n\\end{equation}\\]\nIn beiden Fällen ist der Term\n\\[\n\\frac{(x_{neu} - \\bar{x})^2}{\\sum(x_i - \\bar{x})^2}\n\\]\nenthalten. Anhand des Zählers kann abgeleitet werden, dass die Unsicherheit der Vorhersage mit dem Abstand vom Mittelwert der \\(x\\)-Werte zunimmt. Rein heuristisch macht dies Sinn, da davon ausgegangen werden kann, dass um den Mittelwert der \\(x\\)-Werte auch die meiste Information über \\(y\\) vorhanden ist und dementsprechend umso weiter die Werte sich vom \\(\\bar{x}\\) entfernen die Information abnimmt. Im Nenner ist wiederum wie auch beim Standardfehler \\(\\sigma_{\\beta_1}\\) des Steigungskoeffizienten \\(\\beta_1\\) zu sehen, dass die Varianz abnimmt mit der Streuung der \\(x\\)-Werte. Daher, wenn eine Vorhersage in einem bestimmten Bereich von \\(x\\)-Werten durchgeführt werden soll, dann sollte darauf geachtet werden möglichst diesen Bereich auch zu samplen um die Unsicherheit so klein wie möglich zu halten."
  },
  {
    "objectID": "slm_prediction.html#vorhersagen-in-r-mit-predict",
    "href": "slm_prediction.html#vorhersagen-in-r-mit-predict",
    "title": "8  Vorhersage",
    "section": "8.3 Vorhersagen in R mit predict()",
    "text": "8.3 Vorhersagen in R mit predict()\n\n8.3.1 Erwarteter Mittelwert\n\ndf <- data.frame(v_ms = 11.5) # oder tibble(v_ms = 11.5)\npredict(mod, newdata = df, interval = 'confidence')\n\n       fit      lwr      upr\n1 8.614136 8.482039 8.746234\n\n\n\n\n8.3.2 Individuelle Werte\n\npredict(mod, newdata = df, interval = 'prediction')\n\n       fit      lwr      upr\n1 8.614136 8.118445 9.109827"
  },
  {
    "objectID": "slm_prediction.html#konfidenzintervalle-graphisch",
    "href": "slm_prediction.html#konfidenzintervalle-graphisch",
    "title": "8  Vorhersage",
    "section": "8.4 Konfidenzintervalle graphisch",
    "text": "8.4 Konfidenzintervalle graphisch\n\n\n\n\n\nWeiterführende Literatur sind Kutner u. a. (2005)"
  },
  {
    "objectID": "slm_prediction.html#r2-und-root-mean-square",
    "href": "slm_prediction.html#r2-und-root-mean-square",
    "title": "8  Vorhersage",
    "section": "8.5 \\(R^2\\) und Root-mean-square",
    "text": "8.5 \\(R^2\\) und Root-mean-square"
  },
  {
    "objectID": "slm_prediction.html#einfaches-modell",
    "href": "slm_prediction.html#einfaches-modell",
    "title": "8  Vorhersage",
    "section": "8.6 Einfaches Modell",
    "text": "8.6 Einfaches Modell\n\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n\n\nCall:\nlm(formula = y ~ x, data = simple)\n\nResiduals:\n      1       2       3       4 \n-0.5817  0.9898 -0.2345 -0.1736 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.8414     0.7008   2.628    0.119\nx             0.4574     0.3746   1.221    0.346\n\nResidual standard error: 0.8376 on 2 degrees of freedom\nMultiple R-squared:  0.4271,    Adjusted R-squared:  0.1406 \nF-statistic: 1.491 on 1 and 2 DF,  p-value: 0.3465"
  },
  {
    "objectID": "slm_prediction.html#nochmal-abweichungen",
    "href": "slm_prediction.html#nochmal-abweichungen",
    "title": "8  Vorhersage",
    "section": "8.7 Nochmal Abweichungen",
    "text": "8.7 Nochmal Abweichungen\n\nGesamtvarianz: \\[\nSSTO := \\sum_{i=1}^N (y_i - \\bar{y})^2\n\\]\nRegressionsvarianz: \\[\nSSR :=\\sum_{i=1}^N(\\hat{y}_i - \\bar{y})^2\n\\]\nResidualvarianz: \\[\nSSE := \\sum_{i=1}^N (y_i - \\hat{y}_i)^2\n\\]\n\n\n\n\n\n\nMinimalmodell der Abweichungen"
  },
  {
    "objectID": "slm_prediction.html#verhältnis-von-ssr-zu-ssto",
    "href": "slm_prediction.html#verhältnis-von-ssr-zu-ssto",
    "title": "8  Vorhersage",
    "section": "8.8 Verhältnis von \\(SSR\\) zu \\(SSTO\\)",
    "text": "8.8 Verhältnis von \\(SSR\\) zu \\(SSTO\\)\n\n\n\n\n\nPerfekter Zusammenhang\n\n\n\n\n\\[\n\\frac{SSR}{SSTO} = 1\n\\]\n\n\n\n\n\nKein Zusammenhang\n\n\n\n\n\\[\n\\frac{SSR}{SSTO} = 0\n\\]"
  },
  {
    "objectID": "slm_prediction.html#determinationskoeffizient-r2",
    "href": "slm_prediction.html#determinationskoeffizient-r2",
    "title": "8  Vorhersage",
    "section": "8.9 Determinationskoeffizient \\(R^2\\)",
    "text": "8.9 Determinationskoeffizient \\(R^2\\)\nEs gilt: \\(SSTO = SSR + SSE\\)\n\\[\nR^2 = \\frac{SSR}{SSTO} = 1 - \\frac{SSE}{SSTO} \\in [0,1]\n\\] 1\n\n8.9.1 Korrigierter Determinationskoeffizient \\(R_a^2\\)\n\\[\nR_a^2 = 1 - \\frac{\\frac{SSE}{n-p}}{\\frac{SSTO}{n-1}} = 1 - \\frac{n-1}{n-p}\\frac{SSE}{SSTO}\n\\]\n\n\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "mlm_title.html",
    "href": "mlm_title.html",
    "title": "Multiple Regression",
    "section": "",
    "text": "Im folgenden wird das Modell der einfachen linearen Regression erweitert indem zusätzliche Terme in das Modell aufgenommen werden. Die Prinzipien bleiben dabei jedoch weitestgehendst gleich und können direkt auf den komplizierteren Fall der multiplen Regression übertragen werden. Im Laufe der Erweiterung des Modells wird sich dabei wird herausstellen, dass neben mehreren kontinuierlichen Variablen auch nominale Faktoren in das Modell intergriert werden können. Daraus entsteht ein sehr flexibler Modellapparat, der in den verschiedensten Zusammenhängen angewendet werden kann."
  },
  {
    "objectID": "mlm_basics.html#bedeutung-der-koeffizienten-bei-der-multiplen-regression",
    "href": "mlm_basics.html#bedeutung-der-koeffizienten-bei-der-multiplen-regression",
    "title": "9  Einführung",
    "section": "9.1 Bedeutung der Koeffizienten bei der multiplen Regression",
    "text": "9.1 Bedeutung der Koeffizienten bei der multiplen Regression\nUm die Bedeutung der Regressionskoeffzienten bei der multiple Regression besser zu verstehen ist es von Vorteil sich noch einmal die Bedeutung der Koeffizienten im einfachen Regressionsmodell zu vergegenwärtigen (siehe Abbildung 9.1).\n\n\n\n\n\nAbbildung 9.1: Beispiel für eine einfache Regression und der resultierenden Regressiongeraden\n\n\n\n\nBei der einfachen Regression haben mittels der Methode der kleinsten Quadrate eine Regressiongerade durch unsere Punktwolke gelegt. Dabei haben wir die Regressionsgerade so gewählt, dass die senkrechten Abstände der beobachteten Punkte von der Regressionsgerade minimiert werden bzw. die Abstände zwischen denen auf der Gerade liegenden, vorhergesagten Werte \\(\\hat{y}_i\\) und den beobachteten Wert \\(y_i\\).\nWenn wir nun den Übergang von einer Prädiktorvariablenzum nächstkomplizierteren Fall nehmen mit zwei Prädiktorvariablen \\(x_1\\) und \\(x_2\\), dann wäre eine mögliche Darstellungsform der Daten eine Punktwolke im dreidimensionalen Raum (siehe Abbildung 9.2 (a)).\n\n\n\n\n\n\n\n(a) 3D Punktwolke\n\n\n\n\n\n\n\n(b) 3D Punktwolke mit gefitteter Ebene\n\n\n\n\nAbbildung 9.2: Punktwolken bei der multiple Regression\n\n\nDa jetzt eine einzelne Gerade nicht mehr in der Lage ist die Daten zu fitten, ist die nächst Möglichkeit eine Ebene die in die Punktwolke gelegt wird (siehe Abbildung 9.2 (b)). Dies ermöglicht dann genau die gleiche Herangehensweise wie bei der einfachen linearen Regression anzuwenden. Als Zielgröße wird aus den möglichen Ebenen diejenigen gesucht deren vorhergesagten, auf der Ebene liegenden Punkte \\(\\hat{y}_i\\) die geringsten senkrechten Abstand zu den beobachteten Punkten \\(y_i\\) haben. Anders, wir suchen diejenigen Ebene durch die Punktwolke deren Summe der quadrierten Residuen \\(e_i = y_i - \\hat{y}_i\\) minimal ist.\nDiese Herangehensweise hat den Vorteil, dass sie zum einem die einfache lineare Regression als Spezialfall mit \\(K=1\\) beinhaltet und sich beliebig erweitern lässt mit der Einschränkung, dass bei \\(K>2\\) die dreidimenionale Darstellung mittels einer Grafik nicht mehr möglich ist. Das Prinzip der Minimierung der Abweichungen von \\(\\hat{y}_i\\) zu \\(y\\) bleibt aber immer erhalten. Zusammenfassend hat dieser Ansatz somit die folgenden Vorteile:\n\nDie Berechnungen bleiben alle gleich\nAbweichungen \\(\\hat{\\epsilon_i}\\) sind jetzt nicht mehr Abweichungen von einer Gerade sondern von einer \\(K\\)-dimensionalen Hyperebene. Die Eigenschaften der Residuen bleiben aber alle erhalten.\nDie Modellannahmen bleiben gleich: Unabhängige \\(y_i\\) und \\(\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\) iid\nInferenz für die Koeffizienten mittels \\(t_k = \\frac{\\hat{\\beta}_k}{s_k} \\sim t(N-K-1)\\) (Konfidenzintervall dito)\nKonzepte für die Vorhersage bleiben erhalten\nModelldiagnosetools bleiben alle erhalten\n\nAls nächster Schritt versuchen wir nun die Interpretation der Koeffizienten im multiplen Regressionsmodell besser zu verstehen."
  },
  {
    "objectID": "mlm_basics.html#einfaches-beispiel",
    "href": "mlm_basics.html#einfaches-beispiel",
    "title": "9  Einführung",
    "section": "9.2 Einfaches Beispiel",
    "text": "9.2 Einfaches Beispiel\n\\[\\begin{align*}\ny_i &= \\beta_0 + \\beta_1 \\cdot x_1 + \\beta_2 \\cdot x_2 + \\epsilon_i \\\\\n\\beta_0 &= 1 ,\\beta_1 = 3, \\beta_2 = 0.7 \\\\\n\\epsilon_i &\\sim N(0,\\sigma = 0.5)\n\\end{align*}\\]\n\nN <- 50 # Anzahl Datenpunkte\nbeta_0 <- 1\nbeta_1 <- 3\nbeta_2 <- 0.7\nsigma <- 0.5\nset.seed(123)\ndf <- tibble(\n  x1 = runif(N, -2, 2),\n  x2 = runif(N, -2, 2),\n  y = beta_0 + beta_1*x1 + beta_2*x2 + \n    rnorm(N, 0, sigma)) \n\n\n\n\n\n\nEinfacher Zusammenhang y~x1\n\n\n\n\n\n\n\n\n\nEinfacher Zusammenhang y~x2"
  },
  {
    "objectID": "mlm_basics.html#wie-sieht-der-fit-aus",
    "href": "mlm_basics.html#wie-sieht-der-fit-aus",
    "title": "9  Einführung",
    "section": "9.3 Wie sieht der Fit aus?",
    "text": "9.3 Wie sieht der Fit aus?\n\n\n\nCall:\nlm(formula = y ~ x1 + x2, data = df)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.20883 -0.26741 -0.00591  0.27315  1.01322 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.07674    0.06552   16.43  < 2e-16 ***\nx1           2.96537    0.05604   52.91  < 2e-16 ***\nx2           0.70815    0.05961   11.88 9.27e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4604 on 47 degrees of freedom\nMultiple R-squared:  0.9849,    Adjusted R-squared:  0.9842 \nF-statistic:  1529 on 2 and 47 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "mlm_basics.html#was-bedeuten-die-einzelnen-koeffizienten",
    "href": "mlm_basics.html#was-bedeuten-die-einzelnen-koeffizienten",
    "title": "9  Einführung",
    "section": "9.4 Was bedeuten die einzelnen Koeffizienten?",
    "text": "9.4 Was bedeuten die einzelnen Koeffizienten?\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n1.077\n0.066\n\n\nx1\n2.965\n0.056\n\n\nx2\n0.708\n0.060\n\n\n\n\n\nDer Unterschied in der abhängigen Variablen, wenn zwei Objekte sich in \\(x_i\\) um eine Einheit unterscheiden und die paarweise gleichen Werte in den verbleibenden \\(x_j, j \\neq i\\) annehmen."
  },
  {
    "objectID": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination",
    "href": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination",
    "title": "9  Einführung",
    "section": "9.5 Was bedeuten die Koeffizienten in Kombination?",
    "text": "9.5 Was bedeuten die Koeffizienten in Kombination?\n\n9.5.1 Full model\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n1.077\n0.066\n\n\nx1\n2.965\n0.056\n\n\nx2\n0.708\n0.060\n\n\n\n\n\n\n\n9.5.2 um x2 bereinigt\n\nmod_x1_x2 <- lm(x1 ~ x2, df)\nres_mod_x1_x2 <- resid(mod_x1_x2)\nmod_x1_res <- lm(y ~ res_mod_x1_x2, df)\n\n\n\n              Estimate Std. Error t value\n(Intercept)       1.25       0.16    7.61\nres_mod_x1_x2     2.97       0.14   20.97\n\n\n\n\n9.5.3 um x1 bereinigt\n\nmod_x2_x1 <- lm(x2 ~ x1, df)\nres_mod_x2_x1 <- resid(mod_x2_x1)\nmod_x2_res <- lm(y ~ res_mod_x2_x1, df)\n\n\n\n              Estimate Std. Error t value\n(Intercept)       1.25       0.51    2.44\nres_mod_x2_x1     0.71       0.47    1.51"
  },
  {
    "objectID": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination-1",
    "href": "mlm_basics.html#was-bedeuten-die-koeffizienten-in-kombination-1",
    "title": "9  Einführung",
    "section": "9.6 Was bedeuten die Koeffizienten in Kombination?",
    "text": "9.6 Was bedeuten die Koeffizienten in Kombination?\n\n\\(\\hat{\\beta}_1\\): Wenn ich \\(x_2\\) weiß, welche zusätzlichen Informationen bekomme ich durch \\(x_1\\)\n\\(\\hat{\\beta}_2\\): Wenn ich \\(x_1\\) weiß, welche zusätzlichen Informationen bekomme ich durch \\(x_2\\)\n\nIn Beispiel nicht problematisch, weil nach Konstruktion \\(x_1\\) und \\(x_2\\) unabhängig voneinander sind:\n\nround(cor(df),3)\n\n      x1    x2     y\nx1 1.000 0.078 0.969\nx2 0.078 1.000 0.289\ny  0.969 0.289 1.000"
  },
  {
    "objectID": "mlm_basics.html#added-variable-plots",
    "href": "mlm_basics.html#added-variable-plots",
    "title": "9  Einführung",
    "section": "9.7 Added-variable plots",
    "text": "9.7 Added-variable plots\n\n\n\n\n\nZusammenhang zwischen y und x2 bereinigt um den Einfluß von x1."
  },
  {
    "objectID": "mlm_basics.html#added-variable-plots-mit-caravplots",
    "href": "mlm_basics.html#added-variable-plots-mit-caravplots",
    "title": "9  Einführung",
    "section": "9.8 Added-variable plots mit car::avPlots()",
    "text": "9.8 Added-variable plots mit car::avPlots()\n\ncar::avPlots(mod, ~x2)"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-ich-einen-prädiktor-weg-lasse",
    "href": "mlm_basics.html#was-passiert-wenn-ich-einen-prädiktor-weg-lasse",
    "title": "9  Einführung",
    "section": "9.9 Was passiert wenn ich einen Prädiktor weg lasse?",
    "text": "9.9 Was passiert wenn ich einen Prädiktor weg lasse?\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n1.077\n0.066\n\n\nx1\n2.965\n0.056\n\n\nx2\n0.708\n0.060\n\n\n\n\n\n\ncoef(lm(y ~ x1, df))\n\n(Intercept)          x1 \n   1.007466    3.017589 \n\ncoef(lm(y ~ x2, df))\n\n(Intercept)          x2 \n  1.3377771   0.9555316 \n\n\nIn unserem Beispiel wieder nicht viel, da die Variablen unabhängig (orthogonal) voneinander sind."
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren",
    "title": "9  Einführung",
    "section": "9.10 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.10 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\n\n\nAusschnitt von Körperfettdaten\n\n\ntriceps\nthigh\nmidarm\nbody_fat\n\n\n\n\n19.5\n43.1\n29.1\n11.9\n\n\n24.7\n49.8\n28.2\n22.8\n\n\n30.7\n51.9\n37.0\n18.7\n\n\n29.8\n54.3\n31.1\n20.1\n\n\n19.1\n42.2\n30.9\n12.9\n\n\n25.6\n53.9\n23.7\n21.7\n\n\n\n\n\n1"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-1",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-1",
    "title": "9  Einführung",
    "section": "9.11 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.11 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\nGGally::ggpairs(bodyfat) + theme(text = element_text(size = 10))\n\n\n\n\nKorrelationsmatrize"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-2",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-2",
    "title": "9  Einführung",
    "section": "9.12 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.12 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\n# Alle drei Prädiktoren\nmod_full <- lm(body_fat ~ triceps + thigh + midarm, bodyfat)\n# ohne Arm\nmod_wo_midarm <- lm(body_fat ~ triceps + thigh, bodyfat)\n# Ohne Oberschenkel\nmod_wo_thigh <- lm(body_fat ~ triceps + midarm, bodyfat)\n# Ohne Triceps\nmod_wo_triceps <- lm(body_fat ~ thigh + midarm, bodyfat)"
  },
  {
    "objectID": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-3",
    "href": "mlm_basics.html#was-passiert-wenn-prädiktoren-stark-miteinander-korrelieren-3",
    "title": "9  Einführung",
    "section": "9.13 Was passiert wenn Prädiktoren stark miteinander korrelieren?",
    "text": "9.13 Was passiert wenn Prädiktoren stark miteinander korrelieren?\n\n\n\nfull model\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n117.085\n99.782\n\n\ntriceps\n4.334\n3.016\n\n\nthigh\n-2.857\n2.582\n\n\nmidarm\n-2.186\n1.595\n\n\n\n\n\n\n\n\nw/o midarm\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n-19.174\n8.361\n\n\ntriceps\n0.222\n0.303\n\n\nthigh\n0.659\n0.291\n\n\n\n\n\n\n\n\nw/o thigh\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n6.792\n4.488\n\n\ntriceps\n1.001\n0.128\n\n\nmidarm\n-0.431\n0.177\n\n\n\n\n\n\n\n\nw/o triceps\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n-25.997\n6.997\n\n\nthigh\n0.851\n0.112\n\n\nmidarm\n0.096\n0.161"
  },
  {
    "objectID": "mlm_basics.html#multikollinearität",
    "href": "mlm_basics.html#multikollinearität",
    "title": "9  Einführung",
    "section": "9.14 Multikollinearität2",
    "text": "9.14 Multikollinearität2\n\nGroße Änderungen in den Koeffizienten wenn Prädiktoren ausgelassen/eingefügt werden\nKoeffizienten haben eine andere Richtung als erwartet\nHohe (einfache) Korrelationen zwischen Prädiktoren\nBreite Konfidenzintervalle für “wichtige” Prädiktoren \\(b_j\\)\n\n\\[\n\\widehat{\\text{Var}}(b_j) = \\frac{\\hat{\\sigma}^2}{(n-1)s_j^2}\\frac{1}{1-R_j^2}\n\\]\n\\(R_j^2\\) = Multipler Korrelationskoeffizient der Prädiktoren auf Prädiktorvariable \\(j\\)."
  },
  {
    "objectID": "mlm_basics.html#variance-inflation-factor-vif",
    "href": "mlm_basics.html#variance-inflation-factor-vif",
    "title": "9  Einführung",
    "section": "9.15 Variance Inflation Factor (VIF)",
    "text": "9.15 Variance Inflation Factor (VIF)\n\\[\n\\text{VIF}_j = \\frac{1}{1-R_j^2}\n\\]\n\n\n\n\n\n\nTipp\n\n\n\nWenn VIF > 10 ist, dann deutet dies auf hohe Multikollinearität hin.\n\n\n3"
  },
  {
    "objectID": "mlm_basics.html#variance-inflation-factor-vif-1",
    "href": "mlm_basics.html#variance-inflation-factor-vif-1",
    "title": "9  Einführung",
    "section": "9.16 Variance Inflation Factor (VIF)",
    "text": "9.16 Variance Inflation Factor (VIF)\n\ncar::vif(mod_full) \n\n triceps    thigh   midarm \n708.8429 564.3434 104.6060 \n\n\n4\nÜblicherweise wird der größte Wert betrachtet um die Multikollinearität zu bewerten."
  },
  {
    "objectID": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren",
    "href": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren",
    "title": "9  Einführung",
    "section": "9.17 Wenn Prädiktoren sich gegenseitig maskieren5",
    "text": "9.17 Wenn Prädiktoren sich gegenseitig maskieren5\n\n\n\n\n\nx_pos maskiert den Einfluss von x_neg"
  },
  {
    "objectID": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren-1",
    "href": "mlm_basics.html#wenn-prädiktoren-sich-gegenseitig-maskieren-1",
    "title": "9  Einführung",
    "section": "9.18 Wenn Prädiktoren sich gegenseitig maskieren",
    "text": "9.18 Wenn Prädiktoren sich gegenseitig maskieren\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n0.235\n0.135\n\n\nx_pos\n0.218\n0.147\n\n\n\n\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n0.228\n0.116\n\n\nx_neg\n-0.618\n0.103\n\n\n\n\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\n\n\n\n\n(Intercept)\n0.135\n0.096\n\n\nx_pos\n0.850\n0.123\n\n\nx_neg\n-0.976\n0.099"
  },
  {
    "objectID": "mlm_basics.html#multiple-regression",
    "href": "mlm_basics.html#multiple-regression",
    "title": "9  Einführung",
    "section": "9.19 Multiple Regression",
    "text": "9.19 Multiple Regression\nAus der einfachen Regression\n\\[\ny_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i\n\\]\nwird\n\\[\ny_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\dots + \\beta_K x_{Ki} + \\epsilon_i\n\\]\nmit K Prädiktorvariablen und Multikollinearität."
  },
  {
    "objectID": "mlm_basics.html#zum-nacharbeiten",
    "href": "mlm_basics.html#zum-nacharbeiten",
    "title": "9  Einführung",
    "section": "9.20 Zum Nacharbeiten",
    "text": "9.20 Zum Nacharbeiten\nAltman und Krzywinski (2015) Kutner u. a. (2005, p.278–288) Fox (2011, p.325–327)\n\n\n\n\nAltman, Naomi, und Martin Krzywinski. 2015. „Points of significance: Multiple linear regression“. Nature Methods 12 (12): 1103–4.\n\n\nFox, John. 2011. An R companion to applied regression. 2. Aufl. SAGE Publication Inc., Thousand Oaks.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York.\n\n\nMcElreath, Richard. 2016. Statistical rethinking, A Bayesian Course with Examples in R and Stan. 1. Aufl. Boca Raton: CRC Press."
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten",
    "href": "mlm_interactions.html#beispieldaten",
    "title": "10  Interaktionseffekte",
    "section": "10.1 Beispieldaten1",
    "text": "10.1 Beispieldaten1\n\n\n\nBeispieldaten (synthetisch)\n\n\nVelocity[m/s]\nbody mass[kg]\narm span[cm]\n\n\n\n\n185.42\n68.71\n20.14\n\n\n184.08\n73.85\n21.29\n\n\n200.74\n89.43\n27.57\n\n\n170.34\n84.97\n19.88\n\n\n176.89\n82.40\n20.51\n\n\n200.68\n91.57\n29.22"
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten---deskriptiv",
    "href": "mlm_interactions.html#beispieldaten---deskriptiv",
    "title": "10  Interaktionseffekte",
    "section": "10.2 Beispieldaten - Deskriptiv",
    "text": "10.2 Beispieldaten - Deskriptiv\n\n\n\nDeskriptive Statistik der Handballdaten\n\n\n\nMean\nStd.Dev\nMin\nMax\n\n\n\n\narm_span\n184.3\n7.7\n169.4\n200.7\n\n\nbody_mass\n77.5\n10.3\n58.0\n101.1\n\n\nvel\n21.9\n2.3\n18.5\n29.2"
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten-1",
    "href": "mlm_interactions.html#beispieldaten-1",
    "title": "10  Interaktionseffekte",
    "section": "10.3 Beispieldaten",
    "text": "10.3 Beispieldaten\n\n\n\n\n\nGeschwindigkeit gegen Körpergewicht\n\n\n\n\n\n\n\n\n\nGeschwindigkeit gegen Armspannweite"
  },
  {
    "objectID": "mlm_interactions.html#beispieldaten---startmodell",
    "href": "mlm_interactions.html#beispieldaten---startmodell",
    "title": "10  Interaktionseffekte",
    "section": "10.4 Beispieldaten - Startmodell",
    "text": "10.4 Beispieldaten - Startmodell\n\\[\nY_{i} = \\beta_0 + \\beta_1 \\times \\textrm{bm}_i + \\beta_2 \\times \\textrm{as}_i + \\epsilon_i\n\\]\n\nmod_1 <- lm(vel ~ body_mass + arm_span, handball)\n\n\n\n\nModell 1\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n-1.768\n7.632\n-0.232\n0.818\n\n\nbody_mass\n0.077\n0.033\n2.359\n0.024\n\n\narm_span\n0.096\n0.044\n2.192\n0.035\n\n\n\\(\\hat{\\sigma}\\)\n1.996"
  },
  {
    "objectID": "mlm_interactions.html#modellfit",
    "href": "mlm_interactions.html#modellfit",
    "title": "10  Interaktionseffekte",
    "section": "10.5 Modellfit",
    "text": "10.5 Modellfit\n\n\n\n\n\n3D Streudiagramm"
  },
  {
    "objectID": "mlm_interactions.html#zentrierung",
    "href": "mlm_interactions.html#zentrierung",
    "title": "10  Interaktionseffekte",
    "section": "10.6 Zentrierung",
    "text": "10.6 Zentrierung\n\nhandball <- dplyr::mutate(handball,\n                          body_mass_c = body_mass - mean(body_mass),\n                          arm_span_c = arm_span - mean(arm_span))\n\n\n\n\nDeskriptive Statistik\n\n\n\nMean\nStd.Dev\n\n\n\n\narm_span\n184.29\n7.72\n\n\narm_span_c\n0.00\n7.72\n\n\nbody_mass\n77.46\n10.26\n\n\nbody_mass_c\n0.00\n10.26\n\n\nvel\n21.85\n2.31"
  },
  {
    "objectID": "mlm_interactions.html#modell-mit-zentrierten-variablen",
    "href": "mlm_interactions.html#modell-mit-zentrierten-variablen",
    "title": "10  Interaktionseffekte",
    "section": "10.7 Modell mit zentrierten Variablen",
    "text": "10.7 Modell mit zentrierten Variablen\n\nmod_2 <- lm(vel ~ body_mass_c + arm_span_c, handball)\n\n\n\n\nModell 2\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n21.852\n0.316\n69.247\n<0.001\n\n\nbody_mass_c\n0.077\n0.033\n2.359\n0.024\n\n\narm_span_c\n0.096\n0.044\n2.192\n0.035\n\n\n\\(\\hat{\\sigma}\\)\n1.996"
  },
  {
    "objectID": "mlm_interactions.html#residuen-im-zentrierten-additiven-modell",
    "href": "mlm_interactions.html#residuen-im-zentrierten-additiven-modell",
    "title": "10  Interaktionseffekte",
    "section": "10.8 Residuen im zentrierten, additiven Modell",
    "text": "10.8 Residuen im zentrierten, additiven Modell\n\n\n\n\n\nResiduenplot"
  },
  {
    "objectID": "mlm_interactions.html#added-variable-plot",
    "href": "mlm_interactions.html#added-variable-plot",
    "title": "10  Interaktionseffekte",
    "section": "10.9 Added-variable plot",
    "text": "10.9 Added-variable plot\n\n\n\n\n\nAbbildung 10.1: Added-variable Graph mit car::avPlots()"
  },
  {
    "objectID": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind",
    "href": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind",
    "title": "10  Interaktionseffekte",
    "section": "10.10 Was passiert wenn die Effekte nicht mehr nur additiv sind?",
    "text": "10.10 Was passiert wenn die Effekte nicht mehr nur additiv sind?\n\n\n\n\n\nUnterteilung von Körpergewicht und Armspannweite in Kategorien"
  },
  {
    "objectID": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind-1",
    "href": "mlm_interactions.html#was-passiert-wenn-die-effekte-nicht-mehr-nur-additiv-sind-1",
    "title": "10  Interaktionseffekte",
    "section": "10.11 Was passiert wenn die Effekte nicht mehr nur additiv sind?",
    "text": "10.11 Was passiert wenn die Effekte nicht mehr nur additiv sind?\n\n10.11.1 Neues Modell mit Interaktionen:\n\\[\nY_{i} = \\beta_0 + \\beta_1 \\times \\textrm{bm}_i + \\beta_2 \\times \\textrm{as}_i + \\beta_3 \\times \\textrm{bm}_i \\times \\textrm{as}_i + \\epsilon_i\n\\]"
  },
  {
    "objectID": "mlm_interactions.html#modellierung",
    "href": "mlm_interactions.html#modellierung",
    "title": "10  Interaktionseffekte",
    "section": "10.12 Modellierung",
    "text": "10.12 Modellierung\n\nmod_3 <- lm(vel ~ body_mass_c * arm_span_c, handball) \n\n\n\n\nModell 3\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n21.346\n0.143\n149.296\n<0.001\n\n\nbody_mass_c\n0.119\n0.015\n8.133\n<0.001\n\n\narm_span_c\n0.083\n0.019\n4.380\n<0.001\n\n\nbody_mass_c:arm_span_c\n0.021\n0.002\n12.633\n<0.001\n\n\n\\(\\hat{\\sigma}\\)\n0.868\n\n\n\n\n\n\n\n\n2"
  },
  {
    "objectID": "mlm_interactions.html#einfache-steigungen-in-vergleich",
    "href": "mlm_interactions.html#einfache-steigungen-in-vergleich",
    "title": "10  Interaktionseffekte",
    "section": "10.13 Einfache Steigungen in Vergleich",
    "text": "10.13 Einfache Steigungen in Vergleich\n\n\n\n\n\nModell ohne Interaktionen\n\n\n\n\n\n\n\n\n\nModell mit Interaktionen"
  },
  {
    "objectID": "mlm_interactions.html#interaktionen-sind-symmetrisch",
    "href": "mlm_interactions.html#interaktionen-sind-symmetrisch",
    "title": "10  Interaktionseffekte",
    "section": "10.14 Interaktionen sind symmetrisch",
    "text": "10.14 Interaktionen sind symmetrisch\n\n\n\n\n\nVeränderung mit der Körpergewicht\n\n\n\n\n\n\n\n\n\nVeränderung mit dem Armspannweite"
  },
  {
    "objectID": "mlm_interactions.html#warum-das-model-sinn-macht",
    "href": "mlm_interactions.html#warum-das-model-sinn-macht",
    "title": "10  Interaktionseffekte",
    "section": "10.15 Warum das Model Sinn macht",
    "text": "10.15 Warum das Model Sinn macht\n\n\n\n\n\nVeränderung mit dem Körpergewicht\n\n\n\n\n\n\n\nEinfache Steigungen\n\n\narm span\\centered\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\n\n\n\n10\n22.18\n0.33\n\n\n0\n21.35\n0.12\n\n\n-10\n20.51\n-0.09"
  },
  {
    "objectID": "mlm_interactions.html#warum-das-modell-sinn-macht",
    "href": "mlm_interactions.html#warum-das-modell-sinn-macht",
    "title": "10  Interaktionseffekte",
    "section": "10.16 Warum das Modell Sinn macht",
    "text": "10.16 Warum das Modell Sinn macht\n\n\n\nEinfache Steigungen\n\n\narm span\\centered\n\\(\\beta_0\\)\n\\(\\beta_1\\)\n\n\n\n\n10\n22.18\n0.33\n\n\n0\n21.35\n0.12\n\n\n-10\n20.51\n-0.09\n\n\n\n\n\n\n\n\nModellkoeffizienten\n\n\n\nbetas\n\n\n\n\nb0\n21.35\n\n\nbm_c\n0.12\n\n\nas_c\n0.08\n\n\nbm_c:as_c\n0.02"
  },
  {
    "objectID": "mlm_interactions.html#interpretation-der-koeffizienten",
    "href": "mlm_interactions.html#interpretation-der-koeffizienten",
    "title": "10  Interaktionseffekte",
    "section": "10.17 Interpretation der Koeffizienten",
    "text": "10.17 Interpretation der Koeffizienten\n\\[\nY = b_0 + b_1 \\cdot x_1 + b_2 \\cdot x_2 + b_3 \\cdot x_1 \\cdot x_2 + \\epsilon_i\n\\]\n\n\\(b_0\\): (y-Achsenabschnitt) der Wert von \\(\\hat{Y}\\) wenn \\(x_1 = 0\\) und \\(x_2 = 0\\) gilt.\n\\(b_1\\): Der Unterschied in \\(\\hat{Y}\\) wenn zwei Objekte sich in \\(x_1\\) um eine Einheit unterscheiden und \\(x_2 = 0\\) ist.\n\\(b_2\\): Der Unterschied in \\(\\hat{Y}\\) wenn zwei Objekte sich in \\(x_2\\) um eine Einheit unterscheiden und \\(x_1 = 0\\) ist.\n\\(b_3\\): (Interaktionskoeffizient) Die Veränderung des Effekts von \\(x_1\\) auf \\(\\hat{Y}\\) wenn \\(x_2\\) um eine Einheit größer wird bzw. genau andersherum für \\(x_2\\)."
  },
  {
    "objectID": "mlm_interactions.html#aus-der-ebene-wird-eine-gekrümmte-fläche",
    "href": "mlm_interactions.html#aus-der-ebene-wird-eine-gekrümmte-fläche",
    "title": "10  Interaktionseffekte",
    "section": "10.18 Aus der Ebene wird eine gekrümmte Fläche",
    "text": "10.18 Aus der Ebene wird eine gekrümmte Fläche\n\n\n\n\n\n3D Streudiagramm des Interaktionsmodells"
  },
  {
    "objectID": "mlm_interactions.html#residuenvergleich",
    "href": "mlm_interactions.html#residuenvergleich",
    "title": "10  Interaktionseffekte",
    "section": "10.19 Residuenvergleich",
    "text": "10.19 Residuenvergleich\n\n\n\n\n\nResiduen im additiven Modell\n\n\n\n\n\n\n\n\n\nResiduen im Interaktionsmodell"
  },
  {
    "objectID": "mlm_interactions.html#residuenvergleich---qq-plot",
    "href": "mlm_interactions.html#residuenvergleich---qq-plot",
    "title": "10  Interaktionseffekte",
    "section": "10.20 Residuenvergleich - qq-Plot",
    "text": "10.20 Residuenvergleich - qq-Plot\n\n\n\n\n\nadditives Modell\n\n\n\n\n\n\n\n\n\nInteraktionsmodell"
  },
  {
    "objectID": "mlm_interactions.html#take-away",
    "href": "mlm_interactions.html#take-away",
    "title": "10  Interaktionseffekte",
    "section": "10.21 Take-away",
    "text": "10.21 Take-away\nInteraktionsmodell\n\nErhöht die Flexibilität des linearen Modells.\nBei Interaktionen hängt der Einfluss der einzelnen Variablen immer von den Werten der anderen Variablen ab.\nAchtung: Interpretation der einfachen Haupteffekte nicht mehr möglich bzw. sinnvoll!"
  },
  {
    "objectID": "mlm_interactions.html#zuschlag",
    "href": "mlm_interactions.html#zuschlag",
    "title": "10  Interaktionseffekte",
    "section": "10.22 Zuschlag",
    "text": "10.22 Zuschlag\nWas passiert im Interaktionsmodell mit den Koeffizienten wenn die \\(x_{ki}\\)s zentriert werden?\n\\[\\begin{align*}\ny_i &= \\beta_0 + \\beta_1 (x_{1i} - \\bar{x}_1) + \\beta_2 (x_{2i} - \\bar{x}_2) + \\beta_3 (x_{1i}-\\bar{x}_1)(x_{2i}-\\bar{x}_2) \\\\\n&= \\beta_0 + \\beta_1 x_{1i} - \\beta_1 \\bar{x}_1 + \\beta_2 x_{2i} - \\beta_2 \\bar{x}_2 + \\beta_3 x_{1i} x_{2i} - \\beta_3 x_{1i} \\bar{x}_2 - \\beta_3 \\bar{x}_1 x_{2i} + \\beta_3 \\bar{x}_1 \\bar{x}_2 \\\\\n&= \\beta_0 - \\beta_1 \\bar{x}_1 - \\beta_2 \\bar{x}_2 + \\beta_3 \\bar{x}_1 \\bar{x}_2 + \\beta_1 x_{1i}- \\beta_3 \\bar{x}_2 x_{1i} + \\beta_2 x_{2i} - \\beta_3 \\bar{x}_1 x_{2i} + \\beta_3 x_{1i} x_{2i} \\\\\n&= \\underbrace{\\beta_0 - \\beta_1 \\bar{x}_1 - \\beta_2 \\bar{x}_2 + \\beta_3 \\bar{x}_1 \\bar{x}_2}_{\\beta_0} + \\underbrace{(\\beta_1 - \\beta_3 \\bar{x}_2) x_{1i}}_{\\beta_1 x_{1i}} + \\underbrace{(\\beta_2 - \\beta_3 \\bar{x}_1) x_{2i}}_{\\beta_2 x_{2i}} + \\beta_3 x_{1i} x_{2i}\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_interactions.html#zum-nacharbeiten",
    "href": "mlm_interactions.html#zum-nacharbeiten",
    "title": "10  Interaktionseffekte",
    "section": "10.23 Zum Nacharbeiten",
    "text": "10.23 Zum Nacharbeiten\nKutner u. a. (2005, p.306–313)\n\n\n\n\nDebanne, Thierry, und Guillaume Laffaye. 2011. „Predicting the throwing velocity of the ball in handball with anthropometric variables and isotonic tests“. Journal of Sports Sciences 29 (7): 705–13.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "mlm_dummy_coding.html#beispiel-körpergröße-bei-frauen-und-männern",
    "href": "mlm_dummy_coding.html#beispiel-körpergröße-bei-frauen-und-männern",
    "title": "11  Integration von nominale Variablen",
    "section": "11.1 Beispiel: Körpergröße bei Frauen und Männern",
    "text": "11.1 Beispiel: Körpergröße bei Frauen und Männern\n\n\n\n\n\nSimulierte Daten: Verteilung von Körpergrößen nach Geschlecht"
  },
  {
    "objectID": "mlm_dummy_coding.html#datensatz",
    "href": "mlm_dummy_coding.html#datensatz",
    "title": "11  Integration von nominale Variablen",
    "section": "11.2 Datensatz",
    "text": "11.2 Datensatz\n\n\n\nAusschnitt aus den Daten\n\n\ncm\ngender\n\n\n\n\n174.4\nm\n\n\n177.7\nm\n\n\n195.6\nm\n\n\n171.3\nf\n\n\n164.0\nf\n\n\n176.0\nf"
  },
  {
    "objectID": "mlm_dummy_coding.html#nominale-variablen-in-r",
    "href": "mlm_dummy_coding.html#nominale-variablen-in-r",
    "title": "11  Integration von nominale Variablen",
    "section": "11.3 Nominale Variablen in R",
    "text": "11.3 Nominale Variablen in R\nNominale Variablen werden in R als factor() dargestellt.\n\ngender <- factor(c(0,0,1,1),\n                 levels = c(0,1),\n                 labels = c('m','f'))\ngender\n\n[1] m m f f\nLevels: m f\n\n\n1"
  },
  {
    "objectID": "mlm_dummy_coding.html#t-test-in-r-mit-t.test",
    "href": "mlm_dummy_coding.html#t-test-in-r-mit-t.test",
    "title": "11  Integration von nominale Variablen",
    "section": "11.4 t-Test in R mit t.test()",
    "text": "11.4 t-Test in R mit t.test()\n\nt.test(cm ~ gender, data=height, var.equal=T)\n\n\n\n\n Two Sample t-test\n\ndata: cm by gender\nt = -4.57, df = 58, p-value = <0.001\nd = -10.75, s_e = 2.35\n95 percent confidence interval\n[-15.45, -6.04]"
  },
  {
    "objectID": "mlm_dummy_coding.html#modellformulierung-beim-t-test-n_w-n_m",
    "href": "mlm_dummy_coding.html#modellformulierung-beim-t-test-n_w-n_m",
    "title": "11  Integration von nominale Variablen",
    "section": "11.5 Modellformulierung beim t-Test \\((n_w = n_m)\\)",
    "text": "11.5 Modellformulierung beim t-Test \\((n_w = n_m)\\)\n\\[\\begin{align*}\nY_{if} &= \\mu_{f} + \\epsilon_{if}, \\quad \\epsilon_{if} \\sim \\mathcal{N}(0,\\sigma^2) \\\\\nY_{im} &= \\mu_{m} + \\epsilon_{im}, \\quad \\epsilon_{im} \\sim \\mathcal{N}(0,\\sigma^2)\n\\end{align*}\\]\n\n11.5.1 Hypothesen\n\\[\\begin{align*}\nH_0&: \\delta = 0 \\\\\nH_1&: \\delta \\neq 0\n\\end{align*}\\]\n\n\n11.5.2 Teststatistik\n\\[\nt = \\frac{\\bar{y}_m - \\bar{y}_w}{\\sqrt{\\frac{s_m^2 + s_w^2}{2}}\\sqrt{\\frac{2}{n}}}\n\\]\n\n\n11.5.3 Referenzverteilung\n\\[\nt \\sim t_{df=2n-2}\n\\]\n\n\n\n\n\nt-Verteilung mit \\(df=58\\)"
  },
  {
    "objectID": "mlm_dummy_coding.html#kann-ich-aus-dem-t-test-ein-lineares-modell-machen",
    "href": "mlm_dummy_coding.html#kann-ich-aus-dem-t-test-ein-lineares-modell-machen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.6 Kann ich aus dem t-Test ein lineares Modell machen?",
    "text": "11.6 Kann ich aus dem t-Test ein lineares Modell machen?\n\n11.6.1 t-Test\n\\[\\begin{align*}\nY_{if} &= \\mu_{f} + \\epsilon_{if}, \\quad \\epsilon_{if} \\sim \\mathcal{N}(0,\\sigma^2) \\\\\nY_{im} &= \\mu_{m} + \\epsilon_{im}, \\quad \\epsilon_{im} \\sim \\mathcal{N}(0,\\sigma^2) \\\\\nt &= \\frac{\\bar{y}_m - \\bar{y}_w}{\\sqrt{\\frac{s_m^2 + s_w^2}{2}}\\sqrt{\\frac{2}{n}}} \\\\\nt &\\sim t_{df=2n-2}\n\\end{align*}\\]\n\n\n11.6.2 Lineares Modell\n\\[\\begin{align*}\nY_i &= \\beta_0 + \\beta_1 \\times x_i + \\epsilon_i \\\\\n\\Delta_m &= \\mu_m - \\mu_f \\\\\nY_i &= \\beta_0 + \\beta_1 \\times x_{??} + \\epsilon_i \\\\\nY_i &= \\mu_f + \\Delta_{m} \\times x_{??} + \\epsilon_i\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#dummy--oder-indikatorkodierung",
    "href": "mlm_dummy_coding.html#dummy--oder-indikatorkodierung",
    "title": "11  Integration von nominale Variablen",
    "section": "11.7 Dummy- oder Indikatorkodierung",
    "text": "11.7 Dummy- oder Indikatorkodierung\n\\[\\begin{align*}\nY_i &= \\mu_f + \\Delta_{m} \\times x_{1i} + \\epsilon_i \\\\\n\\Delta_m &= \\mu_m - \\mu_f \\\\\nx_1 &=\n\\begin{cases}\n0\\text{ wenn weiblich}\\\\\n1\\text{ wenn männlich}\n\\end{cases}\n\\end{align*}\\]\nFür eine nominale Variable wird eine Indikatorvariablen (Dummyvariable) definiert. Über diese Indikatorvariable kann die Zugehörigkeit eines Messwerts \\(Y_i\\) zu einer Faktorstufe \\(k\\) bestimmt werden. Eine Faktorstufe ist dabei immer die Referenzstufe bei der die Indikatorvariable gleich \\(0\\) ist."
  },
  {
    "objectID": "mlm_dummy_coding.html#einfach-mal-stumpf-in-lm-eingeben",
    "href": "mlm_dummy_coding.html#einfach-mal-stumpf-in-lm-eingeben",
    "title": "11  Integration von nominale Variablen",
    "section": "11.8 Einfach mal stumpf in lm() eingeben",
    "text": "11.8 Einfach mal stumpf in lm() eingeben\n\nmod <- lm(cm ~ gender, height)\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n168.783\n1.663\n101.477\n<0.001\n\n\ngenderm\n10.746\n2.352\n4.568\n<0.001\n\n\n\n\n\n2"
  },
  {
    "objectID": "mlm_dummy_coding.html#vergleich-der-konfidenzintervalle",
    "href": "mlm_dummy_coding.html#vergleich-der-konfidenzintervalle",
    "title": "11  Integration von nominale Variablen",
    "section": "11.9 Vergleich der Konfidenzintervalle",
    "text": "11.9 Vergleich der Konfidenzintervalle\n\n11.9.1 Lineares Modell\n\nconfint(mod)\n\n                2.5 %    97.5 %\n(Intercept) 165.45401 172.11276\ngenderm       6.03713  15.45403\n\n\n\n\n11.9.2 t-Test\n\nt.test(cm ~ gender,\n       data = height,\n       var.equal=T)$conf\n\n[1] -15.45403  -6.03713\nattr(,\"conf.level\")\n[1] 0.95\n\n\n3"
  },
  {
    "objectID": "mlm_dummy_coding.html#auf-welchen-werten-wird-ein-lineares-modell-gerechnet",
    "href": "mlm_dummy_coding.html#auf-welchen-werten-wird-ein-lineares-modell-gerechnet",
    "title": "11  Integration von nominale Variablen",
    "section": "11.10 Auf welchen Werten wird ein lineares Modell gerechnet???",
    "text": "11.10 Auf welchen Werten wird ein lineares Modell gerechnet???\n\n\n\nRepräsentation der Faktorvariablen\n\n\ncm\ngender\n\\(x_1\\)\n\n\n\n\n174.40\nm\n1\n\n\n177.70\nm\n1\n\n\n195.59\nm\n1\n\n\n160.05\nf\n0\n\n\n164.92\nf\n0\n\n\n154.35\nf\n0"
  },
  {
    "objectID": "mlm_dummy_coding.html#residuen",
    "href": "mlm_dummy_coding.html#residuen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.11 Residuen",
    "text": "11.11 Residuen\n\n\n\n\n\nResiduen"
  },
  {
    "objectID": "mlm_dummy_coding.html#wens-interessiert---t-wert",
    "href": "mlm_dummy_coding.html#wens-interessiert---t-wert",
    "title": "11  Integration von nominale Variablen",
    "section": "11.12 Wen’s interessiert - t-Wert",
    "text": "11.12 Wen’s interessiert - t-Wert\nSeien beide Gruppen gleich groß (\\(n\\)) mit \\(N = n_m + n_w = 2 \\times n\\). Der t-Wert für \\(\\beta_1\\) berechnet sich aus \\(t = \\frac{b_1}{s_b}\\) mit:\n\\[\ns_b = \\sqrt{\\frac{\\sum_{i=1}^N (y_i - \\bar{y})^2}{N-2}\\frac{1}{\\sum_{i=1}^N(x_i-\\bar{x})^2}}\n\\] Dadurch, das die \\(x_i\\) entweder gleich \\(0\\) oder \\(1\\) sind, ist \\(\\bar{x}=0.5\\) und die Abweichungsquadrate im zweiten Term sind alle gleich \\(\\frac{1}{4}\\).\n\\[\n\\sum_{i=1}^N(x_i - \\bar{x})^2=\\sum_{i=1}^N\\left(x_i - \\frac{1}{2}\\right)^2 = \\sum_{i=1}^N\\frac{1}{4}=\\frac{N}{4}=\\frac{2n}{4}=\\frac{n}{2}\n\\]\nDer ersten Term kann mit etwas Algebra und der Definition für die Stichprobenvarianz \\(s^2\\) auf die gewünschte Form gebracht werden.\n\\[\n\\frac{\\sum_{i=1}^N(y_i-\\hat{y})^2}{N-2}=\\frac{\\sum_{i=1}^n(\\overbrace{y_{im} - \\bar{y}_m}^{Männer})^2+\\sum_{i=1}^n(\\overbrace{y_{iw}-\\bar{y}_w}^{Frauen})^2}{2(n-1)}=\\frac{(n-1)s_m^2+(n-1)s_w^2}{2(n-1)}=\\frac{s_m^2+s_w^2}{2}\n\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#wens-interessiert---beta_1-mu_w---mu_m",
    "href": "mlm_dummy_coding.html#wens-interessiert---beta_1-mu_w---mu_m",
    "title": "11  Integration von nominale Variablen",
    "section": "11.13 Wen’s interessiert - \\(\\beta_1 = \\mu_w - \\mu_m\\)",
    "text": "11.13 Wen’s interessiert - \\(\\beta_1 = \\mu_w - \\mu_m\\)\nMit \\(s_x^2 = \\frac{N\\frac{1}{4}}{N-1} = \\frac{N}{4(N-1)}\\) \\[\\begin{align*}\n    b_1 &= \\frac{cov(x,y)}{s_x^2} \\\\\n    &= \\frac{\\sum_{i=1}^N(y_i - \\bar{y})(x_i - \\bar{x})}{N-1} \\frac{4(N-1)}{N} \\\\\n    &= 4\\frac{\\sum_{i=1}^n(y_{im}-\\bar{y})\\frac{-1}{2}+\\sum(y_{iw}-\\bar{y})\\frac{1}{2}}{N} \\\\\n    &= \\frac{4}{2}\\frac{\\sum_{i=1}^n(y_{iw}-\\bar{y}) - \\sum_{i=1}^n(y_{im}-\\bar{y})}{2n} \\\\\n    &= \\frac{\\sum_{i=1}^n y_{iw}}{n} - \\frac{n\\bar{y}}{n} - \\frac{\\sum_{i=1}^n y_{im}}{n} + \\frac{n\\bar{y}}{n} \\\\\n    &= \\bar{y}_w - \\bar{y}_m = \\Delta\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#wens-interessiert---beta_0-mu_m",
    "href": "mlm_dummy_coding.html#wens-interessiert---beta_0-mu_m",
    "title": "11  Integration von nominale Variablen",
    "section": "11.14 Wen’s interessiert - \\(\\beta_0 = \\mu_m\\)",
    "text": "11.14 Wen’s interessiert - \\(\\beta_0 = \\mu_m\\)\nMit \\(b_1 = \\Delta = \\bar{y}_w - \\bar{y}_m\\): \\[\\begin{align*}\nb_0 &= \\bar{y} - \\Delta \\times \\bar{x} \\\\\n&= \\frac{\\sum_{i=1}^N y_i}{N} - \\Delta \\times \\frac{1}{2} \\\\\n&= \\frac{\\sum_{i=1}^n y_{im} + \\sum_{i=1}^n y_{iw}}{2n} - \\frac{1}{2}(\\bar{y}_w - \\bar{y}_m)  \\\\\n&= \\frac{1}{2}\\frac{\\sum_{i=1}^ny_{im}}{n} + \\frac{1}{2}\\frac{\\sum_{i=1}^ny_{iw}}{n} - \\frac{1}{2}\\bar{y}_w + \\frac{1}{2}\\bar{y}_m \\\\\n&= \\frac{1}{2}\\bar{y}_m + \\frac{1}{2}\\bar{y}_w - \\frac{1}{2}\\bar{y}_w + \\frac{1}{2}\\bar{y}_m \\\\\n&= \\bar{y}_m\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#können-auch-mehr-als-zwei-stufen-verwendet-werden",
    "href": "mlm_dummy_coding.html#können-auch-mehr-als-zwei-stufen-verwendet-werden",
    "title": "11  Integration von nominale Variablen",
    "section": "11.15 Können auch mehr als zwei Stufen verwendet werden?",
    "text": "11.15 Können auch mehr als zwei Stufen verwendet werden?\n\n\n\n\n\nEin Reaktionszeitexperiment mit vier Stufen A, B, C und D"
  },
  {
    "objectID": "mlm_dummy_coding.html#deskriptive-daten",
    "href": "mlm_dummy_coding.html#deskriptive-daten",
    "title": "11  Integration von nominale Variablen",
    "section": "11.16 Deskriptive Daten",
    "text": "11.16 Deskriptive Daten"
  },
  {
    "objectID": "mlm_dummy_coding.html#reaktionszeitexperiment-als-lineares-modell",
    "href": "mlm_dummy_coding.html#reaktionszeitexperiment-als-lineares-modell",
    "title": "11  Integration von nominale Variablen",
    "section": "11.17 Reaktionszeitexperiment als lineares Modell",
    "text": "11.17 Reaktionszeitexperiment als lineares Modell\n\n11.17.1 Modell\n\\[\ny_i = \\mu_A + \\Delta_{B-A} x_1 + \\Delta_{C-A} x_2 + \\Delta_{D-A} x_3 + \\epsilon_i\n\\]\n\n\n11.17.2 Dummyvariablen"
  },
  {
    "objectID": "mlm_dummy_coding.html#nochmal-allgemeiner",
    "href": "mlm_dummy_coding.html#nochmal-allgemeiner",
    "title": "11  Integration von nominale Variablen",
    "section": "11.18 Nochmal allgemeiner",
    "text": "11.18 Nochmal allgemeiner\nMit \\(K\\) Faktorstufen werden (K-1) Dummyvariablen \\(x_1, x_2, \\ldots, x_{K-1}\\) benötigt. Eine Stufe wird als Referenz definiert. Die \\(x_1\\) bis \\(x_{K-1}\\) kodieren die Abweichungen der anderen Stufen von dieser Stufe.4"
  },
  {
    "objectID": "mlm_dummy_coding.html#reaktionszeitexperiment-mit-lm",
    "href": "mlm_dummy_coding.html#reaktionszeitexperiment-mit-lm",
    "title": "11  Integration von nominale Variablen",
    "section": "11.19 Reaktionszeitexperiment mit lm()",
    "text": "11.19 Reaktionszeitexperiment mit lm()\n\nmod <- lm(rt ~ group, data)\n\n\n\n\n\nModellfit\n \n  \n      \n    $\\hat{\\beta}$ \n    $s_e$ \n    t \n    p \n  \n \n\n  \n    (Intercept) \n    509.526 \n    10.235 \n    49.784 \n    <0.001 \n  \n  \n    groupB \n    90.150 \n    14.474 \n    6.228 \n    <0.001 \n  \n  \n    groupC \n    197.414 \n    14.474 \n    13.639 \n    <0.001 \n  \n  \n    groupD \n    295.561 \n    14.474 \n    20.420 \n    <0.001"
  },
  {
    "objectID": "mlm_dummy_coding.html#ausblick",
    "href": "mlm_dummy_coding.html#ausblick",
    "title": "11  Integration von nominale Variablen",
    "section": "11.20 Ausblick",
    "text": "11.20 Ausblick\n\nanova(mod)\n\n\n\n\n\nANOVA-Tabelle\n \n  \n     \n    Df \n    SSQ \n    MSQ \n    F \n    p \n  \n \n\n  \n    group \n    3 \n    988935.1 \n    329645.04 \n    157.35 \n    <0.001 \n  \n  \n    Residuals \n    76 \n    159221.0 \n    2095.01"
  },
  {
    "objectID": "mlm_dummy_coding.html#kombination-von-kontinuierlichen-und-nominalen-variablen",
    "href": "mlm_dummy_coding.html#kombination-von-kontinuierlichen-und-nominalen-variablen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.21 Kombination von kontinuierlichen und nominalen Variablen",
    "text": "11.21 Kombination von kontinuierlichen und nominalen Variablen\n\n\n\n\n\nHypothetische Leistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#modellansatz",
    "href": "mlm_dummy_coding.html#modellansatz",
    "title": "11  Integration von nominale Variablen",
    "section": "11.22 Modellansatz",
    "text": "11.22 Modellansatz\n\nAus gender (K = 2) wird eine Dummyvariable\nFrauen werden (zufällig) als Referenz genommen\n\n\\[\\begin{align*}\nY_i &= \\beta_{ta = 0,x_1=0} + \\Delta_m \\times x_1 + \\beta_{ta} \\times ta + \\epsilon_i \\\\\nx_1 &=\n\\begin{cases}\n0\\text{ wenn weiblich}\\\\\n1\\text{ wenn männlich}\n\\end{cases} \\\\\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#modellieren-mit-lm",
    "href": "mlm_dummy_coding.html#modellieren-mit-lm",
    "title": "11  Integration von nominale Variablen",
    "section": "11.23 Modellieren mit lm()",
    "text": "11.23 Modellieren mit lm()\n\nmod <- lm(perf ~ gender_f + ta, lew)\n\n\n\n\n\nModellfit\n \n  \n      \n    $\\hat{\\beta}$ \n    $s_e$ \n  \n \n\n  \n    (Intercept) \n    41.181 \n    1.083 \n  \n  \n    gender\\_fm \n    -10.877 \n    0.805 \n  \n  \n    ta \n    1.927 \n    0.145 \n  \n  \n    $\\hat{\\sigma}$ \n    2.845"
  },
  {
    "objectID": "mlm_dummy_coding.html#die-resultierenden-graden",
    "href": "mlm_dummy_coding.html#die-resultierenden-graden",
    "title": "11  Integration von nominale Variablen",
    "section": "11.24 Die resultierenden Graden",
    "text": "11.24 Die resultierenden Graden\n\n\n\n\n\nLeistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#interaktion-zwischen-kontinuierlichen-und-nominalen-variablen",
    "href": "mlm_dummy_coding.html#interaktion-zwischen-kontinuierlichen-und-nominalen-variablen",
    "title": "11  Integration von nominale Variablen",
    "section": "11.25 Interaktion zwischen kontinuierlichen und nominalen Variablen",
    "text": "11.25 Interaktion zwischen kontinuierlichen und nominalen Variablen\n\n\n\n\n\nLeistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#ansatz-für-ein-interaktionsmodell",
    "href": "mlm_dummy_coding.html#ansatz-für-ein-interaktionsmodell",
    "title": "11  Integration von nominale Variablen",
    "section": "11.26 Ansatz für ein Interaktionsmodell",
    "text": "11.26 Ansatz für ein Interaktionsmodell\nDas vorhergehendes Modell wird um einen Interaktionsterm erweitert.\n\\[\ny_i = \\beta_{ta=0,x_1=0} + \\Delta_m \\times x_1 + \\beta_{ta} \\times ta + \\beta_{ta \\times gender} \\times x_1 \\times ta + \\epsilon_i\n\\]"
  },
  {
    "objectID": "mlm_dummy_coding.html#interaktionsmodell-mit-lm",
    "href": "mlm_dummy_coding.html#interaktionsmodell-mit-lm",
    "title": "11  Integration von nominale Variablen",
    "section": "11.27 Interaktionsmodell mit lm()",
    "text": "11.27 Interaktionsmodell mit lm()\n\nmod <- lm(perf ~ gender_f * ta, lew)\n\n\n\n\n\nModellfit\n \n  \n      \n    $\\hat{\\beta}$ \n    $s_e$ \n  \n \n\n  \n    (Intercept) \n    31.354 \n    1.370 \n  \n  \n    gender\\_fm \n    8.575 \n    2.010 \n  \n  \n    ta \n    1.763 \n    0.195 \n  \n  \n    gender\\_fm:ta \n    2.362 \n    0.290 \n  \n  \n    $\\hat{\\sigma}$ \n    2.828"
  },
  {
    "objectID": "mlm_dummy_coding.html#regressionsgeraden",
    "href": "mlm_dummy_coding.html#regressionsgeraden",
    "title": "11  Integration von nominale Variablen",
    "section": "11.28 Regressionsgeraden",
    "text": "11.28 Regressionsgeraden\n\n\n\n\n\nLeistungsentwicklung in Abhängigkeit vom Alter und Gender"
  },
  {
    "objectID": "mlm_dummy_coding.html#zum-nacharbeiten",
    "href": "mlm_dummy_coding.html#zum-nacharbeiten",
    "title": "11  Integration von nominale Variablen",
    "section": "11.29 Zum Nacharbeiten",
    "text": "11.29 Zum Nacharbeiten\nKutner u. a. (2005, p.313–319) \n\n\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "mlm_hierarchies.html#einfaches-modell",
    "href": "mlm_hierarchies.html#einfaches-modell",
    "title": "12  Modellhierarchien",
    "section": "12.1 Einfaches Modell",
    "text": "12.1 Einfaches Modell\n\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n\n\nCall:\nlm(formula = y ~ x, data = simple)\n\nResiduals:\n      1       2       3       4 \n-0.5817  0.9898 -0.2345 -0.1736 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.8414     0.7008   2.628    0.119\nx             0.4574     0.3746   1.221    0.346\n\nResidual standard error: 0.8376 on 2 degrees of freedom\nMultiple R-squared:  0.4271,    Adjusted R-squared:  0.1406 \nF-statistic: 1.491 on 1 and 2 DF,  p-value: 0.3465"
  },
  {
    "objectID": "mlm_hierarchies.html#einfaches-modell-1",
    "href": "mlm_hierarchies.html#einfaches-modell-1",
    "title": "12  Modellhierarchien",
    "section": "12.2 Einfaches Modell",
    "text": "12.2 Einfaches Modell\n\nmod0 <- lm(y ~ x, simple)\nsummary(mod0)\n\n\nCall:\nlm(formula = y ~ x, data = simple)\n\nResiduals:\n      1       2       3       4 \n-0.5817  0.9898 -0.2345 -0.1736 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)\n(Intercept)   1.8414     0.7008   2.628    0.119\nx             0.4574     0.3746   1.221    0.346\n\nResidual standard error: 0.8376 on 2 degrees of freedom\nMultiple R-squared:  0.4271,    Adjusted R-squared:  0.1406 \nF-statistic: 1.491 on 1 and 2 DF,  p-value: 0.3465"
  },
  {
    "objectID": "mlm_hierarchies.html#abweichungen-noch-mal",
    "href": "mlm_hierarchies.html#abweichungen-noch-mal",
    "title": "12  Modellhierarchien",
    "section": "12.3 Abweichungen … noch mal",
    "text": "12.3 Abweichungen … noch mal\n\n12.3.1 Sum of squares of error\n\\[\nSSE = \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n\\]\nTypischerweise beinhaltet ein Modell zum berechnen der \\(\\hat{y}_i\\) verschiedene Parameter. Bei der einfachen Regression zum Beispiel \\(\\beta_0\\) und \\(\\beta_1\\) (#Modellparameter \\(p\\) = 2) .\n\n\n12.3.2 Freiheitsgrade (degrees of freedom) von SSE\n\\[\ndfE := n - p\n\\]\nDie effektive Anzahl der Beobachtungen um die Varianz \\(\\sigma^2\\) abzuschätzen."
  },
  {
    "objectID": "mlm_hierarchies.html#mse-als-schätzer-für-sigma2",
    "href": "mlm_hierarchies.html#mse-als-schätzer-für-sigma2",
    "title": "12  Modellhierarchien",
    "section": "12.4 MSE als Schätzer für \\(\\sigma^2\\)",
    "text": "12.4 MSE als Schätzer für \\(\\sigma^2\\)\n\n12.4.1 Mean squared error MSE\n\\[\nMSE = \\frac{SSE}{dfE} = \\frac{\\sum_{i=1}^n (y_i - \\hat{y}_i)^2}{n-p}\n\\]\nAls Schätzer \\(\\hat{\\sigma}^2\\) für \\(\\sigma^2\\) aus \\(\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\)\n\n\n12.4.2 Parallel zur Berechnung der Stichprobenvarianz\n\\[\n\\hat{\\sigma}^2 = s^2 = \\frac{1}{n-1}\\sum_{i=1}^2(y_i - \\bar{y})^2\n\\]\nwo \\(s^2\\) ein Schätzer für die Varianz von \\(y\\) ist."
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz",
    "title": "12  Modellhierarchien",
    "section": "12.5 Genereller Linearer Modell Testansatz1",
    "text": "12.5 Genereller Linearer Modell Testansatz1\n\n12.5.1 Idee\nWir bauen uns eine Teststatistik die die Verbesserung in der Vorhersage (\\(=\\) Reduktion der Fehlervarianz) als Metrik verwendet. Modelle werden in eine Hierarchie gesetzt mit einfacheren Modellen untergeordnet zu komplexeren Modellen.\n\n\n12.5.2 Leitfrage:\nBringt mir die Aufnahme Modellparameter eine in der Vorhersage von Y bzw. bezüglich der Aufklärung der Varianz in Y?"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---full-model",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---full-model",
    "title": "12  Modellhierarchien",
    "section": "12.6 Genereller Linearer Modell Testansatz - Full model",
    "text": "12.6 Genereller Linearer Modell Testansatz - Full model\nBeispiel einfache lineare Regression\n\n12.6.1 Volles Modell\n\\[\nY_i = \\beta_0 + \\beta_1 X_i + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\n\\]\n\n\n12.6.2 Residualvarianz SSE(F)\n\\[\n\\textrm{SSE(F)}  = \\sum_{i=1}^n(y_i - \\hat{y}_i)^2 = \\sum_{i=1}^n [y_i - (\\beta_0 + \\beta_1 x_i)]^2\n\\]\nmit \\(p = 2, dfE(F) = n - 2\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---reduced-model",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---reduced-model",
    "title": "12  Modellhierarchien",
    "section": "12.7 Genereller Linearer Modell Testansatz - Reduced model",
    "text": "12.7 Genereller Linearer Modell Testansatz - Reduced model\n\n12.7.1 Reduziertes Modell\n\\[\nY_i = \\beta_0 + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\n\\]\n\n\n12.7.2 Residualvarianz SSE(R)\n\\[\n\\textrm{SSE(R)} = \\sum_{i=1}^n (y_i - \\beta_0)^2 = \\sum_{i=1}^n(y_i - \\bar{y})^2 = \\textrm{SSTO}\n\\]\nmit \\(p = 1, dfE(R) = n - 1\\)\nIm Allgemeinen gilt: \\(SSE(F) \\leq SSE(R)\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#link-reduziertes-modell-und-stichprobenvarianz",
    "href": "mlm_hierarchies.html#link-reduziertes-modell-und-stichprobenvarianz",
    "title": "12  Modellhierarchien",
    "section": "12.8 Link: Reduziertes Modell und Stichprobenvarianz",
    "text": "12.8 Link: Reduziertes Modell und Stichprobenvarianz\n\\[\\begin{align*}\nSSE &= \\sum_{i=1}^n(y_i - \\beta_0)^2 = \\sum_{i=1}^n (y_i^2 - 2y_i\\beta_0 + \\beta_0^2) \\\\\n0 &= \\frac{\\mathrm{d}}{\\mathrm{d} \\beta_0}\\sum_{i=1}^n (y_i^2 - 2y_i\\beta_0 + \\beta_0^2) \\\\\n0 &= \\sum_{i=1}^n (-2y_i + 2 \\beta_0) = -2\\sum_{i=1}^n y_i + 2\\sum_{i=1}^n \\beta_0\\\\\nn\\beta_0 &= \\sum_{i=1}^n y_i \\\\\n\\beta_0 &= \\frac{\\sum_{i=1}^n y_i}{n} = \\bar{y} \\rightarrow \\frac{SSE}{n-1} = \\hat{\\sigma}^2 = s^2\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz-1",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz-1",
    "title": "12  Modellhierarchien",
    "section": "12.9 Genereller Linearer Modell Testansatz",
    "text": "12.9 Genereller Linearer Modell Testansatz\nAnnahme: Das reduzierte Modell ist korrekt. Dann sollte \\[\n\\textrm{SSE(R)} - \\textrm{SSE(F)}\n\\] eher klein sein (Beide Modelle haben einen gleich guten fit).\nAnnahme: Das reduzierte Modell ist falsch: Dann sollte \\[\n\\textrm{SSE(R)} - \\textrm{SSE(F)}\n\\] eher groß sein (Das reduzierte Modell kann die Daten nicht so gut fitten wie das komplizierte Modell)"
  },
  {
    "objectID": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---teststatistik",
    "href": "mlm_hierarchies.html#genereller-linearer-modell-testansatz---teststatistik",
    "title": "12  Modellhierarchien",
    "section": "12.10 Genereller Linearer Modell Testansatz - Teststatistik",
    "text": "12.10 Genereller Linearer Modell Testansatz - Teststatistik\nWenn das reduzierte Modell korrekt ist, dann lässt sich zeigen, dass: \\[\nMS_{\\textrm{test}} = \\frac{\\textrm{SSE(R)} - \\textrm{SSE(F)}}{\\textrm{dfE(R)} - \\textrm{dfE(F)}}\n\\] ein Schätzer für die Varianz \\(\\sigma^2\\) (\\(\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)\\)) ist.\nWenn das reduzierte Modell korrekt ist, dann ist auch das volle Modell korrekt. Daher ist dann:\n\\[\n\\textrm{MSE(F)} = \\frac{\\textrm{SSE(F)}}{\\textrm{dfE(F)}}\n\\] auch ein Schätzer für \\(\\sigma^2\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#f-wert-als-teststatistik",
    "href": "mlm_hierarchies.html#f-wert-als-teststatistik",
    "title": "12  Modellhierarchien",
    "section": "12.11 F-Wert als Teststatistik",
    "text": "12.11 F-Wert als Teststatistik\n\\[\nF = \\frac{MS_{\\textrm{test}}}{MSE(F)}= \\frac{\\frac{\\textrm{SSE(R)} - \\textrm{SSE(F)}}{\\textrm{dfE(R)} - \\textrm{dfE(F)}}}{ \\frac{\\textrm{SSE(F)}}{\\textrm{dfE(F)}}}\n\\]"
  },
  {
    "objectID": "mlm_hierarchies.html#verteilung-der-f-statistik",
    "href": "mlm_hierarchies.html#verteilung-der-f-statistik",
    "title": "12  Modellhierarchien",
    "section": "12.12 Verteilung der F-Statistik",
    "text": "12.12 Verteilung der F-Statistik\n\\[\nF = \\frac{MS_{\\textrm{test}}}{MSE(F)}  \\sim F(\\textrm{dfE(R)}-\\textrm{dfE(F)},\\textrm{dfE(F)})\n\\]\n\n\n\n\n\nBeispiele für die F-Verteilung mit verschiedenen Freiheitsgraden \\(df_1, df_2\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#hypothesentest-mit-f-wert",
    "href": "mlm_hierarchies.html#hypothesentest-mit-f-wert",
    "title": "12  Modellhierarchien",
    "section": "12.13 Hypothesentest mit F-Wert",
    "text": "12.13 Hypothesentest mit F-Wert\n\n\n\n\n\nF-Verteilung mit \\(df_1 = 5, df_2 = 10\\) und kritischem Wert bei \\(\\alpha=0.05\\)\n\n\n\n\n2"
  },
  {
    "objectID": "mlm_hierarchies.html#teilziel",
    "href": "mlm_hierarchies.html#teilziel",
    "title": "12  Modellhierarchien",
    "section": "12.14 Teilziel",
    "text": "12.14 Teilziel\n\nDurch den Vergleich von Modellen kann die Verbesserung/Verschlechterung der Modellvorhersage statistisch Überprüft werden\nAlternativ: Brauchen ich zusätzliche Parameter oder reicht mir das einfache Modell?"
  },
  {
    "objectID": "mlm_hierarchies.html#beispiel-candy-problem",
    "href": "mlm_hierarchies.html#beispiel-candy-problem",
    "title": "12  Modellhierarchien",
    "section": "12.15 Beispiel: Candy-Problem",
    "text": "12.15 Beispiel: Candy-Problem\n\n\n\n\n\nZusammenhang zwischen der Präferenz für ein Bonbon und dem Süßgrad für verschiedene Weichheitsgrade"
  },
  {
    "objectID": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen",
    "href": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen",
    "title": "12  Modellhierarchien",
    "section": "12.16 Modelle als Hierarchien auffassen",
    "text": "12.16 Modelle als Hierarchien auffassen\n\n12.16.1 Full model\n\\[\ny_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i}x_{2i} + \\epsilon_i\n\\]\n\n\n12.16.2 Hierarchie\n\\[\\begin{align*}\nm_0&: y_i = \\beta_0 + \\epsilon_i \\\\\nm_1&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i \\\\\nm_2&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i \\\\\nm_3&: y_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i}x_{2i} + \\epsilon_i\n\\end{align*}\\]\nEs gilt: \\(m_0 \\subseteq m_1 \\subseteq m_2 \\subseteq m_3\\)"
  },
  {
    "objectID": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen-in-r",
    "href": "mlm_hierarchies.html#modelle-als-hierarchien-auffassen-in-r",
    "title": "12  Modellhierarchien",
    "section": "12.17 Modelle als Hierarchien auffassen in R",
    "text": "12.17 Modelle als Hierarchien auffassen in R\nIn R:\n\nmod_0 <- lm(like ~ 1, candy)\nmod_1 <- lm(like ~ sweetness, candy)\nmod_2 <- lm(like ~ sweetness + moisture, candy)\nmod_3 <- lm(like ~ sweetness * moisture, candy)"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-m_0-gegen-m_1",
    "href": "mlm_hierarchies.html#vergleich-m_0-gegen-m_1",
    "title": "12  Modellhierarchien",
    "section": "12.18 Vergleich \\(m_0\\) gegen \\(m_1\\)",
    "text": "12.18 Vergleich \\(m_0\\) gegen \\(m_1\\)\n\\[\\begin{align*}\nm_0: y_i &= \\beta_0 + \\epsilon_i \\\\\nm_1: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_0, mod_1)\n\n\n\n\nVergleich der Modellfits\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ 1\n77\n\n\n\n\n\n\nModel 2: like ~ sweetness\n76\n1\n8342.53\n18.56\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-m_1-gegen-m_2",
    "href": "mlm_hierarchies.html#vergleich-m_1-gegen-m_2",
    "title": "12  Modellhierarchien",
    "section": "12.19 Vergleich \\(m_1\\) gegen \\(m_2\\)",
    "text": "12.19 Vergleich \\(m_1\\) gegen \\(m_2\\)\n\\[\\begin{align*}\nm_1: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\epsilon_i \\\\\nm_2: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_1, mod_2)\n\n\n\n\nVergleich der Modellfits\n\n\n\n\n\n\n\n\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ sweetness\n76\n\n\n\n\n\n\nModel 2: like ~ sweetness + moisture\n75\n1\n25872.36\n233.96\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-m_2-gegen-full-model-m_3",
    "href": "mlm_hierarchies.html#vergleich-m_2-gegen-full-model-m_3",
    "title": "12  Modellhierarchien",
    "section": "12.20 Vergleich \\(m_2\\) gegen full model \\(m_3\\)",
    "text": "12.20 Vergleich \\(m_2\\) gegen full model \\(m_3\\)\n\\[\\begin{align*}\nm_2: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\epsilon_i  \\\\\nm_3: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i} x_{2i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_2, mod_3)\n\n\n\n\nVergleich der Modellfits\n\n\n\n\n\n\n\n\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ sweetness + moisture\n75\n\n\n\n\n\n\nModel 2: like ~ sweetness * moisture\n74\n1\n8041.14\n2353.43\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#vergleich-full-model-m_3-gegen-minmales-modell-m_0",
    "href": "mlm_hierarchies.html#vergleich-full-model-m_3-gegen-minmales-modell-m_0",
    "title": "12  Modellhierarchien",
    "section": "12.21 Vergleich full model \\(m_3\\) gegen minmales Modell \\(m_0\\)",
    "text": "12.21 Vergleich full model \\(m_3\\) gegen minmales Modell \\(m_0\\)\n\\[\\begin{align*}\nm_0: y_i &= \\beta_0 + \\epsilon_i  \\\\\nm_3: y_i &= \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\beta_3 x_{1i} x_{2i} + \\epsilon_i\n\\end{align*}\\]\n\nanova(mod_0, mod_3)\n\n\n\n\nVergleich der Modellfits\n\n\n\n\n\n\n\n\n\n\nModel\nResDF\nDF\nSS\nF\np-val\n\n\n\n\nModel 1: like ~ 1\n77\n\n\n\n\n\n\nModel 2: like ~ sweetness * moisture\n74\n3\n42256.04\n4122.42\n0"
  },
  {
    "objectID": "mlm_hierarchies.html#in-summary-m_3-gegen-m_0",
    "href": "mlm_hierarchies.html#in-summary-m_3-gegen-m_0",
    "title": "12  Modellhierarchien",
    "section": "12.22 In summary() \\(m_3\\) gegen \\(m_0\\)",
    "text": "12.22 In summary() \\(m_3\\) gegen \\(m_0\\)\n\n\n\nCall:\nlm(formula = like ~ sweetness * moisture, data = candy)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-3.2319 -1.2424 -0.2382  1.0003  5.7987 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)        0.794449   0.805501   0.986   0.3272    \nsweetness          0.074027   0.041175   1.798   0.0763 .  \nmoisture           0.082445   0.060838   1.355   0.1795    \nsweetness:moisture 0.160509   0.003309  48.512   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.848 on 74 degrees of freedom\nMultiple R-squared:  0.9941,    Adjusted R-squared:  0.9938 \nF-statistic:  4122 on 3 and 74 DF,  p-value: < 2.2e-16"
  },
  {
    "objectID": "mlm_hierarchies.html#eine-nominale-variable-mit-vier-stufen",
    "href": "mlm_hierarchies.html#eine-nominale-variable-mit-vier-stufen",
    "title": "12  Modellhierarchien",
    "section": "12.23 Eine nominale Variable mit vier Stufen",
    "text": "12.23 Eine nominale Variable mit vier Stufen\n\n\n\n\n\nEin Reaktionszeitexperiment mit vier Stufen A, B, C und D"
  },
  {
    "objectID": "mlm_hierarchies.html#früher---analysis-of-variance-anova-bzw.-aov",
    "href": "mlm_hierarchies.html#früher---analysis-of-variance-anova-bzw.-aov",
    "title": "12  Modellhierarchien",
    "section": "12.24 Früher - Analysis of Variance (ANOVA bzw. AOV)",
    "text": "12.24 Früher - Analysis of Variance (ANOVA bzw. AOV)\n\\[\\begin{align*}\ns_{zwischen}^2 &= \\frac{1}{K-1}\\sum_{j=1}^K N_j (\\bar{x}_{j.}-\\bar{x})^2 \\\\\ns_{innerhalb}^2 &= \\frac{1}{N-K}\\sum_{j=1}^K\\sum_{i=1}^{N_j}(x_{ji}-\\bar{x}_{j.})^2 = \\frac{1}{N-K}\\sum_{j=1}^K(N_j-1)s_j^2 \\\\\nF &= \\frac{\\hat{\\sigma}_{zwischen}^2} {\\hat{\\sigma}_{innerhalb}^2} \\sim F(K-1,N-K)\n\\end{align*}\\]"
  },
  {
    "objectID": "mlm_hierarchies.html#anova-in-r",
    "href": "mlm_hierarchies.html#anova-in-r",
    "title": "12  Modellhierarchien",
    "section": "12.25 ANOVA in R",
    "text": "12.25 ANOVA in R\n\nmod_aov <- aov(rt ~ group, rt_tbl)\nsummary(mod_aov)\n\n\n\n\nAusgabe mit aov()\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\ngroup\n3\n988935.1\n329645\n157.3\n0\n\n\nResiduals\n76\n159221.0\n2095"
  },
  {
    "objectID": "mlm_hierarchies.html#ansatz-mittels-modellhierarchien",
    "href": "mlm_hierarchies.html#ansatz-mittels-modellhierarchien",
    "title": "12  Modellhierarchien",
    "section": "12.26 Ansatz mittels Modellhierarchien",
    "text": "12.26 Ansatz mittels Modellhierarchien\n\n12.26.1 Full model\n\\[\ny_i = \\beta_0 + \\beta_{\\Delta_{B-A}} x_1 + \\beta_{\\Delta_{C-A}} x_2 + \\beta_{\\Delta_{D-A}} x_3 + \\epsilon_i\n\\]\n\n\n12.26.2 Reduced model\n\\[\ny_i = \\beta_0 + \\epsilon_i\n\\]\nWenn das reduced model die Daten gleich gut fittet wie das full model \\(\\Rightarrow\\) Information über das Treatment verbessert meine Vorhersage von \\(y_i\\) nicht."
  },
  {
    "objectID": "mlm_hierarchies.html#model-fit---full-model",
    "href": "mlm_hierarchies.html#model-fit---full-model",
    "title": "12  Modellhierarchien",
    "section": "12.27 Model fit - Full model",
    "text": "12.27 Model fit - Full model\n\nmod <- lm(rt ~ group, rt_tbl)\n\n\n\n\nModellfit\n\n\n\n\\(\\hat{\\beta}\\)\n\\(s_e\\)\nt\np\n\n\n\n\n(Intercept)\n509.526\n10.235\n49.784\n<0.001\n\n\ngroupB\n90.150\n14.474\n6.228\n<0.001\n\n\ngroupC\n197.414\n14.474\n13.639\n<0.001\n\n\ngroupD\n295.561\n14.474\n20.420\n<0.001"
  },
  {
    "objectID": "mlm_hierarchies.html#anova-mit-nur-einem-modell",
    "href": "mlm_hierarchies.html#anova-mit-nur-einem-modell",
    "title": "12  Modellhierarchien",
    "section": "12.28 anova() mit nur einem Modell",
    "text": "12.28 anova() mit nur einem Modell\n\nanova(mod)\n\n\n\n\nÄquivalent zum Vergleich full gegen reduced model\n\n\nterm\ndf\nsumsq\nmeansq\nstatistic\np.value\n\n\n\n\ngroup\n3\n988935.1\n329645\n157.3\n0\n\n\nResiduals\n76\n159221.0\n2095"
  },
  {
    "objectID": "mlm_hierarchies.html#zum-nacharbeiten",
    "href": "mlm_hierarchies.html#zum-nacharbeiten",
    "title": "12  Modellhierarchien",
    "section": "12.29 Zum Nacharbeiten",
    "text": "12.29 Zum Nacharbeiten\nChristensen (2018, p.57–64) \n\n\n\n\nChristensen, Ronald. 2018. Analysis of variance, design, and regression: Linear modeling for unbalanced data. CRC Press.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, und William Li. 2005. Applied Linear Statistical Models. 5. Aufl. McGraw-Hill Irwin New York."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Literatur",
    "section": "",
    "text": "Altman, Douglas G, and J Martin Bland. 1995. “Statistics Notes:\nAbsence of Evidence Is Not Evidence of Absence.” Bmj 311\n(7003): 485.\n\n\nAltman, Naomi, and Martin Krzywinski. 2015a. “Points of\nSignificance: Multiple Linear Regression.” Nature\nMethods 12 (12): 1103–4.\n\n\n———. 2015b. “Points of Significance: Simple Linear\nRegression.” Nature Methods 12 (11).\n\n\n———. 2016a. “Points of Significance: Analyzing Outliers:\nInfluential or Nuisance.” Nature Methods 13 (4): 281–82.\n\n\n———. 2016b. “Points of Significance: Regression\nDiagnostics.” Nature Methods 13 (5): 385–86.\n\n\nChristensen, Ronald. 2018. Analysis of Variance, Design, and\nRegression: Linear Modeling for Unbalanced Data. CRC Press.\n\n\nCohen, Jacob. 1988. Statistical Power Analysis for the Behavioral\nSciences. 2nd ed. Routledge.\n\n\nCumming, Geoff. 2013. Understanding the New Statistics: Effect\nSizes, Confidence Intervals, and Meta-Analysis. Routledge.\n\n\nDebanne, Thierry, and Guillaume Laffaye. 2011. “Predicting the\nThrowing Velocity of the Ball in Handball with Anthropometric Variables\nand Isotonic Tests.” Journal of Sports Sciences 29 (7):\n705–13.\n\n\nFox, John. 2011. An r Companion to Applied Regression. 2nd ed.\nSAGE Publication Inc., Thousand Oaks.\n\n\nKutner, Michael H, Christopher J Nachtsheim, John Neter, and William Li.\n2005. Applied Linear Statistical Models. 5th ed. McGraw-Hill\nIrwin New York.\n\n\nMcElreath, Richard. 2016. Statistical Rethinking, a Bayesian Course\nwith Examples in r and Stan. 1st ed. Boca Raton: CRC Press.\n\n\nSpiegelhalter, David. 2019. The Art of Statistics: Learning from\nData. Penguin UK.\n\n\nWasserstein, Ronald L, and Nicole A Lazar. 2016. “The ASA\nStatement on p-Values: Context, Process, and Purpose.” Taylor\n& Francis.\n\n\nWild, Christopher J, and Georg AF Seber. 2000. Chance Encounters: A\nFirst Course in Data Analysis and Inference. Wiley Press.\n\n\nYoung, Alwyn. 2019. “Channeling Fisher: Randomization Tests and\nthe Statistical Insignificance of Seemingly Significant Experimental\nResults.” The Quarterly Journal of Economics 134 (2):\n557–98."
  },
  {
    "objectID": "stats_significance.html#die-verteilung---1.-deep-dive",
    "href": "stats_significance.html#die-verteilung---1.-deep-dive",
    "title": "2  Statistische Signifikanz, p-Wert und Power",
    "section": "2.2 Die Verteilung - 1. deep dive",
    "text": "2.2 Die Verteilung - 1. deep dive\nWir versuchen jetzt als erstes zu Verstehen was nochmal genau der Graph der Verteilung bedeutet. Auf der x-Achse werden die verschiedenen möglichen Werte der jeweiligen Statistik abgebildet. In unserem bisherigen Beispiel was das die Unterschiede \\(D\\) zwischen der Kontroll- und der Treatmentgruppe. Der Wert auf der y-Achse was zunächst die relative Häufigkeit was auch Sinn gemacht hatte, da wir nur eine bestimmte endliche Anzahl von möglichen Unterschieden \\(D\\) (ihr erinnert auch an die Zahl) vorliegen hatten. Was passiert aber wenn wir tatsächlich eine kontiuierliche Statistik haben, also eine Statistik die alle Werte innerhalb eines Intervalls einnehmen kann. Um den Fall zu verstehen fangen wir aber erst mal wieder mit einem einfachen Modell an.\n\n2.2.1 Der Münzwurf\nWir fangen mit dem einfachsten Experiment an: dem Münzwurf. Beim Münzwurf haben wir zwei mögliche Ausgänge unseres Experiments, entweder Kopf oder Zahl. Wir gehen von einer perfekten Münze aus, d.h. die Münze ist vollkommen symmetrisch auf beiden System und keine der Seiten ist in irgendeiner Form schwere oder beeinflusst in einer Art den Ausgang.\nWenn wir uns an die Schule zurück erinnern, dann haben wir in Wahrscheinlichkeitstheorie schon mal was gehört, das im Fall gleichwahrscheinlicher Ereignisse die Wahrscheinlichkeit für ein bestimmtes Ereignis, mittels der Anzahl der vorteilhaften Ausgänge geteilt durch die Anzahl der möglichen Ausgänge berechnet wird. Also beim einmaligen Münzwurf haben wir zwei Ausgänge \\(\\{\\text{Kopf}, \\text{Zahl}\\}\\) und jeweils nur vorteilhaften Ausang als entweder Kopf oder Zahl, daher folgt daraus.\n\\[\\begin{align}\nP(\\text{Kopf}) &= \\frac{1}{2} \\\\\nP(\\text{Zahl}) &= \\frac{1}{2}\n\\end{align}\\]\nWenn wir das jetzt als Graphen in Form einer Wahrscheinlichkeitsverteilung abtragen, dann sieht das noch wenig interessant aus (siehe Abbildung 2.6). Das Muster ist aber trotzdem wichtig, damit wir später wissen worauf wir hier eigentlich schauen. Auf der x-Achse haben wir die möglichen Ausgänge, Kopf oder Zahl, und auf der y-Achse haben wir die Wahrscheinlichkeit abgetragen.\n\n\n\n\n\nAbbildung 2.6: Wahrscheinlichkeitsverteilung des einmaligen Münzwurfes\n\n\n\n\nDa sich mit einem Münzwurf aber so wenig anfangen lässt, machen wir das Ganze jetzt etwas komplizierter und schauen uns an, wie unser Experiment aussieht wenn wir zwei Münzwwürfe uns anschauen. Rein operational, wir schmeißen unsere Münze in die Luft, schreiben uns das Ergebnis auf, und machen das Ganze noch ein zweites Mal und schreiben uns das Ergebnis auf. D.h. was auch immer im ersten Durchgang passiert, hat keine Auswirkungen auf das Ergebnis des zweiten Wurfs. Wir könnten auch zwei Münzen nehmen und beide gleichzeitig in die Luft werfen. Das wäre das gleiche Experiment. Welche Ausgänge haben wir jetzt beim zweimaligen Münzwurf? Zunächst einmal haben wir jetzt nicht mehr nur einen einzelnen Ausgang sondern wir haben ein Ausgangstupel, eine Liste mit zwei Elementen. Etwas motiviertes krizteln auf einem Schmierblatt wird wahrscheinlich relativ schnell zu folgender Tabelle führen (siehe Tabelle 2.1)\n\n\nTabelle 2.1: Mögliche Ausgänge bei einem zweimaligen Münzwurf\n\n\nAusgang 1. Wurf\nAusgang 2. Wurf\nTupel\n\n\n\n\nKopf\nKopf\n(Kopf, Kopf)\n\n\nKopf\nZahl\n(Kopf, Zahl)\n\n\nZahl\nKopf\n(Zahl, Kopf)\n\n\nZahl\nZahl\n(Zahl, Zahl)\n\n\n\n\nJetzt können wir uns wieder fragen, was die Wahrscheinlichkeit für die jeweiligen Ereignistupel ist. Eine direkte Methode wäre, wieder mittels der Symmetrie zu argumentieren. Es gibt vier verschiedene Ausgänge von denen jetzt keiner in irgendeiner Weise bevorzugt ist, daraus würde folgen das alle vier Ausgänge eine Wahrscheinlichkeit von \\(P = \\frac{1}{4}\\) haben.\nEine weitere Möglichkeit wäre mit den Wahrscheinlichkeiten aus dem einfachen Wurf an das Problem heran zu gehen. Wir betrachten die beiden Münzwürfe jetzt wieder sequentiell (siehe Abbildung 2.7). Im ersten Schritt können wir entweder Kopf oder Zahl beobachten. Beide Wahrscheinlichkeiten sind \\(P = \\frac{1}{2}\\). Darauf folgend können wir wieder zwei verschiedene Ausgänge beobachten, eben Kopf oder Zahl, wieder mit der Wahrscheinlichkeit \\(P = \\frac{1}{2}\\).\n\n\n\n\n\nAbbildung 2.7: Auswahlmöglichkeiten beim sequentiellen zweimaligen Münzwurf\n\n\n\nDa die Münzwürfe voneinander unabhängig sind und keinen Einfluss aufeinander ausüben, folgt daraus, dass die Wahrscheinlichkeiten für jede spezielle Folge von Kopf oder Zahl sich berechnet nach:\n\\[\nP(\\text{Ausgang}) = P(\\text{1. Wurf}) \\times P(\\text{2. Wurf})\n\\tag{2.1}\\]\nAlso in unseren Fall:\n\\[\nP(\\text{Ausgang}) = \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{4}\n\\tag{2.2}\\]\nWomit wir wieder beim gleichen Ergebnis wie vorher angekommen sind. Der Vorteil dieser Herangehensweise ist jedoch, dass wir damit eine einfache Möglichkeit gefunden haben das Ergebnis auf mehr als nur zwei Würfe zu verallgemeinern. Nehmen wir zum Beispiel den dreifachen Münzwurf, dann können wir die Wahrscheinlichkeit für die Folge \\(P(\\text{KKZ}) = \\frac{1}{2}\\times \\frac{1}{2} \\times \\frac{1}{2} = \\frac{1}{8}\\) direkt angeben.\nBleiben wir aber erst noch mal kurz beim zweimaligen Münzwurf und schauen uns die Wahrscheinlichkeitsverteilung an. Hier stoßen wir nämlich auf ein Problem in der Darstellung. Wenn wir bei dem Muster aus ?fig-sts-sig-oin-toss-1 bleiben wollen und auf der x-Achse die möglichen Ergnisse und auf der y-Achse die dazugehörende Wahrscheinlichkeit abtragen wollen, dann ist nicht ganz klar wie wir die Ergebnisse ordnen sollen. Eine mögliche Lösung ist in Abbildung 2.8 zu sehen.\n\n\n\n\n\nAbbildung 2.8: Wahrscheinlichkeitsverteilung des zweimaligen Münzwurfes (K: Kopf, Z: Zahl)\n\n\n\n\nDies ist natürlich nicht die einzige Möglichkeit wie wir die Ereignisse ordenen können sondern wahrscheinlich ist jede der 24 möglichen Anordnungen gleich sinnig. Wir könnten auch beispielsweise nicht mehr die beiden einzelnen Ausgänge als Ereignisse wählen, sondern könnten zum Beispiel nur noch die Anzahl der Köpfe in unseren zwei Würfen zählen. Dies würde zu der folgenden Zuordnung führen (siehe Tabelle 2.2).\n\n\nTabelle 2.2: Zuordnung der Anzahl der Köpfe zu den Ereignissen beim zweimaligen Münzwurf\n\n\nEreignisse\nAnzahl der Köpfe\n\n\n\n\n(Kopf, Kopf)\n2\n\n\n(Kopf, Zahl)\n1\n\n\n(Zahl, Kopf)\n1\n\n\n(Zahl, Zahl)\n0\n\n\n\n\nWir verliegen bei dieser Zuordnung nachtürlich die Information bei welchem Wurf die Zahl beobachtet wurde, aber eigentlich interessiert uns das sowieso nicht so brennend. In der Terminologie der Wahrscheinlichkeitstheorie wird die Anzahl der Köpfe als Zufallsvariable bezeichnet.\n\nDefinition 2.2 (Zufallsvariable) Eine Zufallsvariable ist die Abbildung eines Zufallsereignisses auf eine Zahl.\n\nAnders dargestellt, ist eine Zufallsvariable eine Funktion, die einem Ereignis eine Zahl zuordnet (siehe Abbildung 2.9.\n\n\n\n\n\nAbbildung 2.9: Eine Zufallsvariable ist eine Abbildung.\n\n\n\nWenn wir uns jetzt die Wahrscheinlichkeiten für unsere Zufallsvariable anschauen, dann sehen wir aber, dass wir nicht mehr vier verschiedne Ausgänge haben, sondern nur noch drei und das die gleiche Wahrscheinlichkeit für nicht gleich sind.\n\n\nTabelle 2.3: Wahrscheinlichkeitstabelle für Zufallsvariable “Anzahl der Köpfe beim zweimaligen Münzwurf”.\n\n\n\n\n\n\n\nEreignisse\nZufallsvariale\nWahrscheinlichkeit\n\n\n\n\n(Zahl, Zahl)\nKeine Köpfe\n\\(\\frac{1}{4}\\)\n\n\n(Kopf, Zahl)(Zahl,Kopf)\n1 Kopf\n\\(\\frac{1}{4} + \\frac{1}{4} = \\frac{1}{2}\\)\n\n\n(Kopf,Kopf)\n2 Köpfe\n\\(\\frac{1}{4}\\)\n\n\n\n\nJetzt können wir wieder eine Wahrscheinlichkeitsverteilung für unsere Zufallsvariable abtragen (siehe Abbildung 2.10).\n\n\n\n\n\nAbbildung 2.10: Wahrscheinlichkeitsverteilung für die Anzahl der Köpfe beim zweimaligen Münzwurf\n\n\n\n\nNur nebenher noch einmal das offensichtliche Ansprechen, die Summe der Wahrscheinlichkeiten muss zu \\(1\\) addieren. Das sollte auch einsichtig sein. Wenn ich alle möglichen Ereignisse abfrage also: “Was ist die Wahrscheinlichkeit das ich keine Köpfe, 1 Kopf oder 2 Köpfe beim zweimaligen Münzwurf erhalte”, dann sind das alle möglichen Ausgänge und dementsprechend sollte die Wahrscheinlichkeit dafür “1” sein oder mathematisch ausgedrückt:\n\\[\nP(\\text{0 Köpfe} \\cup \\text{1 Kopf} \\cup \\text{2 Köpfe}) = \\frac{1}{4} + \\frac{1}{2} + \\frac{1}{4} = 1\n\\]\n\n\n2.2.2 Lage- und Skalenparameter\nIn Abbildung 2.3 sind verschiedene Verteilungen abgebildet die sich eigentlich nur in ihrer Position bzw. Lage unterscheiden. Der Parameter der bei einer Verteilungen die Lage steuert ist der Mittelwert den wir bereits schon kennengelernt haben. Hier jetzt aber nicht der Mittelwert \\(\\bar{x}\\) in der Stichprobe, sondern der Mittelwert der zugrundeliegenden Population der dann mit dem Symbol \\(\\mu\\) bezeichnet wird. Die Beschreibung als Parameter der Verteilung heißt nichts anderes das die Verteilung von \\(\\mu\\) abhängt, oder formal das die Verteilung eine Funktion von \\(\\mu\\) ist. Wenn wir uns an Funktionen aus der Schule zurück erinnen wo wir Funktionen \\(f\\) von \\(x\\) kennengelernt haben und als \\(f(x)\\) dargestellt haben. Übertragen auf die Verteilung könnte dies mittels \\(f(\\mu)\\) dargestellt werden.\n\n\n\nNehmen wir nun zwei Verteilungen die sich bezüglich ihrer Mittelwerte \\(\\mu\\) unterscheiden. Zum Beispiel sei \\(\\mu_1 = 0\\) und \\(\\mu_2 = 3\\). Wie in Abbildung 2.11 zu sehen ist, führt dies dazu, das die beiden Verteilungen gegeneinander verschoben sind.\n\n\n\n\n\nAbbildung 2.11: Verteilungen mit zwei unterschiedlichen Mittelwerten\n\n\n\n\nDer Mittelwert \\(\\mu\\) der Verteilung wird auch als Erwartungswert bezeichnet. Dies kann dahingehend interpretiert werden, das wenn Stichproben aus dieser Verteilungen gezogen werden, im Mittel der Wert \\(\\mu\\) erwartet wird. Soweit ist dies eigentlich noch nichts wirklich Neues, sondern hatten dies schon vorher gesehen, als wir alle möglichen Unterschiede zwischen der Kontrollgruppe und der Interventionsgruppe ermittelt haben. Hier war der Mittelwert der Verteilung genau derjenige Wert von \\(\\Delta\\).\nAn dieser Stelle sollte nochmal der Unterschied zwischen \\(\\mu\\) und \\(\\bar{x}\\) klargestellt werden. Der Mittelwert \\(\\mu\\) ist eine Eigenschaft der Population, also letztendlich ein Wert den wir niemals kennen werden ohne die gesamte Population zu untersuchen. Der Mittelwert \\(\\bar{x}\\) ist eine Eigenschaft der Stichprobe aus der Population. Also der konkrete Wert den wir anhand der Stichprobe berechnen. In vielen Fällen versuchen wir über \\(\\bar{x}\\) einen Rückschluss auf \\(\\mu\\) zu ziehen.\nAls zweite Eigenschaft von Verteilungen schauen wir uns jetzt die Streuung in der Population an. Die Streuung in der Population wird als Varianz bezeichnet und wird mit dem Symbol \\(\\sigma^2\\) bezeichnet. Schauen wir uns zunächst an, welchen Einfluss \\(\\sigma^2\\) auf die Form der Verteilung hat. In Abbildung 2.12 sind wieder zwei Verteilungen abgetragen. Dieses Mal ist \\(\\mu\\) in beiden Fällen gleich, aber die Varianzen \\(\\sigma\\) sind mit \\(\\sigma_1^2 = 2\\) und \\(\\sigma_2^2=1\\) unterschiedlich.\n\n\n\n\n\nAbbildung 2.12: Verteilungen mit unterschiedlichen Varianzen\n\n\n\n\n1"
  }
]