# Einfache Datenbearbeitung und Visualisierung in `R`  

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```

```{r}
library(tibble)
```

Im Folgenden werden wir verschiedene Funktion zur Bearbeitung und Visualisierung von Daten kennenlernen. Die verwendeten Funktionen sind alle in einer großen Sammlung von Funktionen dem `tidyverse` zugeordnet. Pakete aus dem `tidyverse` verfolgen alle eine einheitliche Syntax und Herangehensweise an die Datenverarbeitung. Daneben verfügen sie über eine ausgezeichnete Dokumentation. Daher werden die jeweiligen Funktionen hier nur kurz angeschnitten. Weitergehende Informationen und vor allem jede Menge Beispielanwendungen findet ihr in der `tidyervers` [Dokumention](https://tidyvers.org).

## Daten in `R` einlesen

Daten in `R` werden mittels spezieller Funktionen eingelesen, die jeweils auf bestimmte Datentypen spezialisiert sind. Drei Pakete sind dabei für die allermeisten ausreichend. Die Pakete sind `readr`, `readxl` und `haven`. 

### readr

Im Paket `readr` sind eine Reihe von Funktionen enthalten um rechteckige Textdateien einzulesen. Die allgemeineste Funktion ist `read_delim()` bei der angegeben werden muss, welche Trennzeichen (engl. delimiter) zwischen den einzelnen Spalteneinträgen steht. Seien z.B. die folgenden Daten in einer Datei `example_01.txt` in dem Ordner `data` gespeichert.

| id	grp	value
| p1	CON	1
| p2	CON	2
| p3	TRT	3
| p4	TRT	4

Das Trennzeichen zwischen den Eintragen ist ein {{< kbd TAB >}}. Die Datei können wir mittels des folgenden Befehls einlesen.

```{r}
#| echo: true

df <- readr::read_delim(
  file = 'data/example_01.txt',
  delim = '\t'
)
```

Mit der Parameter `\t` spezifizieren das verwendete Trennzeichen. `read_delim()` verwendet eine Reihe von Heuristiken um den jeweiligen Datentyp der Spalten zu bestimmen. Der Rückgabewert von `read_delim()` ist ein `tibble()` mit den Daten, das wir der Variable `df` in dem Fall zuweisen.

```{r}
#| echo: true

df
```

Im Beispiel sind die ersten beiden Spalten als Zeichenketten (`<char>`) erkannt worden, während die dritte Spalte als Zahl (`<dbl>`) erkannt wurde. Manchmal funktionieren die Regeln nicht korrekt. In dem Falle können mit dem Parameter `col_types` die Spaltentypen direkt angegeben werden. Wenn keine Kopfzeile in den Daten vorhanden ist, kann diese über den Parameter `col_names` spezifiziert werden. Mit `skip` können Zeilen zu Beginn der Datei übersprungen werden.

Zum Beispiel wenn wir die Spaltennamen anders haben wollen, können wir die erste Zeile beim einlesen überspringen und andere Spaltennamen angeben.

```{r}
#| echo: true

readr::read_delim(
  file = 'data/example_01.txt',
  delim = '\t',
  skip = 1,
  col_names = c('ID', 'Gruppe','Wert'),
  col_types = 'ccd'
)
```

Wie immer, wenn ihr das Paket `readr` mit `library()` geladen habt, ist die Qualifizierung `readr::` nicht notwendig um die Funktion zu verwenden. Die weiteren Funktionen in `readr`  wie `read_csv`, `read_tsv` usw. sind in den meisten Fällen Spezialversionen von `read_delim` bei denen der Parameter `delim` schon voreingestellt ist. Schaut euch etwas in der [Dokumentation](https://readr.tidyverse.org/reference/index.html) um einen Überblick über die verschiedenen Varianten zu bekommen.


### readxl

Die gleichen Daten in einer Excel-Datei können wir mit der Funktion `read_xlsx()` aus dem Paket `readxl` in `R` laden. Wenn die Daten die folgende Form hat:

```{r}
#| label: fig-r-basics-excel 
#| fig-cap: "Beispieldatei in Excel"

knitr::include_graphics('pics/excel_example.png')
```

Die Daten können mit dem folgenden Befehl dann geladen werden.

```{r}
#| echo: true

df <- readxl::read_xlsx('data/example_01.xlsx',
                        sheet = 'data',
                        range = 'A1:C5')
df
```

### haven

Das gleiche Prinzip nochmal bei SPSS-Dateien (siehe @fig-r-bascis-spss).

```{r}
#| label: fig-r-basics-spss
#| fig-cap: Beispieldatei in SPSS

knitr::include_graphics('pics/spss_example.png')
```

Hier kann die Funktion `read_sav()` aus dem Paket `haven`.

```{r}
#| echo: true

df <- haven::read_sav('data/example_01.sav')
df
```


## Daten in `R` prozessieren mit `tidyverse()`

### Der Pipe operator `|>`

In `R` gibt es einen sogenannten pipe-operator `|>` mit dem Rückgabe aus einer Funktion als das erste Argument einer nachfolgenden Funktion übergeben werden können. Dies ermöglicht es Code zu schreiben der sich wie das gesprochene Wort liest. Schauen wir uns ein einfaches Beispiel an. Wir wollen den Mittelwert eines Zahlenvektors berechnen und anschließend das Ergebnis auf die zweite Nachkommastelle runden. Normalerweise würden wir das wie folgt formulieren wenn wir keine Zwischenvariablen definieren wollen.

```{r}
#| echo: true

vec <- c(1, 7, 3, -5.22, 5, 6.3)
round(mean(vec), 2)
```

D.h. wir haben ein Schachtelung der Funktionen. Die `mean()` Funktion ist innerhalb der `round()` Funktion geschachtelt bzw. der Rückgabewert von `mean()` wird als erstes Argument an `round()` übergeben. Schauen wir uns nun an, wie wir das gleiche Programm mit dem pipe-operator durchführen würden.

```{r}
#| echo: true

vec |> mean() |> round(2)
```

Was ist hier passiert. Die erste pipe `|>` übergibt ihr links stehendes Argument `vec` and das erste Argument der rechts stehenden `mean()`. `mean()` ist jetzt happy und berechnet den Mittelwert des Vektors. Jetzt kommt das die zweite pipe und nimmt wieder das linke Argument, das ist jetzt der berechnete Mittelwert, und übergibt diesen an das erste Argument von `round()`. Wenn ihr euch die Hilfe von `round()` anschaut, dann seht ihr, dass dies der zu rundende Wert ist. Was macht jetzt aber die `2` in `round(2)`. Nun, `|>` stellt den links stehenden Wert an die erste Stelle der rechts stehenden Funktion, dadurch rutsch die `2` an die zweite Argumentenstelle in `round()` und bestimmt somit die Anzahl der zu runden Stellen. Keine Sorge, mit etwas Übung geht euch `|>` in Fleisch und Blut über.

Der Vorteil ist des pipe-Operators ist, dass ihr das Program einfach von links nach rechts lesen könnt. Nimm `vec`, stecke es in `mean()` und stecke das was rauskommt in `round(2)`. Bei dem ursprünglichen Programm musstet ihr euch von innen nach außen arbeiten und dabei immer im Blick behalten auf welcher Stufe ihr seid um die Parameterzuordnung richtig interpretieren zu können.

Noch ein Beispiel, wir wollen den Mittelwert auf den Absolutwerten des Vektors berechnen. Nach der Standardmethode.

```{r}
#| echo: true

round(mean(abs(vec)), 2)
```

Mit dem pipe-Operator

```{r}
#| echo: true

vec |> abs() |> mean() |> round(2)
```

Der pipe-Operator `|>` ist so alltäglich, dass ihr in RStudio einen short-cut für ihn habt {{< kbd STRG+SHIFT+m >}}.

Neben dem Grund das `|>` ziemlich praktisch ist, haben ihn wir hier eingeführt, weil er Umgang mit Datenprozessierung im Zusammenhang mit `tidyverse` praktisch unabkömmlich ist. Die dahinterliegende Idee ist tatsächlich schon relativ lange bekannt in der Informatik [siehe @kernighan1984]. Anstatt große, komplizierte Funktionen zu schreiben die eine Vielzahl von Argumenten haben und mehrere unterschiedliche Aufgaben erledigen, werden lieber viele kleine, spezialisierte Programmer erstellt. Die spezialisierten Programme können dann zusamengesetzt werden um komplizierte Aufgaben zu erfüllen. Der pipe-operator ist dabei zentral für diese Idee, da er es ermöglicht die spezialisierten, kleinen Programmen einfach aneinander zu hängen. Ähnlich wie zum Beispiel bei einen Kinderwasserspielzeug mit Rohren, Schaufeln, Filtern usw..

Um die Daten optimal mit dem `tidyverse` verarbeiten zu können, sollten die Daten im `tibble()` eine bestimmt Struktur haben.

Dabei immer daran denken, wollen wir das Ergebnis einer pipe weiterverwenden, müssen wir das Ergebnis auch wieder eine Variable zuweisen.

```{r}
#| echo: true
abs_mean_2 <- vec |> abs() |> mean() |> round(2)
abs_mean_2
```


### tidy-Data

Zu tidy-Data gibt es in der einfachsten Form nur drei Regeln.

1. Jede Spalte ist eine Variable
2. Jede Zeile ist eine Beobachtung
3. Jeder Zelle ist ein einzelner Eintrag

Schauen wir uns wieder ein einfaches, fiktives Beispiel mit Sprunghöhen an.

```{r}
#| echo: true

df <- tibble(
  time = rep(c('pre','post'), 4),
  gender = rep(c('m','f'), each=4),
  age = rep(round(runif(4, 20, 40)),each=2),
  cmj = round(rnorm(8, c(25,20), 2), 1)
)
df
```

Wir haben vier Spalten, `time`, `gender`, `age` und `cmj` die jeweils eine Variable darstellen. In jeder Zeile ist eine Beobachtung eine Sprunghöhe `cmj` einer Person eines Alters `age` und `gender` zu einem bestimmten Zeitpunkt `time`. Schaut also tidy aus.

Diese Darstellung ist aber wahrscheinlich unterschiedlich zu derjenigen wie ihr solche Daten schon öfter gesehen habt. Wahrscheinlich nämlich eher so.

```{r}
df |> pivot_wider(names_from=time, values_from=cmj)
```

Diese Darstellung ist zwar kompakter aber entspricht nicht mehr den tidy-Anforderungen, da wir nun nicht mehr nur eine Beobachtung pro Zeile haben. Wir haben für jede Person die Sprunghöhe zu zwei Zeitpunkten in einer Zeile. Die Daten sind in dieser Darstellung also *untidy*. Die *tidy*-Version ist etwas länger und enthält redundante Informationen aber wir werden im Folgenden sehen, dass diese Darstellung in der Verarbeitung zahlreiche Vorteile hat. Dazu werden wir auch Funktionen kennenlernen mit denen wir zwischen diesen beiden Formaten hin- und herwechseln können. Die *tidy*-Darstellung wird als long-Format bezeichnet, während die *untidy*-Darstellung als wide-Format bezeichnet wird.

### `filter()`

Lernen wir jezt unseren ersten `tidyverse()` Befehl zur Datenmanipulation kennen. Die Befehle sind immer als Verben bezeichnet und die Regel ist, was im Namen draufsteht ist auch in der Packung drin. Der Befehl `filter` filtered somit die Daten. Dazu wir eine einfache Regel mittels der Vergleichsoperatoren angegeben. Wollen wir beispielsweise auf `gender == 'f' filtern, benutzen wir:

```{r}
#| echo: true

df |> filter(gender == 'f')
```

Oder auf das Alter `age < 30`:

```{r}
#| echo: true

df |> filter(age < 30)
```

Wir können auch mehrere Filteranweisungen zusammensetzen.

```{r}
#| echo: true

df |> filter(age < 25, gender == 'f')
```


In diesem Sinne geht es jetzt immer weiter mit den Befehlen im `tidyverse`.

### `select()`

Mit `select()` können wir einzelne Variablen aus einem `tibble()` auswählen.

```{r}
#| echo: true

df |> select(time, gender)
```

oder mit einem `-` ausschließen.

```{r}
#| echo: true

df |> select(-gender)
```


### `mutate()`

Wenn wir neue Variablen aus den bestehenden Variablen berechnen wollen, dann können wir dazu die `mutate()` Funktion benutzen. Zum Beispiel, wenn wir in unserem Datensatz die Sprunghöhe in Meter anstatt in Zentimeter vorliegen haben wollen.

```{r}
#| echo: true

df |> mutate(cmj_m = cmj / 100)
```

### `summarize()`

Mit der `summarize()` Funktion werden alle Beobachtung (Zeilen) in eine Zeile zusammengefasst. Wollen wir zum Beispiel die durchschnittliche Sprunghöhe über alle Beobachtung berechnen.

```{r}
#| echo: true

df |> summarize(cmj_bar = mean(cmj))
```

`summarize()` kann auch mehrere Werte berechnen.

```{r}
#| echo: true

df |> summarize(cmj_bar = mean(cmj), age_bar = mean(age))
```


### `group_by()`

Die `summarize()` Funktion wird tatsächlich erst richtig mächtig im Zusammenhang mit der `group_by()` Funktion. Mit `group_by()` kann ein Datensatz anhand der Werte einer Variable in Untergruppen geschnitten werden. Wollen wir in unserem Beispiel die Mittelwerte für verschiedenen Zeitpunkte berechnen.

```{r}
#| echo: true

df |> group_by(time) |> summarize(cmj_bar = mean(cmj))
```

Das gruppieren funktioniert auch über mehrere Variablen.

```{r}
#| echo: true

df |> group_by(time, gender) |> summarize(cmj_bar = mean(cmj))
```

Die Kombination aus `filter()`, `group_by()` und `summarize()` deckt wahrscheinlich mehr als die Hälfte der Anwendungen bei der Datenanalyse ab. Die folgenden Befehle sind etwas spezialisiert.

### `separate()`

Mit dem `separate()` Befehle kann eine Variable in der mehrere Informationen gespeichert sind, in mehrere Variablen separiert werden.

```{r}
df_2 <- tibble(
  Kondition = c('pre_trt','post_trt','pre_con','post_con'),
  wert = 1:4
)
df_2
```

Die Variable Kondition hat zwei Variablen in einer kodiert (*untidy*). Mit `separate()` können wir Kondition aufteilen. `separate()` benötigt als Parameter neben dem Spaltennamen eine Vector der neuen Spaltennamen übergeben an das Funktionsargument `into`.

```{r}
#| echo: true

df_2 |> separate(Kondition, into=c('time','group'))
```

### `pivot_wider()`

Mit `pivot_wider()` können *tidy*-Datensätze von der long-Version in die wide-version umkodiert werden. Im einfachsten Fall benötigt `pivot_wider()` zwei Argumente. `names_from` wird der Variablenname übergeben, der einzelne `wide`-Variablen kodieren. `values_from` spezifiziert die einzutragenden Variablen.

```{r}
#| echo: true

df_w <- df |> pivot_wider(names_from=time, values_from=cmj)
df_w
```

### `pivot_longer()`

Die Umkehrfunktion von `pivot_wider()` ist `pivot_longer()`. Wieder im einfachsten Fall müssen die umzukodierenden Spalten angegeben werden, zusammen mit dem neuen Spaltennamen für die Indizierung (`names_to`) und dem neuen Spaltennamen für die Werte (`values_to`).

```{r}
#| echo: true

df_w |> pivot_longer(c(pre, post), names_to = "time", values_to = "cmj")
```

Zusammenfassend ist das hier nur eine schnelle Übersicht über die möglichen Befehle gewesen. Um die ins und outs der Funktionen zu verstehen, ist natürlich mehr Übung notwendig. Meistens hilft es aber schon zu wissen welche der Funktionen ungefähr helfen könnte um dann zusammen mit der Dokumentation eine Lösung zu finden. Eine exzellente Quelle für eine umfassendere Auseinandersetzung mit dem `tidyverse` ist das Buch *R for Data Science* von @wickham2023 das ihr auch kostenlos in der aktuellsten Form [online](https://r4ds.had.co.nz) findet.

## Daten in `R` visualisieren mit `ggplot()`

```{r}
#| echo: true

df <- tibble(
  dv = 1:8,
  iv = 11:18,
  group = rep(c('a','b'), 4),
  team = rep(c('Nuggets','Lakers'), each=4)
)
```

```{r}
knitr::kable(df,
             booktabs = TRUE,
             linesep = '')
```


### `geom_point()`

Fangen mit dem einfachsten geometrischen Objekt an, dem Punkt bzw. den Punkten. Punkte sind mindestens durch eine $x$ und $y$-Position, eine Größe und eine Farbe gekennzeichnet. Schauen wir uns zunächst nur die Position an, und lassen die Farbe und die Größe auf den voreingestellten Werten.

```{r}
#| echo: true
#| fig-cap: "Ein Streudiagramm"
#| label: fig-r-basics-scatterplot

ggplot(df, aes(x = dv, y = iv)) +
  geom_point()
```

Die Funktion `aes()` bestimmt die Abbildung der Variablen auf die Skalen. Links vom Gleichheitszeichen steht die zu bestimmende Skala und rechts die dazugehörige Variable. Somit haben wir in @fig-r-basics-scatterplot ein einfache Streudiagramm der Daten erstellen.

Da es sich bei `aes()` um eine ganz normale `R`-Funktion handelt können und `x` und `y` die ersten beiden Argumente der Funktion sind, hätten wir auch kürzer schreiben können.

```{r}
#| echo: true
#| eval: false

ggplot(df, aes(dv, iv)) +
  geom_point()
```

Diese Schreibweise wird uns im Folgenden immer wieder begegnen. Wenn ihr euch die Hilfe für `geom_point()` anseht, dann stellt ihr fest, dass `geom_point()` auch wieder nur eine Funktion ist und als erstes Argument ebenfalls `mapping` hat. Daher können wir das Streudiagramm auch folgendermaßen erstellen.

```{r}
#| echo: true

ggplot(df) +
  geom_point(aes(dv, iv))
```

Der Unterschied zwischen dem Argument `mapping` in `ggplot()` und in `geom_point()` besteht darin, dass die Abbildung im ersten Falle für alle `geom` gilt, während im zweiten Fall die Abbildung nur `geom_point()` gilt. Wenn wir gleich mehrere `geom` aneinanderreihen wird der Unterschied klarer.

Schauen wir uns als nächste zwei verschiedene Arten an, die Größe für die Punkte zu bestimmen. Hier gibt es auch wieder zwei Fälle zu unterscheiden. Einmal die Größe innerhalb von `aes()` zu bestimmen oder als Argument zu `geom_point()`. Im ersten Fall können wir dynamisch anhand der zugewiesenen Abbildungsvariable die Größe verändern, während im zweiten eine Größe für alle Punkte zugewiesen wird. Innerhalb von `aes()` können wir den Namen der Variable nehmen, während dies in `geom_point()` nicht möglich ist, hier müssen wir eine Zahl übergeben.

```{r}
#| echo: true
#| layout-ncol: 2
#| label: fig-r-basics-scattersize
#| fig-cap: Definition der Punktgröße auf zwei Arten
#| fig-height: 4
#| fig-subcap:
#|   - "Definition in `aes()`"
#|   - "Definition in `geom_point()`"

ggplot(df, aes(dv,iv, size=dv)) +
geom_point()
ggplot(df, aes(dv, iv)) +
geom_point(size=4)
```

In @fig-r-basics-scattersize-1 sehen wir, dass die Größe der Punkte variiert und `ggplot()` auch noch eine Legende der Größen angefügt hat. In @fig-r-basics-scattersize-2 haben alle Punkte die gleiche Größe.

Das gleiche Prinzip können wir auch auf die Farbe der Punkte anwenden.

```{r}
#| echo: true
#| layout-ncol: 2
#| label: fig-r-basics-scattercol
#| fig-cap: Definition der Punktfarbe auf zwei Arten
#| fig-height: 4
#| fig-subcap:
#|   - "Definition in `aes()`"
#|   - "Definition in `geom_point()`"

ggplot(df, aes(dv,iv, color = team)) +
geom_point()
ggplot(df, aes(dv, iv)) +
geom_point(color = 'red')
```

Wenn die Farbe in `aes()` definiert wird, erhalten wir eine Legende und die Farbe wird anhand der Variable bestimmt (siehe @fig-r-basics-scattercol-1), während bei der Definition als Argument zu `geom_point()` alle Punkte die gleiche Farbe bekommen (siehe @fig-r-basics-scattercol-2).

Natürlich können wir auch gleichzeitig die Farbei und die Größe bestimmen.

```{r}
#| echo: true
#| layout-ncol: 2
#| label: fig-r-basics-scattercolsize
#| fig-cap: Definition der Punktfarbe und Punktgröße auf zwei Arten
#| fig-height: 4
#| fig-subcap:
#|   - "Definition in `aes()`"
#|   - "Definition in `geom_point()`"

ggplot(df, aes(dv,iv, size = dv, color = team)) +
geom_point()
ggplot(df, aes(dv, iv)) +
geom_point(size = 4, color = 'red')
```

### `geom_line()`

Schauen wir uns als nächstes `geom_line()` an. Wie der Name vermuten lässt, können wir mit diesem `geom` Linien erstellen. Linen werden zwischen aufeinanderfolgenden Punkten die eine $(x,y)$-Position haben gezogen. Daher sind die gleichen Abbildungen wie bei den Punkten möglich.

```{r}
#| echo: true
#| label: fig-r-basics-line-01
#| fig-cap: "Linendiagramm"

ggplot(df, aes(iv,dv)) +
  geom_line()
```

Wenn wir zwei unterschiedlichen Linien für die Teams erstellen wollen, dann können wir das zum Beispiel über die Farbe steuern.

```{r}
#| echo: true
#| label: fig-r-basics-line-02
#| fig-cap: "Liniendiagramm unterteilt nach Team"

ggplot(df, aes(iv, dv, color = team)) +
  geom_line()
```

Jetzt fehlt in @fig-r-basics-line-02 das Verbindungsstück zwischen den beiden Punkten das in @fig-r-basics-line-01 noch vorhanden war, da `ggplot()` den Datensatz in zwei Teildatensätze unterteilt.

Wie oben schon angedeutet können wir mehrere `geom` miteinander kombinieren.

```{r}
#| echo: true
#| label: fig-r-basics-line-03
#| fig-cap: "Ein kombiniertes Linien und Streudiagramm"

ggplot(df, aes(iv, dv)) +
  geom_line() +
  geom_point()
```

Die Reihenfolge spielt dabei eine Rolle, `geom`s die später dazugefügt werden, liegen oberhalb von `geom`s die früher definiert wurden.

```{r}
#| echo: true
#| layout-ncol: 2
#| label: fig-r-basics-line-04
#| fig-cap: Einfluss der Reihenfolge von `geom`s 
#| fig-height: 4
#| fig-subcap:
#|   - "`geom_point()  vor `geom_line()`"
#|   - "`geom_line()  vor `geom_point()`"

ggplot(df, aes(iv, dv)) +
  geom_point(color = 'red', size = 4) +
  geom_line()
ggplot(df, aes(iv, dv)) +
  geom_line() + 
  geom_point(color = 'red', size = 4) 
```

In @fig-r-basics-line-04-1 sehen wir, dass die Linien die Punkte durchschneiden, da sie oberhalb liegen, während in @fig-r-basics-line-04-2 die Linien hinter den Punkten liegen.

Vielleicht ist es euch schon aufgefallen, das wir in den letzten beiden Beispielen den Mechanismus verwendet haben, dass die Abbilung in `ggplot()` definiert wurden und dann für bei beide `geom`s `geom_point()` und `geom_line()` angewendet wurden. Wenn wir die Abbildung nur ein `geom_point()` definiert hätten, dann würde `geom_point()` meckern, das es nicht weiß wo es die Punkte hinsetzen soll.

```{r}
#| echo: true
#| error: true

ggplot(df)  +
  geom_line(aes(iv, dv)) + 
  geom_point() 
```

Nachdem wir jetzt schon die Grundprinzipien kennengelernt haben, schauen wir uns die nächsten `geom`s etwas kürze an.

### `geom_boxplot()`

Der Boxplot als eine praktische Art der Visualisierung sollte natürlich auch nicht fehlen und hat daher auch ein eigenes `geom` spendiert bekommen. Hier ist zu beachten, dass die Abbildung auf die $x$-Achse üblichweise nicht numerisch sondern entweder nominal oder ordinal ist. In der Praxis können auch Zeichenketten verwendet werden, die dann als Faktor interpretiert werden.

```{r}
#| echo: true
#| label: fig-r-basics-boxplot
#| fig-cap: "Ein Boxplot mit `geom_boxplot()`."

ggplot(df, aes(team, dv)) +
  geom_boxplot()
```

Wir können wieder mehrere Abbildungen kombinieren und zum Beispiel getrennte Boxplots für die Teams und die Gruppen erstellen.

```{r}
#| echo: true
#| label: fig-r-basics-boxplot-2
#| fig-cap: "Getrennte Boxplots nach Team und Gruppe."

ggplot(df, aes(team, dv, fill=group)) +
  geom_boxplot()
```

### `geom_col()`

Die nächste Art von Visualisierung sind Säulendiagramme. Hier müssen wir allerdings etwas Vorarbeit leisten. Bei Säulendiagrammen wird in den meisten Fällen der Mittelwert dargestellt. Daher müssen wir den Mittelwert zunächste berechnen.

```{r}
#| echo: true

df_team <- df |> 
  group_by(team) |> 
  summarize(m = mean(dv), sd = sd(dv))
```

```{r}
df_team |> knitr::kable(booktabs=TRUE, digits = 2)
```

Wir haben gleich auch noch die Standardabweichungen berechnet, da wir die gleich benötigen werden. Säulendiagramme können mit `geom_col()` erstellt werden. Wie bei `geom_boxplot()` sollte die $x$-Skala nominal sein.

```{r}
#| echo: true
#| label: fig-r-basics-col-01
#| fig-cap: "Ein Säulendiagramm mit `geom_col()`."

ggplot(df_team, aes(team, m)) +
  geom_col()
```

So weit so gut, aber keine Darstellung des Mittelwerts ohne eine Darstellung der Streuung. Dazu benötigen wir allerdings ein weiteres `geom`.

### `geom_errorbar()`

Um die Streuung in einem Säulendiagramm mit einzufügen, verwenden wir `geom_errorbar()`. Hier kommen endlich einmal zwei neue Abbildungen ins Spiel. `ymin` bestimmt das untere Ende des Fehlerbalkens, während `ymax` das obere Ende bestimmt. D.h. die Fehlerbalken sind müssen nicht unbedingt in beide Richtungen gleich lang sein.

```{r}
#| echo: true

ggplot(df_team, aes(team, m)) +
  geom_col() +
  geom_errorbar(aes(ymax = m - sd, ymax = m + sd))
```

### `geom_histogram()`
### `facet_grid()`
### `labs()` und `lims()`
### `scale_x|y_continuous()`
### `theme()` 

Insgesamt haben wir wieder nur die Oberfläche von `ggplot` gekratzt. Allerdings sollte ihr mit diesen wenigen `geom`s schon eine Großzahl eurer Anwendungsfälle abbilden können. Im Netz gibt es eine Reihe von sehr guten freien Quellen um sich eingehender mit `ggplot` auseinander zu setzen. Bei Problemen ist auch die extrem gute Dokumentation zu konsultieren. Dazu kommen mittlerweile auch eine Reihe von Zusatzbibliotheken um praktisch jede erdenkliche Art von Visualisierung zu erstellen.
