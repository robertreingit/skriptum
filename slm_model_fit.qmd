# Modellfit 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```

Nachdem ein Modell mittels einer einfachen linearen Regression an die Daten gefittet wurde, sollte immer überprüft werden ob das Modell tatsächlich auch den Annahmen entspricht. Ein zentrales Mittel dazu ist eine Analyse der Residuen.

## Residuen

```{r defs_reg_resid}
adl <- readr::read_delim("adcs;adas\n4.05;50.01\n5.03;46.04\n5.03;39.03\n8.04;49.02\n8.04;46.02\n8.04;42.03\n8.06;55.03\n8.06;37.03\n9.02;52.01\n11.03;57.04\n11.03;51.04\n12.01;47.01\n13.01;52.01\n13.01;50.02\n12.99;41.03\n13.01;36.02\n13.01;28\n14.02;46.04\n15;48.03\n15;42.02\n15;36.02\n15.02;34\n16.02;39.03\n17;45.03\n17;24.02\n17.99;43.02\n18.99;40\n20.01;34.01\n20.01;29\n21.02;33.03\n23;43.02\n23;10\n23.98;25.01\n24.99;49.02\n24.99;35.01\n26.01;35\n26.97;45.03\n28;22\n32.99;55.03\n12.01;50.1\n12.01;49.03\n",
                         delim = ';',
                         col_types = 'dd')
mod <- lm(adcs ~ adas, adl)
adl <- adl |> dplyr::mutate(
  y_hat = predict(mod),
  resid = resid(mod),
  rstudent = rstudent(mod),
  rstandard = rstandard(mod)
)

```

Dazu schauen wir uns zunächst noch einmal an, was überhaupt Residuen $e_i$ sind und gehen noch mal von den grundlegenden Modellannahmen aus (siehe Formel \eqref{eq-sim-model-lr}).
 

\begin{equation}
y_i = \beta_0 + \beta_1 \cdot x_i + \epsilon_i, \qquad \epsilon_i \sim \mathcal{N}(0,\sigma^2)
\label{eq-sim-model-lr}
\end{equation}

Das lineare Regressionsmodell geht von einem linearen Zusammenhang in den Koeffizienten zwischen der Variablen $x_i$ und den Variablen $y_i$ aus. Additiv kommt daz ein normalverteilter Fehler $\epsilon_i$. Die Normalverteilung der $\epsilon_i$ habem einen Erwartungswert von $\mu = 0$ und eine Standardabweichung von $\sigma$. Die Standardabweichung $\sigma$ ist zunächst unbekannt und muss über die Daten abgeschätzt werden. Dies führt dazu,  dass $y_i$ für jeden gegebenen Wert von $x_i$ einer Normalverteilung mit $\mathcal{N}(\beta_0 + \beta_1 x_i, \sigma^2)$ folgen und der bereits bekannten graphischen Darstellung (siehe @fig-slm-model-resid-1).

```{r}
#| fig.cap: "Beispiel einer Regressionsgeraden und der Verteilung der Residuen um den Vorhersagewert $\\hat{y_i}$"
#| label: fig-slm-model-resid-1

set.seed(123)
xx <- seq(-3,3,0.05)
yy <- dnorm(xx)
n <- length(xx) 
n_2 <- 20
df <- tibble::tibble(
  x_0 = rep(1:3, each=n),
  x = x_0 + rep(yy,3),
  y = rep(seq(-1,1,length.out=n), 3) + rep(1:3, each=n),
  g = rep(letters[1:3], each=n)
)
df_2 <- tibble::tibble(x = 1:3, y = 1:3, g = 'a')
df_3 <- tibble::tibble(x = rep(1:3, each=n_2),
                       y = rnorm(3*n_2, mean=x, sd = 0.5), g = 'a')
ggplot(df, aes(x, y, group=g)) + 
  geom_line(data = df_2, aes(x,y), size=1.5) +
  geom_point(data = df_3, aes(x,y), color='red') +
  geom_ribbon(aes(xmin = x_0, xmax = x), fill='red', alpha=0.5) +
  geom_path() +
  geom_point(data = df_2, aes(x,y), size=3) +
  scale_x_continuous(breaks = 1:3) +
  labs(x = 'x-Werte', y = 'y-Werte') 
```

Für jeden gegebenen Wert von $X$ sind die $Y$-Werte Normalverteilt. Die Varianz dieser Normalverteilungen ist gleich $\sigma$ während der Mittelwert $\mu$ immer um den Wert der Regressionsgeraden verschoben ist. D.h. die Streuung von $\epsilon_i$ überträgt sich auf die Streuung von $y_i$ für jeden gegebenen $X$-Wert. Ohne den zufälligen Einfluss der Fehlerwerte würden wir alle $y_i$-Werte perfekt auf der Regressionsgeraden erwarten. Dies deutet daher auch schon eine Möglichkeit an die Residuen $\epsilon_i$ mittels der Daten abzuschätzen. Man verwendet die Abweichungen der beobachteten Werten $y_i$ von den vorhergesagten Werten $\hat{y}_i$ auf der Regressionsgeraden (siehe Formel \eqref{eq-sim-model-res-1}).

\begin{equation}
\hat{\epsilon}_i = e_i = y_i - \hat{y_i}
\label{eq-sim-model-res-1}
\end{equation}

Diese Abweichungen $e_i$ können als Schätzer $\hat{\epsilon}_i$ für die wahren Residuen $\epsilon_i$ verwendet werden (siehe @fig-slm-model-resid-2).

```{r}
#| label: fig-slm-model-resid-2
#| fig.cap: Examplarische Darstellung der Berechnung der Residuen $e_i$ als Abweichung der beobachteten Werte $y_i$ von den vorhergesagten Werten $\hat{y}_i$

set.seed(12)
simple <- tibble::tibble(x = 0:3,
                 y = 2 + 0.5 * x + rnorm(4,0,.5))
mod0 <- lm(y ~ x, simple)
simple$y_hat <- predict(mod0)
simple$epsilon <- paste0('hat(epsilon)[',1:4,']')
simple$ys <- paste0('list(x[',1:4,'],y[',1:4,'])')
simple$yshat <- paste('hat(y)[',1:4,']')
p_res <- ggplot(simple, aes(x,y,label = epsilon)) + 
  geom_point(size=3) +
  geom_line(aes(y = y_hat), size=2, color = 'red') +
  geom_point(aes(y = y_hat), size=3, color = 'red') +
  geom_segment(aes(x = x, y = y_hat, xend = x, yend = y),
               arrow = arrow(type='closed', length=unit(0.05, unit='npc')), size=1,
               color = 'green') +  
  geom_text(aes(x = x - 0.1, y=y_hat, label = yshat), parse=T,
            size = 5, check_overlap = T) +
  geom_text(aes(x = x + 0.14, y = (y_hat + y)/2), parse=T, size=5) + 
  lims(x = c(-.3,3.3), y = c(1,3.8)) 
print(p_res)
```

Da die Normalverteilungen der $\epsilon_i$ für jeden $X$-Wert immer gleich sein sollten bis auf die Verschiebung von $\mu_{Y|X}$, deutet dies ebenfalls eine erste Möglichkeit an, die Modellannahmen graphisch zu überprüfen. Wenn die Residuen $e_i$ geben die vorhergesagten Werte $\hat{y}_i$ abgetragen werden, dann sollte die Verteilung der Residuen $e_i$ überall nahezu gleich sein, da die Streuung $\sigma$ unabhängig von der *Position* auf der Regressionsgerade ist. In `R` können die Residuen mittels der Funktion `residuals()` bzw. der Kurzform `resid()` ermittelt werden. `residuals()` erwartet als Parameter das gefittete `lm()`-Objekt.

```{r}
#| echo: true

residuals(mod)
```

Die anhand des Modells vorhergesagten Werte $\hat{y_i}$ werden der Funktion `predict()` berechnet. Diese Funktion werden wir uns im nächsten Kapitel noch ausführlich betrachten. Als Parameter wird wiederum das gefittete `lm()`-Modell übergeben.

```{r}
#| echo: true

predict(mod)
```

Beide Funktionen, `resid()` und `predict()` geben die berechneten Werte in der Reihenfolge aus, in der die Originaldaten an `lm()` übergeben wurde. D.h. $e_1$ und $\hat{y}_1$ gehören zum ersten $X$-Wert $x_1$ aus den Originaldaten. Mit Hilfe dieser beiden Variablen kann nun ein Residuenplot erstellt werden (siehe @fig-sim-model-rplot-1).

```{r}
#| fig.cap: "Residuenplot der Residuen $e_i$ gegen die vorhergesagten Werte $\\hat{y}_i$"
#| label: fig-sim-model-rplot-1

ggplot(adl, aes(y_hat, resid)) +
  geom_point() +
  geom_hline(yintercept = 0, col = 'red', linetype = 'dashed') +
  scale_x_continuous(expression(hat(y)[i])) +
  scale_y_continuous(expression(e[i]))
```

Der Plot sollte im Optimalfall so aussehen, dass die Residuen $e_i$ gleichmäßig oberhalb und unterhalb um die Nulllinie verteilt sind und keine weiteren Strukturen oder Muster im Zusammenhang mit $\hat{y}_i$ zu erkennen sind. In dem Residuenplot in @fig-sim-model-rplot-1 ist zunächst einmal kein größeres Problem zu erkennen, bis auf den einen Wert links oben.

Um besser zu Verstehen wir Problem aussehen könnten, schauen wir uns zwei Residuenplots an, bei denen eine Struktur zu erkennen ist (siehe @fig-sim-model-rplot-2)

```{r}
#| layout-ncol: 2
#| fig-cap: "Residuenplots die Probleme anzeigen."
#| fig-subcap:
#|   - Parabelförmiger Zusammenhang zwischen $e_i$ und $\hat{y}_i$
#|   - Ansteigende Streuung mit größer werdendem $\hat{y}_i$
#| label: fig-sim-model-rplot-2
#| fig-height: 5

n <- 30
tibble(
  x = seq(0,10,length.out=n),
  y = x*cos(seq(0,6*pi,length.out = n)/10) + 3*x + 2 + rnorm(n),
  resid = resid(lm(y~x)),
  y_hat = predict(lm(y~x))
) |> rplot()

n <- 40
set.seed(125)
tibble(
  y_hat = runif(n, 0, 1),
  resid = 3 * y_hat * rnorm(n, 0, 2),
) |> rplot()
```

In @fig-sim-model-rplot-2-1 ist ein parabelförmiger Zusammenhang zwischen $e_i$ und $\hat{y}_i$ zu erkennen. Für kleine und große $\hat{y}_i$ Werte sind die Residuen $e_i$ negativ während für mittlere Werte von $\hat{y}_i$ die Residuen $e_i$ positiv sind. Diese deutet darauf hin, das zusäztliche Struktur in den Daten nicht im Modell erfasst wird und führt dazu dass die Modellannahmen der Normalverteilung der $\epsilon_i$ nicht erfüllt sind.

In @fig-sim-model-rplot-2-2 ist dagegen eine anderes Problem zu beobachten, die Residuen $e_i$ zeigen zwar keine Struktur bezüglich positiv zu negativen Werten, allerdings werden die Abweichung von $0$ mit größer werdenen $\hat{y}_i$ immer stärker. Dies deutet darauf hin, das die Streuung der Daten nicht gleich ist. Dies wird als Heteroskedastizität bezeichnet und deutet wiederum auf eine Verletzung der Annahmen bei der Homoskedastitzität ausgegangen wird. D.h. die Streuung soll über den gesamten Bereich von $\hat{y}_i$ gleich bleiben.

::: {#def-homoscedasticity}

### Homoskedastizität\index{Homoskedastizität}

Wenn die Größe der Varianz der Residuen $\epsilon_i$ in einem Regressionsmodell unabhängig von der Größe der Vorhersagevariable $X_i$ ist, wird dies als Homoskedastizität bezeichnet. Die Streuung der Residuen ist dann für alle Werte $X_i$ gleich. Wenn dies nicht der Fall ist, wird von Heteroskedastizität\index{Heteroskedastizität} gesprochen.
:::

Da die Varianz also konstant für alle Werte von $X_i$ ist, trifft dies ebenfalls für die vorhergesagten Werte $\hat{Y}_i$ zu. Daher werden bei vielen der Plots die Residuen $\hat{\epsilon}_i$ gegen die $\hat{Y_i}$ abgetragen. Dies hat den Vorteil, dass später bei der multiplen Regression die gleiche Art von Graphen benutzt werden kann, um Homoskeastizität zu analysieren.

Eine weitere Möglichkeit die Verteilung der Residuen zu überprüfen ist die Anfertigung von sogenannten  qq-Plots. Dies ermöglichen etwas strukturierter die Verteilung der Residuen zu überprüfen.

### Quantile-Quantile-Plots 

qq-Plot ist die Kurzform von Quantile-Quantile-Plot. D.h. es werden die Quantilen von zwei Variablen gegeneinander abgetragen. Um die Funktionsweise besser zu verstehen schauen wir uns erst einmal ein Spielzeugbeispiel an. In @tbl-slm-model-toy-1 ist eine kleiner Datensatz mit $n = 5$ Datenpunkten angezeigt.

```{r}
#| tbl-cap: "Spielzeugbeispieldaten mit $n=5$"
#| label: tbl-slm-model-toy-1

df_qq <- tibble::tibble(y = c(-2, 5, -1.2, 0.1, 7))
df_qq %>% knitr::kable(booktabs=T)
```

Wir wollen jetzt überprüfen ob dieser Datensatz einer Normalverteilung folgt (Wohlwissend das mit fünf Datenpunkten keine Verteilungsannahme überprüft werden kann). Dazu schauen wir uns zunächst noch einmal die bekannte Standardnormalverteilung $\Phi(z) = \mathcal{N}(\mu=0,\sigma^2=1)$ an (siehe @fig-slm-model-toy-1).

```{r}
#| fig.cap: "Dichtefunktion der Standardnormalverteilung"
#| label: fig-slm-model-toy-1

df_qq_2 <- tibble::tibble(
  x = seq(-3,3,length.out=100),
  y = dnorm(x)
)
ggplot(df_qq_2, aes(x,y)) +
  geom_ribbon(aes(ymin = 0, ymax = y), fill='red', alpha=.5) +
  geom_line() +
  labs(x = 'Werte', y = 'Dichte') 
```

Im ersten Schritt unterteilen wir die Standardnormalverteilung $\Phi(z)$ in $n+1 = 6$ gleich große Flächen. D.h. die durch die Flächen bestimmten Abschnitte haben alle die gleiche Wahrscheinlichkeit (=Fläche unter der Dichtefunktion). Die Flächen werden durch jeweiligen Trennpunkte unterteilt die gleichzeitig die Quantilen sind.

```{r}
#| fig.cap: "Unterteilung der Standardnormalverteilung in sechs gleich große Flächen"
#| label: fig-slm-model-toy-2

n <- dim(df_qq)[1]
df_qq_3 <- tibble::tibble(
    x = qnorm(1/(n+1)*(1:n)),
    y = dnorm(x)
  )
ggplot(df_qq_2, aes(x,y)) +
  geom_ribbon(aes(ymin = 0, ymax = y), fill='red', alpha=.5) +
  geom_line() +
  geom_segment(data = df_qq_3, aes(x = x, xend = x, y = 0, yend = y)) +
  scale_x_continuous(breaks = round(df_qq_3$x,2)) +
  labs(x = NULL, y = 'Dichte') +
  theme(axis.text.x = element_text(angle = 45, vjust=1, hjust=1))
```

In unserem Fall haben wir $n=5$ Datenpunkte, unterteilen also unsere Verteilung in $6$ Abschnitte die jeweils eine Fläche von $p = \frac{1}{6} = `r round(1/6,2)`$ haben. D.h. $\frac{1}{6}$ der Werte von $\Phi(x)$ liegen links des ersten Trennpunktes, $\frac{2}{6}$ der Werte von $\Phi(x)$ liegen links des zweiten Trennpunktes, usw. D.h. die Trennpunkte bestimmen die jeweiligen Quantilen, oder genauer die theoretischen Quantilen die unter der Verteilungsannahme erwartet werden.


Die Idee hinter dem qq-Plot besteht nun darin, die empirischen Quantilen gegen die theoretischen Quantilen abzutragen (siehe @fig-slm-model-qqconcept). Wenn die beobachteten Daten aus der gleichen Verteilung wie die theoretische Verteilung stammen, dann sollten die Punkte einer Geraden folgen. Die Steigung der Geraden ist $1$, wenn es sich um die identischen Verteilungen handelt. Wenn die Steigung $\neq1$ ist, dann kommen die Datenpunkte aus der gleichen Familie sind aber um einen Skalierungsfaktor unterschiedlich bzw. um den Mittelwert verschoben. Die Punkte sollten aber trotzdem auf einer Geraden liegen. 

```{r}
#| label: fig-slm-model-qqconcept
#| fig-cap: "Skizze der theoretischen und der empirischen Verteilung mit unterschiedlicher Skalierung (Faktor $2\\times$) aber aus der gleichen Verteilungsfamilie. In beiden Graphen ist die gleiche Quartile markiert"

foo_qq <- function() {
  x <- seq(-5, 5, length.out = 200)
  sigma <- 1.5
  df <- tibble(
    x = x,
    y_1 = dnorm(x),
    y_2 = dnorm(x, sd = sigma)
  ) |> pivot_longer(-x)
  
  q_1_1 <- qnorm(0.05)
  q_1_2 <- qnorm(0.05, sd = sigma)
  d_1_1 <- dnorm(q_1_1)
  d_1_2 <- dnorm(q_1_2, sd = sigma)
  y_1 <- -0.1; y_2 <- -0.15
  df_pts <- tibble(
    x = c(q_1_1, q_1_2, q_1_1, q_1_2),
    value = c(d_1_1, d_1_2, y_1, y_2),
    name = c('y_1','y_2','y_1','y_2')
  )
  df_q_1 <- tibble(
    x = seq(-5, q_1_1, length.out = 50),
    value = dnorm(x),
    name = 'y_1'
  )
  df_q_2 <- tibble(
    x = seq(-5, q_1_2, length.out = 50),
    value = dnorm(x, sd = sigma) ,
    name = 'y_2'
  )
  ggplot(df, aes(x, value, color=name)) +
    geom_line() +
    geom_point(data = df_pts) +
    geom_ribbon(data = df_q_1, aes(ymin = 0, ymax = value), fill = 'red', alpha = 0.3) +
    geom_ribbon(data = df_q_2, aes(ymin = 0, ymax = value), fill = 'blue', alpha = 0.3) +
    annotate('segment', x = -5, xend = 5, y = y_1, yend = y_1, color = 'red') +
    annotate('segment', x = -5, xend = 5, y = y_2, yend = y_2, color = 'blue') +
    annotate('segment', x = seq(-3, 3, length.out = 7),
             xend = seq(-3, 3, length.out = 7), y = y_1, yend = y_1-0.02, color = 'red') +
    annotate('segment', x = seq(-4, 4, length.out = 5),
             xend = seq(-4, 4, length.out = 5), y = y_2, yend = y_2-0.02, color = 'blue') +
    annotate('segment', x = q_1_1, xend = q_1_1, y = d_1_1, yend = y_1, linetype = 'dotted') +
    annotate('segment', x = q_1_2, xend = q_1_2, y = d_1_2, yend = y_2, linetype = 'dotted') +
    annotate('segment', x = q_1_1, xend = q_1_2, y = y_1, yend = y_2, linetype = 'dotted') +
    annotate('text', x = 0, y = y_1-0.03, label = expression(mu)) +
    annotate('text', x = 0, y = y_2-0.03, label = expression(mu)) +
    scale_x_continuous('Werte', labels = NULL) +
    scale_y_continuous('Dichte', limits = c(-.2, .45), labels = NULL) +
    scale_color_manual('Verteilung',
                       values = c('red', 'blue'), labels = c('Theoretisch', 'Empirisch'))
}
foo_qq()
```

Um die empirischen Quartilen zu bestimmen, werden dazu zunächst die beobachteten Datenpunkte aus @tbl-slm-model-toy-1 aufsteigend nach der Größe sortiert (siehe @tbl-slm-model-toy-2). Diese Werte können als *empirische* Quantilen bezeichnet werden. Unter der Annahme, dass die Werte eine repräsentative Stichprobe aus der Verteilung darstellen, erwarten wir, dass wenn wir weitere Werte beobachten würden, etwa $\frac{1}{6}$ der Werte kleiner als der kleinste Wert wären, $\frac{2}{6}$ der weiteren Werte kleiner als der 2. kleinste Wert wären und so weiter und so fort.

| kleinster | 2.kleinster | mittlerer | 2.größter | größter |
| --- | --- | --- | --- | --- |
| `r df_qq$y[1]` |`r df_qq$y[3]` |`r df_qq$y[4]` | `r df_qq$y[2]` |`r df_qq$y[5]` |

: Sortierte Datenwerte des Spielzeugbeispiels {#tbl-slm-model-toy-2}

Daher, wenn die beobachteten Werte der angenommenen theoretischen Verteilung folgen, dann sollte ein Graph der empirischen Quartilen gegen die theoretischen Quartilen nahezu (Stichprobenvariabilität) einer Geraden folgen.

```{r}
#| fig-cap: "Streudiagramm der empirischen Werte gegen die theoretischen Quantilen"
#| label: fig-slm-model-toy-3

df_qq_3 %>% 
  add_column(d = sort(df_qq$y)) %>% 
  ggplot(aes(x, d)) + 
  geom_point(size = 2) +
  scale_x_continuous(breaks = round(df_qq_3$x,2)) +
  labs(x = 'Theoretisch', y = 'Empirisch') 
```

In @fig-slm-model-toy-3 sind die empirischen Quartilen gegen die theoretischen Quantilen für unser kleines Beispiel abgetragen. Tatsächlich ist es in diesem Fall schwierig eine Gerade zu erkennen bzw. von einer zu sprechen, da es sich nur um besagte fünf Wert handelt. Nochmals, mit $n=5$ kann eine realistische Verteilungsannahme nicht überprüft werden. 

Wenn der Datensatz größer ist, dann eignet sich ein qq-Plot allerdings sehr gut Abweichungen zu erkennen. In @fig-slm-model-qqplots sind verschiedene Beispiele abgetragen.

```{r}
#| layout-ncol: 2
#| layout-nrow: 2
#| label: fig-slm-model-qqplots
#| fig-subcap:
#|   - "Perfekt"
#|   - "Enden schwer"
#|   - "Enden leicht"
#|   - "Rechtsschief"
#| fig-cap: "Beispiele für verschiedenen qq-Plots"
 
par(mar=c(1,1,1,1))
pp <- ppoints(50)
pp_norm <- qnorm(pp)
pp_cauchy <- qcauchy(pp)
pp_chisq <- qf(pp, 10, 8)

qqplot(pp_norm, pp_norm, xlab='theoretical', ylab='empirical', main='Perfekt')
qqline(pp_norm, col = 'steelblue', lwd=2) 


qqplot(pp_norm, pp_cauchy, xlab='theoretical', ylab='empirical', main='Tails heavy')
qqline(pp_cauchy, col = 'steelblue', lwd=2)


qqplot(pp_cauchy, pp_norm, xlab='theoretical', ylab='empirical', main='Tails light')
qqline(pp_norm, col = 'steelblue', lwd=2)


qqplot(pp_norm, pp_chisq, xlab='theoretical', ylab='empirical', main='Rechtsschief')
qqline(pp_chisq, col = 'steelblue', lwd=2)
```

In @fig-slm-model-qqplots-1 ist ein perfekter Zusammenhang zwischen den empirischen und den theoretischen Quantilen abgebildet. In diesem Falle wurden synthetisch für 50 normalverteiltet Zufallsdaten ein qq-Plot erstellt. Es ist zu sehen, das tatsächlich eine Gerade den Zusammenhang beschreibt. In @fig-slm-model-qqplots-2 ist dagegen ein Zusammenhang abgetragen, bei dem die empirischen und die theoretische Verteilung nicht zusammenpassen. In diesem Fall sind die haben die Randwerte der empirischen Vereteilung eine höhere Wahrscheinlichkeit als die unter der theoretischen Verteilung zu erwarten ist. D.h. extreme Werte kommen in der beobachteten Verteilung öfter in der theoretischen Verteilung vor. Dies deutet darauf hin, dass die Streuung der Daten möglicherweise nicht korrekt modelliert wurde. In diesem Fall, wird von einer *tail heavy* Verteilung gesprochen.

In @fig-slm-model-qqplots-3 ist der gegenteilige Effekt abgetragen. Hier hat die theoretische Verteilung mehr Wahrscheinlichkeitsmasse in den Randzonen als die empirische Verteilung. Die beobachtete Verteilung ist *tail light*. Entsprechend ist in @fig-slm-model-qqplots-4 ein Beispiel abgebildet, bei dem nur eine der Randzonen zu viel Wahrscheinlichkeitsmasse besitzt. Da die theoretische Verteilung wiederum die Normalverteilung ist und diese Symmetrisch ist, deutet diese darauf hin, das die empirische Verteilung ähnlich wie in @fig-slm-model-qqplots-2 in der rechten Randzone zu *viele* Werte hat und daher Rechtsschief ist.

Für unsere Daten ergibt sich das folgende qq-Diagramm (siehe @fig-slm-model-qqplot-data)
```{r}
#| fig-cap: "QQ-Diagramm der Residuen des ADAS-ADCS-Modells"
#| label: fig-slm-model-qqplot-data
 
adl |> 
  ggplot(aes(sample = resid)) +
  geom_qq() +
  geom_qq_line() +
  labs(x = 'Theoretische Verteilung', y = 'Empirische Verteilung')
```

Der Graph sieht zunächst einmal gar nicht so schlecht aus. Allerdings deutet die Abweichung rechts oben darauf hin, das möglicherweise die Streuung nicht korrekt abgeschätzt wurde. Insbesondere ist ein Wert zu sehen, der im Verhältnis zu den anderen Werten schon relativ weit von der Gerade weg ist. Daher ist es hier angezeigt, diesen Wert noch einmal genauer zu untersuchen.

### qq-Plot in `R`

In `R` gibt es zwei direkte Methoden einen qq-Plot zu erstellen. Mittels des Standardgrafiksystem können mit den Funktionen `qqnorm()` und `qqline()` qq-Plots mit der dazugehörigen Gerade erstellt werden. Für das `ggplot()`-System stehen die `geom`s `geom_qq()` und `geom_qq_line()` zur Verfügung. Wichtig ist hierbei, das in `aes()` der Parameter `sample` definiert werden muss. Für unser Spielzeugbeispiel sieht dies folgendermaßen aus:

```{r}
#| echo: true
#| label: fig-slm-model-qqplot-toy
#| fig-cap: "qq-Plot der Spielzeugdaten mittels `ggplot()`"

df_toy <- tibble::tibble(y = c(-2, 5, -1.2, 0.1, 7))
ggplot(df_toy, aes(sample=y)) +
  geom_qq() +
  geom_qq_line()
```


### Standardisierte Residuen

Eine Möglichkeit so einen Wert zu untersuchen, ist abzuschätzen wie *ungewöhnlich* der zu dem Residuen $e_i$ gehörende $y_i$-Wert ist. Ein Problem der einfachen Residuen $e_i$ ist, dass diese laut der Modellannahmen die gleiche Varianz $\sigma^2$ haben sollten. Allerdings, auf Grund der Art, wie die $e_i$ berechnet werden, folgt die Randbedingung, dass die Summe der $e_i$ gleich Null ist, $\sum_{i=1}^n e_i = 0$. Dies führt dazu, dass die einfachen Residuen nicht unanbhängig voneinander sind und nicht immer Homoskedastizität besitzen. Daher gibt es eine weitere Art Residuen anhand des Modell zu berechnen, die nicht unter diesen Beschränkungen leiden. Dies sind die standardisierten Residuen $e_{Si}$. Dazu müssen wir uns zunächst mit Hebelwerte $h_i$ beschäftigen.

#### Hebelwerte

Wenn ein Modell an die Daten gefittet wird, dann haben nicht alle Werte den gleichen Einfluss auf die Modellparameter. Manche Werte üben einen stärkeren Einfluss auf das Modell aus als andere Werte. In @fig-slm-model-outlier-1 ist ein Beispiel abgebildet für einen Datensatz bei dem ein einzelner Punkt einen übermäßig großen Einfluss auf das Modell ausübt.

```{r}
#| fig-cap: "Beispiel für einen Datenpunkt mit einem großen Einfluss auf das Modell. Die resultierenden Regressionsgeraden sind mit dem Punkt (rot) und ohne den Punkt (grün) abgetragen."
#| label: fig-slm-model-outlier-1
 
n <- 30
df <- tibble(
  x = c(runif(n, -1, 1),3),
  y = c(runif(n, -1, 1),3),
  g = rep(c('a','b'),c(n,1))) 
mod1 <- lm(x ~ y, df)
mod2 <- lm(x ~ y, df |> dplyr::filter(g == 'a'))
df <- df |> mutate(hat = round(hatvalues(mod1),2))
ggplot(df, aes(x,y)) +
  geom_point(aes(color=g)) +
  geom_abline(intercept = coef(mod1)[1], slope = coef(mod1)[2], linetype = 'dashed', color='red') +
  geom_abline(intercept = coef(mod2)[1], slope = coef(mod2)[2], linetype = 'dashed', color='green') +
  guides(color = "none")
```

Der einzelen Punkt rechts oben in @fig-slm-model-outlier-1 hat einen großen Einfluss auf die resultierende Regressionsgerade wie in der Abbildung zu sehen ist. Der Einfluss ist zum Teil durch den großen Abstand des $x_i$-Wertes vom Mittelwert der $x_i$-Werte $\bar{x}$ bestimmt. Der Einfluss jedes einzelnen $x$-Wertes wird mittels der sogenannten Hebelwerte $h_i$ bestimmt. Die genaue Berechnung der Hebelwerte $h_i$ ist für das weitere Verständnis allerdings nicht wichtig, sondern mehr das Verständnis des Konzepts. Die Hebelwerte $h_i$ können Werte in $h_i \in [1/n,1]$ annehmen. In `R` können die Hebelwerte mit der Funktion `hatvalues()` berechnet werden.

Tragen wir in die Grafik die Hebelwerte in die Grafik @fig-slm-model-outlier-1 ein (siehe @fig-slm-model-outlier-2), dann ist zu sehen, dass der abgesetzte Wert auch den größten Hebelwert hat.

```{r}
#| fig-cap: "Beispiel für einen Datenpunkt mit einem großen Einfluss auf das Modell. Die Werte geben die jeweiligen Hebelwerte $h_i$ der Datenpunkte wieder."
#| label: fig-slm-model-outlier-2
 
ggplot(df, aes(x,y)) +
  geom_point(aes(color=g)) +
  geom_abline(intercept = coef(mod1)[1], slope = coef(mod1)[2], linetype = 'dashed', color='red') +
  geom_label(aes(label = hat), alpha=.5) +
  guides(color = "none") 
```

Eine Daumenregel für die Hebelwerte ist der Schwellenwert von $(2k+2)/n$, wobei $k$ die Anzahl der unabhängigen Variablen ist. Für den Beispieldatensatz in @fig-slm-model-outlier-2 würde sich daher ein Wert von $(2\cdot 1+2)/30 = 0.13$ ergeben. Entsprechend wäre der abgesetzte Wert mit einem Hebelwert von $h_i = `r max(df$hat)`$ als problematisch einzustufen.

Nach diesem kurzen Exkurs zu den Hebelwerten $h_i$, schauen wir uns für unsere weitere Betrachtung der Residuen zunächst den Zusammenhang zwischen der Varianz der Residuen in der Population $\sigma^2$ und der Varianz der geschätzten Residuen $\sigma^2(\hat{\epsilon}_i) = \sigma^2(e_i)$ an. Es gilt:

\begin{equation}
\sigma^2(e_i) = \sigma^2 (1 - h_i)
\label{eq-slm-model-vare_i}
\end{equation}

D.h. wenn ein Datenpunkt $x_i$ einen kleineren Einfluss auf das Modell ausübt und dementsprechend einen kleinen Hebelwert $h_i$, dann wird die Varianz für diesen Wert nahezu korrekt eingeschätzt. Hat der Wert $x_i$ allerdings, einen großen Hebelwert $h_i$, führt die dazu, dass die Varianz für diesen Wert stärker unterschützt wird. Dieser Zusammenhang kann dazu benutzt werden standardisierte Residuen\index{standardisierte Residuen} zu erstellen.

\begin{equation}
e_{Si} = \frac{e_i}{\hat{\sigma}\sqrt{1-h_i}}
\label{eq-slm-model-stresid}
\end{equation}

Die standardisierten Residuen $e_{Si}$ haben dazu die Eigenschaft, dass sie eine Varianz und damit Standardabweichung von $\sigma^2(e_{Si}) = 1$ haben, also Standardnormalverteilt $\Phi(z)$ sein sollten. Dadurch können Abweichungen von den Modellannahmen leichter Identifiziert werden, da die Skala normiert ist. In `R` kann die standardiserten Residuen $e_{Si}$ mittels der Funktion `rstandard()` berechnet werden. Eine Standardgrafik zum inspizieren der standardisierten Residuen ist wiederum eine Abbildung der $e_{Si}$ gegen die $\hat{y}_i$.

```{r}
#| fig-cap: "Grafik der standardisierten Residuen $e_{Si}$ gegen die Vorhersagewerte $\\hat{y}_i$ für das ADL-Modell."
#| label: fig-slm-model-rstandard

ggplot(adl, aes(y_hat, rstandard)) +
  geom_point() +
  geom_hline(yintercept = c(-2,-1,0,1,2),
             linetype= c('dotted','dotted','dashed','dotted','dotted'),
             color = c('red','red','green','red','red')) +
  labs(x = expression(hat(y)[i]), y = expression(e[Si]))
```

Die @fig-slm-model-rstandard sieht relativ ähnlich zu @fig-sim-model-rplot-1 aus. Durch die Änderung der Skala ist jetzt aber leichter abschätzbar ob die Verteilung der erwarteten Normalverteilung folgt. D.h. etwa $\frac{2}{3}$ der Werte sollten zwischen $-1$ und $1$ liegen und etwa $95\%$ zwischen $-2$ und $2$. Bis auf den einen Punkt oben rechts, sieht alles soweit unauffällig aus.

### Studentized Residuals

Die letzte Art von Residuen sind die sogenannten Studentized Residuals $e_{Ti}$, die mittels der folgenden Formel berechnet werden.

\begin{equation}
e_{Ti} = \frac{e_i}{\hat{\sigma}_{(-i)}\sqrt{1-h_i}}
\label{eq-slm-model-rstudent}
\end{equation}

Die Formel \eqref{eq-slm-model-rstudent} ist sehr ähnlich zu derer für die standardisierten Residuen, der einzige Unterschied ist der Term $\hat{\sigma}_{(-i)}$. Dieser bezeichnet die Residualvarianz wenn dass Modell ohne den Datenpunkt $i$ gefittet wird. D.h. wie stark verändert sich die Schätzung der Varianz wenn ein Datenpunkt weggelassen wird. Normalerweise sollte eine einzelner Punkt keinen übermäßigen Einfluss auf die geschätzte Varianz haben, daher können die Studentized Residuals dazu verwendet werden problematische Datenpunkte zu identifizieren. Wenn die tatsächlichen Residuen einer Normalverteilung folgen, dann kann gezeigt werden, dass die Studentized Residuals einer $t$-Verteilung mit $N-k-2$ Freiheitsgeraden folgen. Daher könnte sogar ein formaler statistischer Test durchgeführt werden. In `R` können die Studentized Residuals $e_{Ti}$ mittels der Funktion `rstudent()` berechnet werden und werden entsprechend den anderen Residuen in dem üblichen Graphen gegen die vorhergesagten Werte $\hat{y}_i$ abgetragen.

```{r}
#| label: fig-slm-model-restudent-1
#| fig-cap: "Graph der Studentized Residuals $S_{Ti}$ gegen die vorhergesagten Werte $\\hat{y}_i$ vor das `adl`-Modell"

ggplot(adl, aes(y_hat, rstudent)) +
  geom_hline(yintercept = 0, linetype = 'dashed', color = 'red') +
  geom_point() +
  labs(x = expression(hat(y)[i]), y = expression(e[Ti]))
```

### Übersicht über die Residuenarten


In @tbl-slm-model-resids sind noch einmal die drei Arten von Residuen aufgelistet.

| Typ | Berechnung | Ziel |
| --- | --- | --- |
| Einfache Residuen | $e_i = y_i - \hat{y}_i$ | Verteilungsannahme |
| Standardisierte Residuen |  $e_{Si} = \frac{e_i}{\hat{\sigma}\sqrt{1-h_i}}$ | Verteilungsannahme |
| Studentized Residuen |  $e_{Ti} = \frac{e_i}{\hat{\sigma}_{(-i)}\sqrt{1-h_i}}$ | Einfluss  auf Modell |

: Übersicht über verschiedene Arten von Residuen {#tbl-slm-model-resids}

### Ausgabe von `summary()` (continued)

Nach dieser Betrachtung der Residuen, die nach jedem Modellfit inspiziert werden sollten um zu überprüfen ob die Modellannahmen angemessen sind schauen wir uns noch einmal kurz die Ausgabe von `summary()` an.

```{r}
summary(mod)
```

Nach der Wiedergabe des gefitten Modells erfolgt direkt eine Zusammenfassung der Residuen über Minimum und Maximum, Q1 und Q3 und den Median. Jetzt sollte daher auch besser nachvollziehbar sein, warum es sinnvoll ist diese Statistiken über die Residuen direkt anzugeben. Die beiden Extremwerte geben einen ersten Überblick auf mögliche Ausreißer, während die erste Quartile Q1 und die dritte Quartile Q3 möglich Asymmetrien in der Verteilung der Residuen anzeigen. Laut der Annahem der Residuen als Normalverteilt mit $\mu = 0$, sollten diese beiden Werte etwa gleich weit von Null entfernt sein. Dementsprechend sollte der Median nahe an Null dran sein. Was nah ist, kommt dabei immer auf die Einheit der abhängigen Variablen an, wenn der Abstand in Kilometern ist kann ein kleiner Wert schon problematisch sein, während wenn eine Sprungweite in Mikrometern angeben wird eine großer Wert unbedenklich sein kann. Der Schätzerwert für $\sigma$ selbst, wir unten mit `Residual standard error` angegeben.

Im vorliegenden Fall des Modells für die `adl`-Daten ist der Median dementsprechend doch etwas weit von Null entfernt und der geschätzte Residualfehler $\hat{\sigma} = `r round(sigma(mod),2)`$ ebenfalls relativ groß. $\hat{\sigma}$ kann mittels der Funktion `sigma()` erhalten werden.

### Zum Nachlesen

Zum weiteren Vertiefen der Inhalte findet ihr in @kutner2005 [p.100-114], @pos_residuals und 
@fox2011 [p.285-296] noch einmal gute Zusammenfassungen.

## Einflussmetriken

Um das gefittet Modell zu diagnostizieren reicht es allerdings nicht aus, sich nur die Residuen anzuschauen. Ein weiterer wichtiger Punkt ist die Analyse des Einflusses der einzelnen Datenpunkte auf das Modell. Wenn alles gut läuft sollte es keine einzelnen Datenpunkte geben, die einen übermäßig großen Einfluss auf das Modell ausüben. Anders ausgedrückt, die Anwesenheit bzw. Abwesenheit von einzelnen Datenpunkte sollte nicht dazu führen, dass die Aussage des Modells sich stark verändert. Im folgenden schauen wir uns dazu verschiedene Einflussmetriken die den Einfluss der Datenpunkte auf das Modell abschätzen.
Die Idee der Einflussmetriken ist dabei die Gleiche wie schon bei den Studentized Residuals. Der Einfluss der Datenpunkte auf den Modellfit wird interpretiert indem ein Modell mit und ein Modell ohne den jeweiligen Datenpunkt gefittet wird. Der Einfluss auf verschiedene Modellparameter wird dann bestimmt und dementsprechend als möglicherweise bedenklich eingestuft. Die Meisten der im folgenden vorgestellten Ansätze verwenden in der einen oder anderen Form die Hebelwerte $h_i$ die wir bereits kennengelernt haben. 

### DFFITS (difference in fits)

Das erst Maß, daß wir uns anschauen ist DFFITS \index{DFFITS} (kurz für difference in fits). Das DFFITS-Maß wird getreent für jeden einzelnen Datenpunkt berechnet und der Einfluss des Datenpunkts auf den gefitteten Werte $\hat{y}_i$ für den jeweiligen Datenpunkt berechnet. Formal:

\begin{equation}
(DFFITS)_i = \frac{\hat{y}_i - \hat{y}_{i(i)}}{\hat{\sigma}\sqrt{h_i}}
\label{eq-slm-model-dffits}
\end{equation}

Im Zähler kommen von Formel\eqref{eq-slm-model-dffits} kommen zweimal die vorhergesagte $y$-Werte vor. $\hat{y}_i$ ist dabei der ganz normale Vorhersagewert der uns mittlerweile schon mehrfach begegnet ist. Der zweite Wert $\hat{y}_{i(i)}$ bezeichnet den vorhergesagten Wert aus dem Modell aus dem der Wert $y_i$ weggelassen wurde. D.h, dass Modell ist mit einem Wert weniger gefittet worden. Daher misst die Differenz $\hat{y}_i - \hat{y}_{i(i)}$ den Unterschied in den Vorhersagewerte zwischen den zwei Modellen bei denen einmal der Wert $y_i$ zum fitten verwendet wurde und einmal wenn $y_i$ weggelassen wurde. Umso größer der Unterschied zwischen diesen beiden Werte umso größer ist der Einfluss des Wertes $y_i$ auf den Modellfit. Im Nenner von Formel\eqref{eq-slm-model-dffits} wird wieder ein ähnlicher Normierungswert wie bei den Studentizied Residuals angewendet. Insgesamt, wird mittels DFFITS daher für jeden Datenpunkt ein Wert ermittelt und umso größer dieser Wert ist umso größer ist der Einfluss des jeweiligen Datenpunktes auf den Modellfit.

Im idealen Fall sollte alle Datenpunkt ungefähr den gleichen Einfluss haben und einzelne Datenpunkte die einen übermäßig großen Einfluss auf das Modell haben sollten noch einmal genauer inspiziert werden.

::: {.callout-tip}
Als Daumenregel, kann für kleine bis mittlere Datensätze ein DFFITS von $\approx 1$ auf Probleme hindeuten, während bei großen Datensätzen $\approx 2\sqrt{k/N}$ als Orientierungshilfe verwendet werden kann (k := Anzahl der Prediktoren, N := Stichprobengröße).
:::

::: {.callout-warning}
Wenn ein Wert außerhalb der Daumenregel liegt, heißt das nicht, dass er automatisch ausgeschlossen werden muss/soll, sondern lediglich inspiziert werden sollte und das Modell mit und ohne diesen Wert interpretiert werden sollte.
:::

In `R` können die DFFITS werden mittels der `dffits()`-Funktion berechnet werden. Als Parameter erwartet `dffits()` das gefittete `lm()`-Objekt. Ähnlich wie bei den Residuen, werden die DFFITS-Werte gegen die vorhergesagten $y_i$-Werte graphisch abgetragen um die Wert zu inspizieren und Probleme in der Modellspezifikation zu identifizieren.

```{r}
#| fig.cap: "Graph der DFFITS-Werte gegen $\\hat{y}_i$ für das `adl`-Modell."
#| label: fig-slm-model-dffits


adl <- adl |> mutate(dffits = dffits(mod))
ggplot(adl, aes(y_hat, dffits)) +
  geom_hline(yintercept = c(-1,1), col = 'red', linetype = 'dashed') +
  geom_point() +
  labs(x = expression(hat(y)[i]), y = 'dffits')
```

In @fig-slm-model-dffits sind die DFFITS-Werte gegen die vorhergesagten Werte $\hat{y}_i$ abgetragen und zusätzlich die Daumenregel $\pm1$ eingezeichnet. Hier ist ein Wert nur gerade so außerhalb des vorgeschlagenen Bereichs. Hier könnte daher sich dieser Datenpunkt noch einmal genauer angeschaut werden, ob bei Ausschluß des Wertes es zu einer qualitativ anderen Interpretation der Daten kommt oder ob bespielsweise Übertragungsfehler für diesen Wert vorliegen oder sonstige Gründe.

### Cook-Abstand

Während DFFITS den Einfluss des Datenpunktes $i$ auf den jeweiligen Datenpunkt abschätzt, wird bei dem sogenanten Cook-Abstand\index{Cook-Abstand} der Einfluss des $i$-ten Datenpunktes auf alle $n$ vorhergesagten Werte $\hat{y}_i$. Formal:

\begin{equation}
D_i = \frac{\sum_{j=1}^N(\hat{y_j} - \hat{y}_{j(i)})}{k\hat{\sigma}^2}
\label{eq-slm-model-cook}
\end{equation}

Hier bedeutet die Syntax $\hat{y}_{j(i)}$ der vorhergesagte Wert für den Datenpunkt $j$ wenn der $i$-te Datenpunkt ausgelassen wird. In `R` können die Cook-Abstände mit Hilfe der Funktion `cooks.distance()` berechnet werden.

::: {.callout-tip}
Eine Daumenregel um einen *möglichen* Ausreißer zu identifzieren kann über  $D_i > 1$ abgeschätzt werden.
:::

In @fig-slm-model-cook ist wiederum der übliche Graph gegen die vorhergesagten Werte $\hat{y}_i$ zu sehen. Anhand der abgebildeten Wert ist keiner der Datenpunkte als problematisch zu identifizieren.

```{r}
#| fig-cap: "Cook's $D_i$ gegen $\\hat{y}_i$ für das `adl`-Modell."
#| label: fig-slm-model-cook

adl <- adl |> mutate(cook = cooks.distance(mod))
ggplot(adl, aes(y_hat, cook)) +
  geom_hline(yintercept = c(-1,1), col = 'red', linetype = 'dashed') +
  geom_point() +
  labs(x = expression(hat(y)[i]), y = 'Cook-Abstand')
```

### DFBETAS

Als letztes Maß schauen wir uns noch DFBETAS\index{DFBETAS} an. DFBETAS berechnet ein Maß für die Veränderung der $\beta$-Koeffizienten auf Grund der einzelnen Datenpunkte $i$. D.h. es wird jetzt nicht nur ein Wert für jeden Wert berechnet, sondern ein Wert für den jeden Datenpunkt und jeden $\beta$-Koeffizienten. In unseren Fall mit einem y-Achsenabschnitt $\beta_0$ und einem Steigungskoeffizienten $\beta_1$ werden entsprechend $2 \times x$ Werte berechnet. Formal:

\begin{equation}
(DFBETAS)_{k(i)} = \frac{\hat{\beta}_k - \hat{\beta}_{k(i)}}{\sqrt{\hat{\sigma}^2c_{kk}}}
\label{eq-slm-model-dfbetas}
\end{equation}

Wie aus Formel \eqref{eq-slm-model-dfbetas} ersichtlich wird, wird die Veränderungen der Koeffizienten $\beta_i$ bei weglassen des $i$-ten Datenpunktes abgeschätzt. Den Wert $c_{kk}$ lassen wir unberücksichtigt, da er wiederum nur einen Normierungsfaktor darstellt.

::: {.callout-tip}
Als Daumenregel gilt für kleine bis mittlere Datensätze $\approx 1$, bzw. für große Datensätze $\approx 2/\sqrt{N}$ 
:::

Wiederum gibt es eine spezielle Funktion in `R` um die DFBETAS zu berechnen `dfbeta()`. Dabei ist jedoch zu beachten das eine Matrize mit $k$-Spalten von `dfbeta()` zurück gegeben wird. Jede Spalte gibt den Wert für den jeweiligen $\beta$-Koeffizienten an.

```{r}
#| fig.cap: "DFBETA-Werte für $\\beta_0$ und $\\beta_1$ gegen $\\hat{y}_i$"
#| label: fig-slm-model-dfbeta

adl <- adl %>% dplyr::mutate(`dfbeta[1]` = dfbeta(mod)[,1],
                      `dfbeta[2]` = dfbeta(mod)[,2])
adl %>% dplyr::select(y_hat, `dfbeta[1]`, `dfbeta[2]`) %>%
  tidyr::pivot_longer(-y_hat) %>%
  ggplot(aes(y_hat, value)) +
  geom_hline(yintercept = c(1,-1), col = 'red', linetype = 'dashed') +
  geom_point() +
  facet_grid(~name, labeller = label_parsed) + 
  labs(x = expression(hat(y)[i]), y = 'DFBETA')
```

In @fig-slm-model-dfbeta sind die DFBETAS für die beiden Koeffizienten $\hat{beta}_0$ und $\hat{beta}_1$ abgetragen. Hier ist zu sehen, dass die Wert für den Steigunsgkoeffizienten $\beta_1$ alle als unproblematisch anzusehen sind, während in Bezug auf $\beta_0$ ein paar wenige Fälle eine weiter Inspektion nach sich ziehen könnten. Allerdings sollte berücksichtigt werden, dass der y-Achsenabschnitt sehr stark durch die Verteilung der Datenpunkte in Bezug auf die $x$-Werte beeinflusst ist, da der Mittelwert der $x$-Werte bei $\bar{x} = `r round(mean(adl[['adas']]),1)`$ liegt.

### Übersicht über die Einflussmetriken 

In @tbl-slm-model-influence sind noch einmal die verschiedenen Methoden tabellarisch dargestellt.

| Typ | Veränderung | Daumenregel |
| --- | ---  | ---  |
| $(DFFITS)_i$ | Vorhersagewert i | $2\sqrt{k/N}$ |
| Cook | Durchschnittliche Vorhersagewerte | $>1$ |
| $(DFBETAS)_{k(i)}$ |  Koeffizient i | $2\sqrt{N}$ |
| $e_{Ti}$ | Residuum i  | t-Verteilung(n-k-2)|

: Übersicht über die verschiedene Einflussmaße zur Bewertung der Modellgüte {#tbl-slm-model-influence}

Nochmal, die Daumenregeln sind wirklich auch nur Daumenregeln und identifzieren nicht automatisch ein Problem im Datensatz.

### Zum Nacharbeiten

Noch mal weitere Informationen findet Ihr in @pos_diagnostics, @fox2011 [p.294-302] und @young2019.

## Diagnoseplots in `R`

Da die Diagnose eines gefitten Modell in jedem Fall durchgeführt werden soll und es sich dabei also um eine alltägliche Aufgabe handelt, gibt es mit `plot(mod)` einen short-cut um eine Reihe von Diagnoseplots direkt erstellen zu können.

```{r, echo=T, eval=F}
plot(mod)
```
```{r}
#| fig-height: 5
mar <- par()$mar
par(mfrow=c(2,2), mar=c(3,4,5,3))
plot(mod)
par(mfrow=c(1,1), mar=mar)
```

Eine weitere Möglichkeit ist das package `performance` das zahlreiche Funktion enthält rund um die Analyse von Modellfits (siehe beispielweise `performance::check_model()`).



