# Modellfit 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```

Nachdem ein Modell mittels einer einfachen linearen Regression an die Daten gefittet wurde, sollte immer überprüft werden ob das Modell tatsächlich auch den Annahmen entspricht. Ein zentrales Mittel dazu ist eine Analyse der Residuen.

## Residuen

```{r defs_reg_resid}
adl <- readr::read_delim("adcs;adas\n4.05;50.01\n5.03;46.04\n5.03;39.03\n8.04;49.02\n8.04;46.02\n8.04;42.03\n8.06;55.03\n8.06;37.03\n9.02;52.01\n11.03;57.04\n11.03;51.04\n12.01;47.01\n13.01;52.01\n13.01;50.02\n12.99;41.03\n13.01;36.02\n13.01;28\n14.02;46.04\n15;48.03\n15;42.02\n15;36.02\n15.02;34\n16.02;39.03\n17;45.03\n17;24.02\n17.99;43.02\n18.99;40\n20.01;34.01\n20.01;29\n21.02;33.03\n23;43.02\n23;10\n23.98;25.01\n24.99;49.02\n24.99;35.01\n26.01;35\n26.97;45.03\n28;22\n32.99;55.03\n12.01;50.1\n12.01;49.03\n",
                         delim = ';',
                         col_types = 'dd')
mod <- lm(adcs ~ adas, adl)
adl <- adl |> dplyr::mutate(
  y_hat = predict(mod),
  resid = resid(mod),
  rstudent = rstudent(mod),
  rstandard = rstandard(mod)
)

```

Dazu schauen wir uns zunächst noch einmal an, was überhaupt Residuen $e_i$ sind und gehen noch mal von den grundlegenden Modellannahmen aus (siehe Formel \eqref{eq-sim-model-lr}).
 

\begin{equation}
y_i = \beta_0 + \beta_1 \cdot x_i + \epsilon_i, \qquad \epsilon_i \sim \mathcal{N}(0,\sigma^2)
\label{eq-sim-model-lr}
\end{equation}

Das lineare Regressionsmodell geht von einem linearen Zusammenhang in den Koeffizienten zwischen der Variablen $x_i$ und den Variablen $y_i$ aus. Additiv kommt daz ein normalverteilter Fehler $\epsilon_i$. Die Normalverteilung der $\epsilon_i$ habem einen Erwartungswert von $\mu = 0$ und eine Standardabweichung von $\sigma$. Die Standardabweichung $\sigma$ ist zunächst unbekannt und muss über die Daten abgeschätzt werden. Dies führt dazu,  dass $y_i$ für jeden gegebenen Wert von $x_i$ einer Normalverteilung mit $\mathcal{N}(\beta_0 + beta_1 x_i, \sigma^2)$ folgen und der bereits bekannten graphischen Darstellung (siehe @fig-slm-model-resid-1).

```{r}
#| fig.cap: "Beispiel einer Regressionsgeraden und der Verteilung der Residuen um den Vorhersagewert $\\hat{y_i}$"
#| label: fig-slm-model-resid-1

set.seed(123)
xx <- seq(-3,3,0.05)
yy <- dnorm(xx)
n <- length(xx) 
n_2 <- 20
df <- tibble::tibble(
  x_0 = rep(1:3, each=n),
  x = x_0 + rep(yy,3),
  y = rep(seq(-1,1,length.out=n), 3) + rep(1:3, each=n),
  g = rep(letters[1:3], each=n)
)
df_2 <- tibble::tibble(x = 1:3, y = 1:3, g = 'a')
df_3 <- tibble::tibble(x = rep(1:3, each=n_2),
                       y = rnorm(3*n_2, mean=x, sd = 0.5), g = 'a')
ggplot(df, aes(x, y, group=g)) + 
  geom_line(data = df_2, aes(x,y), size=1.5) +
  geom_point(data = df_3, aes(x,y), color='red') +
  geom_ribbon(aes(xmin = x_0, xmax = x), fill='red', alpha=0.5) +
  geom_path() +
  geom_point(data = df_2, aes(x,y), size=3) +
  scale_x_continuous(breaks = 1:3) +
  labs(x = 'x-Werte', y = 'y-Werte') 
```

Für jeden gegebenen Wert von $X$ sind die $Y$-Werte Normalverteilt. Die Varianz dieser Normalverteilungen ist gleich $\sigma$ während der Mittelwert $\mu$ immer um den Wert der Regressionsgeraden verschoben ist. D.h. die Streuung von $\epsilon_i$ überträgt sich auf die Streuung von $y_i$ für jeden gegebenen $X$-Wert. Ohne den zufälligen Einfluss der Fehlerwerte würden wir alle $y_i$-Werte perfekt auf der Regressionsgeraden erwarten. Dies deutet daher auch schon eine Möglichkeit an die Residuen $\epsilon_i$ mittels der Daten abzuschätzen. Man verwendet die Abweichungen der beobachteten Werten $y_i$ von den vorhergesagten Werten $\hat{y}_i$ auf der Regressionsgeraden (siehe Formel \eqref{eq-sim-model-res-1}).

\begin{equation}
\hat{\epsilon}_i = e_i = y_i - \hat{y_i}
\label{eq-sim-model-res-1}
\end{equation}

Diese Abweichungen $e_i$ können als Schätzer $\hat{\epsilon}_i$ für die wahren Residuen $\epsilon_i$ verwendet werden (siehe @fig-slm-model-resid-2).

```{r}
#| label: fig-slm-model-resid-2
#| fig.cap: Examplarische Darstellung der Berechnung der Residuen $e_i$ als Abweichung der beobachteten Werte $y_i$ von den vorhergesagten Werten $\hat{y}_i$

set.seed(12)
simple <- tibble::tibble(x = 0:3,
                 y = 2 + 0.5 * x + rnorm(4,0,.5))
mod0 <- lm(y ~ x, simple)
simple$y_hat <- predict(mod0)
simple$epsilon <- paste0('hat(epsilon)[',1:4,']')
simple$ys <- paste0('list(x[',1:4,'],y[',1:4,'])')
simple$yshat <- paste('hat(y)[',1:4,']')
p_res <- ggplot(simple, aes(x,y,label = epsilon)) + 
  geom_point(size=3) +
  geom_line(aes(y = y_hat), size=2, color = 'red') +
  geom_point(aes(y = y_hat), size=3, color = 'red') +
  geom_segment(aes(x = x, y = y_hat, xend = x, yend = y),
               arrow = arrow(type='closed', length=unit(0.05, unit='npc')), size=1,
               color = 'green') +  
  geom_text(aes(x = x - 0.1, y=y_hat, label = yshat), parse=T,
            size = 5, check_overlap = T) +
  geom_text(aes(x = x + 0.14, y = (y_hat + y)/2), parse=T, size=5) + 
  lims(x = c(-.3,3.3), y = c(1,3.8)) 
print(p_res)
```

Da die Normalverteilungen der $\epsilon_i$ für jeden $X$-Wert immer gleich sein sollten bis auf die Verschiebung von $\mu_{Y|X}$, deutet dies ebenfalls eine erste Möglichkeit an, die Modellannahmen graphisch zu überprüfen. Wenn die Residuen $e_i$ geben die vorhergesagten Werte $\hat{y}_i$ abgetragen werden, dann sollte die Verteilung der Residuen $e_i$ überall nahezu gleich sein, da die Streuung $\sigma$ unabhängig von der *Position* auf der Regressionsgerade ist. In `R` können die Residuen mittels der Funktion `residuals()` bzw. der Kurzform `resid()` ermittelt werden. `residuals()` erwartet als Parameter das gefittete `lm()`-Objekt.

```{r}
#| echo: true

residuals(mod)
```

Die anhand des Modells vorhergesagten Werte $\hat{y_i}$ werden der Funktion `predict()` berechnet. Diese Funktion werden wir uns im nächsten Kapitel noch ausführlich betrachten. Als Parameter wird wiederum das gefittete `lm()`-Modell übergeben.

```{r}
#| echo: true

predict(mod)
```

Beide Funktionen, `resid()` und `predict()` geben die berechneten Werte in der Reihenfolge aus, in der die Originaldaten an `lm()` übergeben wurde. D.h. $e_1$ und $\hat{y}_1$ gehören zum ersten $X$-Wert $x_1$ aus den Originaldaten. Mit Hilfe dieser beiden Variablen kann nun ein Residuenplot erstellt werden (siehe @fig-sim-model-rplot-1).

```{r}
#| fig.cap: "Residuenplot der Residuen $e_i$ gegen die vorhergesagten Werte $\\hat{y}_i$"
#| label: fig-sim-model-rplot-1

ggplot(adl, aes(y_hat, resid)) +
  geom_point() +
  geom_hline(yintercept = 0, col = 'red', linetype = 'dashed') +
  scale_x_continuous(expression(hat(y)[i])) +
  scale_y_continuous(expression(e[i]))
```

Der Plot sollte im Optimalfall so aussehen, dass die Residuen $e_i$ gleichmäßig oberhalb und unterhalb um die Nulllinie verteilt sind und keine weiteren Strukturen oder Muster im Zusammenhang mit $\hat{y}_i$ zu erkennen sind. In dem Residuenplot in @fig-sim-model-rplot-1 ist zunächst einmal kein größeres Problem zu erkennen, bis auf den einen Wert links oben.

Um besser zu Verstehen wir Problem aussehen könnten, schauen wir uns zwei Residuenplots an, bei denen eine Struktur zu erkennen ist (siehe @fig-sim-model-rplot-2)

```{r}
#| layout-ncol: 2
#| fig-cap: "Residuenplots die Probleme anzeigen."
#| fig-subcap:
#|   - Parabelförmiger Zusammenhang zwischen $e_i$ und $\hat{y}_i$
#|   - Ansteigende Streuung mit größer werdendem $\hat{y}_i$
#| label: fig-sim-model-rplot-2
#| fig-height: 5

n <- 30
tibble(
  x = seq(0,10,length.out=n),
  y = x*cos(seq(0,6*pi,length.out = n)/10) + 3*x + 2 + rnorm(n),
  resid = resid(lm(y~x)),
  y_hat = predict(lm(y~x))
) |> rplot()

n <- 40
set.seed(125)
tibble(
  y_hat = runif(n, 0, 1),
  resid = 3 * y_hat * rnorm(n, 0, 2),
) |> rplot()
```

In @fig-sim-model-rplot-2-1 ist ein parabelförmiger Zusammenhang zwischen $e_i$ und $\hat{y}_i$ zu erkennen. Für kleine und große $\hat{y}_i$ Werte sind die Residuen $e_i$ negativ während für mittlere Werte von $\hat{y}_i$ die Residuen $e_i$ positiv sind. Diese deutet darauf hin, das zusäztliche Struktur in den Daten nicht im Modell erfasst wird und führt dazu dass die Modellannahmen der Normalverteilung der $\epsilon_i$ nicht erfüllt sind.

In @fig-sim-model-rplot-2-2 ist dagegen eine anderes Problem zu beobachten, die Residuen $e_i$ zeigen zwar keine Struktur bezüglich positiv zu negativen Werten, allerdings werden die Abweichung von $0$ mit größer werdenen $\hat{y}_i$ immer stärker. Dies deutet darauf hin, das die Streuung der Daten nicht gleich ist. Dies wird als Heteroskedastizität bezeichnet und deutet wiederum auf eine Verletzung der Annahmen bei der Homoskedastitzität ausgegangen wird. D.h. die Streuung soll über den gesamten Bereich von $\hat{y}_i$ gleich bleiben.

::: {#def homoscedasticity}

## Homoskedastizität\index{Homoskedastizität}

Wenn die Varianz der Residuen $\epsilon_i$ in einem Regressionsmodell unabhängig von der Größe der Vorhersagevariable $X_i$ gleich ist, wird die als Homoskedastizität bezeichnet. Die Streuung der Residuen ist dann für alle Werte $X_i$ gleich. Wenn dies nicht der Fall ist, wird von Heteroskedastizität\index{Heteroskedastizität} gesprochen.
:::

Eine weitere Möglichkeit die Residuen zu überprüfen ist die Anfertigung von sogenannten  qq-Plots. Dies ermöglichen etwas strukturierter die Verteilung der Residuen zu überprüfen.

## Quantile-Quantile-Plots 

qq-Plot ist die Kurzform von Quantile-Quantile-Plot. D.h. es werden die Quantilen von zwei Variablen gegeneinander abgetragen. Um die Funktionsweise besser zu verstehen schauen wir uns erst einmal ein Spielzeugbeispiel an. In @tbl-slm-model-toy-1 ist eine kleiner Datensatz mit $n = 5$ Datenpunkten angezeigt.

```{r}
#| tbl-cap: "Spielzeugbeispieldaten mit $n=5$"
#| label: tbl-slm-model-toy-1

df_qq <- tibble::tibble(y = c(-2, 5, -1.2, 0.1, 7))
df_qq %>% knitr::kable(booktabs=T)
```

Wir wollen jetzt überprüfen ob dieser Datensatz einer Normalverteilung folgt (Wohlwissend das mit fünf Datenpunkten keine Verteilungsannahme überprüft werden kann). Dazu schauen wir uns zunächst noch einmal die bekannte Standardnormalverteilung $\Phi(z) = \mathcal{N}(\mu=0,\sigma^2=1)$ an (siehe @fig-slm-model-toy-1).

```{r}
#| fig.cap: "Dichtefunktion der Standardnormalverteilung"
#| label: fig-slm-model-toy-1

df_qq_2 <- tibble::tibble(
  x = seq(-3,3,length.out=100),
  y = dnorm(x)
)
ggplot(df_qq_2, aes(x,y)) +
  geom_ribbon(aes(ymin = 0, ymax = y), fill='red', alpha=.5) +
  geom_line() +
  labs(x = 'Werte', y = 'Dichte') 
```

Im ersten Schritt unterteilen wir die Standardnormalverteilung $\Phi(z)$ in $n+1 = 6$ gleich große Flächen. D.h. die durch die Flächen bestimmten Abschnitte haben alle die gleiche Wahrscheinlichkeit (=Fläche unter der Dichtefunktion). Die Flächen werden durch jeweiligen Trennpunkte unterteilt die gleichzeitig die Quantilen sind.

```{r}
#| fig.cap: "Unterteilung der Standardnormalverteilung in sechs gleich große Flächen"
#| label: fig-slm-model-toy-2

n <- dim(df_qq)[1]
df_qq_3 <- tibble::tibble(
    x = qnorm(1/(n+1)*(1:n)),
    y = dnorm(x)
  )
ggplot(df_qq_2, aes(x,y)) +
  geom_ribbon(aes(ymin = 0, ymax = y), fill='red', alpha=.5) +
  geom_line() +
  geom_segment(data = df_qq_3, aes(x = x, xend = x, y = 0, yend = y)) +
  scale_x_continuous(breaks = round(df_qq_3$x,2)) +
  labs(x = NULL, y = 'Dichte') +
  theme(axis.text.x = element_text(angle = 45, vjust=1, hjust=1))
```

In unserem Fall haben wir $n=5$ Datenpunkte, unterteilen also unsere Verteilung in $6$ Abschnitte die jeweils eine Fläche von $p = \frac{1}{6} = `r round(1/6,2)`$ haben. D.h. $\frac{1}{6}$ der Werte von $\Phi(x)$ liegen links des ersten Trennpunktes, $\frac{2}{6}$ der Werte von $\Phi(x)$ liegen links des zweiten Trennpunktes, usw. D.h. die Trennpunkte bestimmen die jeweiligen Quantilen, oder genauer die theoretischen Quantilen die unter der Verteilungsannahme erwartet werden.


Die Idee hinter dem qq-Plot besteht nun darin, die empirischen Quantilen gegen die theoretischen Quantilen abzutragen (siehe @fig-slm-model-qqconcept). Wenn die beobachteten Daten aus der gleichen Verteilung wie die theoretische Verteilung stammen, dann sollten die Punkte einer Geraden folgen. Die Steigung der Geraden ist $1$, wenn es sich um die identischen Verteilungen handelt. Wenn die Steigung $\neq1$ ist, dann kommen die Datenpunkte aus der gleichen Familie sind aber um einen Skalierungsfaktor unterschiedlich bzw. um den Mittelwert verschoben. Die Punkte sollten aber trotzdem auf einer Geraden liegen. 

```{r}
#| label: fig-slm-model-qqconcept
#| fig-cap: "Skizze der theoretischen und der empirischen Verteilung mit unterschiedlicher Skalierung (Faktor $2\\times$) aber aus der gleichen Verteilungsfamilie. In beiden Graphen ist die gleiche Quartile markiert"

foo_qq <- function() {
  x <- seq(-5, 5, length.out = 200)
  sigma <- 1.5
  df <- tibble(
    x = x,
    y_1 = dnorm(x),
    y_2 = dnorm(x, sd = sigma)
  ) |> pivot_longer(-x)
  
  q_1_1 <- qnorm(0.05)
  q_1_2 <- qnorm(0.05, sd = sigma)
  d_1_1 <- dnorm(q_1_1)
  d_1_2 <- dnorm(q_1_2, sd = sigma)
  y_1 <- -0.1; y_2 <- -0.15
  df_pts <- tibble(
    x = c(q_1_1, q_1_2, q_1_1, q_1_2),
    value = c(d_1_1, d_1_2, y_1, y_2),
    name = c('y_1','y_2','y_1','y_2')
  )
  df_q_1 <- tibble(
    x = seq(-5, q_1_1, length.out = 50),
    value = dnorm(x),
    name = 'y_1'
  )
  df_q_2 <- tibble(
    x = seq(-5, q_1_2, length.out = 50),
    value = dnorm(x, sd = sigma) ,
    name = 'y_2'
  )
  ggplot(df, aes(x, value, color=name)) +
    geom_line() +
    geom_point(data = df_pts) +
    geom_ribbon(data = df_q_1, aes(ymin = 0, ymax = value), fill = 'red', alpha = 0.3) +
    geom_ribbon(data = df_q_2, aes(ymin = 0, ymax = value), fill = 'blue', alpha = 0.3) +
    annotate('segment', x = -5, xend = 5, y = y_1, yend = y_1, color = 'red') +
    annotate('segment', x = -5, xend = 5, y = y_2, yend = y_2, color = 'blue') +
    annotate('segment', x = seq(-3, 3, length.out = 7),
             xend = seq(-3, 3, length.out = 7), y = y_1, yend = y_1-0.02, color = 'red') +
    annotate('segment', x = seq(-4, 4, length.out = 5),
             xend = seq(-4, 4, length.out = 5), y = y_2, yend = y_2-0.02, color = 'blue') +
    annotate('segment', x = q_1_1, xend = q_1_1, y = d_1_1, yend = y_1, linetype = 'dotted') +
    annotate('segment', x = q_1_2, xend = q_1_2, y = d_1_2, yend = y_2, linetype = 'dotted') +
    annotate('segment', x = q_1_1, xend = q_1_2, y = y_1, yend = y_2, linetype = 'dotted') +
    annotate('text', x = 0, y = y_1-0.03, label = expression(mu)) +
    annotate('text', x = 0, y = y_2-0.03, label = expression(mu)) +
    scale_x_continuous('Werte', labels = NULL) +
    scale_y_continuous('Dichte', limits = c(-.2, .45), labels = NULL) +
    scale_color_manual('Verteilung',
                       values = c('red', 'blue'), labels = c('Theoretisch', 'Empirisch'))
}
foo_qq()
```

Um die empirischen Quartilen zu bestimmen, werden dazu zunächst die beobachteten Datenpunkte aus @tbl-slm-model-toy-1 aufsteigend nach der Größe sortiert (siehe @tbl-slm-model-toy-2). Diese Werte können als *empirische* Quantilen bezeichnet werden. Unter der Annahme, dass die Werte eine repräsentative Stichprobe aus der Verteilung darstellen, erwarten wir, dass wenn wir weitere Werte beobachten würden, etwa $\frac{1}{6}$ der Werte kleiner als der kleinste Wert wären, $\frac{2}{6}$ der weiteren Werte kleiner als der 2. kleinste Wert wären und so weiter und so fort.

| kleinster | 2.kleinster | mittlerer | 2.größter | größter |
| --- | --- | --- | --- | --- |
| `r df_qq$y[1]` |`r df_qq$y[3]` |`r df_qq$y[4]` | `r df_qq$y[2]` |`r df_qq$y[5]` |

: Sortierte Datenwerte des Spielzeugbeispiels {#tbl-slm-model-toy-2}

Daher, wenn die beobachteten Werte der angenommenen theoretischen Verteilung folgen, dann sollte ein Graph der empirischen Quartilen gegen die theoretischen Quartilen nahezu (Stichprobenvariabilität) einer Geraden folgen.

```{r}
#| fig-cap: "Streudiagramm der empirischen Werte gegen die theoretischen Quantilen"
#| label: fig-slm-model-toy-3

df_qq_3 %>% 
  add_column(d = sort(df_qq$y)) %>% 
  ggplot(aes(x, d)) + 
  geom_point(size = 2) +
  scale_x_continuous(breaks = round(df_qq_3$x,2)) +
  labs(x = 'Theoretisch', y = 'Empirisch') 
```

In @fig-slm-model-toy-3 sind die empirischen Quartilen gegen die theoretischen Quantilen für unser kleines Beispiel abgetragen. Tatsächlich ist es in diesem Fall schwierig eine Gerade zu erkennen bzw. von einer zu sprechen, da es sich nur um besagte fünf Wert handelt. Nochmals, mit $n=5$ kann eine realistische Verteilungsannahme nicht überprüft werden. 

Wenn der Datensatz größer ist, dann eignet sich ein qq-Plot allerdings sehr gut Abweichungen zu erkennen. In @fig-slm-model-qqplots sind verschiedene Beispiele abgetragen.

```{r}
#| layout-ncol: 2
#| layout-nrow: 2
#| label: fig-slm-model-qqplots
#| fig-subcap:
#|   - "Perfekt"
#|   - "Enden schwer"
#|   - "Enden leicht"
#|   - "Rechtsschief"
#| fig-cap: "Beispiele für verschiedenen qq-Plots"
 
par(mar=c(1,1,1,1))
pp <- ppoints(50)
pp_norm <- qnorm(pp)
pp_cauchy <- qcauchy(pp)
pp_chisq <- qf(pp, 10, 8)

qqplot(pp_norm, pp_norm, xlab='theoretical', ylab='empirical', main='Perfekt')
qqline(pp_norm, col = 'steelblue', lwd=2) 


qqplot(pp_norm, pp_cauchy, xlab='theoretical', ylab='empirical', main='Tails heavy')
qqline(pp_cauchy, col = 'steelblue', lwd=2)


qqplot(pp_cauchy, pp_norm, xlab='theoretical', ylab='empirical', main='Tails light')
qqline(pp_norm, col = 'steelblue', lwd=2)


qqplot(pp_norm, pp_chisq, xlab='theoretical', ylab='empirical', main='Rechtsschief')
qqline(pp_chisq, col = 'steelblue', lwd=2)
```

In @fig-slm-model-qqplots-1 ist ein perfekter Zusammenhang zwischen den empirischen und den theoretischen Quantilen abgebildet. In diesem Falle wurden synthetisch für 50 normalverteiltet Zufallsdaten ein qq-Plot erstellt. Es ist zu sehen, das tatsächlich eine Gerade den Zusammenhang beschreibt. In @fig-slm-model-qqplots-2 ist dagegen ein Zusammenhang abgetragen, bei dem die empirischen und die theoretische Verteilung nicht zusammenpassen. In diesem Fall sind die haben die Randwerte der empirischen Vereteilung eine höhere Wahrscheinlichkeit als die unter der theoretischen Verteilung zu erwarten ist. D.h. extreme Werte kommen in der beobachteten Verteilung öfter in der theoretischen Verteilung vor. Dies deutet darauf hin, dass die Streuung der Daten möglicherweise nicht korrekt modelliert wurde. In diesem Fall, wird von einer *tail heavy* Verteilung gesprochen.

In @fig-slm-model-qqplots-3 ist der gegenteilige Effekt abgetragen. Hier hat die theoretische Verteilung mehr Wahrscheinlichkeitsmasse in den Randzonen als die empirische Verteilung. Die beobachtete Verteilung ist *tail light*. Entsprechend ist in @fig-slm-model-qqplots-4 ein Beispiel abgebildet, bei dem nur eine der Randzonen zu viel Wahrscheinlichkeitsmasse besitzt. Da die theoretische Verteilung wiederum die Normalverteilung ist und diese Symmetrisch ist, deutet diese darauf hin, das die empirische Verteilung ähnlich wie in @fig-slm-model-qqplots-2 in der rechten Randzone zu *viele* Werte hat und daher Rechtsschief ist.

Für unsere Daten ergibt sich das folgende qq-Diagramm (siehe @fig-slm-model-qqplot-data)
```{r}
#| fig-cap: "QQ-Diagramm der Residuen des ADAS-ADCS-Modells"
#| label: fig-slm-model-qqplot-data
 
adl |> 
  ggplot(aes(sample = resid)) +
  geom_qq() +
  geom_qq_line() +
  labs(x = 'Theoretische Verteilung', y = 'Empirische Verteilung')
```

Der Graph sieht zunächst einmal gar nicht so schlecht aus. Allerdings deutet die Abweichung rechts oben darauf hin, das möglicherweise die Streuung nicht korrekt abgeschätzt wurde. Insbesondere ist ein Wert zu sehen, der im Verhältnis zu den anderen Werten schon relativ weit von der Gerade weg ist. Daher ist es hier angezeigt, diesen Wert noch einmal genauer zu untersuchen.

### qq-Plot in `R`

In `R` gibt es zwei direkte Methoden einen qq-Plot zu erstellen. Mittels des Standardgrafiksystem können mit den Funktionen `qqnorm()` und `qqline()` qq-Plots mit der dazugehörigen Gerade erstellt werden. Für das `ggplot()`-System stehen die `geom`s `geom_qq()` und `geom_qq_line()` zur Verfügung. Wichtig ist hierbei, das in `aes()` der Parameter `sample` definiert werden muss. Für unser Spielzeugbeispiel sieht dies folgendermaßen aus:

```{r}
#| echo: true
#| label: fig-slm-model-qqplot-toy
#| fig-cap: "qq-Plot der Spielzeugdaten mittels `ggplot()`"

df_toy <- tibble::tibble(y = c(-2, 5, -1.2, 0.1, 7))
ggplot(df_toy, aes(sample=y)) +
  geom_qq() +
  geom_qq_line()
```


## Standardisierte Residuen

Eine Möglichkeit so einen Wert zu untersuchen, ist abzuschätzen wie *ungewöhnlich* der zu dem Residuen $e_i$ gehörende $y_i$-Wert ist. Ein Problem der einfachen Residuen $e_i$ ist, dass diese laut der Modellannahmen die gleiche Varianz $\sigma^2$ haben sollten. Allerdings, auf Grund der Art, wie die $e_i$ berechnet werden, folgt die Randbedingung, dass die Summe der $e_i$ gleich Null ist, $\sum_{i=1}^n e_i = 0$. Dies führt dazu, dass die einfachen Residuen nicht unanbhängig voneinander sind und nicht immer Homoskedastizität besitzen. Daher gibt es eine weitere Art Residuen anhand des Modell zu berechnen, die nicht unter diesen Beschränkungen leiden. Dies sind die standardisierten Residuen $e_{Si}$. Dazu müssen wir uns zunächst mit Hebelwerte $h_i$ beschäftigen.

### Hebelwerte

Wenn ein Modell an die Daten gefittet wird, dann tragen nicht alle Werte gleichermaßen zu der Modellspezifikation bei. Manche Werte üben einen stärkeren Einfluss auf das Modell aus als andere Werte. In @fig-slm-model-outlier-1 ist ein Beispiel abgebildet für einen Datensatz bei dem ein einzelner Punkt einen übermäßig großen Einfluss auf das Modell ausübt.

```{r}
#| fig-cap: "Beispiel für einen Datenpunkt mit einem großen Einfluss auf das Modell. Die resultierenden Regressionsgeraden sind mit dem Punkt (rot) und ohne den Punkt (grün) abgetragen."
#| label: fig-slm-model-outlier-1
 
n <- 30
df <- tibble(
  x = c(runif(n, -1, 1),3),
  y = c(runif(n, -1, 1),3),
  g = rep(c('a','b'),c(n,1))) 
mod1 <- lm(x ~ y, df)
mod2 <- lm(x ~ y, df |> dplyr::filter(g == 'a'))
ggplot(df, aes(x,y)) +
  geom_point(aes(color=g)) +
  geom_abline(intercept = coef(mod1)[1], slope = coef(mod1)[2], linetype = 'dashed', color='red') +
  geom_abline(intercept = coef(mod2)[1], slope = coef(mod2)[2], linetype = 'dashed', color='green') +
  guides(color = "none")
```

Der einzelen Punkt rechts oben in @fig-slm-model-outlier-1 hat einen großen Einfluss auf die resultierende Regressionsgerade wie in der Abbildung zu sehen ist. Der Einfluss ist zu einem großen Teil durch den Abstand des jeweiligen $x_i$-Wertes vom Mittelwert der $x_i$-Werte $\bar{x}$ bestimmt. Die genaue Berechnung der Hebelwerte $h_i$ ist für das weitere Verständnis nicht wichtig, da sie ein Herleitung mittels Matrizenalgebra erforden. In `R` können die Hebelwerte mit der Funktion `hatvalues()` berechnet werden.

Für unsere weitere Betrachtung der Residuen ist zunächst der Zusammenhang zwischen der Varianz der Residuen $\sigma^2(e_i)$ wichtig. Es gilt:

\begin{equation}
\sigma^2(e_i) = \sigma^2 (1 - h_i)
\label{eq-slm-model-vare_i}
\end{equation}

Dieser Zusammenhang kann dazu benutzt werden standardisierte Residuen\index{standardisierte Residuen} zu erstellen.

\begin{equation}
e_{Si} = \frac{e_i}{\hat{\sigma}\sqrt{1-h_i}}
\label{eq-slm-model-stresid}
\end{equation}

Table: Übersicht über verschiedene Arten von Residuen^[$h_i$ = Influenz von Punkt $i$]

| Typ | Berechnung | Ziel |
| --- | --- | --- |
| Einfache Residuen | $e_i = y_i - \hat{y}_i$ | Verteilungsannahme |
| Standardisierte Residuen |  $e_{Si} = \frac{e_i}{\hat{\sigma}\sqrt{1-h_i}}$ | Verteilungsannahme |
| Studentized Residuen |  $e_{Ti} = \frac{e_i}{\hat{\sigma}_{(-i)}\sqrt{1-h_i}}$ | Einfluss  auf Modell |

## Residuen in `R` berechnen mit `residuals()` und Freunden

```{r, echo=T}
rstandard(mod)[1:5] # standardisierte Residuen
rstudent(mod)[1:5] # studentized Residuen
```


## Residuen in `R` inspizieren

```{r, eval=F, echo=T}
y_hat <- predict(mod)
plot(y_hat, rstandard(mod))
plot(y_hat, rstudent(mod))
```


## Diagnoseplot - Einfache Residuen $\hat{\epsilon_i} \sim \hat{y_i}$
```{r}
#| fig.cap="Streudiagramm der Residuen $\\hat{\\epsilon_i}$ gegen die Vorhersagewerte $\\hat{y}_i$"

plot(resid ~ y_hat, adl, ylab=expression(e[i]),
     xlab=expression(paste(hat(y)[i], '-ADCS-MCI-ADL score')),
     ylim=c(-20,20)) 
abline(h = 0, lty = 2, col = 'red')
```

## Diagnoseplot - Standardisierte Residuen $\hat{\epsilon}_{Si} \sim \hat{y_i}$

```{r}
#| fig.align='center', fig.cap="Streudiagramm der standardisierten Residuen $\\hat{\\epsilon}_{Si}$ gegen die Vorhersagewerte $\\hat{y}_i$"

plot(rstandard ~ y_hat, adl, ylim=c(-4,4),
     xlab = expression(paste(hat(y)[i], '-ADCS-MCI-ADL score')),
     ylab = expression(e[Si])) 
abline(h = 0, lty = 2, col = 'red')
abline(h = c(-2,-1,1,2), lty=3, col = 'gray')
```

## Diagnoseplot - Studentized Residuen $\hat{\epsilon}_{Ti} \sim \hat{y_i}$
```{r}
#| fig.cap="Streudiagramm der studentized Residuals $\\hat{\\epsilon}_{Ti}$ gegen die Vorhersagewerte $\\hat{y}_i$"

plot(rstudent ~ y_hat, adl, 
     xlab = expression(paste(hat(y)[i], '-ADCS-MCI-ADL score')),
     ylab = expression(e[Ti]),
     ylim=c(-4,4))
abline(h = 0, lty = 2, col = 'red')
```






## `summary()`

\scriptsize
```{r}
summary(mod)
```

## Neue Idee zu Residuen

```{r}
#| fig.cap: "Spielzeugbeispiel mit Residuen $\\hat{\\epsilon}_i = e_i = y_i - \\hat{y}_i$"

print(p_res)
```


## Zum Nacharbeiten

@kutner2005 [p.100-114] \newline
@pos_residuals \newline
@fox2011 [p.285-296]




## DFFITS

Mit Hilfe der Hebelwerte lassen sich verschiedene Maße erstellen um den Einfluss von Datenpunkten auf das Modell zu überprüfen. Ein Maß wird als \index{DFFITS} bezeichnet (siehe @eq-dffits)

$$
(DFFITS)_i = \frac{\hat{y}_i - \hat{y}_{i(i)}}{\sqrt{\hat{\sigma}^2h_i}}
$${#eq-dffits}

Im Zähler kommen vin @eq-dffits zweimal vorhergesagte $y$-Werte vor. $\hat{y}_i$ ist dabei der ganz normale Vorhersagewert der uns mittlerweile schon mehrfach begegnet ist. Der zweite Wert $\hat{y}_{i(i)}$ bezeichnet den vorhergesagten Wert aus dem Modell aus dem der Wert $y_i$ weggelassen wurde. D.h, dass Modell ist mit einem Wert weniger gefittet worden. Daher misst die Differenz $\hat{y}_i - \hat{y}_{i(i)}$ den Unterschied in den Vorhersagewerte zwischen zwei Modellen bei denen einmal der Wert $y_i$ zum fitten verwendet wurde und einmal wenn $y_i$ nicht zum fitten verwendet wurde. Umso größer der Unterschied zwischen diesen beiden Werte umso größer ist der Einfluss des Wertes $y_i$ auf den Modellfit. Den Nenner von @eq-dffits lassen wir mal fallen, da es sich dabei nur um einen Normierungswert handelt. Dementsprechend, wird mittels DFFITS für jeden Datenpunkt ein Wert ermittelt und umso größer dieser Wert ist umso größer ist der Einfluss des jeweiligen Datenpunktes auf den Modellfit.

Im idealen Fall sollte alle Datenpunkt ungefähr den gleichen Einfluss haben und einzelne Datenpunkte die einen übermäßig großen Einfluss auf das Modell haben sollten noch einmal genauer inspiziert werden.

::: {.callout-tip}
Als Daumenregel, kann für kleine bis mittlere Datensätze ein DFFITS von $\approx 1$ auf Probleme hindeuten, während bei großen Datensätzen $\approx 2\sqrt{k/N}$ als Orientierungshilfe verwendet werden kann (k := Anzahl der Prediktoren, N := Stichprobengröße).
:::

::: {.callout-warning}
Wenn ein Wert außerhalb der Daumenregel liegt, heißt das nicht, dass er automatisch ausgeschlossen werden muss/soll, sondern lediglich inspiziert werden sollte und das Modell mit und ohne diesen Wert interpretiert werden sollte.
:::

In `R` können die DFFITS werden mittels der `dffits()`-Funktion berechnet werden. Als Parameter erwartet `dffits()` das gefittete `lm()`-Objekt. Ähnlich wie bei den Residuen, werden die DFFITS-Werte gegen die vorhergesagten $y_i$-Werte graphisch abgetragen um die Wert zu inspizieren und Probleme in der Modellspezifikation zu identifizieren.

```{r}
#| echo: true
#| fig.cap: "Beispiel für DFFITS gegen $\\hat{y}_i$"
#| label: fig-dffits

plot(adl$y_hat, dffits(mod),
     ylim=c(-2,2),
     xlab=expression(hat(y)[i]),
     ylab='DFFIT-Wert')
abline(h=c(-1,1), col='red', lty=2)
```

In @fig-dffits sind die DFFITS-Werte gegen die vorhergesagten Werte $\hat{y}_i$ abgetragen und zusätzlich die Daumenregel $\pm1$ eingezeichnet. Hier ist ein Wert nur gerade so außerhalb des vorgeschlagenen Bereichs. Hier könnte daher sich dieser Datenpunkt noch einmal genauer angeschaut werden, ob bei Ausschluß des Wertes es zu einer qualitativ anderen Interpretation der Daten kommt oder ob bespielsweise Übertragungsfehler für diesen Wert vorliegen oder sonstige Gründe.

## Cooks-Abstand

Ein Maß um den Einfluss von einzelnen Datenpunkten auf die Vorhersagewerte $\hat{y}_i$ über alle Werte abzuschätzen.

$$
D_i = \frac{\sum_{j=1}^N(\hat{y_j} - \hat{y}_{j(i)})}{k\hat{\sigma}^2}
$$

### Daumenregel

$D_i > 1$

### In `R`

`cooks.distance()`

## Cooks-Abstand plot

```{r}
#| fig.cap: "Cook's $D_i$ gegen $\\hat{y}_i$"

plot(adl$y_hat, cooks.distance(mod), ylim=c(-2,2),
     xlab=expression(hat(y)[i]),
     ylab="Cook's D")
abline(h=c(-1,1), col='red', lty=2)
```

## DFBETAS

Ein Maß für die Veränderung der $\beta$-Koeffizienten durch einzelne Datenpunkte $i$. 

$$
(DFBETAS)_{k(i)} = \frac{\hat{\beta}_k - \hat{\beta}_{k(i)}}{\sqrt{\hat{\sigma}^2c_{kk}}}
$$

### Daumenregel

Für kleine bis mittlere Datensätze $\approx 1$ \
Für große Datensätze $\approx 2/\sqrt{N}$

### In `R`

`dfbeta()`^[Es wird eine Matrize mit $k$-Spalten zurückgegeben.]

## DFBETAS

```{r}
#| fig.cap: "DFBETA-Werte für $\\beta_0$ und $\\beta_1$ gegen $\\hat{y}_i$"

adl <- adl %>% dplyr::mutate(`dfbetas[1]` = dfbeta(mod)[,1],
                      `dfbetas[2]` = dfbeta(mod)[,2])
adl %>% dplyr::select(y_hat, `dfbetas[1]`, `dfbetas[2]`) %>%
  tidyr::pivot_longer(-y_hat) %>%
  ggplot(aes(y_hat, value)) +
  geom_point() +
  facet_grid(~name, labeller = label_parsed) + 
  labs(x = expression(hat(y)[i]), y = 'Veränderung')
```

## Zusammenfassung

Table: Übersicht über die verschiedene Einflussmaße zur Bewertung der Modellgüte

| Typ | Veränderung | Daumenregel |
| --- | ---  | ---  |
| $(DFFITS)_i$ | Vorhersagewert i | $2\sqrt{k/N}$ |
| Cook | Durchschnittliche Vorhersagewerte | $>1$ |
| $(DFBETAS)_{k(i)}$ |  Koeffizient i | $2\sqrt{N}$ |
| $e_{Ti}$ | Residuum i  | t-Verteilung(n-k-2)|


## Diagnoseplots in R mit `plot(mod)`


```{r, echo=T, eval=F}
plot(mod)
```
```{r}
par(mfrow=c(2,2))
par(mar=c(1,1,1,1))
plot(mod)
par(mfrow=c(1,1))
```

## Zum Nacharbeiten

@pos_diagnostics\newline
@fox2011 [p.294-302]

### Weiterführendes

@young2019


