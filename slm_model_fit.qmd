# Modellfit 

```{r}
#| echo: false
#| warning: false
#| message: false
source('_common.R')
```

## Residuen

```{r defs_reg_resid}
adl <- readr::read_delim("adcs;adas\n4.05;50.01\n5.03;46.04\n5.03;39.03\n8.04;49.02\n8.04;46.02\n8.04;42.03\n8.06;55.03\n8.06;37.03\n9.02;52.01\n11.03;57.04\n11.03;51.04\n12.01;47.01\n13.01;52.01\n13.01;50.02\n12.99;41.03\n13.01;36.02\n13.01;28\n14.02;46.04\n15;48.03\n15;42.02\n15;36.02\n15.02;34\n16.02;39.03\n17;45.03\n17;24.02\n17.99;43.02\n18.99;40\n20.01;34.01\n20.01;29\n21.02;33.03\n23;43.02\n23;10\n23.98;25.01\n24.99;49.02\n24.99;35.01\n26.01;35\n26.97;45.03\n28;22\n32.99;55.03\n12.01;50.1\n12.01;49.03\n",
                         delim = ';',
                         col_types = 'dd')
mod <- lm(adcs ~ adas, adl)
```


## Was sind noch mal Residuen $\epsilon_i$ bzw. deren Schätzer $\hat{\epsilon}_i = e_i$

$$
y_i = \beta_0 + \beta_1 \times x_i + \epsilon_i
$$

```{r}
#| fig.cap: "Spielzeugbeispiel mit Residuen $\\hat{\\epsilon}_i = e_i = y_i - \\hat{y}_i$"

set.seed(12)
simple <- tibble::tibble(x = 0:3,
                 y = 2 + 0.5 * x + rnorm(4,0,.5))
mod0 <- lm(y ~ x, simple)
simple$y_hat <- predict(mod0)
simple$epsilon <- paste0('hat(epsilon)[',1:4,']')
simple$ys <- paste0('list(x[',1:4,'],y[',1:4,'])')
simple$yshat <- paste('hat(y)[',1:4,']')
p_res <- ggplot(simple, aes(x,y,label = epsilon)) + 
  geom_point(size=3) +
  geom_line(aes(y = y_hat), size=2, color = 'red') +
  geom_point(aes(y = y_hat), size=3, color = 'red') +
  geom_segment(aes(x = x, y = y_hat, xend = x, yend = y),
               arrow = arrow(type='closed', length=unit(0.05, unit='npc')), size=1,
               color = 'green') +  
  geom_text(aes(x = x - 0.1, y=y_hat, label = yshat), parse=T,
            size = 5, check_overlap = T) +
  geom_text(aes(x = x + 0.14, y = (y_hat + y)/2), parse=T, size=5) + 
  lims(x = c(-.3,3.3), y = c(1,3.8)) 
print(p_res)
```

## Annahme: $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$

```{r}
#| fig.cap="Verteilung der Werte für verschiedene x-Werte (rote Punkte) und die resultierende Regressionsgerade mit den Vorhersagewerte $\\hat{y}_i$ (schwarze Punkte)"

set.seed(123)
xx <- seq(-3,3,0.05)
yy <- dnorm(xx)
n <- length(xx) 
n_2 <- 20
df <- tibble::tibble(
  x_0 = rep(1:3, each=n),
  x = x_0 + rep(yy,3),
  y = rep(seq(-1,1,length.out=n), 3) + rep(1:3, each=n),
  g = rep(letters[1:3], each=n)
)
df_2 <- tibble::tibble(x = 1:3, y = 1:3, g = 'a')
df_3 <- tibble::tibble(x = rep(1:3, each=n_2),
                       y = rnorm(3*n_2, mean=x, sd = 0.5), g = 'a')
ggplot(df, aes(x, y, group=g)) + 
  geom_line(data = df_2, aes(x,y), size=1.5) +
  geom_point(data = df_3, aes(x,y), color='red') +
  geom_ribbon(aes(xmin = x_0, xmax = x), fill='red', alpha=0.5) +
  geom_path() +
  geom_point(data = df_2, aes(x,y), size=3) +
  scale_x_continuous(breaks = 1:3) +
  labs(x = 'x-Werte', y = 'y-Werte') 
```



## Übersicht Residuen

Table: Übersicht über verschiedene Arten von Residuen^[$h_i$ = Influenz von Punkt $i$]

| Typ | Berechnung | Ziel |
| --- | --- | --- |
| Einfache Residuen | $e_i = y_i - \hat{y}_i$ | Verteilungsannahme |
| Standardisierte Residuen |  $e_{Si} = \frac{e_i}{\hat{\sigma}\sqrt{1-h_i}}$ | Verteilungsannahme |
| Studentized Residuen |  $e_{Ti} = \frac{e_i}{\hat{\sigma}_{(-i)}\sqrt{1-h_i}}$ | Einfluss  auf Modell |

## Residuen in `R` berechnen mit `residuals()` und Freunden

```{r, echo=T}
residuals(mod)[1:5] # einfache Residuen
rstandard(mod)[1:5] # standardisierte Residuen
rstudent(mod)[1:5] # studentized Residuen
```

```{r}
adl <- adl %>% dplyr::mutate(
  y_hat = predict(mod),
  resid = resid(mod),
  rstudent = rstudent(mod),
  rstandard = rstandard(mod)
)
```

## Residuen in `R` inspizieren

```{r, eval=F, echo=T}
y_hat <- predict(mod)
plot(y_hat, residuals(mod))
plot(y_hat, rstandard(mod))
plot(y_hat, rstudent(mod))
```


## Diagnoseplot - Einfache Residuen $\hat{\epsilon_i} \sim \hat{y_i}$
```{r}
#| fig.cap="Streudiagramm der Residuen $\\hat{\\epsilon_i}$ gegen die Vorhersagewerte $\\hat{y}_i$"

plot(resid ~ y_hat, adl, ylab=expression(e[i]),
     xlab=expression(paste(hat(y)[i], '-ADCS-MCI-ADL score')),
     ylim=c(-20,20)) 
abline(h = 0, lty = 2, col = 'red')
```

## Diagnoseplot - Standardisierte Residuen $\hat{\epsilon}_{Si} \sim \hat{y_i}$

```{r}
#| fig.align='center', fig.cap="Streudiagramm der standardisierten Residuen $\\hat{\\epsilon}_{Si}$ gegen die Vorhersagewerte $\\hat{y}_i$"

plot(rstandard ~ y_hat, adl, ylim=c(-4,4),
     xlab = expression(paste(hat(y)[i], '-ADCS-MCI-ADL score')),
     ylab = expression(e[Si])) 
abline(h = 0, lty = 2, col = 'red')
abline(h = c(-2,-1,1,2), lty=3, col = 'gray')
```

## Diagnoseplot - Studentized Residuen $\hat{\epsilon}_{Ti} \sim \hat{y_i}$
```{r}
#| fig.cap="Streudiagramm der studentized Residuals $\\hat{\\epsilon}_{Ti}$ gegen die Vorhersagewerte $\\hat{y}_i$"

plot(rstudent ~ y_hat, adl, 
     xlab = expression(paste(hat(y)[i], '-ADCS-MCI-ADL score')),
     ylab = expression(e[Ti]),
     ylim=c(-4,4))
abline(h = 0, lty = 2, col = 'red')
```

## Diagnoseplot - Wie sehen Probleme aus?

```{r}
#| fig.cap="Beispielstreudiagramm"

n <- 30
df_res <- tibble(
  x = seq(0,10,length.out=n),
  y = x*cos(seq(0,6*pi,length.out = n)/10) + 3*x + 2 + rnorm(n),
  resid = resid(lm(y~x)),
  y_hat = predict(lm(y~x))
)
plot(resid~y_hat, df_res,
     xlab = expression(paste('Vorhersagewerte ', hat(y)[i])),
     ylab = expression(hat(epsilon)[i]))
abline(h = 0, lty = 2, col = 'red')
```

## Diagnoseplot - Wie sehen Probleme aus?

```{r}
#| fig.cap="Beispielstreudiagramm"

n <- 40
set.seed(125)
df_res_2 <- tibble(
  y_hat = runif(n, 0, 1),
  resid = 3 * y_hat * rnorm(n, 0, 2),
)
plot(resid~y_hat, df_res_2,
     xlab = expression(paste('Vorhersagewerte ', hat(y)[i])),
     ylab = expression(hat(epsilon)[i]))
abline(h = 0, lty = 2, col = 'red')
```

## Wie kann die Verteilung der Residuen überprüft werden?

```{r}
df_qq <- tibble::tibble(y = c(-2, 5, -1.2, 0.1, 7))
df_qq %>% knitr::kable(booktabs=T,
                       caption="Spielzeugbeispieldaten mit $n=5$")
```

```{r, fig.cap="Dichtefunktion der Standardnormalverteilung", fig.height=4}
df_qq_2 <- tibble::tibble(
  x = seq(-3,3,length.out=100),
  y = dnorm(x)
)
ggplot(df_qq_2, aes(x,y)) +
  geom_ribbon(aes(ymin = 0, ymax = y), fill='red', alpha=.5) +
  geom_line() +
  labs(x = 'Werte', y = 'Dichte') 
```

## Konstruktion eines qq-Graphen

```{r}
n <- dim(df_qq)[1]
df_qq_3 <- tibble::tibble(
    x = qnorm(1/(n+1)*(1:n)),
    y = dnorm(x)
  )
ggplot(df_qq_2, aes(x,y)) +
  geom_ribbon(aes(ymin = 0, ymax = y), fill='red', alpha=.5) +
  geom_line() +
  geom_segment(data = df_qq_3, aes(x = x, xend = x, y = 0, yend = y)) +
  scale_x_continuous(breaks = round(df_qq_3$x,2)) +
  labs(x = NULL, y = 'Dichte') +
  theme(axis.text.x = element_text(angle = 45, vjust=1, hjust=1))
```

Table: Sortierte Datenwerte

| kleinster | 2.kleinster | mittlerer | 2.größter | größter |
| --- | --- | --- | --- | --- |
| `r df_qq$y[1]` |`r df_qq$y[3]` |`r df_qq$y[4]` | `r df_qq$y[2]` |`r df_qq$y[5]` |

## Konstruktion eines qq-Graphen

```{r, fig.cap = "Streudiagramm der empirischen Werte gegen die theoretischen Quantilen"}
df_qq_3 %>% 
  add_column(d = sort(df_qq$y)) %>% 
  ggplot(aes(x, d)) + 
  geom_point(size = 2) +
  scale_x_continuous(breaks = round(df_qq_3$x,2)) +
  labs(x = 'Theoretisch', y = 'Empirisch') 
```


## Beispiele für qq-Graphen mit `qqnorm()` und `qqline()`


```{r}
par(mfrow=c(2,2))
pp <- ppoints(50)
pp_norm <- qnorm(pp)
pp_cauchy <- qcauchy(pp)
pp_chisq <- qf(pp, 10, 8)
#pp_chisq <- qchisq(pp, df = 3)
qqplot(pp_norm, pp_norm, xlab='theoretical', ylab='empirical', main='Perfekt')
qqline(pp_norm, col = 'steelblue', lwd=2) 


qqplot(pp_norm, pp_cauchy, xlab='theoretical', ylab='empirical', main='Tails heavy')
qqline(pp_cauchy, col = 'steelblue', lwd=2)


qqplot(pp_cauchy, pp_norm, xlab='theoretical', ylab='empirical', main='Tails light')
qqline(pp_norm, col = 'steelblue', lwd=2)


qqplot(pp_norm, pp_chisq, xlab='theoretical', ylab='empirical', main='Rechtsschief')
qqline(pp_chisq, col = 'steelblue', lwd=2)
par(mfrow=c(1,1))
```



## Diagnoseplot - QQ-Diagramm
\small
```{r}
#| fig.cap: "QQ-Diagramm der Residuen des ADAS-ADCS-Modells"
 
par(mar=c(4,4,1,1))
qqnorm(resid(mod))
```

^[In `R` mit `qqnorm(resid(mod))`]


## `summary()`

\scriptsize
```{r}
summary(mod)
```

## Neue Idee zu Residuen

```{r}
#| fig.cap: "Spielzeugbeispiel mit Residuen $\\hat{\\epsilon}_i = e_i = y_i - \\hat{y}_i$"

print(p_res)
```


## Zum Nacharbeiten

@kutner2005 [p.100-114] \newline
@pos_residuals \newline
@fox2011 [p.285-296]


## Hebelwerte

```{r}
adl <- adl %>% dplyr::mutate(
  y_hat = predict(mod),
  resid = resid(mod),
  rstudent = rstudent(mod),
  rstandard = rstandard(mod)
)
```


```{r}
#| fig.cap: "Streudiagramm der ADCS-MCI-ADL scores gegen ADAS-cos scores"

ggplot(adl, aes(adas,adcs)) +
  geom_point(size=2) +
  labs(x = 'ADAS-cog score', y = 'ADCS-MCI-ADL score') 
```



```{r}
#| fig.cap: "Hebelwerte der jeweiligen $x_i$s"

adl_2 <- adl %>% dplyr::mutate(h = hatvalues(mod))
ggplot(adl_2,
       aes(adas, h)) +
  geom_segment(aes(xend=adas, y=0, yend=h), size=1.3) +
  geom_point(size=4) +
  labs(x = 'ADAS-cog score',
       y = 'Leverage') 
```

```{r}
#| fig.cap: "Hebelwerte der jeweiligen Datenpunkte"

ggplot(adl_2, aes(adas, adcs)) +
  geom_point(aes(size = h)) +
  geom_point(col = 'red', size=.3) +
  geom_vline(xintercept = mean(adl_2$adas), linetype = 'dashed',col='red') +
  labs(x = 'ADAS-cog score',
       y = 'ADCS-MCI-ADL score') +
  scale_size_continuous(name = 'Leverage') 
```


## DFFITS

Mit Hilfe der Hebelwerte lassen sich verschiedene Maße erstellen um den Einfluss von Datenpunkten auf das Modell zu überprüfen. Ein Maß wird als \index{DFFITS} bezeichnet (siehe @eq-dffits)

$$
(DFFITS)_i = \frac{\hat{y}_i - \hat{y}_{i(i)}}{\sqrt{\hat{\sigma}^2h_i}}
$${#eq-dffits}

Im Zähler kommen vin @eq-dffits zweimal vorhergesagte $y$-Werte vor. $\hat{y}_i$ ist dabei der ganz normale Vorhersagewert der uns mittlerweile schon mehrfach begegnet ist. Der zweite Wert $\hat{y}_{i(i)}$ bezeichnet den vorhergesagten Wert aus dem Modell aus dem der Wert $y_i$ weggelassen wurde. D.h, dass Modell ist mit einem Wert weniger gefittet worden. Daher misst die Differenz $\hat{y}_i - \hat{y}_{i(i)}$ den Unterschied in den Vorhersagewerte zwischen zwei Modellen bei denen einmal der Wert $y_i$ zum fitten verwendet wurde und einmal wenn $y_i$ nicht zum fitten verwendet wurde. Umso größer der Unterschied zwischen diesen beiden Werte umso größer ist der Einfluss des Wertes $y_i$ auf den Modellfit. Den Nenner von @eq-dffits lassen wir mal fallen, da es sich dabei nur um einen Normierungswert handelt. Dementsprechend, wird mittels DFFITS für jeden Datenpunkt ein Wert ermittelt und umso größer dieser Wert ist umso größer ist der Einfluss des jeweiligen Datenpunktes auf den Modellfit.

Im idealen Fall sollte alle Datenpunkt ungefähr den gleichen Einfluss haben und einzelne Datenpunkte die einen übermäßig großen Einfluss auf das Modell haben sollten noch einmal genauer inspiziert werden.

::: {.callout-tip}
Als Daumenregel, kann für kleine bis mittlere Datensätze ein DFFITS von $\approx 1$ auf Probleme hindeuten, während bei großen Datensätzen $\approx 2\sqrt{k/N}$ als Orientierungshilfe verwendet werden kann (k := Anzahl der Prediktoren, N := Stichprobengröße).
:::

::: {.callout-warning}
Wenn ein Wert außerhalb der Daumenregel liegt, heißt das nicht, dass er automatisch ausgeschlossen werden muss/soll, sondern lediglich inspiziert werden sollte und das Modell mit und ohne diesen Wert interpretiert werden sollte.
:::

In `R` können die DFFITS werden mittels der `dffits()`-Funktion berechnet werden. Als Parameter erwartet `dffits()` das gefittete `lm()`-Objekt. Ähnlich wie bei den Residuen, werden die DFFITS-Werte gegen die vorhergesagten $y_i$-Werte graphisch abgetragen um die Wert zu inspizieren und Probleme in der Modellspezifikation zu identifizieren.

```{r}
#| echo: true
#| fig.cap: "Beispiel für DFFITS gegen $\\hat{y}_i$"
#| label: fig-dffits

plot(adl$y_hat, dffits(mod),
     ylim=c(-2,2),
     xlab=expression(hat(y)[i]),
     ylab='DFFIT-Wert')
abline(h=c(-1,1), col='red', lty=2)
```

In @fig-dffits sind die DFFITS-Werte gegen die vorhergesagten Werte $\hat{y}_i$ abgetragen und zusätzlich die Daumenregel $\pm1$ eingezeichnet. Hier ist ein Wert nur gerade so außerhalb des vorgeschlagenen Bereichs. Hier könnte daher sich dieser Datenpunkt noch einmal genauer angeschaut werden, ob bei Ausschluß des Wertes es zu einer qualitativ anderen Interpretation der Daten kommt oder ob bespielsweise Übertragungsfehler für diesen Wert vorliegen oder sonstige Gründe.

## Cooks-Abstand

Ein Maß um den Einfluss von einzelnen Datenpunkten auf die Vorhersagewerte $\hat{y}_i$ über alle Werte abzuschätzen.

$$
D_i = \frac{\sum_{j=1}^N(\hat{y_j} - \hat{y}_{j(i)})}{k\hat{\sigma}^2}
$$

### Daumenregel

$D_i > 1$

### In `R`

`cooks.distance()`

## Cooks-Abstand plot

```{r}
#| fig.cap: "Cook's $D_i$ gegen $\\hat{y}_i$"

plot(adl$y_hat, cooks.distance(mod), ylim=c(-2,2),
     xlab=expression(hat(y)[i]),
     ylab="Cook's D")
abline(h=c(-1,1), col='red', lty=2)
```

## DFBETAS

Ein Maß für die Veränderung der $\beta$-Koeffizienten durch einzelne Datenpunkte $i$. 

$$
(DFBETAS)_{k(i)} = \frac{\hat{\beta}_k - \hat{\beta}_{k(i)}}{\sqrt{\hat{\sigma}^2c_{kk}}}
$$

### Daumenregel

Für kleine bis mittlere Datensätze $\approx 1$ \
Für große Datensätze $\approx 2/\sqrt{N}$

### In `R`

`dfbeta()`^[Es wird eine Matrize mit $k$-Spalten zurückgegeben.]

## DFBETAS

```{r}
#| fig.cap: "DFBETA-Werte für $\\beta_0$ und $\\beta_1$ gegen $\\hat{y}_i$"

adl <- adl %>% dplyr::mutate(`dfbetas[1]` = dfbeta(mod)[,1],
                      `dfbetas[2]` = dfbeta(mod)[,2])
adl %>% dplyr::select(y_hat, `dfbetas[1]`, `dfbetas[2]`) %>%
  tidyr::pivot_longer(-y_hat) %>%
  ggplot(aes(y_hat, value)) +
  geom_point() +
  facet_grid(~name, labeller = label_parsed) + 
  labs(x = expression(hat(y)[i]), y = 'Veränderung')
```

## Zusammenfassung

Table: Übersicht über die verschiedene Einflussmaße zur Bewertung der Modellgüte

| Typ | Veränderung | Daumenregel |
| --- | ---  | ---  |
| $(DFFITS)_i$ | Vorhersagewert i | $2\sqrt{k/N}$ |
| Cook | Durchschnittliche Vorhersagewerte | $>1$ |
| $(DFBETAS)_{k(i)}$ |  Koeffizient i | $2\sqrt{N}$ |
| $e_{Ti}$ | Residuum i  | t-Verteilung(n-k-2)|


## Diagnoseplots in R mit `plot(mod)`


```{r, echo=T, eval=F}
plot(mod)
```
```{r}
par(mfrow=c(2,2))
plot(mod)
par(mfrow=c(1,1))
```

## Zum Nacharbeiten

@pos_diagnostics\newline
@fox2011 [p.294-302]

### Weiterführendes

@young2019


